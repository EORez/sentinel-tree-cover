{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU, LeakyReLU\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import itertools\n",
    "from tflearn.layers.conv import global_avg_pool\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.layers import batch_normalization\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_anomolies(idx):\n",
    "    arr = data_x[idx, :, :, :, :]\n",
    "    diffs = []\n",
    "    for i in range(0, 24):\n",
    "        mins, maxs = (np.min(arr[i, :, :, 1]), np.max(arr[i, :, :, 1]))\n",
    "        diff = (maxs - mins)\n",
    "        diffs.append(diff)\n",
    "    print(np.min(diffs)/np.max(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/zoneout.py\n",
    "%run ../src/convgru.py\n",
    "%run ../src/lovasz.py\n",
    "%run ../src/utils.py\n",
    "%run ../src/adabound.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "Finished data loading\n",
      "(672, 14, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/subplot.csv\")\n",
    "df1 = pd.read_csv(\"../data/subplot2.csv\")\n",
    "df2 = pd.read_csv(\"../data/subplot3.csv\")\n",
    "df3 = pd.read_csv(\"../data/subplot4.csv\")\n",
    "\n",
    "df = df.drop('IMAGERY_TITLE', axis = 1).dropna(axis = 0)\n",
    "df1 = df1.drop('IMAGERY_TITLE', axis = 1).dropna(axis = 0)\n",
    "df2 = df2.drop('IMAGERY_TITLE', axis = 1).dropna(axis = 0)\n",
    "df3 = df3.drop('IMAGERY_TITLE', axis = 1).dropna(axis = 0)\n",
    "\n",
    "lens = [len(x) for x in [df, df1, df2, df3]]\n",
    "\n",
    "df = pd.concat([df, df1, df2, df3], ignore_index = True)\n",
    "df = df.dropna(axis = 0)\n",
    "\n",
    "existing = [int(x[:-4]) for x in os.listdir('../data/shifted/') if \".DS\" not in x]\n",
    "\n",
    "df = df[df['PLOT_ID'].isin(existing)]\n",
    "N_SAMPLES = int(df.shape[0]/196)\n",
    "print(N_SAMPLES)\n",
    "\n",
    "plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "\n",
    "def reconstruct_images(plot_id):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    rows = []\n",
    "    lats = reversed(sorted(subs['LAT'].unique()))\n",
    "    for i, val in enumerate(lats):\n",
    "        subs_lat = subs[subs['LAT'] == val]\n",
    "        subs_lat = subs_lat.sort_values('LON', axis = 0)\n",
    "        rows.append(list(subs_lat['TREE']))\n",
    "    return rows\n",
    "\n",
    "data = [reconstruct_images(x) for x in plot_ids]\n",
    "\n",
    "# Initiate empty lists to store the X and Y data in\n",
    "data_x, data_y, lengths = [], [], []\n",
    "\n",
    "# Iterate over each plot\n",
    "pad = True\n",
    "flip = False\n",
    "for i in plot_ids:\n",
    "    # Load the sentinel imagery\n",
    "    x = np.load(\"../data/shifted/\" + str(i) + \".npy\")\n",
    "    x = x[0, :, :, :, :]\n",
    "    # Shape check\n",
    "    x = ndvi(x, image_size = 16)\n",
    "    x = evi(x, image_size = 16)\n",
    "    x = savi(x, image_size = 16)\n",
    "    x = remove_blank_steps(x)\n",
    "    x_grad, y_grad = np.gradient(np.reshape(x[0, :, :, 10], (16, 16)))\n",
    "        #x[:, :, :, 10] = (x[:, :, :, 10] - np.min(x[:, :, :, 10]) / np.max(x[:, :, :, 10])\n",
    "    mag = np.stack([np.reshape(np.sqrt(x_grad**2 + y_grad**2)*10, (16, 16, 1))]*x.shape[0])\n",
    "        #if np.max(mag) > 0:\n",
    "        #    mag = (mag - np.min(mag)) / np.max(mag)\n",
    "    x = np.concatenate([x, mag], axis = -1)\n",
    "    x = x[:, :, :, [x for x in range(0, 15) if x != 10]]\n",
    "    #x = np.clip(x, 0, 1)\n",
    "    print(x.shape[0])\n",
    "    y = reconstruct_images(i)\n",
    "    lengths.append(x.shape[0])\n",
    "    if pad:\n",
    "        if x.shape[0] < 24:\n",
    "            padding = np.zeros((24 - x.shape[0], IMAGE_SIZE, IMAGE_SIZE, 13))\n",
    "            x = np.concatenate((x, padding), axis = 0)\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)\n",
    "    if flip:\n",
    "            # FLIP HORIZONTAL\n",
    "        x1 = np.flip(x, 1)\n",
    "        data_x.append(x1)\n",
    "        data_y.append(np.flip(y, 0))\n",
    "        lengths.append(x.shape[0])\n",
    "\n",
    "            # FLIP BOTH\n",
    "        x2 = np.flip(x, 2)\n",
    "        x2 = np.flip(x2, 1)\n",
    "        data_x.append(x2)\n",
    "        data_y.append(np.flip(y, [0, 1]))\n",
    "        lengths.append(x.shape[0])\n",
    "            # FLIP VERTICAL\n",
    "        x3 = np.flip(x, 2)\n",
    "        data_x.append(x3)\n",
    "        data_y.append(np.flip(y, 1))\n",
    "        lengths.append(x.shape[0])\n",
    "\n",
    "data_x = np.stack(data_x)\n",
    "data_y = np.stack(data_y)\n",
    "data_y = np.reshape(data_y, (N_SAMPLES, 14, 14, 1))\n",
    "lengths = np.stack(lengths)\n",
    "lengths = np.reshape(lengths, (lengths.shape[0], 1))\n",
    "\n",
    "print(\"Finished data loading\")\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509 170\n"
     ]
    }
   ],
   "source": [
    "ZONE_OUT_PROB = 0.1 #(0.05, 0.20, 0.05) --> 4\n",
    "L2_REG = 0.001 #(1-e6, 1-e1, x10) --> 5\n",
    "INITIAL_LR = 2e-5 #(1e-6, 1e-3, x5) --> 10\n",
    "FINAL_LR = 2e-3 # (1e - 5, 1e-2, x5) --> 10\n",
    "LOSS_WEIGHTING = 0.5 #(0.2, 1, 0.2) --> 5\n",
    "SQUEEZE_RATIO = 4 # --> 4, 8, 12, 16 --> 4\n",
    "BN_MOMENTUM = 0.9 # --> 3\n",
    "N_LAYERS = 4 # --> 3\n",
    "REG_TYPE = 'kernel' # kernel # --> 2\n",
    "SQUEEZE = True\n",
    "LAYER_NORM = True \n",
    "BATCH_SIZE = 4 # -->4\n",
    "LOSS_TYPE = 'bce-jaccard' #bce-jaccard, bce-dice, bce-lovasz, focal-jaccard, etc. --> 4\n",
    "N_CONV_PER_LAYER = 1 # --> 2\n",
    "ACTIVATION_TYPE = 'ELU' #RELU, PRELU --> 2\n",
    "MASK_LOSS = False # --> 2\n",
    "PAD_INPUT_TYPE = 'none' # zero, reflect, none # --> 2\n",
    "RENORM_CLIPPING = None # --> 5\n",
    "FRESH_START = False\n",
    "TRAIN_RATIO = 0.75\n",
    "TEST_RATIO = 0.25\n",
    "\n",
    "\n",
    "AUGMENTATION_RATIO = 4\n",
    "IMAGE_SIZE = 16\n",
    "N_SAMPLES = 679\n",
    "RESIZE_OUTPUT = False\n",
    "\n",
    "LABEL_SIZE = 14\n",
    "#if LABEL_SIZE == 16 and not RESIZE_OUTPUT:\n",
    "#    LABEL_SIZE = IMAGE_SIZE\n",
    "    \n",
    "TRAIN_SAMPLES = int((N_SAMPLES * AUGMENTATION_RATIO) * TRAIN_RATIO)\n",
    "TEST_SAMPLES = int((N_SAMPLES * AUGMENTATION_RATIO) - TRAIN_SAMPLES)\n",
    "print(TRAIN_SAMPLES // AUGMENTATION_RATIO, N_SAMPLES - (TRAIN_SAMPLES // AUGMENTATION_RATIO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.contrib.slim import conv2d\n",
    "\n",
    "def cse_block(prevlayer, prefix):\n",
    "    mean = Lambda(lambda xin: K.mean(xin, axis=[1, 2]))(prevlayer)\n",
    "    lin1 = Dense(K.int_shape(prevlayer)[3] // 2, name=prefix + 'cse_lin1', activation='relu')(mean)\n",
    "    lin2 = Dense(K.int_shape(prevlayer)[3], name=prefix + 'cse_lin2', activation='sigmoid')(lin1)\n",
    "    x = Multiply()([prevlayer, lin2])\n",
    "    return x\n",
    "\n",
    "\n",
    "def sse_block(prevlayer, prefix):\n",
    "    # Bug? Should be 1 here?\n",
    "    conv = Conv2D(K.int_shape(prevlayer)[3], (1, 1), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                  activation='sigmoid', strides=(1, 1),\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
    "    return conv\n",
    "\n",
    "\n",
    "def csse_block(x, prefix):\n",
    "    '''\n",
    "    Implementation of Concurrent Spatial and Channel ‘Squeeze & Excitation’ in Fully Convolutional Networks\n",
    "    https://arxiv.org/abs/1803.02579\n",
    "    '''\n",
    "    cse = cse_block(x, prefix)\n",
    "    sse = sse_block(x, prefix)\n",
    "    x = Add(name=prefix + \"_csse_mul\")([cse, sse])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def Batch_Normalization(x, training, scope):\n",
    "    return batch_normalization(inputs=x, \n",
    "                               momentum = BN_MOMENTUM, \n",
    "                               training=training,\n",
    "                               renorm = True,\n",
    "                               reuse=None,\n",
    "                               name = scope)\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "\n",
    "def conv_bn_elu(inp, is_training, kernel_size, scope, filter_count = 16):\n",
    "    if kernel_size == 3:\n",
    "        padded = ReflectionPadding2D((1, 1,))(inp)\n",
    "        padding = 'valid'\n",
    "    else:\n",
    "        padded = inp\n",
    "        padding = 'same'\n",
    "    conv = Conv2D(filters = filter_count, kernel_size = (kernel_size, kernel_size),\n",
    "                      padding = padding, kernel_regularizer=reg)(padded)\n",
    "    elu = ELU()(conv)\n",
    "    bn = Batch_Normalization(elu, training=is_training, scope = scope + \"bn\")\n",
    "    return bn\n",
    "    \n",
    "def fpa(inp, filter_count):\n",
    "    one = conv_bn_elu(inp, is_training, 1, 'forward1', filter_count)\n",
    "    three = conv_bn_elu(inp, is_training, 3, 'down1', filter_count)\n",
    "    #three_f = conv_bn_elu(three, is_training, 3, 'down1_f', filter_count)\n",
    "    two = conv_bn_elu(three, is_training, 2, 'down2', filter_count)\n",
    "    #two_f = conv_bn_elu(two, is_training, 2, 'down2_f', filter_count)\n",
    "    \n",
    "    # top block\n",
    "    pooled = tf.keras.layers.GlobalAveragePooling2D()(inp)\n",
    "    one_top = conv_bn_elu(tf.reshape(pooled, (-1, 1, 1, pooled.shape[-1])), is_training, 1, 'top1', filter_count)\n",
    "    four_top = tf.keras.layers.UpSampling2D((4, 4))(one_top)\n",
    "    \n",
    "    \n",
    "    concat_1 = tf.multiply(one, tf.add(three, two))\n",
    "    concat_2 = tf.add(concat_1, four_top)\n",
    "    print(\"Feature pyramid attention shape {}\".format(concat_2.shape))\n",
    "    return concat_2\n",
    "\n",
    "def upconv2d(X, filters, is_training, scope):\n",
    "    X = tf.image.resize_images(X, [X.shape[1]*2, X.shape[2]*2],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    X = conv_bn_elu(X, is_training, 3, scope, filter_count = filters)\n",
    "    return X\n",
    "\n",
    "    \n",
    "def create_deconv_init(filter_size, num_channels):\n",
    "    bilinear_kernel = np.zeros([filter_size, filter_size], dtype=np.float32)\n",
    "    scale_factor = (filter_size + 1) // 2\n",
    "    if filter_size % 2 == 1:\n",
    "        center = scale_factor - 1\n",
    "    else:\n",
    "        center = scale_factor - 0.5\n",
    "    for x in range(filter_size):\n",
    "        for y in range(filter_size):\n",
    "            bilinear_kernel[x,y] = (1 - abs(x - center) / scale_factor) * \\\n",
    "                                   (1 - abs(y - center) / scale_factor)\n",
    "    weights = np.zeros((filter_size, filter_size, num_channels, num_channels))\n",
    "    for i in range(num_channels):\n",
    "        weights[:, :, i, i] = bilinear_kernel\n",
    "\n",
    "    #assign numpy array to constant_initalizer and pass to get_variable\n",
    "    bilinear_init = tf.constant_initializer(value=weights, dtype=tf.float32)\n",
    "    return bilinear_init\n",
    "\n",
    "def get_deconv2d(inp, filter_count, num_channels, scope, is_training):\n",
    "    bilinear_init = create_deconv_init(4, filter_count)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters = filter_count, kernel_size = (4, 4),\n",
    "                                             strides=(2, 2), padding='same', kernel_initializer = bilinear_init)(inp)\n",
    "    x = ELU()(x)\n",
    "    x = Batch_Normalization(x, training=is_training, scope = scope + \"bn\")\n",
    "    return x\n",
    "    \n",
    "\n",
    "def gau(x_low_level, x_high_level, scope, is_training, filter_count, uptype, size = 4):\n",
    "    \"\"\"\n",
    "    The global attention upsample to replace the up_cat_conv element\n",
    "    \"\"\"\n",
    "    low_feat = conv_bn_elu(x_low_level, is_training, 3, 'gauforward' + scope, filter_count)\n",
    "    high_gap = tf.keras.layers.GlobalAveragePooling2D()(x_high_level)\n",
    "    high_feat = tf.keras.layers.Reshape((1, 1, -1))(high_gap)\n",
    "    high_feat_gate = tf.keras.layers.UpSampling2D((size, size))(high_feat)\n",
    "    gated_low = tf.keras.layers.multiply([low_feat, high_feat_gate])\n",
    "    gated_low = conv_bn_elu(gated_low, is_training, 3, 'gauforward5' + scope, filter_count)\n",
    "    if uptype == \"upconv\":\n",
    "        gated_high = upconv2d(gated_low, filter_count, is_training, scope)\n",
    "    elif uptype == \"transpose\":\n",
    "        bilinear_init = create_deconv_init(4, filter_count)\n",
    "        gated_high = tf.keras.layers.Conv2DTranspose(filters = filter_count, kernel_size = (4, 4),\n",
    "                                             strides=(2, 2), padding='same', kernel_initializer = bilinear_init)(gated_low)\n",
    "        gated_high = ELU()(gated_high)\n",
    "        gated_high = Batch_Normalization(gated_high, training=is_training, scope = scope + \"bn\")\n",
    "    high_clamped = conv_bn_elu(x_high_level, is_training, 3, 'gauforward1' + scope, filter_count)\n",
    "    return tf.keras.layers.add([gated_high, high_clamped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/johnbrandt/Documents/GitHub/collect-earth-automation/src/utils.py:76: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Down block shape: (?, 16, 16, 16)\n",
      "WARNING:tensorflow:From <ipython-input-7-8b77518a60b7>:42: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "Down block shape: (?, 8, 8, 32)\n",
      "Down block shape: (?, 4, 4, 44)\n",
      "Feature pyramid attention shape (?, 4, 4, 44)\n",
      "Up block conv 1 shape: (?, 8, 8, 32)\n",
      "Up block conv 1 shape: (?, 16, 16, 16)\n",
      "(?, 12, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "reg = keras.regularizers.l2(L2_REG)\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 24, IMAGE_SIZE, IMAGE_SIZE, 14))\n",
    "length = tf.placeholder(tf.int32, shape = (None, 1))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 14, 14))#, 1))\n",
    "length2 = tf.reshape(length, (-1,))\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training')\n",
    "\n",
    "weights = tf.ones([14, 14], tf.float32)\n",
    "weights = tf.pad(weights, [[1, 1], [1, 1]], 'constant')\n",
    "weights = tf.reshape(weights, (16*16,)) \n",
    "\n",
    "reg = keras.regularizers.l2(L2_REG)\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 24, IMAGE_SIZE, IMAGE_SIZE, 14))\n",
    "length = tf.placeholder(tf.int32, shape = (None, 1))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 14, 14))#, 1))\n",
    "alpha = tf.placeholder(tf.float32, shape = (None))\n",
    "\n",
    "\n",
    "\n",
    "length2 = tf.reshape(length, (-1,))\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training')\n",
    "power = tf.placeholder_with_default(1.0, (), 'power')\n",
    "\n",
    "if PAD_INPUT_TYPE == 'zero':\n",
    "    inp_pad = tf.pad(inp, [[0, 0], [0, 0], [1, 1], [1, 1], [0, 0]], \"CONSTANT\")\n",
    "\n",
    "if PAD_INPUT_TYPE == 'reflect':\n",
    "    inp_pad = tf.pad(inp, [[0, 0], [0, 0], [1,1], [1,1], [0,0] ], 'REFLECT')\n",
    "    \n",
    "if PAD_INPUT_TYPE == 'none':\n",
    "    inp_pad = inp\n",
    "    \n",
    "FILTER_SIZE = LABEL_SIZE if RESIZE_OUTPUT else IMAGE_SIZE\n",
    "\n",
    "down_16 = 8\n",
    "down_8 = 32\n",
    "down_4f = 44\n",
    "#down_2f = 2\n",
    "#up_4 = 30\n",
    "up_8 = 32\n",
    "up_16 = 16\n",
    "\n",
    "def down_block(inp, length, size, flt, scope, train):\n",
    "    with tf.variable_scope(scope):\n",
    "        cell_fw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'SAME')\n",
    "        cell_bw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'SAME')\n",
    "        cell_fw = ZoneoutWrapper(\n",
    "            cell_fw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        cell_bw = ZoneoutWrapper(\n",
    "            cell_bw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        gru = convGRU(inp, cell_fw, cell_bw, length)\n",
    "        down = TimeDistributed(MaxPool2D(pool_size = (2, 2)))(gru[0])\n",
    "        print(\"Down block shape: {}\".format(gru[1].shape))\n",
    "    return down, gru[1]\n",
    "\n",
    "def down_block_no_gru(inp, flt, scope, train):\n",
    "    with tf.variable_scope(scope):\n",
    "        padded = ReflectionPadding2D((1, 1))(inp)\n",
    "        \n",
    "        # Conv block 1\n",
    "        conv = Conv2D(filters = flt, kernel_size = (3, 3),\n",
    "                      padding = 'valid', kernel_regularizer=reg)(padded)\n",
    "        elu = ELU()(conv)\n",
    "        bn = Batch_Normalization(elu, training=is_training, scope = scope + \"bn\")\n",
    "        x = csse_block(bn, prefix='csse_block_{}'.format(scope))\n",
    "        down = MaxPool2D(pool_size = (2, 2))(x)\n",
    "        print(\"Down block shape: {}\".format(down.shape))\n",
    "    return down\n",
    "\n",
    "\n",
    "def up_block(inp, concat_inp, flt, sq, scope, concat, is_training, uptype, padding = True):\n",
    "    with tf.variable_scope(scope):\n",
    "        \n",
    "        gau_layer = gau(inp, concat_inp, scope, is_training, flt, uptype, inp.shape[-2])\n",
    "        x = csse_block(gau_layer, prefix='csse_block_{}'.format(scope))\n",
    "        print(\"Up block conv 1 shape: {}\".format(x.shape))\n",
    "        return x\n",
    "        \n",
    "        \n",
    "down_1, copy_1 = down_block(inp_pad, length2, [FILTER_SIZE, FILTER_SIZE], down_16, 'down_16', is_training)\n",
    "down_2 = down_block_no_gru(copy_1, down_8, 'down_8', is_training)\n",
    "down_3 = down_block_no_gru(down_2, down_4f, 'down_4', is_training)\n",
    "\n",
    "down_fpa = fpa(down_3, down_4f)\n",
    "up_3 = up_block(down_fpa, down_2, up_8, up_8, 'up_8', True, is_training, \"transpose\", padding =  True, ) # 4 - 8\n",
    "up_2 = up_block(up_3, copy_1, up_16, up_16, 'up_16', True, is_training, \"transpose\", padding = True) # 8 - 16\n",
    "\n",
    "#\n",
    "up_4_16 = get_deconv2d(down_2, down_8, up_8, \"upfinal1\", is_training)\n",
    "up_8_16 = get_deconv2d(up_3, up_8, up_16, 'upfinal2', is_training)        \n",
    "concat_final = tf.concat([up_2, up_4_16, up_8_16], axis = -1)\n",
    "up_2 = Conv2D(filters = 24, kernel_size = (3, 3), padding = 'valid')(concat_final)\n",
    "elu = ELU()(up_2)\n",
    "bn = Batch_Normalization(elu, training=is_training, scope = \"out1bn\")\n",
    "#x = csse_block(elu, prefix='csse_block_{}'.format(\"out1\"))\n",
    "\n",
    "x = Conv2D(filters = 24, kernel_size = (3, 3), padding = 'valid')(bn)\n",
    "\n",
    "#up_2 = Conv2D(filters = 20, kernel_size = (3, 3), padding = 'valid', kernel_regularizer=reg)(x)\n",
    "#elu = ELU()(up_2)\n",
    "\n",
    "#B = tf.Variable([-np.log(0.99/0.01)]) \n",
    "init = tf.constant_initializer([-np.log(0.98/0.02)])\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1), \n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid',\n",
    "            #bias_initializer = init,\n",
    "            )(x)\n",
    "print(fm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight = np.full((len(data_x), 9), 1/9)\n",
    "weight = np.zeros((len(data_x), 9))\n",
    "for i in range(weight.shape[0]):\n",
    "    weight[i, 0] = 1.\n",
    "    #weight[i, np.random.randint(0, 9)] = 1.\n",
    "#weight = np.load(\"weights.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alignment(true, pred):\n",
    "    wt = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        clipped_tensor = [true[i, 1:13, 1:13],\n",
    "                         true[i, 0:12, 1:13],\n",
    "                         true[i, 2:14, 1:13],\n",
    "                         true[i, 1:13, 0:12],\n",
    "                         true[i, 1:13, 2:14],\n",
    "                         true[i, 2:14, 0:12],\n",
    "                         true[i, 0:12, 0:12],\n",
    "                         true[i, 2:14, 2:14],\n",
    "                         true[i, 0:12, 2:14]]\n",
    "        \n",
    "        pred_i = pred[i, :, :, :]\n",
    "        \n",
    "        clipped_ces = tf.stack([binary_crossentropy(tf.reshape(x, (12, 12, 1)), pred_i) for x in clipped_tensor])\n",
    "        clipped_ces = tf.reduce_mean(clipped_ces, axis = [1,2])\n",
    "\n",
    "        clipped_ces = tf.reshape(clipped_ces, (-1, 9))\n",
    "        clipped_ces = clipped_ces# - tf.reduce_mean(clipped_ces)\n",
    "        wt.append(clipped_ces)\n",
    "    print(\"WT CONCAT\", tf.squeeze(tf.stack(wt), axis = 1).shape)\n",
    "    return tf.squeeze(tf.stack(wt, axis =1))\n",
    "\n",
    "def loss_fn(true, pred, weights):\n",
    "    print(weights)\n",
    "    ce = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        weights_i = weights[i, :]\n",
    "        clipped_tensor = [true[i, 1:13, 1:13],\n",
    "                         true[i, 0:12, 1:13],\n",
    "                         true[i, 2:14, 1:13],\n",
    "                         true[i, 1:13, 0:12],\n",
    "                         true[i, 1:13, 2:14],\n",
    "                         true[i, 2:14, 0:12],\n",
    "                         true[i, 0:12, 0:12],\n",
    "                         true[i, 2:14, 2:14],\n",
    "                         true[i, 0:12, 2:14]]\n",
    "    \n",
    "        clipped_ces = [binary_crossentropy(tf.reshape(x, (-1, 12, 12, 1)), tf.reshape(pred[i, :, :], (1, 12, 12, 1))) for x in clipped_tensor]\n",
    "        clipped_ces = tf.stack(clipped_ces)\n",
    "        clipped_ces = tf.reshape(clipped_ces, (1, 9, 12, 12))\n",
    "        #weights_i = tf.stack([weights_i] * 12*12)\n",
    "        loss = clipped_ces * tf.reshape(weights_i, (1, 9, 1, 1))\n",
    "        loss = tf.reduce_sum(loss, axis = 1)\n",
    "        ce.append(loss)\n",
    "    ce = tf.reshape(tf.stack(ce), (BATCH_SIZE, 12, 12, 1))\n",
    "    print(\"LOSS SHAPE\", ce.shape)\n",
    "    return ce\n",
    "\n",
    "def loss_fn(true, pred, weights):\n",
    "    losses = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        weights_i = weights[i, :]\n",
    "        true_i = tf.reshape(true[i], (1, 14, 14, 1))\n",
    "        pred_i = tf.reshape(pred[i], (1, 12, 12, 1))\n",
    "        true_p = true_i\n",
    "        #loss_o = binary_crossentropy(true_p, pred)\n",
    "        # extract out the candidate shifts\n",
    "        true_m = true_i[:, 1:13, 1:13]\n",
    "        true_l = true_i[:, 0:12, 1:13]\n",
    "        true_r = true_i[:, 2:14, 1:13]\n",
    "        true_u = true_i[:, 1:13, 0:12]\n",
    "        true_d = true_i[:, 1:13, 2:14]\n",
    "        true_dr = true_i[:, 2:14, 0:12]\n",
    "        true_dl = true_i[:, 0:12, 0:12]\n",
    "        true_ur = true_i[:, 2:14, 2:14]\n",
    "        true_ul = true_i[:, 0:12, 2:14]\n",
    "        true_shifts = [true_m, true_l, true_r, true_u, true_d, true_dr, true_dl, true_ur, true_ul]\n",
    "        bce_shifts = tf.stack([binary_crossentropy(x, pred_i) for x in true_shifts])\n",
    "        loss = tf.reshape(bce_shifts, (1, 9, 12, 12)) * tf.reshape(weights_i, (1, 9, 1, 1))\n",
    "        loss = tf.reduce_sum(loss, axis = 1)\n",
    "        losses.append(loss)\n",
    "    loss = tf.reshape(tf.stack(losses), (BATCH_SIZE, 12, 12, 1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING A 0 EXPECTATION STEP\n",
      "WT CONCAT (16, 9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1ffc9a64274f1c8bbf99613a5000c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0: LOSS 0.4754714071750641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0208c1b34240459dcfb566131c2efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1: LOSS 0.33973047137260437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c81185910624bcea8eda261d5c70986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2: LOSS 0.31933146715164185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675b1f3ed6ac408ea0beda525f4ce5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3: LOSS 0.31053510308265686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2757e379034bbd82587d2a20932c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 4: LOSS 0.3049091398715973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd6833c120f4888b6cf5242def37a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 5: LOSS 0.3030838072299957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdf9b3b7a1c4de6b6ea0dbb735c03c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 6: LOSS 0.29818961024284363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094f7aa9f43145e3bccaec88adb4f737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 7: LOSS 0.2962213158607483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe27bdf3281480f90add3bab663b873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 8: LOSS 0.29499387741088867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3577bd036dff4f0f9d4da652e7454ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 9: LOSS 0.30258238315582275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d70f6d261b49c38eae15c96367d2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 10: LOSS 0.3153976500034332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e99dd46eb444ea98cc517dac0da3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 11: LOSS 0.3092428147792816\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63846e7cd7f84b6fb46d0da39cdae0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 12: LOSS 0.3023674488067627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fb36717fa246c69cc5465cfe3f1bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 13: LOSS 0.2917332649230957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4aab09000a4d1582207d8e5d041220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 14: LOSS 0.2978825867176056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3676aba9d732435e9c34c682901cd853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 15: LOSS 0.29510483145713806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31442a1e49a542808dcc9a2f8d05b3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 16: LOSS 0.32266396284103394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60b8109e7994f66b5dfa6d97f373c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 17: LOSS 0.2939566969871521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11458ab34e7429ea6aaf5be73555137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 18: LOSS 0.2968900799751282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1a92ae025440a9b87178e59213c343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 19: LOSS 0.2847312092781067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d58d43380d403ab500f8e2579f11d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 20: LOSS 0.2825743556022644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c768538454a944aba5d8dabb8966bbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 21: LOSS 0.2796999216079712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b602751ae0417e898d9dd729714429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 22: LOSS 0.2818887233734131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33b0ce993ad473ebf0070d980fef4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 23: LOSS 0.28522926568984985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607d32c41d5b46e6b40fc81d1985fb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 24: LOSS 0.29130157828330994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cdcd31134941eab04f62c9edfa7c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 25: LOSS 0.28895220160484314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13f8e8e084349e696c0c8b9edc061ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ac8043cc26de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                          \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                                          \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                                                          \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                                                          })\n\u001b[1;32m     39\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "BATCH_SIZE = 16\n",
    "weights = tf.placeholder(tf.float32, shape=(None, 9))#, 1))\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "ids = [x for x in range(0, len(data_x))]\n",
    "\n",
    "for total_step in range(0, 40):\n",
    "    MODE = 'EXPECTATION'\n",
    "    print(\"RUNNING A {} {} STEP\".format(total_step, MODE))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(5e-6)\n",
    "    weight_upd = calc_alignment(labels, fm)\n",
    "    #loss = bce_shift(labels, fm, 1.5)\n",
    "    loss = loss_fn(labels, fm, weights)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizer = optimizer.minimize(loss)  \n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    orig = np.argmax(weight, axis = 1)\n",
    "    # Run training loop\n",
    "    for i in range(50):\n",
    "        if i == 49:\n",
    "            mode = 'MAXIMIZATION'\n",
    "            print(\"RUNNING A {} {} STEP\".format(total_step, MODE))\n",
    "        losses = []\n",
    "\n",
    "        for k in tnrange(int(len(ids) // BATCH_SIZE)):\n",
    "            batch_ids = ids[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "            batch_y = data_y[batch_ids, :, :].reshape(BATCH_SIZE, 14, 14)\n",
    "            op, tr, weight_update = sess.run([optimizer, loss, weight_upd],\n",
    "                                              feed_dict={inp: data_x[batch_ids, :, :, :],\n",
    "                                                         length: lengths[batch_ids],\n",
    "                                                         labels: data_y[batch_ids, :, :].reshape(BATCH_SIZE, 14, 14),\n",
    "                                                         is_training: True,\n",
    "                                                         weights: weight[batch_ids],\n",
    "                                                         })\n",
    "            losses.append(tr)\n",
    "            if k == 50:\n",
    "                print(weight_update)\n",
    "            if i == 49:\n",
    "                #weight_update = np.clip(weight_update, -0.25, 0.25)\n",
    "                #weight[batch_ids] -= weight_update\n",
    "                weight[batch_ids] = weight_update\n",
    "                #weight[batch_ids] = np.clip(weight[batch_ids], 0, 1)\n",
    "                div = np.sum(weight[batch_ids], axis = 1)\n",
    "                #print(div)\n",
    "                #div = np.clip(div, 1, 10)\n",
    "                weight[batch_ids] = weight[batch_ids] / div[:, np.newaxis]\n",
    "        print(\"EPOCH {}: LOSS {}\".format(i, np.mean(losses)))\n",
    "    print('MEANS', np.mean(weight, axis = 0))\n",
    "    print('MAXS', np.max(weight, axis = 0))\n",
    "    diffs = [x for x, y in zip(np.argmax(weight, axis = 1), orig) if x != y]\n",
    "    print(\"{} samples changed\".format(len(diffs)))\n",
    "    if MODE == 'maximization':\n",
    "        weight = weight_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.391956  , 0.38259098, 0.56062657, 0.5666053 , 0.396108  ,\n",
       "        0.6800679 , 0.55190575, 0.5459731 , 0.39960805],\n",
       "       [0.13759007, 0.13825016, 0.15357661, 0.12642668, 0.16201049,\n",
       "        0.13980034, 0.12431583, 0.18228412, 0.16347381],\n",
       "       [0.20386437, 0.2092442 , 0.1850372 , 0.25341082, 0.19302367,\n",
       "        0.25554606, 0.2335638 , 0.15467122, 0.20803918],\n",
       "       [0.27741238, 0.32971025, 0.35237202, 0.32516357, 0.35574353,\n",
       "        0.42343676, 0.33833238, 0.3858012 , 0.41808817],\n",
       "       [0.02224661, 0.02224661, 0.02224661, 0.02224661, 0.02224661,\n",
       "        0.02224661, 0.02224661, 0.02224661, 0.02224661],\n",
       "       [0.24029917, 0.2541683 , 0.24658097, 0.20816694, 0.2548617 ,\n",
       "        0.22118714, 0.22390962, 0.26841748, 0.2621986 ],\n",
       "       [0.04230591, 0.04230591, 0.04230591, 0.04230591, 0.04230591,\n",
       "        0.04230591, 0.04230591, 0.04230591, 0.04230591],\n",
       "       [0.26691633, 0.24148029, 0.41353002, 0.39917672, 0.33417284,\n",
       "        0.48394358, 0.39206564, 0.45665348, 0.34024423],\n",
       "       [0.07043777, 0.0682187 , 0.07720488, 0.07310894, 0.05309064,\n",
       "        0.07662836, 0.07254573, 0.0566968 , 0.05250598],\n",
       "       [0.43961477, 0.47608027, 0.49301684, 0.46578917, 0.48852146,\n",
       "        0.4874363 , 0.4903958 , 0.5418182 , 0.5244875 ],\n",
       "       [0.22942072, 0.24152058, 0.27279398, 0.28246272, 0.26511684,\n",
       "        0.2924404 , 0.3248214 , 0.31668368, 0.23950201],\n",
       "       [0.05259157, 0.05259157, 0.05259157, 0.05259157, 0.05259157,\n",
       "        0.05259157, 0.05259157, 0.05259157, 0.05259157],\n",
       "       [0.3414446 , 0.36171976, 0.33518553, 0.43044263, 0.38855308,\n",
       "        0.39518547, 0.4829928 , 0.3896692 , 0.3775117 ],\n",
       "       [0.04132785, 0.04132785, 0.04132785, 0.04132785, 0.04132785,\n",
       "        0.04132785, 0.04132785, 0.04132785, 0.06192145],\n",
       "       [0.46732202, 0.60037684, 0.5062644 , 0.6520062 , 0.42737886,\n",
       "        0.7069746 , 0.72496974, 0.42592335, 0.5877191 ],\n",
       "       [0.09505443, 0.08970592, 0.11838273, 0.10736598, 0.0994143 ,\n",
       "        0.11757917, 0.1061364 , 0.12226033, 0.0970965 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"weights.npy\", weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight2 = np.load(\"weights.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = [x for x, y in zip(np.argmax(weight, axis = 1), np.argmax(weight2, axis = 1)) if x != y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADuCAYAAAC+l5vEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XuUXGd95vvn6ZsulmTLF2wjy0ZgkcHmZvAFQrBzjA3KYWFlBgiKw8RewxwNAZ9hHRaTMYssZzBhDpeEDGvhBVbAEMJhFHBCliYIhDE4XIIZyeDYSMaxLIzUwka+yJZ17e6q3/mjqkXRSOqqfvem37f0/bBq0bVr/6p2Wd1Pv/2r/b7bESEAAAAAAADkbWC2DwAAAAAAAADTo4kDAAAAAABQAJo4AAAAAAAABaCJAwAAAAAAUACaOAAAAAAAAAWgiQMAAAAAAFAAmjgAAAAAAAAFoIkDAAAAAABQAJo4QEFsr7B9v+2ttq8/xn6vtx22L+zY9u523f22X/PrOWIAAAAAQFWGetl5wfxlUdeBdCOU9vJLF5yWVP/6+cuT6q88MJ5UP2+wkVT/9eF5SfWSNCyn1Sd+B31+YntS/elDC9MOQNI/bv9yT/8Rxh/b1vW7Hj712Ud9btuDkm6SdKWkUUkbba+LiC1T9lso6R2Svt+x7TxJqySdL+mZkr5u+7kRkfZNNUvOP/2SpO+kM4ZPTHr9ZUOLkuoX9Ra9v+InzX1J9acOzE2qf/WhkaR6SXrevKeS6p/an/YefjSUVr9x6GBS/Ysaaa8vSf/3js/NShbhF/7NMy5KyqKL5i1Nev0djT1J9RcPpY2Lrh1Me/1mpH+bfaq5IKn+3sbupPonJtLy+Knx/Un1+yfSsujgxFhSvSTt3ruVLJplQyNLkrJocCDtc/0Bp9WfPDft53hkIG1c9dRY2s+hJO0bT/tZjEj7I2lkcDip/rR5aWPbSxeem1QvSS9opv2t+q7tx8+4iDNxgLo1G93fju1iSVsjYltEjElaK2nlEfZ7n6QPSur8bbJS0tqIOBQRP5G0tf18AI4X1WURAMwcWQQgBwVnEU0coG7R7P52bEsk7ei4P9redpjtl0haGhFf7rUWQJ+rLosAYObIIgA5KDiL0s49AzC9Zvc/+LZXS1rdsWlNRKzpsnZA0kckXdvL4QE4TvSQRQBQG7IIQA4KziKaOEDNoofubbthc7SmzU5JnQsonNXeNmmhpOdLusO2JJ0haZ3tq7qoBdDneskiAKgLWQQgByVnEU0coG6NiaqeaaOk5baXqdWAWSXp6skHI+IpSadO3rd9h6R3RcQm2wckfd72R9Ra2Hi5pP9d1YEBKEB1WQQAM0cWAchBwVlEEweoW0WLYUXEhO3rJG2QNCjplojYbPtGSZsiYt0xajfb/oKkLZImJL291CtTAZihDBfmA3AcIosA5KDgLKKJA9StwlP1ImK9pPVTtt1wlH1/e8r990t6f2UHA6AsBZ82DKCPkEUAclBwFtHEAepW8KJZAPoIWQQgB2QRgBwUnEU0cYCalbxoFoD+QRYByAFZBCAHJWcRTRygbgV3eQH0EbIIQA7IIgA5KDiLaOIAdWuMz/YRAABZBCAPZBGAHBScRTRxgLoVfKoegD5CFgHIAVkEIAcFZxFNHKBuBZ+qB6CPkEUAckAWAchBwVlEEweoW8FdXgB9hCwCkAOyCEAOCs4imjhA3Qru8gLoI2QRgByQRQByUHAW0cQBahbNchfNAtA/yCIAOSCLAOSg5CzqqYnzrIWnJ73Yzw/uTqofkJPqL5l/dlL9dWc9nFR/4h++OKl+4IUvS6p/kaTxz/110nM0940l1Y9c8fKk+t/90M+T6nf8fH5S/YwU3OXN1aKhtH/H3Y39SfXzBoaT6h9spv0cPT6xN6n+px5Mqr9L0ulDC5Oe41UTpyTVPz8mkupPakRS/cjQQFL9zwdnIRfIosqdOXJSUv3WibRx0dMTB5Lqfza4KKn+u4cWJ9VL0vzEb8ttQ08m1R9qpmVJRFqWnDA0J6l+0dC8pHpJ+tmBx5OfoydkUeXOP/mcpPo94/uS6ucMjiTVnzv3GUn1C502LpOkRxpp/w3+dd/PkuoPJV4paeFwWhb81oLnJNU3I/T7B9O+D85f8khSfc8KzqJf25k4qQ0cpEtt4GCGCp5vCRxJagMHs4QsQmZSGzhI92tv4EhkEbKT2sCBkhs4s6LgLGI6FVC3ZmO2jwAAyCIAeag4i2yvkPRRSYOSPhkRH5jy+Dsl/UdJE5IelfQfIuKn7ccaku5t77o9Iq6q9OAA5KvgcVHa+eAAphfN7m8AUBeyCEAOKswi24OSbpL0O5LOk/T7ts+bstsPJV0YES+UdKukD3U8diAiXty+0cABjicVj4tsr7B9v+2ttq8/xn6vtx22L+zY9u523f22XzPda3EmDlC3gudbAugjZBGAHFSbRRdL2hoR2yTJ9lpJKyVtmdwhIr7Zsf+dkt5c5QEAKFSFWdTRUL5S0qikjbbXRcSWKfstlPQOSd/v2HaepFWSzpf0TElft/3ciDjqqUKciQPUrTHR/Q0A6kIWAchBD1lke7XtTR231VOebYmkHR33R9vbjuYtkr7ScX9u+3nvtP27Fb1DACWodlx0uKEcEWOSJhvKU71P0gclHezYtlLS2og4FBE/kbS1/XxHxZk4QN349BtADsgiADnoIYsiYo2kNVW8rO03S7pQ0mUdm8+JiJ22ny3pG7bvjYgHq3g9AJnrIYvaDeTOJvKadj5NOlJD+ZIpz/ESSUsj4su2/8uU2jun1B6rGU0TB6jbMc6EA4BfG7IIQA4qzqKdkpZ23D+rve2X2L5C0nskXRYRh35xLLGz/f/bbN8h6QJJNHGA40AvWZTaULY9IOkjkq6d6XN0ookD1I1PvwHkgCwCkINqs2ijpOW2l6nVvFkl6erOHWxfIOlmSSsiYlfH9sWS9kfEIdunSnqFfnnRYwD9rNosmq6hvFDS8yXdYVuSzpC0zvZVXdT+Cpo4QN240guAHJBFAHJQYRZFxITt6yRtUOsS47dExGbbN0raFBHrJH1Y0gJJX2z/8TR5KfHnSbrZdlOtdUI/MHURUgB9rNpx0TEbyhHxlKRTJ++3z/x7V0Rssn1A0udtf0SthY2XS/rfx3oxmjhA3fj0G0AOKs4i2yskfVStP5w+GREfmPL4WyW9XVJD0l5Jqyf/QLL9brUWGG1I+s8RsaHSgwOQr4qzKCLWS1o/ZdsNHV9fcZS6f5b0gkoPBkA5KsyiLhvKR6vdbPsLal1Vb0LS2491ZSqJJg5QP670AiAHFWZRl5fS/HxEfKK9/1VqzQVfMZNLaQLoI4yLAOSg4iyarqE8ZftvT7n/fknv7/a1aOIAdWMKA4AcVJtFhy+lKUm2Jy+lebiJExF7OvY/QVK0vz58KU1JP7E9eSnN71V5gAAyxbgIQA4KziKaOEDdmE4FIAfVZtG0l9KUJNtvl/ROSSOSLu+o7elSmgD6COMiADkoOIsGZvsAgL7XbHZ/A4C69JBFtlfb3tRxWz2Tl4yImyLiOZL+q6Q/qfYNASgS4yIAOSg4izgTB6hbwafqAegjPWRRRKyRtOYYu/R6Ocy1kj4+w1oA/YRxEYAcFJxFNHGAurGAH4AcVJtFx7yUpiTZXh4RD7TvvlbS5Nfr1OOlNAH0EcZFAHJQcBbRxAHqluEpeACOQ7/+S2leZ/sKSeOSdku6pl3b86U0AfQRxkUAclBwFtHEAepW8Kl6APpIxVk03aU0I+Idx6jt6VKaAPoI4yIAOSg4i3pq4uwZ3zfjFxqr4HSl4YHBpPpHmweS6g/tTet5NX/8YFr9T7Yn1XskvWc38qpLk+qHXvl7SfVnnv3cpPoTP/LJpPoZKbjLm6v794wm1Z84Mj+pft7ASFL9sNPWlB9MXJN+wcCcpPp9zbGkekl6YPhQUv0Zg2nv4UVznkqq3z92YlL96ROzcAovWVS5scQTiPY1DqbVT6SNax5u7E2q3zU4L6n+8aH0E7Du3Zu2nNJYczz5GFKMJ46PhwfTxnZVjM97RhZV7t+PPDup/qvDjybV70nMsvHEP6afVtrP8aLEcZEknTCUlocHJtLGVsMDw0n1C52WJbsTs0iSmg0nP0dvL1huFnEmDlC3ggMCQB8hiwDkgCwCkIOCs4gmDlC3iNk+AgAgiwDkgSwCkIOCs4gmDlC32Zg2AQBTkUUAckAWAchBwVlEEweoW8GLZgHoI2QRgByQRQByUHAW0cQB6lbwfEsAfYQsApADsghADgrOIpo4QN0Knm8JoI+QRQByQBYByEHBWZR2nVoA02s2u79Nw/YK2/fb3mr7+iM8/lbb99q+2/Z3bJ/X3n6l7bvaj91l+/Ia3imAnFWYRQAwY2QRgBwUnEWciQPUraIffNuDkm6SdKWkUUkbba+LiC0du30+Ij7R3v8qSR+RtELSY5JeFxE/s/18SRskLankwACUIcNBCIDjEFkEIAcFZxFNHKBm0WhU9VQXS9oaEdskyfZaSSslHW7iRMSejv1PkBTt7T/s2L5Z0jzbcyLiUFUHByBvFWYRAMwYWQQgByVnEU0coG49dHltr5a0umPTmohY0/56iaQdHY+NSrrkCM/xdknvlDQi6UjTpl4v6Qc0cIDjTMGfOAHoI2QRgBwUnEU0cYC69XD5unbDZs20Ox77OW6SdJPtqyX9iaRrJh+zfb6kD0p6dcprAChQwZfSBNBHyCIAOSg4i2jiAHVrVrby+U5JSzvun9XedjRrJX188o7tsyR9SdIfRsSDVR0UgEJUl0UAMHNkEYAcFJxFNHGAulV3qt5GScttL1OrebNK0tWdO9heHhEPtO++VtID7e0nSfqypOsj4rtVHRCAghR82jCAPkIWAchBwVlEEweoW0WLZkXEhO3r1Lqy1KCkWyJis+0bJW2KiHWSrrN9haRxSbv1i6lU10k6V9INtm9ob3t1ROyq5OAA5K/gBfwA9BGyCEAOCs4imjhA3Srs8kbEeknrp2y7oePrdxyl7s8k/VllBwKgPAV/4gSgj5BFAHJQcBbRxAHqVvB8SwB9hCwCkAOyCEAOCs4imjhA3Qpe+RxAHyGLAOSALAKQg4KzqKcmzqHG+Ixf6NDEzGsnjXkiqf7H+x9Oqv+zgeck1Z/9d3OS6geTqqUTm/MSn0H6d3duSKpfuOGOpPoDDxxIqn/soQVJ9ZJ0cq8FBXd5czVgJ9UvHJ6fVH/mUNr30XjiL415w8NJ9S8eXJxU/6jGkuolaUyz+4tzyYv3JNUvHdmbVD/8giVJ9TNCFlXuxMG5SfWHmmljo5OG07Jo/sBIUv3SibQsftlE+vfk9+ek5dnPDj6eVN9U2nuYSPx9Nt5IGxvPCrKocm/7k9OS6m9/X9rPwUSkrS3yRGNfUv3TE2l/HyxOzFJJOjFxbDl3MG1s95yRU5Pqf+dg2l+a4xWM67745OlJ9X/ca0HBWcSZOEDNouD5lgD6B1kEIAdkEYAclJxFNHGAuhW88jmAPkIWAcgBWQQgBwVnEU0coG4Fn6oHoI+QRQByQBYByEHBWTQw2wcA9L1ms/sbANSFLAKQg4qzyPYK2/fb3mr7+iM8/k7bW2zfY/t22+d0PHaN7Qfat2sqfJcAclfwuIgzcYC6FdzlBdBHyCIAOagwi2wPSrpJ0pWSRiVttL0uIrZ07PZDSRdGxH7bfyTpQ5LeZPtkSX8q6UJJIemudu3uyg4QQL4KHhdxJg5Qt2h2fwOAupBFAHJQbRZdLGlrRGyLiDFJayWt/KWXi/hmROxv371T0lntr18j6baIeKLduLlN0opK3iOA/BU8LqKJA9StGd3fAKAuZBGAHFSbRUsk7ei4P9redjRvkfSVGdYC6CcVj4u6mNr5Vtv32r7b9ndsn9fefqXtu9qP3WX78ulei+lUQM1iotyVzwH0D7IIQA56ySLbqyWt7ti0JiLWzOR1bb9ZralTl82kHkB/qXJc1OXUzs9HxCfa+18l6SNqnf33mKTXRcTPbD9f0gZN01CmiQPUjU+1AeSALAKQgx6yqN2wOVbTZqekpR33z2pv+yW2r5D0HkmXRcShjtrfnlJ7R9cHB6Bs1Y6LDk/tlCTbk1M7DzdxImJPx/4nqLUWlyLihx3bN0uaZ3tOR1b9Cpo4QN0ynEcJ4DhEFgHIQbVZtFHSctvL1GrKrJJ0decOti+QdLOkFRGxq+OhDZL+u+3F7fuvlvTuKg8OQMZ6yKIuzgo80vTMS47wPG+X9E5JI5KONG3q9ZJ+cKwGjkQTB6gfn34DyAFZBCAHFWZRREzYvk6thsygpFsiYrPtGyVtioh1kj4saYGkL9qWpO0RcVVEPGH7fWo1giTpxoh4orKDA5C3as8K7PZ5bpJ0k+2rJf2JpGsmH7N9vqQPqtVQPiaaOEDNgj+cAGSALAKQg6qzKCLWS1o/ZdsNHV9fcYzaWyTdUukBAShCxVnU1dTODmslfXzyju2zJH1J0h9GxIPTvRhNHKBuLCYKIAdkEYAckEUAclBtFnUztXN5RDzQvvtaSQ+0t58k6cuSro+I73bzYlxiHKgbl/UFkINf/6U032l7i+17bN9u+5wpjy+yPWr7YxW9QwAlYFwEIAcVZlFETEianNp5n6QvTE7tbF+JSpKus73Z9t1qrYszOZXqOknnSrqhffnxu20/41ivx5k4QN0YhADIQYVZ1OWlNH8o6cKI2G/7jyR9SNKbOh5/n6RvVXZQAMrAuAhADn79UzvfcZS6P5P0Z728FmfiADWLiK5vAFCXirPo8KU0I2JMrbndK6e83jcjYn/77p1qzQ+XJNl+qaTTJX2tkjcHoBiMiwDkoOQs4kwcoG584gQgBz1kUVWX0uzwFklfaT/3gKS/kPRmSUddcBRAn2JcBCAHBWdRT02cpmb3jTZ7uJb7kewZ25dU/70DO6bf6Ri2jyxOqj9/8KSk+tHBtP9+kvSiback1S95ek9S/UO7Tk+qH6jge/i8XgsKDohcnTr3xKT6c0bSvo/HE7Po5xN7k+qfbhxIql80d05S/VwPJtVL0r4YT6r/6fDcpPpH75ufVH/GRWNJ9SNvvTGpfkZm4VKakmT7zZIulHRZe9PbJK2PiNH25X6L9ch42u+0A43E76OB2f0sbldiFPzmiU8mH8Nv7U8bF9zWTPs3GFDa9/DexsGk+gONQ0n1s/IzyLiocj45bVxzMCaS6p+eSBuXpNp1IC1LHht4KvkYls4/Lan+xMG0cckzBtLGRbsH0wL9m8Pp3wPfePqB6Xc6hj/utaDgLOJMHKBmMZHePAOAVBVnUVeX0rR9haT3SLosIib/2ny5pFfafpukBZJGbO+NiF9ZHBlA/2FcBCAHJWcRTRygbuXmA4B+Um0WdXMpzQsk3SxpRUTsmtweEX/Qsc+1ai1+TAMHOF4wLgKQg4KziCYOULMo+FQ9AP2jyiyKiAnbk5fSHJR0y+SlNCVtioh1kj6s1pk2X2xP2dgeEVcd9UkBHBcYFwHIQclZRBMHqFvBAQGgj/z6L6U57aLFEfEZSZ+p9MAA5I1xEYAcFJxFNHGAuhV8qh6APkIWAcgBWQQgBwVnEU0coGYln6oHoH+QRQByQBYByEHJWUQTB6hZTJQbEAD6B1kEIAdkEYAclJxFNHGAuhV8qh6APkIWAcgBWQQgBwVnEU0coGZRcEAA6B9kEYAckEUAclByFtHEAepWcEAA6CNkEYAckEUAclBwFtHEAWpWcpcXQP8giwDkgCwCkIOSs4gmDlCzmJjtIwAAsghAHsgiADkoOYto4gA1K7nLC6B/kEUAckAWAchByVlEEweoWckBAaB/kEUAckAWAchByVk0MNsHAPS9cPe3adheYft+21ttX3+Ex99pe4vte2zfbvucKY8vsj1q+2MVvkMAJagwiwBgxsgiADkoOIs4EweoWVVdXtuDkm6SdKWkUUkbba+LiC0du/1Q0oURsd/2H0n6kKQ3dTz+PknfquaIAJSk5E+cAPQPsghADkrOIpo4QM2iWVn39mJJWyNimyTZXitppaTDTZyI+GbH/ndKevPkHdsvlXS6pK9KurCqgwJQhgqzCABmjCwCkIOSs6inJs7ikYUzfqGxxuwv/3za3JOS6i+dd870Ox3DSyZGkupPOZjWLvz63PR2408G5ybVH9iV1jf8yrykcp3dTO9b/naP+zcb3QeE7dWSVndsWhMRa9pfL5G0o+OxUUmXHOPp3iLpK+3nHZD0F2o1da7o+oAy9YzhRUn1vzEw8yyTpDGl/SztHRhLqn90bE9S/Y8P7UqqXzqyOKlekp6b+G/wvIORVL9wycGkeg0NJpU3tt2V9vqShk99dk/795JF6M4zh09Mqt8ZTybV22n/pqlz6u/y3qT6E/eclngE0qNDaT/LJwzMSapfMJA2tjsz8Xto68G0PJ+TePwzQRbVYDjt33HxYNoAe9/wgqT6iWgk1T+mp5Lqx5tpry9JB5vjSfWpY9tUBxJ/LB9tJo6rJD12IG1826uSs4gzcYCa9XKqXrths2baHadh+81qnW1zWXvT2yStj4jR1EE/gDKVfNowgP5BFgHIQclZRBMHqFmFp+rtlLS04/5Z7W2/xPYVkt4j6bKIONTe/HJJr7T9NkkLJI3Y3hsRv7I4MoD+VPJpwwD6B1kEIAclZxFNHKBmkTbro9NGScttL1OrebNK0tWdO9i+QNLNklZExOFzrCPiDzr2uVatxY9p4ADHkQqzCABmjCwCkIOSs4gmDlCzqrq8ETFh+zpJGyQNSrolIjbbvlHSpohYJ+nDap1p88X2tKntEXFVJQcAoGglf+IEoH+QRQByUHIW0cQBalblolkRsV7S+inbbuj4etpFiyPiM5I+U9lBAShCyQv4AegfZBGAHJScRTRxgJqV3OUF0D/IIgA5IIsA5KDkLKKJA9QsotyAANA/yCIAOSCLAOSg5CwamO0DAPpdNLu/AUBdyCIAOag6i2yvsH2/7a22f+WiDbYvtf0D2xO23zDlsYbtu9u3ddW8QwAlKHlcxJk4QM2aBXd5AfQPsghADqrMItuDkm6SdKWkUUkbba+LiC0du22XdK2kdx3hKQ5ExIsrOyAAxSh5XEQTB6hZyafqAegfZBGAHFScRRdL2hoR2yTJ9lpJKyUdbuJExEPtxzL8PB3AbCl5XMR0KqBmzYa7vgFAXcgiADnoJYtsr7a9qeO2esrTLZG0o+P+aHtbt+a2n/dO27+b/OYAFKPqcVEXUzvfaXuL7Xts3277nCmPL7I9avtj070WZ+IANSt55XMA/YMsApCDXrIoItZIWlPf0eiciNhp+9mSvmH73oh4sMbXA5CJKsdFXU7t/KGkCyNiv+0/kvQhSW/qePx9kr7VzetxJg5Qs2a46xsA1IUsApCDirNop6SlHffPam/rSkTsbP//Nkl3SLqg+3cCoGQVZ9HhqZ0RMSZpcmrnYRHxzYjY3757p1p5JUmy/VJJp0v6WjcvRhMHqFmEu74BQF3IIgA5qDiLNkpabnuZ7RFJqyR1dZUp24ttz2l/faqkV6hjLR0A/a2XLKphaudbJH1FkmwPSPoLHXnx9SNiOhVQs4jZPgIAIIsA5KHKLIqICdvXSdogaVDSLRGx2faNkjZFxDrbF0n6kqTFkl5n+70Rcb6k50m6ub3g8YCkD0yZ+gCgj/WSRVVO7bT9ZkkXSrqsveltktZHxKjd3QdpNHGAmjE1AUAOyCIAOag6iyJivaT1U7bd0PH1RnVMW+jY/s+SXlDpwQAoRsVZ1NXUTttXSHqPpMsi4lB788slvdL22yQtkDRie29E/MriyJNo4gA1a7KYKIAMkEUAckAWAchBxVl0eGqnWs2bVZKu7tzB9gWSbpa0IiJ2TW6PiD/o2OdatRY/PmoDR+qxidOIZi+7/5IBzX5gL51zclL9e5/z86T6Rx5clFT/94Np9T8afzypXpJ2Ds5Lqj8wMJFU//T4oel3OobfGOjlqpPV4NPv6g06bTmv548PJtWH0upPGj4tqX7+/JGk+qcaB5LqT2otIZDkVQfSfi5+69VpeTz8ihcm1Y/90z1J9Y+/4+NJ9ZK05Htv7Gl/sqh6zxhI+534rLkLkurnJi5t+MLELBxInBZzdjPtd7okPTKYlkcLhk9Nql/eGE6q35f4Y/nE8P7pdzqGx8efTjuAGSCLqnf/f/5OUn3qIqmnDM5Pqj8jsX6smfb3xc8P7k6ql9L+TpakiWgk1ae9urQg8QnOG0r7O1WSvj2Q9jupV1VmUTdTOyV9WK0zbb7Ynja1PSKumsnrcSYOUDMWCQWQg6qzyPYKSR9Va7DyyYj4wJTHL5X0PyS9UNKqiLi147EPSXqtWn873CbpHRGs2gMcDxgXAchB1VnUxdTOK7p4js9I+sx0+9HEAWrGJ04AclBlFtkelHSTpCvVugLDRtvrpiwKul3StZpytQXbv6nWVWAmT4f6jlqL+91R2QECyBbjIgA5KDmLaOIANeOjZQA5qDiLLpa0NSK2SZLttZJWquPyvBHxUPuxqSdph6S5kkYkWdKwpLT5cQCKwbgIQA5KziKaOEDNGs3UmcYAkK6XLLK9WtLqjk1r2pfXnLRE0o6O+6OSLunmuSPie7a/KelhtZo4H4uI+7o+OABFY1wEIAclZxFNHKBmqQuNAUAVesmidsNmzbQ7zoDtcyU9T7+45O9ttl8ZEd+u4/UA5IVxEYAclJxFNHGAmkUGV2YDgIqzaKekpR33z2pv68a/lXRnROyVJNtfkfRySTRxgOMA4yIAOSg5i8o9hwgoRDO6vwFAXSrOoo2SltteZntE0ipJ67o8lO2SLrM9ZHtYrUWNmU4FHCcYFwHIQclZRBMHqFlT7voGAHWpMosiYkLSdZI2qNWA+UJEbLZ9o+2rJMn2RbZHJb1R0s22N7fLb5X0oKR7Jf2LpH+JiP9V/TsGkCPGRQByUHIWMZ0KqFnJp+oB6B9VZ1FErJe0fsq2Gzq+3qhfrHvTuU9D0n+q9GAAFINxEYAclJxFNHGAmjUKDggA/YMsApADsghADkrOIpo4QM1KXvkcQP8giwDkgCwCkIOSs4gmDlCzkgMCQP8giwDkgCwCkIOSs4gmDlCzkudlQaE2AAAWqElEQVRbAugfZBGAHJBFAHJQchbRxAFq1iw3HwD0EbIIQA7IIgA5KDmLaOIANcvxsnQAjj9kEYAckEUAclByFtHEAWrWmO0DAACRRQDyQBYByEHJWUQTB6hZ0+V2eQH0D7IIQA7IIgA5KDmLemrijAzMvOcz3kzvdTUibQ3pR8efTqrf+KOzk+q/My/tG+W7E48k1T/dOJhUL0mLBucm1c9xWt+wORBJ9Vee+GhS/UykHTGOZNHAnKT6544fSKp/wZvGkuobP9+bVH/HN89Mql83N+3n+EBMJNVL0jPn7E+qH3rOM5LqB15wcVL9yFN7kuq3f++xpHpJWtLj/mRR9c6OtCy64FDav8rpA2m/15/3qqeS6kded1lS/dDlb06ql6QXv/utSfXNveNp9QfTxqaHHh1Iqt81enpS/Tcbh5LqZ4Isqt5fejip/scHdibV/5u5ab+T/+tI2rhsQ/PcpPpbhx5OqpekQ4ljo9Sx7XwNJtU/bzDt7+QzDqSNLSVp7cj85OfoRclZxJk4QM1KvnwdgP5BFgHIAVkEIAclZxFNHKBmJa98DqB/kEUAckAWAchByVlEEweoWaPglc8B9A+yCEAOyCIAOSg5i9Im4gKYVtPd36Zje4Xt+21vtX39ER6/1PYPbE/YfsOUx862/TXb99neYvtZVb1HAPmrMosAYKbIIgA5KDmLOBMHqFlV8y1tD0q6SdKVkkYlbbS9LiK2dOy2XdK1kt51hKf4rKT3R8RtthdUeGgACsAPPIAckEUAclByFtHEAWpW4crnF0vaGhHbJMn2WkkrJR1u4kTEQ+3HfimXbJ8naSgibmvvl3Z5JADFKfkqDAD6B1kEIAclZxFNHKBmFZ6Ct0TSjo77o5Iu6bL2uZKetP33kpZJ+rqk6yOiUdnRAchajqcDAzj+kEUAclByFrEmDlCzZg8326ttb+q4ra7oMIYkvVKtaVYXSXq2WtOuABwneskiAKgLWQQgByVnEWfiADVr9NDljYg1ktYc5eGdkpZ23D+rva0bo5Lu7piK9Q+SXibpU90fHYCS9ZJFAFAXsghADkrOIpo4QM0q7N5ulLTc9jK1mjerJF3dQ+1Jtk+LiEclXS5pU3WHBiB3OX6SBOD4QxYByEHJWcR0KqBmVZ2qFxETkq6TtEHSfZK+EBGbbd9o+ypJsn2R7VFJb5R0s+3N7dqGWlOpbrd9ryRL+qtK3yiArJV82jCA/lF1FtleYft+21ttX3+Exy+1/QPbE7bfMOWxa2w/0L5dk/C2ABSm5HERZ+IANaty5fOIWC9p/ZRtN3R8vVGtaVZHqr1N0gsrPBwABSn5KgwA+keVWWR7UNJNkq5Ua+r4RtvrImJLx27b1VoH8F1Tak+W9KeSLmwf1l3t2t0VHiKATJU8LqKJA9Ss5JXPAfQPsghADirOooslbe1Y82+tpJWSDjdxIuKh9mNTP1B/jaTbIuKJ9uO3SVoh6X9WeoQAslTyuIgmDlCzHE/BA3D8IYsA5KCXLGpfpbPzSp1r2heBmLRE0o6O+6OSLuny6Y9Uu6SHwwNQsJLHRTRxgJo1ZvsAAEBkEYA89JJF01y1EwBmrORxEQsbAzVruvsbANSFLAKQg4qzaKekpR33z2pvq7sWQOGqHhclLrJ+tu2v2b7P9hbbzzrWa9HEAWpW8srnAPoHWQQgBxVn0UZJy20vsz0iaZWkdV0eygZJr7a92PZiSa9ubwNwHKgyizoWWf8dSedJ+n3b503ZbXKR9c8f4Sk+K+nDEfE8tdb62nWs1+tpOtXcgeFedq/cRGMiqf5nBx5Pqv/C4jOS6sci7aStEwZGkuoXDc5NqpekS704qX7Pr6wp15ufazyp/ozfS/tvOBMlr3yeq5MH5iTVL5w7llTv4bSZqNu+syip/u/mHEyqv3PfT5Pq5w2m/xx9au7ZSfUv/avBpPolH/9fSfXbRtK+B75Twe/Tz/W4P1lUvU3xZFL9+NwTk+pHlXba1L+97fSk+tdcsT+pfuLuryXVS9LezWnjgh8/eFpS/cHEz0N3Jv4+OTCU9vvsYDPtv99MVHzVzgnb16nVfBmUdEtEbLZ9o6RNEbHO9kWSviRpsaTX2X5vRJwfEU/Yfp9ajSBJunFykePS3Df2WFJ9I9LG58OJPwfP/D/S/kb6D3PSsnj4S2cm1UvSjsG0/4aNxJ+MwcTfB9vHT0iqP2fOvqR6SVqo+cnP0YuKx0UzXmS93ewZal9JWBGxd7oXY00coGZN/nQCkAGyCEAOqs6iiFgvaf2UbTd0fL1RralSR6q9RdItlR4QgCL0kkU1L7L+XElP2v57ScskfV3S9RFHPwOEJg5Qs5IXzQLQP8giADkgiwDkIKNF1ockvVLSBWpNufpbtaZdfepoBayJA9SMdSgA5IAsApADsghADirOopSF0kcl3R0R2yJiQtI/SHrJsQo4EweoGVd6AZADsghADsgiADmoOIsOL7KuVvNmlaSre6g9yfZpEfGopMslbTpWAWfiADVrKrq+AUBdyCIAOSCLAOSgyixqn0Ezucj6fZK+MLnIuu2rJMn2RbZHJb1R0s22N7drG5LeJel22/dKsqS/OtbrcSYOUDOGIAByUHUW2V4h6aNqXRHmkxHxgSmPXyrpf0h6oaRVEXFre/uLJX1c0iK1pqS/PyL+tuLDA5ApxkUAclB1FiUusn6bWuOlrtDEAWrGnG4AOagyi2wPSrpJ0pVqzeXeaHtdRGzp2G27WgvzvWtK+X5JfxgRD9h+pqS7bG+ISLxeN4AiMC4CkIOSs4gmDlCzBp85AchAxVl0saStEbFNkmyvlbRS0uEmTkQ81H7sl8ZJEfGvHV//zPYuSadJookDHAcYFwHIQclZRBMHqFnJXV4A/aOXLLK9WtLqjk1r2pfXnLRE0o6O+6OSLun1mGxfLGlE0oO91gIoE+MiADkoOYto4gA1Y2E+ADnoJYvaDZs10+6YwPaZkv5G0jURUfJYCkAPGBcByEHJWUQTB6hZufEAoJ9UnEU7JS3tuH9We1tXbC+S9GVJ74mIO6s9NAA5Y1wEIAclZxFNHKBmfLwMIAcVZ9FGScttL1OrebNK0tXdFNoekfQlSZ+dvGIVgOMH4yIAOSg5i2jiADUredEsAP2jyiyKiAnb10naoNYlxm+JiM22b5S0KSLW2b5IrWbNYkmvs/3eiDhf0u9JulTSKbavbT/ltRFxd2UHCCBbjIsA5KDkLKKJA9Ss5PmWAPpH1VkUEeslrZ+y7YaOrzeqNc1qat3nJH2u0oMBUAzGRQByUHIW0cQBalZuPADoJ2QRgByQRQByUHIW0cQBalZylxdA/yCLAOSALAKQg5KziCYOULOSF80C0D/IIgA5IIsA5KDkLOqpifOugWUzfqH/vnBixrWTfvr0rqT6OYPDSfUvbs5Lqn/RobGk+h/MWZBUv3Mg/d9gTuJ3+5CcVD/a3JtU/6e3nJRUL0l/fsP0+3SKgru8uXqseSip/r0eSKp/7edPSKq/ZzjtZ/FHB3ck1e8Z25dUP2duWpZK0hORloe3DaXVnzCc9hnGw82nk+rvfvqnSfUzQRZVb18z7fvwX532s/jIRNrvxEeGz0yqf/Kvvp9U/8DWB5PqJenTc09Oqt8+/GRS/cmDaWPDg9FIqh89uDupfs942vfgTJBF1Zs/kPZ7eeHInKT6C5T2N8rw//mbSfVDr3hDUv3/dYM09okeB/hT7Pnqw0n1P922OKl+q+Yn1S9KHJctPT8tSyXpN+87O/k5elFyFnEmDlCzklc+B9A/yCIAOSCLkJvUBg7KVHIW0cQBalbyqXoA+gdZBCAHZBGAHJScRTRxgJo1o9wuL4D+QRYByAFZBCAHJWcRTRygZuXGA4B+QhYByAFZBCAHJWcRTRygZiVfvg5A/yCLAOSALAKQg5KziCYOULOSVz4H0D/IIgA5IIsA5KDkLKKJA9RsouCAANA/yCIAOSCLAOSg5CyiiQPUrOQuL4D+QRYByAFZBCAHJWcRTRygZiVfvg5A/yCLAOSALAKQg5KziCYOULMo+PJ1APoHWQQgB2QRgByUnEU0cYCalbzyOYD+QRYByAFZBCAHJWfRwGwfANDvGoqub9OxvcL2/ba32r7+CI/Psf237ce/b/tZ7e3Dtv/a9r2277P97srfKICsVZlFADBTZBGAHJScRZyJA9Ssqi6v7UFJN0m6UtKopI2210XElo7d3iJpd0Sca3uVpA9KepOkN0qaExEvsD1f0hbb/zMiHqrk4ABkr+RPnAD0D7IIQA5KziKaOEDNKpxvebGkrRGxTZJsr5W0UlJnE2elpP/W/vpWSR+zbUkh6QTbQ5LmSRqTtKeqAwOQv5LnfgPoH2QRgByUnEVMpwJq1uzhZnu17U0dt9UdT7VE0o6O+6PtbTrSPhExIekpSaeo1dDZJ+lhSdsl/XlEPFHl+wSQt16yCADqUnUWJUw1f5btA7bvbt8+kfzmABSj5HERZ+IANYseTtWLiDWS1tRwGBdLakh6pqTFkr5t++uTZ/UA6H+9ZBEA1KXKLEqcai5JD0bEiys7IADFKHlcxJk4QM2aiq5v09gpaWnH/bPa2464T3vq1ImSHpd0taSvRsR4ROyS9F1JF1bw9gAUosIsAoAZqziLDk81j4gxSZNTzTutlPTX7a9vlfSq9lRzAMexksdFNHGAmjWi2fVtGhslLbe9zPaIpFWS1k3ZZ52ka9pfv0HSN6I14XO7pMslyfYJkl4m6ccVvUUABagwiwBgxnrJommmmUtpU80laZntH9r+J9uvrOHtAshUyeOinqZTXf7sqR/6d++BHefOuHbSJ8f3JdUPDczu7LFNc0eS6m9vPp5Uf2hiPKlekh4amJdUv9hzkuo37xtNqr/jwJbpd5rGn/e4f1Wn6kXEhO3rJG2QNCjplojYbPtGSZsiYp2kT0n6G9tbJT2hVqNHap1q/GnbmyVZ0qcj4p5KDmwW3LZrdg/94VPS8mxZnJRUf8bwoqT6uYNpWXT58JlJ9ZK0tJH2GcI/endS/Y6JtHW9D8VEUv1sLKZX8mnDuTp3KO1n+fcOpP0c7BxamFT/+pVpS6ON/TRtYLtwZCypXpIORdp/w0biagfP9vyk+qfdSKr/waGfJNU/eShtbD0TmUwzl1rrBJ4dEY/bfqmkf7B9fkQUd+GHR8efTqo/Z84p0+90DHuc9nPU+Oc7k+rjX9M+l9z/Tzum32kaOx9anFT/9yNpfyP9qJmW5ycMDyfV/8Z9U3unvXtgYlfyc/Si5HERa+IANWtW+MdaRKyXtH7Kths6vj6o1uXEp9btPdJ2AMePKrMIAGaq4izqZar5aOdU8/aZyockKSLusv2gpOdK2lTlAQLIU9XjItsrJH1UrQ/bPxkRH5jy+BxJn5X0UrWWu3hTRDxke1jSJyW9RK3+zGcj4v891msxnQqoWfRwA4C6kEUAclBxFs14qrnt09oLI8v2syUtl8QFH4DjRJVZ1LHI+u9IOk/S79s+b8puhxdZl/SXai2yLrU+aJ8TES9Qq8Hznyavonc0nIkD1CzHxbAAHH/IIgA5qDKLEqeaXyrpRtvjal1F+K0RkTYnBUAxKh4XHV5kXZJsTy6y3rmWx0pJ/6399a2SPtZeZD0kndA+U3CepDFJx5zWSRMHqBl/OAHIAVkEIAdVZ1HCVPO/k/R3lR4MgGL0kkXtRdU7F1Zf016za9KRFlm/ZMrT/NIi67YnF1m/Va0Gz8OS5kv6f6ZrKNPEAWqW44rmAI4/ZBGAHJBFAHLQSxbVvMj6xZIakp4pabGkb9v++uRZPUdCEweoWckrnwPoH2QRgByQRQByUHEWzXiRdUlXS/pqRIxL2mX7u5Iu1DHW6GJhY6BmEdH1DQDqQhYByAFZBCAHFWfRjBdZl7Rd0uWSZPsESS+T9ONjvRhn4gA1Yx0KADkgiwDkgCwCkIOMFlm/SdKnbW+WZEmfjoh7jvV6NHGAmvFJEoAckEUAckAWAchB1VmUsMj63iNtPxamUwE1a6jZ9Q0A6lJ1FtleYft+21ttX3+Ex+fY/tv249+3/ayOx15o+3u2N9u+1/bcyt4ogKwxLgKQg5KziDNxgJo1+cQJQAaqzCLbg2qd/nulWpfR3Gh7XURs6djtLZJ2R8S5tldJ+qCkN7UX8/ucpH8fEf9i+xRJ45UdHICsMS4CkIOSs4gzcYCaRQ//A4C6VJxFF0vaGhHbImJM0lpJK6fss1LSX7e/vlXSq2xb0qsl3RMR/yJJEfF4RDQqeZMAsse4CEAOSs4izsQBalZylxdA/+gli2yvlrS6Y9OaiFjTcX+JpB0d90clXTLlaQ7v017w7ylJp0h6rqSwvUHSaZLWRsSHuj44AEVjXAQgByVnEU0coGY5dm8BHH96yaJ2w2bNtDvOzJCk35J0kaT9km63fVdE3F7T6wHICOMiADkoOYto4gA1K7nLC6B/VJxFOyUt7bh/VnvbkfYZba+Dc6Kkx9U6a+dbEfGYJNleL+klkmjiAMcBxkUAclByFtHEAWrWiPxWNAdw/Kk4izZKWm57mVrNmlWSrp6yzzpJ10j6nqQ3SPpGRExOo/pj2/MljUm6TNJfVnlwAPLFuAhADkrOIpo4QM1KPlUPQP+oMovaa9xcJ2mDpEFJt0TEZts3StoUEeskfUrS39jeKukJtRo9iojdtj+iViMoJK2PiC9XdnAAssa4CEAOSs6inpo439965oxfaHTuoRnXTjo4MZZU/3TzQFL9/zf806T6vY2DSfW7Dz2dVD93aCSpXpLG556aVP9IY29S/VNj+5PqxxsTSfUzEQV3eXM10Uy7kM2AnVQ/qLT6ZuIvjeWDi5Lq5w6elFT/X17xSFK9JA0sGE6q95dPS6r//nBaHi+PuUn13x46Ial+JqrOoohYL2n9lG03dHx9UNIbj1L7ObUuM1603ZE2tjnotO+De4bTfqd96x/nJ9XvbKRl2RON3Un1kjS6/7Gk+kONtKvb/2Rk16y+/u6DaeOqRvPXP0ZhXFS98cRx0cNjTyXV/yDxT4zPfP7kpPqDTvsbcaMXJ9VL0mjsSaq//4ktSfVjiX/jzB+ek1S/dW7av6EkbXlye/Jz9KLkLOJMHKBmqX+wA0AVyCIAOSCLAOSg5CyiiQPULApeNAtA/yCLAOSALAKQg5KziCYOULOSu7wA+gdZBCAHZBGAHJScRTRxgJrNxnxzAJiKLAKQA7IIQA5KziKaOEDNSl75HED/IIsA5IAsApCDkrOIJg5Qs5LnWwLoH2QRgByQRQByUHIW0cQBalbyfEsA/YMsApADsghADkrOIpo4QM1K7vIC6B9kEYAckEUAclByFtHEAWpW8qJZAPoHWQQgB2QRgByUnEU0cYCalXyqHoD+QRYByAFZBCAHJWcRTRygZiWfqgegf5BFAHJAFgHIQclZRBMHqFmz4IAA0D/IIgA5IIsA5KDkLKKJA9QsCj5VD0D/IIsA5IAsApCDkrOIJg5Qs5K7vAD6B1kEIAdkEYAclJxFNHGAmjWj3JXPAfQPsghADsgiADkoOYto4gA1K3nRLAD9gywCkAOyCEAOSs4imjhAzUoOCAD9gywCkAOyCEAOSs4il3zwAAAAAAAAx4uB2T4AAAAAAAAATI8mDgAAAAAAQAFo4gAAAAAAABSAJg4AAAAAAEABaOIAAAAAAAAUgCYOAAAAAABAAWjiAAAAAAAAFIAmDgAAAAAAQAFo4gAAAAAAABSAJg4AAAAAAEAB/n+Kyf5R6fJP/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO @jombrandt \n",
    "#TODO @jombrandt -- remove augmentation of val set\n",
    "import random \n",
    "\n",
    "def multiplot(matrices):\n",
    "    '''Plot multiple heatmaps with subplots'''\n",
    "    fig, axs = plt.subplots(ncols=4)\n",
    "    fig.set_size_inches(20, 4)\n",
    "    for i,matrix in enumerate(matrices):\n",
    "        sns.heatmap(data = matrix, ax = axs[i], )\n",
    "        axs[i].set_xlabel(\"\")\n",
    "        axs[i].set_ylabel(\"\")\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_xticks([])\n",
    "    plt.show()\n",
    "    \n",
    "test_losses = []\n",
    "matrix_ids = random.sample(ids, 4)\n",
    "#matrix_ids = [988, 900, 2055, 444]\n",
    "# 63\"\"\n",
    "preds = []\n",
    "trues = []\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    y = sess.run([fm], feed_dict={inp: data_x[idx].reshape(1, 24, IMAGE_SIZE, IMAGE_SIZE, 14),\n",
    "                                  length: lengths[idx].reshape(1, 1),\n",
    "                                  is_training: False,\n",
    "                                  labels: data_y[idx].reshape(1, 14, 14)\n",
    "                                  })\n",
    "    y = np.array(y).reshape(12, 12)\n",
    "    if LABEL_SIZE == 16:\n",
    "        y = y[1:15, 1:15]\n",
    "    #y[np.where(y < 0.05)] = 0\n",
    "    preds.append(y)\n",
    "    true = data_y[idx].reshape(14, 14)\n",
    "\n",
    "    trues.append(true)\n",
    "    \n",
    "multiplot(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot(trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10038101, 0.        , 0.25865188, 0.        , 0.21697257,\n",
       "        0.17307693, 0.        , 0.25091761, 0.        ],\n",
       "       [0.07872518, 0.22697157, 0.        , 0.27978949, 0.        ,\n",
       "        0.1220213 , 0.28531937, 0.        , 0.0071731 ],\n",
       "       [0.09773434, 0.00424431, 0.17724928, 0.        , 0.26959614,\n",
       "        0.        , 0.        , 0.30172839, 0.14944754],\n",
       "       [0.47200323, 0.04005432, 0.06583271, 0.04901004, 0.18373267,\n",
       "        0.        , 0.        , 0.18936704, 0.        ],\n",
       "       [0.16465229, 0.01314757, 0.        , 0.        , 0.38835179,\n",
       "        0.        , 0.        , 0.29093397, 0.14291438],\n",
       "       [0.16666667, 0.        , 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667, 0.        , 0.16666667, 0.        ],\n",
       "       [0.03969682, 0.        , 0.31974922, 0.        , 0.08307043,\n",
       "        0.21656611, 0.        , 0.34091742, 0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight[68:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-toolkit",
   "language": "python",
   "name": "policy-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
