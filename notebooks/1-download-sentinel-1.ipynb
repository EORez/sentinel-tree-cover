{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants, DataSource, CustomUrlParam\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage.transform import resize\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import splu\n",
    "\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "        key = (yaml.safe_load(stream))\n",
    "        API_KEY = key['key'] \n",
    "        \n",
    "%run ../src/slope.py\n",
    "%run ../src/utils-bilinear.py\n",
    "%run ../src/dsen2/utils/DSen2Net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ('2018-12-15', '2020-01-15')\n",
    "EPSG = CRS.WGS84\n",
    "IMSIZE = 48\n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions (to be moved to a utils file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic Model Created.\n"
     ]
    }
   ],
   "source": [
    "def calculate_proximal_steps_index(date, satisfactory):\n",
    "    arg_before = None\n",
    "    arg_after = None\n",
    "    if date > 0:\n",
    "        idx_before = satisfactory - date\n",
    "        arg_before = idx_before[np.where(idx_before < 0, idx_before, -np.inf).argmax()]\n",
    "    if date < np.max(satisfactory):\n",
    "        idx_after = satisfactory - date\n",
    "        arg_after = idx_after[np.where(idx_after > 0, idx_after, np.inf).argmin()]\n",
    "    if not arg_after and not arg_before:\n",
    "        arg_after = date\n",
    "        arg_before = date\n",
    "    if not arg_after:\n",
    "        arg_after = arg_before\n",
    "    if not arg_before:\n",
    "        arg_before = arg_after\n",
    "    return arg_before, arg_after\n",
    "\n",
    "def speyediff(N, d, format = 'csc'):\n",
    "    shape = (N-d, N)\n",
    "    diagonals = np.zeros(2*d + 1)\n",
    "    diagonals[d] = 1.\n",
    "    for i in range(d):\n",
    "        diff = diagonals[:-1] - diagonals[1:]\n",
    "        diagonals = diff\n",
    "    offsets = np.arange(d+1)\n",
    "    spmat = sparse.diags(diagonals, offsets, shape, format = format)\n",
    "    return spmat\n",
    "\n",
    "def smooth(y, lmbd, d = 2):\n",
    "    m = len(y)\n",
    "    E = sparse.eye(m, format = 'csc')\n",
    "    D = speyediff(m, d, format = 'csc')\n",
    "    coefmat = E + lmbd * D.conj().T.dot(D)\n",
    "    z = splu(coefmat).solve(y)\n",
    "    return z\n",
    "\n",
    "MDL_PATH = \"../src/dsen2/models/\"\n",
    "\n",
    "input_shape = ((4, None, None), (6, None, None))\n",
    "model = s2model(input_shape, num_layers=6, feature_size=128)\n",
    "predict_file = MDL_PATH+'s2_032_lr_1e-04.hdf5'\n",
    "print('Symbolic Model Created.')\n",
    "\n",
    "model.load_weights(predict_file)\n",
    "\n",
    "def DSen2(d10, d20):\n",
    "    test = [d10, d20]\n",
    "    input_shape = ((4, None, None), (6, None, None))\n",
    "    prediction = _predict(test, input_shape, deep=False)\n",
    "    #prediction *= 5\n",
    "    return prediction\n",
    "\n",
    "def _predict(test, input_shape, model = model, deep=False, run_60=False):\n",
    "    \n",
    "    print(\"Predicting using file: {}\".format(predict_file))\n",
    "    prediction = model.predict(test, verbose=1)\n",
    "    return prediction\n",
    "\n",
    "c_arr = np.array([[1, 1, 1, 1, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 2, 3, 2, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 1, 1, 1, 1,],])\n",
    "                  \n",
    "c_arr = c_arr / 3\n",
    "o_arr = 1 - c_arr\n",
    "c_arr = np.tile(c_arr[:, :, np.newaxis], (1, 1, 11))\n",
    "o_arr = np.tile(o_arr[:, :, np.newaxis], (1, 1, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCoords(xy, src='', targ=''):\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])\n",
    "\n",
    "def calc_bbox(plot_id, df):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    # TOP, LEFT, BOTTOM, RIGHT\n",
    "    # (min x, min y), (max x, max y)\n",
    "    return [(min(subs['LON']), min(subs['LAT'])),\n",
    "            (max(subs['LON']), max(subs['LAT']))]\n",
    "\n",
    "def bounding_box(points, expansion = 160):\n",
    "    # LONG, LAT FOR SOME REASON\n",
    "    bl = list(points[0])\n",
    "    tr = list(points[1])\n",
    "    \n",
    "    if 78 <= tr[0] <= 84:\n",
    "        epsg = 32644 if tr[1] > 0 else 32744\n",
    "    if 72 <= tr[0] <= 78:\n",
    "        epsg = 32643 if tr[1] > 0 else 32743\n",
    "    if 66 <= tr[0] <= 72:\n",
    "        epsg = 32642 if tr[1] > 0 else 32742\n",
    "    if 60 <= tr[0] <= 66:\n",
    "        epsg = 32641 if tr[1] > 0 else 32741\n",
    "    if 54 <= tr[0] <= 60:\n",
    "        epsg = 32640 if tr[1] > 0 else 32740\n",
    "    if 48 <= tr[0] <= 54:\n",
    "        epsg = 32639 if tr[1] > 0 else 32739\n",
    "    if 42 <= tr[0] <= 48:\n",
    "        epsg = 32638 if tr[1] > 0 else 32738\n",
    "    if 36 <= tr[0] <= 42:\n",
    "        epsg = 32637 if tr[1] > 0 else 32737\n",
    "    if 30 <= tr[0] <= 36:\n",
    "        epsg = 32636 if tr[1] > 0 else 32736\n",
    "    if 24 <= tr[0] <= 30:\n",
    "        epsg = 32635 if tr[1] > 0 else 32735\n",
    "    if 18 <= tr[0] <= 24:\n",
    "        epsg = 32634 if tr[1] > 0 else 32734\n",
    "    if 12 <= tr[0] <= 18:\n",
    "        epsg = 32633 if tr[1] > 0 else 32733\n",
    "    if 6 <= tr[0] <= 12:\n",
    "        epsg = 32632 if tr[1] > 0 else 32732\n",
    "    if 0 <= tr[0] <= 6:\n",
    "        epsg = 32631 if tr[1] > 0 else 32731\n",
    "    if -6 <= tr[0] <= 0:\n",
    "        epsg = 32630 if tr[1] > 0 else 32730\n",
    "    if -12 <= tr[0] <= -6:\n",
    "        epsg = 32629 if tr[1] > 0 else 32729\n",
    "    if -18 <= tr[0] <= -12:\n",
    "        epsg = 32628 if tr[1] > 0 else 32728\n",
    "    if -24 <= tr[0] <= -18:\n",
    "        epsg = 32627 if tr[1] > 0 else 32727\n",
    "    if -30 <= tr[0] <= -24:\n",
    "        epsg = 32626 if tr[1] > 0 else 32726\n",
    "    if -36 <= tr[0] <= -30:\n",
    "        epsg = 32625 if tr[1] > 0 else 32725\n",
    "    if -42 <= tr[0] <= -36:\n",
    "        epsg = 32624 if tr[1] > 0 else 32724\n",
    "    if -48 <= tr[0] <= -42:\n",
    "        epsg = 32623 if tr[1] > 0 else 32723\n",
    "    if -78 <= tr[0] <= -72:\n",
    "        epsg = 32618 if tr[1] > 0 else 32718\n",
    "    if -84 <= tr[0] <= -78:\n",
    "        epsg = 32617 if tr[1] > 0 else 32717\n",
    "    if -90 <= tr[0] <= -84:\n",
    "        epsg = 32616 if tr[1] > 0 else 32716\n",
    "    if -96 <= tr[0] <= -90:\n",
    "        epsg = 32615 if tr[1] > 0 else 32715\n",
    "\n",
    "    bl = convertCoords(bl, 4326, epsg)\n",
    "    tr = convertCoords(tr, 4326, epsg)\n",
    "    init = [b - a for a,b in zip(bl, tr)]\n",
    "    distance1 = tr[0] - bl[0]\n",
    "    distance2 = tr[1] - bl[1]\n",
    "    expansion1 = (expansion - distance1)/2\n",
    "    expansion2 = (expansion - distance2)/2\n",
    "    bl = [bl[0] - expansion1, bl[1] - expansion2]\n",
    "    tr = [tr[0] + expansion1, tr[1] + expansion2]\n",
    "\n",
    "    after = [b - a for a,b in zip(bl, tr)]   \n",
    "    print(after)\n",
    "    if max(init) > 130:\n",
    "        print(\"ERROR: Initial field greater than 130m\")\n",
    "    if min(init) < 120:\n",
    "        print(\"ERROR: Initial field less than 130m\")\n",
    "        \n",
    "    if min(after) < (expansion - 4.5):\n",
    "        print(\"ERROR\")\n",
    "    if max(after) > (expansion + 5):\n",
    "        print(\"ERROR\")\n",
    "    diffs = [b - a for b, a in zip(after, init)]\n",
    "\n",
    "    bl = convertCoords(bl, epsg, 4326)\n",
    "    tr = convertCoords(tr, epsg, 4326)\n",
    "    return bl, tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_clouds(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        cloud_request = WmsRequest(\n",
    "            layer='CLOUD_DETECTION',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=IMSIZE,\n",
    "            height=IMSIZE,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.75,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        cloud_img = cloud_request.get_data()\n",
    "        cloud_probs = cloud_detector.get_cloud_probability_maps(np.array(cloud_img))\n",
    "        means = np.mean(cloud_probs, (1, 2))\n",
    "        clean_steps = [i for i, val in enumerate(means) if val < 0.20]\n",
    "        return clean_steps, means, cloud_probs\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(val, df, epsg = EPSG, ):\n",
    "    location = calc_bbox(val, df = df)\n",
    "    bbox = bounding_box(location, expansion = (IMSIZE+2)*10)\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=IMSIZE+2,\n",
    "                         height=IMSIZE+2,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, IMSIZE+2, IMSIZE+2)),\n",
    "                  np.full((IMSIZE+2, IMSIZE+2), 10), np.full((IMSIZE+2, IMSIZE+2), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((IMSIZE+2, IMSIZE+2, 1))\n",
    "    dem_image = dem_image[1:IMSIZE+1, 1:IMSIZE+1, :]\n",
    "    return dem_image\n",
    "\n",
    "def check_zenith(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        zenith = WmsRequest(\n",
    "            layer='ZENITH',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=IMSIZE,\n",
    "            height=IMSIZE,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.75,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        zenith = zenith.get_data()\n",
    "        return zenith\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "        \n",
    "def download_layer(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A20',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        img_20 = np.stack(img_bands)\n",
    "        img_20 = resize(img_20, (img_20.shape[0], IMSIZE, IMSIZE, img_20.shape[-1]), order = 0)\n",
    "        \n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A10',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'BICUBIC',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        img_bands = image_request.get_data()\n",
    "        img_10 = np.stack(img_bands)\n",
    "        print(\"Original size: {}\".format(img_10.shape))\n",
    "        img_10 = resize(img_10, (img_10.shape[0], IMSIZE, IMSIZE, img_10.shape[-1]), order = 0)\n",
    "        shadows = img_10[:, :, :, -1]\n",
    "        img_10 = img_10[:, :, :, :-1]\n",
    "        \n",
    "        shadows[np.where(shadows != 3)] = 0\n",
    "        shadows[np.where(shadows == 3)] = 1\n",
    "        shadows_sums = np.sum(shadows, axis = 0)\n",
    "        before = np.sum(shadows)\n",
    "        #shadows[np.where(shadows_sums > shadows.shape[0]/2)] = 0.\n",
    "        print(\"Difference: {}\".format(np.sum(shadows) - before))\n",
    "        print(\"Shadows: {}\".format(shadows.shape))\n",
    "        shadow_sum = np.sum(shadows, axis = (1, 2))\n",
    "        shadow_steps = np.argwhere(shadow_sum > (IMSIZE*IMSIZE) / 5)\n",
    "        \n",
    "        img = np.concatenate([img_10, img_20], axis = -1)\n",
    "        return img, image_request, shadows, shadow_steps\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "        \n",
    "def download_sentinel_1(bbox, epsg = EPSG, time = time, year = 2019):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer='SENT',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=1.0,\n",
    "                resx='5m', resy='5m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        s1 = np.stack(img_bands)\n",
    "        s1 = resize(s1, (s1.shape[0], IMSIZE*2, IMSIZE*2, s1.shape[-1]), order = 0)\n",
    "        s1 = np.reshape(s1, (s1.shape[0], s1.shape[1]//2, 2, s1.shape[2] // 2, 2, s1.shape[-1]))\n",
    "        s1 = np.mean(s1, (2, 4))\n",
    "        s1 = s1[:, 8:24, 8:24, :]\n",
    "        \n",
    "        image_dates = []\n",
    "        for date in image_request.get_dates():\n",
    "            if date.year == year - 1:\n",
    "                image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year:\n",
    "                image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year + 1:\n",
    "                image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "        image_dates = np.array(image_dates)\n",
    "        to_remove = np.argwhere(np.max(s1, (1, 2, 3)) == 1.).flatten()\n",
    "        s1 = np.delete(s1, to_remove, 0)\n",
    "        #print(np.max(s1, (1, 2, 3)))\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        return s1, image_dates\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.max(x, (1, 2, 3)) == 1.).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud and shadow removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cloud_and_shadows(tiles, probs, shadows, image_dates, wsize = 5):\n",
    "    c_probs = np.copy(probs)\n",
    "    c_probs = c_probs - np.min(c_probs, axis = 0)\n",
    "    c_probs[np.where(c_probs > 0.33)] = 1.\n",
    "    c_probs[np.where(c_probs < 0.33)] = 0.\n",
    "    c_probs = np.reshape(c_probs, [c_probs.shape[0], int(IMSIZE/8), 8, int(IMSIZE/8), 8])\n",
    "    c_probs = np.sum(c_probs, (2, 4))\n",
    "    c_probs = resize(c_probs, (c_probs.shape[0], IMSIZE, IMSIZE), 0)\n",
    "    c_probs[np.where(c_probs < 12)] = 0.\n",
    "    c_probs[np.where(c_probs >= 12)] = 1.\n",
    "    c_probs += shadows\n",
    "    c_probs[np.where(c_probs >= 1.)] = 1.\n",
    "    n_interp = 0\n",
    "    for cval in range(0, IMSIZE - 4, 1):\n",
    "        for rval in range(0, IMSIZE - 4, 1):\n",
    "            subs = c_probs[:, cval:cval + wsize, rval:rval+wsize]\n",
    "            satisfactory = [x for x in range(c_probs.shape[0]) if np.sum(subs[x, :, :]) < 10]\n",
    "            satisfactory = np.array(satisfactory)\n",
    "            for date in range(0, tiles.shape[0]):\n",
    "                if np.sum(subs[date, :, :]) > 10:\n",
    "                    n_interp += 1\n",
    "                    before, after = calculate_proximal_steps_index(date, satisfactory)\n",
    "                    before = date + before\n",
    "                    after = date + after\n",
    "                    bef = tiles[before, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    aft = tiles[after, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    before = image_dates[before]\n",
    "                    after = image_dates[after]\n",
    "                    before_diff = abs(image_dates[date] - before)\n",
    "                    after_diff = abs(image_dates[date] - after)\n",
    "                    bef_wt = 1 - before_diff / (before_diff + after_diff)\n",
    "                    aft_wt = 1 - bef_wt\n",
    "                    candidate = bef_wt*bef + aft_wt*aft\n",
    "                    candidate = candidate*c_arr + tiles[date, cval:cval+wsize, rval:rval+wsize, : ]*o_arr\n",
    "                    tiles[date, cval:cval+wsize, rval:rval+wsize, : ] = candidate  \n",
    "    print(\"Interpolated {} px\".format(n_interp))\n",
    "    return tiles\n",
    "\n",
    "def remove_missed_clouds(img):\n",
    "    iqr = np.percentile(img[:, :, :, 3].flatten(), 75) - np.percentile(img[:, :, :, 3].flatten(), 25)\n",
    "    thresh_t = np.percentile(img[:, :, :, 3].flatten(), 75) + iqr*2\n",
    "    thresh_b = np.percentile(img[:, :, :, 3].flatten(), 25) - iqr*2\n",
    "    diffs_fw = np.diff(img, 1, axis = 0)\n",
    "    diffs_fw = np.mean(diffs_fw, axis = (1, 2, 3))\n",
    "    diffs_fw = np.array([0] + list(diffs_fw))\n",
    "    diffs_bw = np.diff(np.flip(img, 0), 1, axis = 0)\n",
    "    diffs_bw = np.flip(np.mean(diffs_bw, axis = (1, 2, 3)))\n",
    "    diffs_bw = np.array(list(diffs_bw) + [0])\n",
    "    diffs = abs(diffs_fw - diffs_bw) * 100 # 3, -3 -> 6, -3, 3 -> 6, -3, -3\n",
    "    #diffs = [int(x) for x in diffs]\n",
    "    outlier_percs = []\n",
    "    for step in range(img.shape[0]):\n",
    "        bottom = len(np.argwhere(img[step, :, :, 3].flatten() > thresh_t))\n",
    "        top = len(np.argwhere(img[step, :, :, 3].flatten() < thresh_b))\n",
    "        p = 100* ((bottom + top) / (IMSIZE*IMSIZE))\n",
    "        outlier_percs.append(p)\n",
    "    to_remove = np.argwhere(np.array(outlier_percs) > 15)\n",
    "    print([int(x) for x in outlier_percs])\n",
    "    return to_remove\n",
    "\n",
    "def threshold_shadows(arr):\n",
    "    arr = np.copy(arr)\n",
    "    iqr = np.percentile(arr.flatten(), 75) - np.percentile(arr.flatten(), 25)\n",
    "    low = np.percentile(arr.flatten(), 25)\n",
    "    #high = np.percentile(arr.flatten(), 75)\n",
    "    thresh_low = low - 1.5*iqr\n",
    "    #thresh_high = high + 2*iqr\n",
    "    #arr[np.where(arr > thresh_high)] = 1.\n",
    "    arr[np.where(arr < thresh_low)] = 1.\n",
    "    arr[np.where(arr < 1)] = 0.\n",
    "    arr = np.reshape(arr, (arr.shape[0], 6, 8, 6, 8))\n",
    "    arr = np.sum(arr, axis = (2, 4))\n",
    "    arr = resize(arr, (arr.shape[0], 48, 48), 0)\n",
    "    fake_shadows = np.zeros((arr.shape[0], arr.shape[1], arr.shape[2]))\n",
    "    for step in range(arr.shape[0]):\n",
    "        if step > 0:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        before = arr[step - 1, x, y]\n",
    "                        if abs(before - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "                            \n",
    "    for step in range(arr.shape[0]):\n",
    "        if step < arr.shape[0] - 1:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        after = arr[step + 1, x, y]\n",
    "                        if abs(after - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "    arr[np.where(arr > 5)] = 1.\n",
    "    arr[np.where(arr < 5)] = 0.\n",
    "    before = np.sum(arr)\n",
    "    arr[np.where(fake_shadows == 1)] = 0.\n",
    "    after = np.sum(arr)\n",
    "    \n",
    "    print(\"Removed {} fake shadows, leaving {}\".format(before - after, after))\n",
    "    print(\"The total percent shadow cover is: {}%\".format(100*(after/(arr.shape[0]*arr.shape[1]*arr.shape[2]))))\n",
    "    for step in range(arr.shape[0]):\n",
    "        for x in range(1, arr.shape[1] -1):\n",
    "            for y in range(1, arr.shape[2] - 1):\n",
    "                if np.sum(arr[step, x-1:x+2, y-1:y+2]) == 1:\n",
    "                    if arr[step, x, y] != 0:\n",
    "                        print(\"Removing: {} {} {} {}\".format(step, x, y, np.sum(arr[step, x-1:x+2, y-1:y+2])))\n",
    "                        arr[step, x, y] = 0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_best_images(img_bands, image_dates):\n",
    "    # This function interpolates data to 5 day windows linearly\n",
    "\n",
    "    biweekly_dates = [day for day in range(0, 360, 5)] # ideal imagery dates are every 15 days\n",
    "    \n",
    "    # Clouds have been removed at this step, so all steps are satisfactory\n",
    "    satisfactory_ids = [x for x in range(0, img_bands.shape[0])]\n",
    "    satisfactory_dates = [value for idx, value in enumerate(image_dates) if idx in satisfactory_ids]\n",
    "    \n",
    "    \n",
    "    selected_images = {}\n",
    "    for i in biweekly_dates:\n",
    "        distances = [abs(date - i) for date in satisfactory_dates]\n",
    "        closest = np.min(distances)\n",
    "        closest_id = np.argmin(distances)\n",
    "        # If there is imagery within 5 days, select it\n",
    "        if closest < 8:\n",
    "            date = satisfactory_dates[closest_id]\n",
    "            image_idx = int(np.argwhere(np.array(image_dates) == date)[0])\n",
    "            selected_images[i] = {'image_date': [date], 'image_ratio': [1], 'image_idx': [image_idx]}\n",
    "        # If there is not imagery within 7 days, look for the closest above and below imagery\n",
    "        else:\n",
    "            distances = np.array([(date - i) for date in satisfactory_dates])\n",
    "            # Number of days above and below the selected date of the nearest clean imagery\n",
    "            above = distances[np.where(distances < 0, distances, -np.inf).argmax()]\n",
    "            below = distances[np.where(distances > 0, distances, np.inf).argmin()]\n",
    "            if abs(above) > 240: # If date is the last date, occassionally argmax would set above to - number\n",
    "                above = below\n",
    "            if abs(below) > 240:\n",
    "                below = above\n",
    "            if above != below:\n",
    "                below_ratio = above / (above - below)\n",
    "                above_ratio = 1 - below_ratio\n",
    "            else:\n",
    "                above_ratio = below_ratio = 0.5\n",
    "                \n",
    "            # Extract the image date and imagery index for the above and below values\n",
    "            above_date = i + above\n",
    "            above_image_idx = int(np.argwhere(np.array(image_dates) == above_date)[0])\n",
    "            \n",
    "            below_date = i + below\n",
    "            below_image_idx = int(np.argwhere(np.array(image_dates) == below_date)[0])\n",
    "            \n",
    "            selected_images[i] = {'image_date': [above_date, below_date], 'image_ratio': [above_ratio, below_ratio],\n",
    "                                 'image_idx': [above_image_idx, below_image_idx]}\n",
    "                               \n",
    "    max_distance = 0\n",
    "    \n",
    "    for i in selected_images.keys():\n",
    "        #print(i, selected_images[i])\n",
    "        if len(selected_images[i]['image_date']) == 2:\n",
    "            dist = selected_images[i]['image_date'][1] - selected_images[i]['image_date'][0]\n",
    "            if dist > max_distance:\n",
    "                max_distance = dist\n",
    "    \n",
    "    print(\"Maximum time distance: {}\".format(max_distance))\n",
    "        \n",
    "    # Compute the weighted average of the selected imagery for each time step\n",
    "    keep_steps = []\n",
    "    use_median = False\n",
    "    for i in selected_images.keys():\n",
    "        step1_additional = None\n",
    "        step2_additional = None\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "        if len(info['image_idx']) == 2:\n",
    "            step1 = img_bands[info['image_idx'][0]] # * info['image_ratio'][0]\n",
    "            step2 = img_bands[info['image_idx'][1]]\n",
    "            #if info['image_idx'][0] == 0:\n",
    "            #    step1_additional = img_bands[-1]\n",
    "            #    print(\"Using last step\")\n",
    "            #if info['image_idx'][1] == (img_bands.shape[0] - 1):\n",
    "            #    step2_additional = img_bands[0]\n",
    "            ##    print(\"Using first step\")\n",
    "            #if step1_additional is None and step2_additional is None:\n",
    "            step = step1 * 0.5 + step2 * 0.5\n",
    "            #if step1_additional is not None:\n",
    "            #    print(\"Echo\")\n",
    "            #    step = (step1 + step2 + step1_additional) * (1/3)\n",
    "            #if step2_additional is not None:\n",
    "             #   print(\"Echo\")\n",
    "            #    step = (step1 + step2 + step2_additional) * (1/3)\n",
    "        keep_steps.append(step)\n",
    "    '''\n",
    "    for i in selected_images.keys():\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "            use_median = False\n",
    "        if len(info['image_idx']) == 2:\n",
    "            difference = np.max([abs(info['image_date'][0] - int(i)),\n",
    "                                 abs(info['image_date'][1] - int(i))]) \n",
    "            step1 = img_bands[info['image_idx'][0]] # * info['image_ratio'][0]\n",
    "            step2_idx = info['image_idx'][0] - 1\n",
    "            if step2_idx < 0:\n",
    "                step2_idx = (img_bands.shape[0] - 1)\n",
    "            step2 = img_bands[step2_idx]\n",
    "            step3 = img_bands[info['image_idx'][1]]\n",
    "            step4_idx = info['image_idx'][1] + 1\n",
    "            if step4_idx > (img_bands.shape[0] - 1):\n",
    "                step4_idx = 0\n",
    "            step4 = img_bands[step4_idx]\n",
    "            #step2 = img_bands[info['image_idx'][1]] * 0.5 # info['image_ratio'][1]\n",
    "            if difference > 100 or use_median == True:\n",
    "                print(\"Median, {}\".format(difference))\n",
    "                use_median = True\n",
    "                stacked = np.stack([step1, step2, step3, step4])\n",
    "                step = np.median(stacked, axis = 0)\n",
    "            else:\n",
    "                use_median = False\n",
    "                step = step1 * 0.5 + step3 * 0.5\n",
    "        '''\n",
    "        #keep_steps.append(step)\n",
    "        \n",
    "    keep_steps = np.stack(keep_steps)\n",
    "    return keep_steps, max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  31  59  90 120 151 181 212 243 273 304 334]\n"
     ]
    }
   ],
   "source": [
    "days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "starting_days = np.cumsum(days_per_month)\n",
    "print(starting_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "super_resolve = True\n",
    "year = 2019\n",
    "\n",
    "DATA_LOCATION = '../data/ghana-test.csv'\n",
    "OUTPUT_FOLDER = '../data/test-smooth-200/'\n",
    "\n",
    "\n",
    "def download_plots(data_location = DATA_LOCATION, output_folder = OUTPUT_FOLDER):\n",
    "    df = pd.read_csv(data_location)\n",
    "    df = df.drop('IMAGERY_TITLE', axis = 1)\n",
    "    df = df.dropna(axis = 0)\n",
    "    plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "    existing = [int(x[:-4]) for x in os.listdir(output_folder) if \".DS\" not in x]\n",
    "    to_download = [x for x in plot_ids if x not in existing]\n",
    "    print(\"STARTING DOWNLOAD OF {} plots from {} to {}\".format(len(to_download), data_location, output_folder))\n",
    "    errors = []\n",
    "    for i, val in enumerate(to_download):\n",
    "        print(i, val)\n",
    "        print(\"Downloading {}/{}, {}\".format(i+1, len(to_download), val))\n",
    "        location = calc_bbox(val, df = df)\n",
    "        location = bounding_box(location, expansion = IMSIZE*10)\n",
    "        try:\n",
    "            # Identify cloud steps, download DEM, and download L2A series\n",
    "            s1, s1_dates = download_sentinel_1(location)\n",
    "            print(s1.shape)\n",
    "            print(s1_dates.shape)\n",
    "            if s1_dates.shape[0] > 0:\n",
    "                s1, max_distance_s1 = calculate_and_save_best_images(s1, s1_dates)\n",
    "\n",
    "\n",
    "                # Retain only iamgery every 15 days\n",
    "                biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "                to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "                s1 = np.delete(s1, to_remove, 0)\n",
    "\n",
    "                if max_distance_s1 <= 240:\n",
    "                    np.save(output_folder + str(val), s1)\n",
    "                    print(\"\\n\")\n",
    "                else:\n",
    "                    print(\"Skipping {} because there is a {} distance\".format(val, max_distance))\n",
    "                    print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.fatal(e, exc_info=True)\n",
    "            errors.append(img)\n",
    "            #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING DOWNLOAD OF 0 plots from ../data/test-csv/ghana-test.csv to ../data/test-super-fuse/\n",
      "STARTING DOWNLOAD OF 22 plots from ../data/test-csv/kenya-test.csv to ../data/test-super-fuse/\n",
      "0 135542550\n",
      "Downloading 1/22, 135542550\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "1 135542552\n",
      "Downloading 2/22, 135542552\n",
      "[480.0, 480.0]\n",
      "(10, 16, 16, 2)\n",
      "(10,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "2 135542554\n",
      "Downloading 3/22, 135542554\n",
      "[480.0, 480.0]\n",
      "(24, 16, 16, 2)\n",
      "(24,)\n",
      "Maximum time distance: 25\n",
      "\n",
      "\n",
      "3 135542555\n",
      "Downloading 4/22, 135542555\n",
      "[480.0, 480.0]\n",
      "(11, 16, 16, 2)\n",
      "(11,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "4 135542557\n",
      "Downloading 5/22, 135542557\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "5 135542559\n",
      "Downloading 6/22, 135542559\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "6 135542564\n",
      "Downloading 7/22, 135542564\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "7 135542566\n",
      "Downloading 8/22, 135542566\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "8 135542571\n",
      "Downloading 9/22, 135542571\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "9 135542572\n",
      "Downloading 10/22, 135542572\n",
      "[480.0, 480.0]\n",
      "(13, 16, 16, 2)\n",
      "(13,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "10 135542573\n",
      "Downloading 11/22, 135542573\n",
      "[480.0, 480.0]\n",
      "(24, 16, 16, 2)\n",
      "(24,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "11 135542577\n",
      "Downloading 12/22, 135542577\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "12 135542580\n",
      "Downloading 13/22, 135542580\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "(13, 16, 16, 2)\n",
      "(13,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "13 135542587\n",
      "Downloading 14/22, 135542587\n",
      "[480.0, 480.0]\n",
      "(22, 16, 16, 2)\n",
      "(22,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "14 135542589\n",
      "Downloading 15/22, 135542589\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "15 135542592\n",
      "Downloading 16/22, 135542592\n",
      "[480.0, 480.0]\n",
      "(14, 16, 16, 2)\n",
      "(14,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "16 135542593\n",
      "Downloading 17/22, 135542593\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "17 135542595\n",
      "Downloading 18/22, 135542595\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "18 135542604\n",
      "Downloading 19/22, 135542604\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "(13, 16, 16, 2)\n",
      "(13,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "19 135542606\n",
      "Downloading 20/22, 135542606\n",
      "[480.0, 480.0]\n",
      "(13, 16, 16, 2)\n",
      "(13,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "20 135542609\n",
      "Downloading 21/22, 135542609\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "21 135542615\n",
      "Downloading 22/22, 135542615\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "(13, 16, 16, 2)\n",
      "(13,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "STARTING DOWNLOAD OF 114 plots from ../data/test-csv/ethiopia-test.csv to ../data/test-super-fuse/\n",
      "0 135505799\n",
      "Downloading 1/114, 135505799\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "1 135505800\n",
      "Downloading 2/114, 135505800\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "2 135505801\n",
      "Downloading 3/114, 135505801\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "3 135505803\n",
      "Downloading 4/114, 135505803\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "4 135505804\n",
      "Downloading 5/114, 135505804\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "5 135505805\n",
      "Downloading 6/114, 135505805\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "6 135505806\n",
      "Downloading 7/114, 135505806\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "7 135505807\n",
      "Downloading 8/114, 135505807\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "8 135505808\n",
      "Downloading 9/114, 135505808\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "9 135505809\n",
      "Downloading 10/114, 135505809\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "10 135505810\n",
      "Downloading 11/114, 135505810\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "11 135505811\n",
      "Downloading 12/114, 135505811\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "12 135505813\n",
      "Downloading 13/114, 135505813\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "13 135505814\n",
      "Downloading 14/114, 135505814\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "14 135505815\n",
      "Downloading 15/114, 135505815\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "15 135505821\n",
      "Downloading 16/114, 135505821\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "16 135505822\n",
      "Downloading 17/114, 135505822\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "17 135505823\n",
      "Downloading 18/114, 135505823\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "18 135505825\n",
      "Downloading 19/114, 135505825\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "19 135505827\n",
      "Downloading 20/114, 135505827\n",
      "[480.0, 480.0]\n",
      "(14, 16, 16, 2)\n",
      "(14,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "20 135505832\n",
      "Downloading 21/114, 135505832\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "21 135505833\n",
      "Downloading 22/114, 135505833\n",
      "[480.0, 480.0]\n",
      "(13, 16, 16, 2)\n",
      "(13,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "22 135505834\n",
      "Downloading 23/114, 135505834\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "23 135505835\n",
      "Downloading 24/114, 135505835\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "24 135505836\n",
      "Downloading 25/114, 135505836\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "25 135505837\n",
      "Downloading 26/114, 135505837\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "26 135505838\n",
      "Downloading 27/114, 135505838\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "27 135505839\n",
      "Downloading 28/114, 135505839\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "28 135505841\n",
      "Downloading 29/114, 135505841\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "29 135505842\n",
      "Downloading 30/114, 135505842\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "30 135505843\n",
      "Downloading 31/114, 135505843\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "31 135505845\n",
      "Downloading 32/114, 135505845\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "32 135505847\n",
      "Downloading 33/114, 135505847\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "33 135505849\n",
      "Downloading 34/114, 135505849\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "34 135505853\n",
      "Downloading 35/114, 135505853\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "35 135505856\n",
      "Downloading 36/114, 135505856\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "36 135505861\n",
      "Downloading 37/114, 135505861\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 25\n",
      "\n",
      "\n",
      "37 135505863\n",
      "Downloading 38/114, 135505863\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "38 135505869\n",
      "Downloading 39/114, 135505869\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "39 135505870\n",
      "Downloading 40/114, 135505870\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "40 135505873\n",
      "Downloading 41/114, 135505873\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "41 135505877\n",
      "Downloading 42/114, 135505877\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "42 135505880\n",
      "Downloading 43/114, 135505880\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "43 135505887\n",
      "Downloading 44/114, 135505887\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "44 135505888\n",
      "Downloading 45/114, 135505888\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "45 135505889\n",
      "Downloading 46/114, 135505889\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "46 135505891\n",
      "Downloading 47/114, 135505891\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 25\n",
      "\n",
      "\n",
      "47 135505892\n",
      "Downloading 48/114, 135505892\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "48 135505893\n",
      "Downloading 49/114, 135505893\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "49 135505894\n",
      "Downloading 50/114, 135505894\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "50 135505898\n",
      "Downloading 51/114, 135505898\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "51 135505899\n",
      "Downloading 52/114, 135505899\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "52 135505901\n",
      "Downloading 53/114, 135505901\n",
      "[480.0, 480.0]\n",
      "(14, 16, 16, 2)\n",
      "(14,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "53 135505902\n",
      "Downloading 54/114, 135505902\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "54 135505904\n",
      "Downloading 55/114, 135505904\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "55 135505907\n",
      "Downloading 56/114, 135505907\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "56 135505910\n",
      "Downloading 57/114, 135505910\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "57 135505912\n",
      "Downloading 58/114, 135505912\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "58 135505913\n",
      "Downloading 59/114, 135505913\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "59 135505914\n",
      "Downloading 60/114, 135505914\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "60 135505917\n",
      "Downloading 61/114, 135505917\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "61 135505919\n",
      "Downloading 62/114, 135505919\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "62 135505920\n",
      "Downloading 63/114, 135505920\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "63 135505927\n",
      "Downloading 64/114, 135505927\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "64 135505928\n",
      "Downloading 65/114, 135505928\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "65 135505931\n",
      "Downloading 66/114, 135505931\n",
      "[480.0, 480.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "66 135505933\n",
      "Downloading 67/114, 135505933\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "67 135505934\n",
      "Downloading 68/114, 135505934\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "68 135505935\n",
      "Downloading 69/114, 135505935\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "69 135505936\n",
      "Downloading 70/114, 135505936\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "70 135505937\n",
      "Downloading 71/114, 135505937\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "71 135505939\n",
      "Downloading 72/114, 135505939\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "72 135505942\n",
      "Downloading 73/114, 135505942\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "73 135505946\n",
      "Downloading 74/114, 135505946\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "74 135505948\n",
      "Downloading 75/114, 135505948\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "75 135505949\n",
      "Downloading 76/114, 135505949\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "76 135505950\n",
      "Downloading 77/114, 135505950\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "77 135505951\n",
      "Downloading 78/114, 135505951\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "78 135505956\n",
      "Downloading 79/114, 135505956\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "79 135505957\n",
      "Downloading 80/114, 135505957\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "80 135505958\n",
      "Downloading 81/114, 135505958\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "81 135505959\n",
      "Downloading 82/114, 135505959\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "82 135505965\n",
      "Downloading 83/114, 135505965\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "83 135505968\n",
      "Downloading 84/114, 135505968\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "84 135505970\n",
      "Downloading 85/114, 135505970\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "85 135505973\n",
      "Downloading 86/114, 135505973\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 25\n",
      "\n",
      "\n",
      "86 135505977\n",
      "Downloading 87/114, 135505977\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "87 135505978\n",
      "Downloading 88/114, 135505978\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "88 135505979\n",
      "Downloading 89/114, 135505979\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "89 135505984\n",
      "Downloading 90/114, 135505984\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "90 135505990\n",
      "Downloading 91/114, 135505990\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "91 135505991\n",
      "Downloading 92/114, 135505991\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "92 135505993\n",
      "Downloading 93/114, 135505993\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "93 135505994\n",
      "Downloading 94/114, 135505994\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "94 135505996\n",
      "Downloading 95/114, 135505996\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "95 135505997\n",
      "Downloading 96/114, 135505997\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "96 135505998\n",
      "Downloading 97/114, 135505998\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "97 135505999\n",
      "Downloading 98/114, 135505999\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "98 135506000\n",
      "Downloading 99/114, 135506000\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "99 135506001\n",
      "Downloading 100/114, 135506001\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "100 135506008\n",
      "Downloading 101/114, 135506008\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "101 135506009\n",
      "Downloading 102/114, 135506009\n",
      "[480.0, 480.0]\n",
      "(14, 16, 16, 2)\n",
      "(14,)\n",
      "Maximum time distance: 35\n",
      "\n",
      "\n",
      "102 135506010\n",
      "Downloading 103/114, 135506010\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "103 135506012\n",
      "Downloading 104/114, 135506012\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "104 135506014\n",
      "Downloading 105/114, 135506014\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "105 135506024\n",
      "Downloading 106/114, 135506024\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "106 135506025\n",
      "Downloading 107/114, 135506025\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "107 135506029\n",
      "Downloading 108/114, 135506029\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "108 135506031\n",
      "Downloading 109/114, 135506031\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "109 135506036\n",
      "Downloading 110/114, 135506036\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "110 135506037\n",
      "Downloading 111/114, 135506037\n",
      "[480.0, 480.0]\n",
      "(12, 16, 16, 2)\n",
      "(12,)\n",
      "Maximum time distance: 60\n",
      "\n",
      "\n",
      "111 135506039\n",
      "Downloading 112/114, 135506039\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "112 135506040\n",
      "Downloading 113/114, 135506040\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "113 135506043\n",
      "Downloading 114/114, 135506043\n",
      "[480.0, 480.0]\n",
      "(0, 16, 16, 2)\n",
      "(0,)\n",
      "STARTING DOWNLOAD OF 36 plots from ../data/test-csv/ghana-test-large.csv to ../data/test-super-fuse/\n",
      "0 135702560\n",
      "Downloading 1/36, 135702560\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "1 135702564\n",
      "Downloading 2/36, 135702564\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "2 135702571\n",
      "Downloading 3/36, 135702571\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "3 135702572\n",
      "Downloading 4/36, 135702572\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "4 135702577\n",
      "Downloading 5/36, 135702577\n",
      "[480.0, 480.0]\n",
      "(51, 16, 16, 2)\n",
      "(51,)\n",
      "Maximum time distance: 0\n",
      "\n",
      "\n",
      "5 135702579\n",
      "Downloading 6/36, 135702579\n",
      "[480.0, 480.0]\n",
      "(39, 16, 16, 2)\n",
      "(39,)\n",
      "Maximum time distance: 25\n",
      "\n",
      "\n",
      "6 135702583\n",
      "Downloading 7/36, 135702583\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "7 135702584\n",
      "Downloading 8/36, 135702584\n",
      "[480.0, 480.0]\n",
      "(25, 16, 16, 2)\n",
      "(25,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "8 135702585\n",
      "Downloading 9/36, 135702585\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "9 135702592\n",
      "Downloading 10/36, 135702592\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "10 135702596\n",
      "Downloading 11/36, 135702596\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "11 135702608\n",
      "Downloading 12/36, 135702608\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "12 135702611\n",
      "Downloading 13/36, 135702611\n",
      "[480.0, 480.0]\n",
      "(39, 16, 16, 2)\n",
      "(39,)\n",
      "Maximum time distance: 20\n",
      "\n",
      "\n",
      "13 135702614\n",
      "Downloading 14/36, 135702614\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "14 135702615\n",
      "Downloading 15/36, 135702615\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "15 135702618\n",
      "Downloading 16/36, 135702618\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "16 135702619\n",
      "Downloading 17/36, 135702619\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "17 135702623\n",
      "Downloading 18/36, 135702623\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "18 135702629\n",
      "Downloading 19/36, 135702629\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "19 135702637\n",
      "Downloading 20/36, 135702637\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "20 135702644\n",
      "Downloading 21/36, 135702644\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "21 135702646\n",
      "Downloading 22/36, 135702646\n",
      "[480.0, 480.0]\n",
      "(51, 16, 16, 2)\n",
      "(51,)\n",
      "Maximum time distance: 0\n",
      "\n",
      "\n",
      "22 135702651\n",
      "Downloading 23/36, 135702651\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "23 135702657\n",
      "Downloading 24/36, 135702657\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "24 135702661\n",
      "Downloading 25/36, 135702661\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "25 135702662\n",
      "Downloading 26/36, 135702662\n",
      "[480.0, 480.0]\n",
      "(39, 16, 16, 2)\n",
      "(39,)\n",
      "Maximum time distance: 25\n",
      "\n",
      "\n",
      "26 135702669\n",
      "Downloading 27/36, 135702669\n",
      "[480.0, 480.0]\n",
      "(39, 16, 16, 2)\n",
      "(39,)\n",
      "Maximum time distance: 25\n",
      "\n",
      "\n",
      "27 135702671\n",
      "Downloading 28/36, 135702671\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "28 135702679\n",
      "Downloading 29/36, 135702679\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "29 135702685\n",
      "Downloading 30/36, 135702685\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "30 135702691\n",
      "Downloading 31/36, 135702691\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "31 135702702\n",
      "Downloading 32/36, 135702702\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "32 135702707\n",
      "Downloading 33/36, 135702707\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "33 135702714\n",
      "Downloading 34/36, 135702714\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "34 135702730\n",
      "Downloading 35/36, 135702730\n",
      "[480.0, 480.0]\n",
      "(39, 16, 16, 2)\n",
      "(39,)\n",
      "Maximum time distance: 25\n",
      "\n",
      "\n",
      "35 135702741\n",
      "Downloading 36/36, 135702741\n",
      "[480.0, 480.0]\n",
      "(26, 16, 16, 2)\n",
      "(26,)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(\"../data/test-csv\"):\n",
    "    if \".csv\" in i:\n",
    "        download_plots(\"../data/test-csv/\" + i, \"../data/test-super-fuse/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"../data/test-super-fuse/135702363.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-toolkit",
   "language": "python",
   "name": "policy-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
