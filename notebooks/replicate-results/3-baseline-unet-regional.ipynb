{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "from osgeo import ogr, osr\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from scipy.ndimage import median_filter\n",
    "%run ../../src/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../../models/unet-resnet/new/34-65-9/model\n"
     ]
    }
   ],
   "source": [
    "model = \"../../models/unet-resnet/new/34-65-9/\"\n",
    "new_saver = tf.train.import_meta_graph(model + \"model.meta\")\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    try:\n",
    "        fm = tf.get_default_graph().get_tensor_by_name(\"conv2d_{}/Sigmoid:0\".format(i))\n",
    "    except Exception:\n",
    "        pass\n",
    "#logits = tf.get_default_graph().get_tensor_by_name(\"conv2d_11/Sigmoid:0\")\n",
    "inp = tf.get_default_graph().get_tensor_by_name(\"Placeholder:0\")\n",
    "labels = tf.get_default_graph().get_tensor_by_name(\"Placeholder_2:0\")\n",
    "rmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_4:0\")\n",
    "rmin = tf.get_default_graph().get_tensor_by_name(\"Placeholder_5:0\")\n",
    "dmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_6:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_all = [0.20792677521705638,\n",
    " 0.2990041905641556,\n",
    " 0.4360648360848427,\n",
    " 0.5161105132102968,\n",
    " 0.4825860628485681,\n",
    " 0.4943232241272928,\n",
    " 0.5178957056999209,\n",
    " 0.5291672283411026,\n",
    " 0.6659183305501939,\n",
    " 0.6092100739479065,\n",
    " 0.37346625328063965,\n",
    " 0.7162704998254776,\n",
    " 0.40363759160041823,\n",
    " 0.6478493613004686,\n",
    " 0.8438000082969666,\n",
    " 0.15365000069141388]\n",
    "\n",
    "min_all = [0.01872335869818926,\n",
    " 0.03467957343906164,\n",
    " 0.021185510214418172,\n",
    " 0.08898216009140014,\n",
    " 0.052402322441339494,\n",
    " 0.07628638863563539,\n",
    " 0.083824477866292,\n",
    " 0.08768215030431747,\n",
    " 0.05718051139265299,\n",
    " 0.0372315139323473,\n",
    " 0.0,\n",
    " 0.007564654648303981,\n",
    " -0.019136652257293465,\n",
    " 0.0064204379683360435,\n",
    " 0.006225000135600567,\n",
    " 4.999999873689376e-05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 outliers: []\n",
      "\n",
      "\n",
      "[] []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823d5d39600946caa39086e9a7365029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=153), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The data has been scaled to [-1.0, 1.0]\n",
      "(153, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "test_x = np.load(\"../../tile_data/processed/test_x_l2a_processed.npy\")\n",
    "test_y = np.load(\"../../tile_data/processed/test_y_l2a_processed.npy\")\n",
    "\n",
    "test_x = np.delete(test_x, 14, -1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.5]\n",
    "above_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.5]\n",
    "min_vals = [np.min(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.5]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "print(\"There are {} outliers: {}\".format(len(outliers), outliers))\n",
    "print(\"\\n\")\n",
    "print(min_vals, max_vals)\n",
    "        \n",
    "test_x = test_x[[x for x in range(0, len(test_x)) if x not in outliers]]\n",
    "test_y = test_y[[x for x in range(0, len(test_y)) if x not in outliers]]\n",
    "\n",
    "for sample in tnrange(0, len(test_x)):\n",
    "    filtered = median_filter(test_x[sample, 0, :, :, 10], size = 5)\n",
    "    filtered = np.reshape(filtered, (8, 2, 8, 2))\n",
    "    filtered = np.mean(filtered, axis = (1, 3))\n",
    "    filtered = resize(filtered, (16, 16), 0)\n",
    "    test_x[sample, :, :, :, 10] = np.stack([filtered] * 24)\n",
    "    \n",
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[:, :, :, :, band] = np.clip(test_x[:, :, :, :, band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[:, :, :, :, band] - midrange) / (rng / 2)\n",
    "    test_x[:, :, :, :, band] = standardized\n",
    "    \n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(test_x), np.max(test_x)))\n",
    "test_x = np.mean(test_x, axis = 1)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipping_params = {\n",
    "    'rmax': rmax,\n",
    "    'rmin': rmin,\n",
    "    'dmax': dmax\n",
    "}\n",
    "\n",
    "\n",
    "def run_predictions(x, y, debug = False):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    diffs = None\n",
    "    for sample in tnrange(x.shape[0]):\n",
    "        if sample not in [558, 563, 596, 599, 602, 615, 634]:\n",
    "            pred = sess.run([fm], feed_dict={inp: x[sample].reshape(1, 16, 16, 16),\n",
    "                                      clipping_params['rmax']: 5,\n",
    "                                      clipping_params['rmin']: 0,\n",
    "                                      clipping_params['dmax']: 3,\n",
    "                                      })\n",
    "            preds.append(np.array(pred))\n",
    "            trues.append(y[sample])\n",
    "    if debug:\n",
    "        thresh = 0.58\n",
    "        preds_i = np.copy(preds)\n",
    "        for i in range(len(preds_i)):\n",
    "            preds_i[i] = np.array(preds_i[i])\n",
    "            preds_i[i][np.where(preds_i[i] >= thresh)] = 1.\n",
    "            preds_i[i][np.where(preds_i[i] < thresh)] = 0.\n",
    "        diffs = [abs(np.sum(np.array(a)) - np.sum(np.array(b))) for a, b in zip(preds_i, trues)]\n",
    "    #preds = np.concatenate(preds)\n",
    "    #trues = np.concatenate(trues)\n",
    "    return preds, trues, diffs\n",
    "\n",
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def calc_thresh_relaxed(trues, preds):\n",
    "    means = []\n",
    "    for thresh in tnrange(10, 90, 2):\n",
    "        tp = 0\n",
    "        fp = 0 \n",
    "        fn = 0\n",
    "        for i in range(len(trues)):\n",
    "            pred_c = np.copy(preds[i])\n",
    "            pred_c = np.array(pred_c.reshape((14, 14)))\n",
    "            pred_c[np.where(pred_c >= thresh / 100)] = 1.\n",
    "            pred_c[np.where(pred_c < thresh / 100)] = 0.\n",
    "           \n",
    "            \n",
    "            tpi, fpi, fni = compute_f1_score_at_tolerance(np.array(trues[i].reshape((14, 14))),\n",
    "                                                 pred_c)\n",
    "            tp += tpi\n",
    "            fp += fpi\n",
    "            fn += fni\n",
    "        ua = (tp) / (tp + fn)\n",
    "        pa = (tp) / (tp + fp)\n",
    "        print(thresh, ua, pa)\n",
    "        means.append((ua + pa) / 2)\n",
    "    \n",
    "    best_acc = np.max(means)\n",
    "    best_thresh = [x for x in range(10, 90, 2)][np.argmax(np.array(means))] / 100\n",
    "    return best_thresh\n",
    "\n",
    "def calc_thresh(trues, preds, threshold = None):\n",
    "    trues = np.array(trues).flatten()\n",
    "    preds = np.array(preds).flatten()\n",
    "    f1s = []\n",
    "    if not threshold:\n",
    "        for thresh in range(10, 90, 2):\n",
    "            pred_i = np.copy(preds)\n",
    "            pred_i[np.where(pred_i >= thresh / 100)] = 1.\n",
    "            pred_i[np.where(pred_i < thresh / 100)] = 0.\n",
    "            f1 = f1_score(trues, pred_i)\n",
    "            f1s.append(f1)\n",
    "        best_f1 = np.max(f1s)\n",
    "        best_thresh = [x for x in range(10, 90, 2)][np.argmax(np.array(f1s))] / 100\n",
    "    else:\n",
    "        pred_i = np.copy(preds)\n",
    "        pred_i[np.where(pred_i >= threshold)] = 1.\n",
    "        pred_i[np.where(pred_i < threshold)] = 0.\n",
    "        f1 = f1_score(trues, pred_i)\n",
    "        best_f1 = f1\n",
    "        best_thresh = threshold\n",
    "        \n",
    "    return best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8fae20c65c48559fd0d589004f5900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=153), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9069b5cc884b45e99f756d708b03bc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1.0 0.07096060203629925\n",
      "12 0.9968808484092326 0.07551271146394481\n",
      "14 0.9968808484092326 0.08100162206001622\n",
      "16 0.9900187149095446 0.08702089159401218\n",
      "18 0.9875233936369308 0.09545344910757357\n",
      "20 0.9806612601372426 0.10498898016429573\n",
      "22 0.9762944479101684 0.11596028452874926\n",
      "24 0.9669369931378665 0.12729960578186597\n",
      "26 0.9606986899563319 0.1413492427719137\n",
      "28 0.950093574547723 0.15924299456294438\n",
      "30 0.9451029320024953 0.18303733236679956\n",
      "32 0.9394884591391142 0.2096908939014202\n",
      "34 0.9301310043668122 0.23848368522072938\n",
      "36 0.9182782283218964 0.2720384402143781\n",
      "38 0.9045539613225203 0.3165938864628821\n",
      "40 0.8870867124142233 0.3704089606668403\n",
      "42 0.8565190268247037 0.42507739938080497\n",
      "44 0.8365564566437929 0.5077622112836047\n",
      "46 0.8128509045539614 0.5914661824784385\n",
      "48 0.7897691827822833 0.6712619300106044\n",
      "50 0.7573300062383032 0.7489204194941395\n",
      "52 0.7036805988771054 0.8203636363636364\n",
      "54 0.6668746101060512 0.8662884927066451\n",
      "56 0.6306924516531504 0.90999099909991\n",
      "58 0.5757953836556456 0.9323232323232323\n",
      "60 0.5265127885215222 0.9525959367945824\n",
      "62 0.4678727386150967 0.9652509652509652\n",
      "64 0.4098565190268247 0.9762258543833581\n",
      "66 0.3418590143480973 0.9873873873873874\n",
      "68 0.27386150966936995 0.9909706546275395\n",
      "70 0.23767935121646913 1.0\n",
      "72 0.198378041172801 1.0\n",
      "74 0.13162819713038054 1.0\n",
      "76 0.09107922645040549 1.0\n",
      "78 0.05240174672489083 1.0\n",
      "80 0.022457891453524642 1.0\n",
      "82 0.011852776044915784 1.0\n",
      "84 0.006238303181534623 1.0\n",
      "86 0.004366812227074236 1.0\n",
      "88 0.0 nan\n",
      "\n",
      "0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/.local/lib/python3.6/site-packages/ipykernel_launcher.py:82: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "preds, trues, diffs = run_predictions(test_x, test_y, debug = False)\n",
    "thresh = calc_thresh_relaxed(trues, preds)\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.36\n",
    "true_canopy = []\n",
    "error_canopy = []\n",
    "pred_canopy = []\n",
    "tp_softs = []\n",
    "fp_softs = []\n",
    "fn_softs = []\n",
    "for i in range(len(trues)):\n",
    "    preds[i][np.where(preds[i] >= thresh)] = 1.\n",
    "    preds[i][np.where(preds[i] < thresh)] = 0.\n",
    "    \n",
    "    true_canopy.append(np.sum(trues[i]) / 1.96)\n",
    "    error_canopy.append(abs(np.sum(preds[i]) - np.sum(trues[i])) / 1.96)\n",
    "    pred_canopy.append(np.sum(preds[i]) / 1.96)\n",
    "    tp_soft, fp_soft, fn_soft = compute_f1_score_at_tolerance(np.array(trues[i].reshape((14, 14))),\n",
    "                                                 np.array(preds[i].reshape((14, 14))))\n",
    "    tp_softs.append(tp_soft)\n",
    "    fp_softs.append(fp_soft)\n",
    "    fn_softs.append(fn_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6996117761242316 0.6969062197873026 30.310287380258224 32.3094543940025 39.556434818825494\n"
     ]
    }
   ],
   "source": [
    "precision = np.sum(tp_softs) / (np.sum(tp_softs) + np.sum(fp_softs))\n",
    "recall = np.sum(tp_softs) / (np.sum(tp_softs) + np.sum(fn_softs))\n",
    "print(precision, recall, np.mean(error_canopy), np.mean(true_canopy), np.mean(pred_canopy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
