{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "from osgeo import ogr, osr\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from scipy.ndimage import median_filter\n",
    "%run ../../src/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../../models/april-10/88-69-5/model\n"
     ]
    }
   ],
   "source": [
    "model = \"../../models/april-10/88-69-5/\"\n",
    "new_saver = tf.train.import_meta_graph(model + \"model.meta\")\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    try:\n",
    "        fm = tf.get_default_graph().get_tensor_by_name(\"conv2d_{}/Sigmoid:0\".format(i))\n",
    "    except Exception:\n",
    "        pass\n",
    "#logits = tf.get_default_graph().get_tensor_by_name(\"conv2d_11/Sigmoid:0\")\n",
    "inp = tf.get_default_graph().get_tensor_by_name(\"Placeholder:0\")\n",
    "labels = tf.get_default_graph().get_tensor_by_name(\"Placeholder_2:0\")\n",
    "rmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_4:0\")\n",
    "rmin = tf.get_default_graph().get_tensor_by_name(\"Placeholder_5:0\")\n",
    "length = tf.get_default_graph().get_tensor_by_name(\"Placeholder_1:0\")\n",
    "dmax = tf.get_default_graph().get_tensor_by_name(\"Placeholder_6:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_all = [0.20792677521705638,\n",
    " 0.2990041905641556,\n",
    " 0.4360648360848427,\n",
    " 0.5161105132102968,\n",
    " 0.4825860628485681,\n",
    " 0.4943232241272928,\n",
    " 0.5178957056999209,\n",
    " 0.5291672283411026,\n",
    " 0.6659183305501939,\n",
    " 0.6092100739479065,\n",
    " 0.37346625328063965,\n",
    " 0.7162704998254776,\n",
    " 0.40363759160041823,\n",
    " 0.6478493613004686,\n",
    " 0.8438000082969666,\n",
    " 0.15365000069141388]\n",
    "\n",
    "min_all = [0.01872335869818926,\n",
    " 0.03467957343906164,\n",
    " 0.021185510214418172,\n",
    " 0.08898216009140014,\n",
    " 0.052402322441339494,\n",
    " 0.07628638863563539,\n",
    " 0.083824477866292,\n",
    " 0.08768215030431747,\n",
    " 0.05718051139265299,\n",
    " 0.0372315139323473,\n",
    " 0.0,\n",
    " 0.007564654648303981,\n",
    " -0.019136652257293465,\n",
    " 0.0064204379683360435,\n",
    " 0.006225000135600567,\n",
    " 4.999999873689376e-05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 24, 16, 16, 17)\n",
      "There are 0 outliers: []\n",
      "\n",
      "\n",
      "[] []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a5b8c517e8461593146556e5c73997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=153), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The data has been scaled to [-1.0, 1.0]\n",
      "(153, 24, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "test_x = np.load(\"../../tile_data/processed/test_x_l2a_processed.npy\")\n",
    "print(test_x.shape)\n",
    "test_y = np.load(\"../../tile_data/processed/test_y_l2a_processed.npy\")\n",
    "test_lengths = np.load(\"../../tile_data/processed/test_length_l2a_processed.npy\")\n",
    "\n",
    "test_x = np.delete(test_x, 14, -1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.5]\n",
    "above_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.5]\n",
    "min_vals = [np.min(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.5]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "print(\"There are {} outliers: {}\".format(len(outliers), outliers))\n",
    "print(\"\\n\")\n",
    "print(min_vals, max_vals)\n",
    "        \n",
    "test_x = test_x[[x for x in range(0, len(test_x)) if x not in outliers]]\n",
    "test_y = test_y[[x for x in range(0, len(test_y)) if x not in outliers]]\n",
    "test_lengths = test_lengths[[x for x in range(0, len(test_lengths)) if x not in outliers]]\n",
    "\n",
    "for sample in tnrange(0, len(test_x)):\n",
    "    filtered = median_filter(test_x[sample, 0, :, :, 10], size = 5)\n",
    "    filtered = np.reshape(filtered, (8, 2, 8, 2))\n",
    "    filtered = np.mean(filtered, axis = (1, 3))\n",
    "    filtered = resize(filtered, (16, 16), 0)\n",
    "    test_x[sample, :, :, :, 10] = np.stack([filtered] * 24)\n",
    "    \n",
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[:, :, :, :, band] = np.clip(test_x[:, :, :, :, band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[:, :, :, :, band] - midrange) / (rng / 2)\n",
    "    test_x[:, :, :, :, band] = standardized\n",
    "    \n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(test_x), np.max(test_x)))\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipping_params = {\n",
    "    'rmax': rmax,\n",
    "    'rmin': rmin,\n",
    "    'dmax': dmax\n",
    "}\n",
    "\n",
    "\n",
    "def run_predictions(x, y, lengths, debug = False):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    diffs = None\n",
    "    for sample in tnrange(x.shape[0]):\n",
    "        if sample not in [558, 563, 596, 599, 602, 615, 634]:\n",
    "            pred = sess.run([fm], feed_dict={inp: x[sample].reshape(1, 24, 16, 16, 16),\n",
    "                                      length: lengths[sample].reshape(1, 1),\n",
    "                                      clipping_params['rmax']: 5,\n",
    "                                      clipping_params['rmin']: 0,\n",
    "                                      clipping_params['dmax']: 3,\n",
    "                                      })\n",
    "            preds.append(np.array(pred))\n",
    "            trues.append(y[sample])\n",
    "    if debug:\n",
    "        thresh = 0.58\n",
    "        preds_i = np.copy(preds)\n",
    "        for i in range(len(preds_i)):\n",
    "            preds_i[i] = np.array(preds_i[i])\n",
    "            preds_i[i][np.where(preds_i[i] >= thresh)] = 1.\n",
    "            preds_i[i][np.where(preds_i[i] < thresh)] = 0.\n",
    "        diffs = [abs(np.sum(np.array(a)) - np.sum(np.array(b))) for a, b in zip(preds_i, trues)]\n",
    "    #preds = np.concatenate(preds)\n",
    "    #trues = np.concatenate(trues)\n",
    "    return preds, trues, diffs\n",
    "\n",
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def calc_thresh_relaxed(trues, preds):\n",
    "    means = []\n",
    "    for thresh in tnrange(10, 90, 2):\n",
    "        tp = 0\n",
    "        fp = 0 \n",
    "        fn = 0\n",
    "        for i in range(len(trues)):\n",
    "            pred_c = np.copy(preds[i])\n",
    "            pred_c = np.array(pred_c.reshape((14, 14)))\n",
    "            pred_c[np.where(pred_c >= thresh / 100)] = 1.\n",
    "            pred_c[np.where(pred_c < thresh / 100)] = 0.\n",
    "           \n",
    "            \n",
    "            tpi, fpi, fni = compute_f1_score_at_tolerance(np.array(trues[i].reshape((14, 14))),\n",
    "                                                 pred_c)\n",
    "            tp += tpi\n",
    "            fp += fpi\n",
    "            fn += fni\n",
    "        ua = (tp) / (tp + fn)\n",
    "        pa = (tp) / (tp + fp)\n",
    "        print(thresh, ua, pa)\n",
    "        means.append((ua + pa) / 2)\n",
    "    \n",
    "    best_acc = np.max(means)\n",
    "    best_thresh = [x for x in range(10, 90, 2)][np.argmax(np.array(means))] / 100\n",
    "    return best_thresh\n",
    "\n",
    "def calc_thresh(trues, preds, threshold = None):\n",
    "    trues = np.array(trues).flatten()\n",
    "    preds = np.array(preds).flatten()\n",
    "    f1s = []\n",
    "    if not threshold:\n",
    "        for thresh in range(10, 90, 2):\n",
    "            pred_i = np.copy(preds)\n",
    "            pred_i[np.where(pred_i >= thresh / 100)] = 1.\n",
    "            pred_i[np.where(pred_i < thresh / 100)] = 0.\n",
    "            f1 = f1_score(trues, pred_i)\n",
    "            f1s.append(f1)\n",
    "        best_f1 = np.max(f1s)\n",
    "        best_thresh = [x for x in range(10, 90, 2)][np.argmax(np.array(f1s))] / 100\n",
    "    else:\n",
    "        pred_i = np.copy(preds)\n",
    "        pred_i[np.where(pred_i >= threshold)] = 1.\n",
    "        pred_i[np.where(pred_i < threshold)] = 0.\n",
    "        f1 = f1_score(trues, pred_i)\n",
    "        best_f1 = f1\n",
    "        best_thresh = threshold\n",
    "        \n",
    "    return best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3109a529f8c64e1cab7823d0827dcd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=153), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31661e7a3474ccc80a31264ed415e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9887710542732376 0.11149409116488464\n",
      "12 0.9850280723643169 0.1422394378884785\n",
      "14 0.974422956955708 0.1719696135638005\n",
      "16 0.9644416718652526 0.20151199165797706\n",
      "18 0.9638178415470992 0.23198198198198197\n",
      "20 0.950093574547723 0.25804811928159943\n",
      "22 0.9413599500935745 0.28671860155804674\n",
      "24 0.933873986275733 0.31350785340314136\n",
      "26 0.9332501559575795 0.33915211970074816\n",
      "28 0.9270118527760449 0.3649312377210216\n",
      "30 0.9238927011852776 0.392317880794702\n",
      "32 0.9195258889582034 0.4245391705069124\n",
      "34 0.9182782283218964 0.4504283965728274\n",
      "36 0.9139114160948222 0.4790712884238064\n",
      "38 0.9114160948222083 0.5055363321799308\n",
      "40 0.9070492825951342 0.5339698861549761\n",
      "42 0.9001871490954461 0.5537221795855718\n",
      "44 0.8902058640049907 0.5810260586319218\n",
      "46 0.8877105427323768 0.6099442777539649\n",
      "48 0.8808484092326887 0.6363226678684092\n",
      "50 0.875857766687461 0.6632026452527161\n",
      "52 0.8683718028696195 0.689108910891089\n",
      "54 0.8627573300062383 0.7195629552549427\n",
      "56 0.8540237055520898 0.7456427015250545\n",
      "58 0.8402994385527136 0.7728055077452668\n",
      "60 0.8303181534622582 0.8047158403869408\n",
      "62 0.8153462258265751 0.8246056782334384\n",
      "64 0.8041172800998129 0.8508250825082508\n",
      "66 0.7878976918278229 0.8662551440329218\n",
      "68 0.7623206487835309 0.8810382119682768\n",
      "70 0.7379912663755459 0.9023646071700991\n",
      "72 0.7167810355583282 0.9192\n",
      "74 0.6974422956955708 0.9308909242298085\n",
      "76 0.6699937616968185 0.9487632508833922\n",
      "78 0.6313162819713038 0.9601518026565465\n",
      "80 0.5970056144728634 0.9666666666666667\n",
      "82 0.5315034310667498 0.9793103448275862\n",
      "84 0.47723019338739864 0.982028241335045\n",
      "86 0.4192139737991266 0.9896907216494846\n",
      "88 0.3686837180286962 0.9966273187183811\n",
      "\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "preds, trues, diffs = run_predictions(test_x, test_y, test_lengths, debug = False)\n",
    "thresh = calc_thresh_relaxed(trues, preds)\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_canopy = []\n",
    "error_canopy = []\n",
    "pred_canopy = []\n",
    "tp_softs = []\n",
    "fp_softs = []\n",
    "fn_softs = []\n",
    "for i in range(len(trues)):\n",
    "    preds[i][np.where(preds[i] >= thresh)] = 1.\n",
    "    preds[i][np.where(preds[i] < thresh)] = 0.\n",
    "    \n",
    "    true_canopy.append(np.sum(trues[i]) / 1.96)\n",
    "    error_canopy.append(abs(np.sum(preds[i]) - np.sum(trues[i])) / 1.96)\n",
    "    pred_canopy.append(np.sum(preds[i]) / 1.96)\n",
    "    tp_soft, fp_soft, fn_soft = compute_f1_score_at_tolerance(np.array(trues[i].reshape((14, 14))),\n",
    "                                                 np.array(preds[i].reshape((14, 14))))\n",
    "    tp_softs.append(tp_soft)\n",
    "    fp_softs.append(fp_soft)\n",
    "    fn_softs.append(fn_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9760131210278138 0.9874853073359607 11.280612244897961 73.79081632653062 83.21428571428571\n"
     ]
    }
   ],
   "source": [
    "precision = np.sum(tp_softs) / (np.sum(tp_softs) + np.sum(fp_softs))\n",
    "recall = np.sum(tp_softs) / (np.sum(tp_softs) + np.sum(fn_softs))\n",
    "print(precision, recall, np.mean(error_canopy), np.mean(true_canopy), np.mean(pred_canopy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wall to wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
