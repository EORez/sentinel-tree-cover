{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree segmentation with multitemporal Sentinel 1/2 imagery\n",
    "\n",
    "## John Brandt\n",
    "## April 02, 2020\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook contains the TensorFlow model training and prediction used to segment trees for [Restoration Mapper](https://restorationmapper.org). The notebook uses tensorflow 1.13.1 and additionally relies on Keras and tflearn. \n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Package loading\n",
    "- Utility scripts\n",
    "- Hyperparameter definitions\n",
    "- Custom tensorflow layer functions\n",
    "- Tensorflow graph creation\n",
    "- Data loading\n",
    "- Data preprocessing\n",
    "- Equibatch creation\n",
    "- Loss definition\n",
    "- Tensorflow graph initialization\n",
    "- Training\n",
    "- Model validation\n",
    "- Sanity Checks\n",
    "\n",
    "## Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.keras.layers import Conv2D, Lambda, Dense, Multiply, Add\n",
    "from tensorflow.python.keras.activations import selu\n",
    "from tensorflow.initializers import glorot_normal, lecun_normal\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim import conv2d\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.layers import batch_normalization\n",
    "from tensorflow.python.util import deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/layers/zoneout.py\n",
    "%run ../src/layers/convgru.py\n",
    "%run ../src/layers/adabound.py\n",
    "%run ../src/layers/dropblock.py\n",
    "%run ../src/layers/extra_layers.py\n",
    "%run ../src/preprocessing/indices.py\n",
    "%run ../src/preprocessing/slope.py\n",
    "%run ../src/utils/metrics.py\n",
    "%run ../src/not_for_release/lovasz.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONE_OUT_PROB = 0.20 #0.2 for master model\n",
    "GRU_FILTERS = 32\n",
    "FPA_FILTERS = 28\n",
    "OUT_FILTERS = 32\n",
    "AVERAGE_GRU_FILTERS = True\n",
    "ACTIVATION_FUNCTION = 'relu'\n",
    "\n",
    "INITIAL_LR = 1e-4\n",
    "FINAL_LR = 2e-2\n",
    "DROPBLOCK_MAXSIZE = 5\n",
    "DECONV = 'bilinear'\n",
    "N_CONV_BLOCKS = 1\n",
    "FINAL_ALPHA = 0.7\n",
    "LABEL_SMOOTHING = 0.10 #0.075 for master\n",
    "BATCH_RENORM = 'norm'\n",
    "\n",
    "L2_REG = 0.0\n",
    "BN_MOMENTUM = 0.9\n",
    "BATCH_SIZE = 16\n",
    "MAX_DROPBLOCK = 0.85\n",
    "\n",
    "gru_flt = 32\n",
    "fpa_flt = 28\n",
    "out_conv_flt = 32\n",
    "\n",
    "IMAGE_SIZE = 16\n",
    "LABEL_SIZE = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter grid search definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 3.8 million combinations of hyperparameters\n",
    "params = {\n",
    "    'zone_out' : [0],#range(0, 0.5, 0.1), #6\n",
    "    'gru_filters': [0], #range(16, 64, 8), #6\n",
    "    'fpa_filters': [0], #range(24, 48, 4), # 6\n",
    "    'out_conv_filter': range(16, 64, 16), # 5\n",
    "    'average_gru_filters': [True, False], # 2\n",
    "    'activation_function': ['relu', 'selu', 'elu'], # relu > elu ? selu\n",
    "    'final_lr': [5e-3, 1e-2, 2e-2, 5e-2], # 4\n",
    "    'dropblock_maxsize': [7, 6, 5, 4, 3], # 5\n",
    "    'deconv': ['bilinear', 'convtranspose2d'], # 2\n",
    "    'n_conv_blocks': [3, 2, 1], # 3\n",
    "    'final_alpha': [0.8, 0.75, 0.7, 0.65, 0.6], #5\n",
    "    'label_smoothing': [0., 0.025, 0.05, 0.075, 0.10, 0.125],\n",
    "    'batch_renorm': ['renorm', 'norm']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom layer definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility blocks (Batch norm, cSSE, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batch_Normalization(x, training, scope, clipping_params):\n",
    "    '''Batch renormalization layer from tensorflow.layers\n",
    "\n",
    "         Parameters:\n",
    "          x (tf.Variable): input layer\n",
    "          training (tf.Variable): flag to differentiate between train/test ops\n",
    "          scope (str): tensorflow scope\n",
    "          clipping_params (dict): specifies clipping of \n",
    "                                  rmax, dmax, rmin for renormalization\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of batch renormalization\n",
    "          \n",
    "         References:\n",
    "          https://github.com/tensorflow/docs/blob/r1.13/site/en/\n",
    "          api_docs/python/tf/layers/batch_normalization.md\n",
    "    '''\n",
    "    return batch_normalization(inputs=x, \n",
    "                               momentum = BN_MOMENTUM, \n",
    "                               training=training,\n",
    "                               renorm = True,\n",
    "                               reuse=None,\n",
    "                               renorm_clipping = clipping_params,\n",
    "                               name = scope)\n",
    "\n",
    "\n",
    "def calc_renorm_params(epoch, n_samples, batch_size, k = 0):\n",
    "    '''Calculates the clipping parameters for renormalization\n",
    "       based on the learning schedule outlined in the original paper\n",
    "       where rmax is initialized to 1, dmax to 0, rmin to 0,\n",
    "       (effectively batch normalization), and then rmax and dmax\n",
    "       are gradually reaxed to 3 and 5 over 40k and 25k steps,\n",
    "       respectively. In this case, 40k has been reduced to 30k, and 25k\n",
    "       has been reduced to 20k.\n",
    "\n",
    "         Parameters:\n",
    "          epoch (int): number of current training epoch\n",
    "                       if testing, epoch number of model used\n",
    "          n_samples (int): total number of training samples\n",
    "          batch_size (int): training batch size \n",
    "\n",
    "         Returns:\n",
    "          rmax (float)\n",
    "          dmax (float)\n",
    "          rmin (float)\n",
    "    '''\n",
    "    step = epoch * (n_samples // batch_size)\n",
    "    step += k\n",
    "    if step < 2500:\n",
    "        rmax = 1.\n",
    "        dmax = 0.\n",
    "        rmin = 0.\n",
    "    if step >= 2500:\n",
    "        rmax = np.min([1 + 2*((step-2500)/20000), 3])\n",
    "        dmax = np.min([1 + 5*((step-2500)/15000), 5])\n",
    "        rmin = 0.\n",
    "    return rmax, dmax, rmin\n",
    "\n",
    "def cse_block(prevlayer, prefix):\n",
    "    '''Channel excitation and spatial squeeze layer. \n",
    "       Calculates the mean of the spatial dimensions and then learns\n",
    "       two dense layers, one with relu, and one with sigmoid, to rerank the\n",
    "       input channels\n",
    "       \n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the cse_block\n",
    "    '''\n",
    "    mean = Lambda(lambda xin: K.mean(xin, axis=[1, 2]))(prevlayer)\n",
    "    lin1 = Dense(K.int_shape(prevlayer)[3] // 2, name=prefix + 'cse_lin1', activation='relu')(mean)\n",
    "    lin2 = Dense(K.int_shape(prevlayer)[3], name=prefix + 'cse_lin2', activation='sigmoid')(lin1)\n",
    "    x = Multiply()([prevlayer, lin2])\n",
    "    return x\n",
    "\n",
    "\n",
    "def sse_block(prevlayer, prefix):\n",
    "    '''Spatial excitation and channel squeeze layer.\n",
    "       Calculates a 1x1 convolution with sigmoid activation to create a \n",
    "       spatial map that is multiplied by the input layer\n",
    "\n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the sse_block\n",
    "    '''\n",
    "    conv = Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=\"glorot_uniform\",\n",
    "                  activation='sigmoid', strides=(1, 1),\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
    "    return conv\n",
    "\n",
    "\n",
    "def csse_block(x, prefix):\n",
    "    '''Implementation of Concurrent Spatial and Channel \n",
    "       ‘Squeeze & Excitation’ in Fully Convolutional Networks\n",
    "    \n",
    "        Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): added output of cse and sse block\n",
    "          \n",
    "         References:\n",
    "          https://arxiv.org/abs/1803.02579\n",
    "    '''\n",
    "    cse = cse_block(x, prefix)\n",
    "    sse = sse_block(x, prefix)\n",
    "    x = Add(name=prefix + \"_csse_mul\")([cse, sse])\n",
    "\n",
    "    return x\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv GRU Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_block(inp, length, size, flt, scope, train, normalize = True):\n",
    "    '''Bidirectional convolutional GRU block with \n",
    "       zoneout and CSSE blocks in each time step\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): (B, T, H, W, C) layer\n",
    "          length (tf.Variable): (B, T) layer denoting number of\n",
    "                                steps per sample\n",
    "          size (int): kernel size of convolution\n",
    "          flt (int): number of convolution filters\n",
    "          scope (str): tensorflow variable scope\n",
    "          train (tf.Bool): flag to differentiate between train/test ops\n",
    "          normalize (bool): whether to compute layer normalization\n",
    "\n",
    "         Returns:\n",
    "          gru (tf.Variable): (B, H, W, flt*2) bi-gru output\n",
    "          steps (tf.Variable): (B, T, H, W, flt*2) output of each step\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        print(\"GRU input shape {}, zoneout: {}\".format(inp.shape, ZONE_OUT_PROB))\n",
    "        cell_fw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        cell_bw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', normalize = normalize, sse = True)\n",
    "        cell_fw = ZoneoutWrapper(\n",
    "           cell_fw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        cell_bw = ZoneoutWrapper(\n",
    "            cell_bw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        steps, out = convGRU(inp, cell_fw, cell_bw, length)\n",
    "        gru = tf.concat(out, axis = -1)\n",
    "        steps = tf.concat(steps, axis = -1)\n",
    "        print(\"Down block output shape {}\".format(gru.shape))\n",
    "    return gru, steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_selu(inp, is_training, kernel_size, scope,\n",
    "                filter_count = 16, pad = True, padding = 'valid', dilated = False,\n",
    "                activation = True):\n",
    "    '''Convolutional 2D layer with SELU activation and Lecun normal initialization\n",
    "       with no batch norm. Only used if params['activation'] = 'selu'\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): (B, H, W, C) input layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          kernel_size (int): kernel size of convolution\n",
    "          scope (str): tensorflow variable scope\n",
    "          filter_count (int): number of convolution filters\n",
    "          pad (bool): whether or not to reflect pad input\n",
    "          padding (str): one of ['valid', 'same']\n",
    "          dilated (bool): whether to perform atruous convolution\n",
    "          activation (bool): whether to activate output\n",
    "\n",
    "         Returns:\n",
    "          conv (tf.Variable): output of Conv2D -> SELU\n",
    "          \n",
    "         References:\n",
    "          https://arxiv.org/abs/1706.02515\n",
    "    '''\n",
    "    if activation:\n",
    "        act = selu\n",
    "    else:\n",
    "        act = None\n",
    "    if not dilated:\n",
    "        padded = ReflectionPadding2D((1, 1,))(inp)\n",
    "        conv = Conv2D(filters = filter_count, kernel_size = (kernel_size, kernel_size), activation = act,\n",
    "                        padding = padding, kernel_initializer = lecun_normal())(padded)\n",
    "    if not dilated and not pad:\n",
    "        conv = Conv2D(filters = filter_count, kernel_size = (kernel_size, kernel_size), activation = act,\n",
    "                        padding = padding, kernel_initializer = lecun_normal())(inp)\n",
    "    if dilated:\n",
    "        padded = ReflectionPadding2D((2, 2,))(inp)\n",
    "        conv = Conv2D(filters = filter_count, kernel_size = (3, 3), activation = act, dilation_rate = (2, 2),\n",
    "                        padding = padding, kernel_initializer = lecun_normal())(padded)\n",
    "    return conv\n",
    "\n",
    "def conv_bn_relu(inp, \n",
    "                 is_training, \n",
    "                 kernel_size,\n",
    "                 scope,\n",
    "                 filters, \n",
    "                 clipping_params,\n",
    "                 keep_rate,\n",
    "                 stride = (1, 1),\n",
    "                 activation = True,\n",
    "                 use_bias = False,\n",
    "                 batch_norm = True,\n",
    "                 dropblock = True,\n",
    "                 csse = True):\n",
    "    '''2D convolution, batch renorm, relu block, 3x3 drop block. \n",
    "       Use_bias must be set to False for batch normalization to work. \n",
    "       He normal initialization is used with batch normalization.\n",
    "       RELU is better applied after the batch norm.\n",
    "       DropBlock performs best when applied last, according to original paper.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          kernel_size (int): size of convolution\n",
    "          scope (str): tensorflow variable scope\n",
    "          filters (int): number of filters for convolution\n",
    "          clipping_params (dict): specifies clipping of \n",
    "                                  rmax, dmax, rmin for renormalization\n",
    "          activation (bool): whether to apply RELU\n",
    "          use_bias (str): whether to use bias. Should always be false\n",
    "\n",
    "         Returns:\n",
    "          bn (tf.Variable): output of Conv2D -> Batch Norm -> RELU\n",
    "        \n",
    "         References:\n",
    "          http://papers.nips.cc/paper/8271-dropblock-a-regularization-\n",
    "              method-for-convolutional-networks.pdf\n",
    "          https://arxiv.org/abs/1702.03275\n",
    "          \n",
    "    '''\n",
    "    \n",
    "    bn_flag = \"Batch Renorm\" if batch_norm else \"\"\n",
    "    activation_flag = \"RELU\" if activation else \"Linear\"\n",
    "    csse_flag = \"CSSE\" if csse else \"No CSSE\"\n",
    "    bias_flag = \"Bias\" if use_bias else \"NoBias\"\n",
    "    drop_flag = \"DropBlock\" if dropblock else \"NoDrop\"\n",
    "        \n",
    "    \n",
    "    print(\"{} {} Conv 2D {} {} {} {} {}\".format(scope, kernel_size,\n",
    "                                                   bn_flag, activation_flag,\n",
    "                                                   csse_flag, bias_flag, drop_flag))\n",
    "    \n",
    "    with tf.variable_scope(scope + \"_conv\"):\n",
    "        conv = Conv2D(filters = filters, kernel_size = (kernel_size, kernel_size),  strides = stride,\n",
    "                      activation = None, padding = 'valid', use_bias = use_bias,\n",
    "                      kernel_initializer = tf.keras.initializers.he_normal())(inp)\n",
    "    if batch_norm:\n",
    "        conv = Batch_Normalization(conv, is_training, scope, clipping_params)\n",
    "    if activation:\n",
    "        conv = tf.nn.relu(conv)\n",
    "    if csse:\n",
    "        conv = csse_block(conv, 'csse_' + scope)\n",
    "    if dropblock: \n",
    "        with tf.variable_scope(scope + \"_drop\"):\n",
    "            drop_block = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "            conv = drop_block(conv, is_training)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def create_deconv_init(filter_size, num_channels):\n",
    "    '''Initializes a kernel weight matrix with a bilinear deconvolution\n",
    "    \n",
    "         Parameters:\n",
    "          filter_size (int): kernel size of convolution\n",
    "          num_channels (int): number of filters for convolution\n",
    "\n",
    "         Returns:\n",
    "          bilinear_init (tf.Variable): [filter_size, filter_size, num_channels] kernel\n",
    "    '''\n",
    "    bilinear_kernel = np.zeros([filter_size, filter_size], dtype=np.float32)\n",
    "    scale_factor = (filter_size + 1) // 2\n",
    "    if filter_size % 2 == 1:\n",
    "        center = scale_factor - 1\n",
    "    else:\n",
    "        center = scale_factor - 0.5\n",
    "    for x in range(filter_size):\n",
    "        for y in range(filter_size):\n",
    "            bilinear_kernel[x,y] = (1 - abs(x - center) / scale_factor) * \\\n",
    "                                   (1 - abs(y - center) / scale_factor)\n",
    "    weights = np.zeros((filter_size, filter_size, num_channels, num_channels))\n",
    "    for i in range(num_channels):\n",
    "        weights[:, :, i, i] = bilinear_kernel\n",
    "\n",
    "    #assign numpy array to constant_initalizer and pass to get_variable\n",
    "    bilinear_init = tf.constant_initializer(value=weights, dtype=tf.float32)\n",
    "    return bilinear_init\n",
    "\n",
    "def get_deconv2d(inp, filter_count, num_channels, scope, is_training, clipping_params):\n",
    "    '''Creates a deconvolution layer with Conv2DTranspose. Following recent\n",
    "       recommendations to use 4 kernel, 2 stride to avoid artifacts. \n",
    "       Initialize kernel with bilinear upsampling.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input tensorflow layer (B, X, Y, C) shape\n",
    "          filter_count (int): number of filters for convolution\n",
    "          num_channels (int): number of output channels\n",
    "          scope (str): tensorflow variable scope\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          clipping_params (dict): specifies clipping of \n",
    "                                  rmax, dmax, rmin for renormalization\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): layer with (B, x * 2, y * 2, C) shape\n",
    "          \n",
    "         References:\n",
    "          https://distill.pub/2016/deconv-checkerboard/\n",
    "    '''\n",
    "    bilinear_init = create_deconv_init(4, filter_count)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters = filter_count, kernel_size = (4, 4),\n",
    "                                        strides=(2, 2), padding='same', \n",
    "                                        use_bias = False,\n",
    "                                        kernel_initializer = bilinear_init)(inp)\n",
    "    #x = ELU()(x)\n",
    "    #x = tf.nn.relu(x)\n",
    "    x = Batch_Normalization(x, training=is_training, scope = scope + \"bn\", clipping_params = clipping_params)\n",
    "    return x\n",
    "    \n",
    "def fpa(inp, is_training, filter_count, clipping_params, \n",
    "        keep_rate, upsample = \"upconv\"):\n",
    "    '''Feature pyramid attention layer block, that allows for cross-scale combination\n",
    "       of different size features without making blurry feature maps.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input tensorflow layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          filter_count (int): number of filters for convolution\n",
    "          clipping_params (dict): specifies clipping of \n",
    "                                  rmax, dmax, rmin for renormalization\n",
    "\n",
    "         Returns:\n",
    "          concat_1 (tf.Variable): output of FPA\n",
    "          \n",
    "         References:\n",
    "          https://arxiv.org/abs/1805.10180\n",
    "    '''\n",
    "    one = conv_bn_relu(inp = inp, is_training = is_training, \n",
    "                       kernel_size = 1, scope =  'forward1',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = False,\n",
    "                       use_bias = False, batch_norm = True,\n",
    "                       dropblock = False,\n",
    "                       csse = False)\n",
    "    \n",
    "    seven = conv_bn_relu(inp = inp_pad, is_training = is_training, \n",
    "                       kernel_size = 7, scope =  'down1',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, csse = True, dropblock = False)\n",
    "    \n",
    "    seven_f = conv_bn_relu(inp = seven, is_training = is_training, \n",
    "                       kernel_size = 7, scope =  'down1_f',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = False,\n",
    "                       use_bias = False, batch_norm = True, csse = False, dropblock = False)\n",
    "    \n",
    "    five = conv_bn_relu(inp = seven, is_training = is_training, \n",
    "                       kernel_size = 5, scope =  'down2',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, csse = True, dropblock = False)\n",
    "    \n",
    "    five_f = conv_bn_relu(inp = five, is_training = is_training, \n",
    "                       kernel_size = 5, scope =  'down2_f',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = False,\n",
    "                       use_bias = False, batch_norm = True, csse = False, dropblock = False)\n",
    "    \n",
    "    three = conv_bn_relu(inp = five, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'down3',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, csse = True, dropblock = False)\n",
    "    \n",
    "    three_f = conv_bn_relu(inp = three, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'down3_f', stride = (2, 2),\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = False,\n",
    "                       use_bias = False, batch_norm = True, csse = True, dropblock = False)\n",
    "        \n",
    "    \n",
    "    if upsample == 'upconv' or 'bilinear':\n",
    "        three_up = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'bilinear')(three_f)\n",
    "        if upsample == 'upconv':\n",
    "            three_up = ReflectionPadding2D((1, 1,))(three_up)\n",
    "            three_up = conv_bn_relu(inp = three_up, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'upconv1',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True,\n",
    "                       csse = False, dropblock = False)\n",
    "            \n",
    "            # 4x4\n",
    "            three_up = tf.nn.relu(tf.add(three_up, five_f))\n",
    "            \n",
    "    \n",
    "    if upsample == 'upconv' or \"bilinear\":\n",
    "        five_up = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'bilinear')(three_up)\n",
    "        if upsample == 'upconv':\n",
    "            five_up = ReflectionPadding2D((1, 1,))(five_up)\n",
    "            five_up = conv_bn_relu(inp = five_up, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'upconv2',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, \n",
    "                       csse = False, dropblock = False)\n",
    "            five_up = tf.nn.relu(tf.add(five_up, seven_f))\n",
    "            \n",
    "    if upsample == 'upconv' or \"bilinear\":\n",
    "        seven_up = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'bilinear')(five_up)\n",
    "        if upsample == 'upconv':\n",
    "            seven_up = ReflectionPadding2D((1, 1,))(seven_up)\n",
    "            seven_up = conv_bn_relu(inp = seven_up, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'upconv3',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, \n",
    "                       csse = False, dropblock = False)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    print(\"One: {}\".format(one.shape))\n",
    "    print(\"Seven: {}\".format(seven.shape))\n",
    "    print(\"Seven f: {}\".format(seven_f.shape))\n",
    "    print(\"Five: {}\".format(five.shape))\n",
    "    print(\"Five_F: {}\".format(five_f.shape))\n",
    "    print(\"Three: {}\".format(three.shape))\n",
    "    print(\"Three_f: {}\".format(three_f.shape))\n",
    "    print(\"Three_up: {}\".format(three_up.shape))\n",
    "    print(\"Five_up: {}\".format(five_up.shape))\n",
    "    print(\"Seven_up: {}\".format(seven_up.shape))\n",
    "    \n",
    "    # top block\n",
    "\n",
    "    #pooled = tf.keras.layers.GlobalAveragePooling2D()(inp)\n",
    "    #one_top = conv_bn_relu(inp = tf.reshape(pooled, (-1, 1, 1, pooled.shape[-1])),\n",
    "    #                       is_training = is_training, \n",
    "    #                   kernel_size = 1, scope =  'topconv',\n",
    "    #                   filters = filter_count, clipping_params = clipping_params,\n",
    "    #                   keep_rate = keep_rate, activation = False,\n",
    "    #                   use_bias = False, batch_norm = True, \n",
    "    #                   csse = False, dropblock = False)\n",
    "    #one_top = conv_bn_relu(tf.reshape(pooled, (-1, 1, 1, pooled.shape[-1])),\n",
    "    ##                      is_training, 1, 'top1', filter_count, pad = False)\n",
    "    #four_top = tf.keras.layers.UpSampling2D((16, 16))(one_top)\n",
    "    \n",
    "    seven_up = tf.multiply(one, seven_up)\n",
    "    out = tf.nn.relu(seven_up + four_top)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpa(inp, is_training, filter_count, clipping_params, \n",
    "        keep_rate, upsample = \"upconv\"):\n",
    "    '''Feature pyramid attention layer block, that allows for cross-scale combination\n",
    "       of different size features without making blurry feature maps.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input tensorflow layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          filter_count (int): number of filters for convolution\n",
    "          clipping_params (dict): specifies clipping of \n",
    "                                  rmax, dmax, rmin for renormalization\n",
    "\n",
    "         Returns:\n",
    "          concat_1 (tf.Variable): output of FPA\n",
    "          \n",
    "         References:\n",
    "          https://arxiv.org/abs/1805.10180\n",
    "    '''\n",
    "    one = conv_bn_relu(inp = inp, is_training = is_training, \n",
    "                       kernel_size = 1, scope =  'forward1',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = False,\n",
    "                       use_bias = False, batch_norm = True,\n",
    "                       dropblock = False,\n",
    "                       csse = False)\n",
    "    inp_pad = ReflectionPadding2D(padding = (2, 2))(inp)\n",
    "    seven = conv_bn_relu(inp = inp_pad, is_training = is_training, \n",
    "                       kernel_size = 5, scope =  'down1', stride = (2, 2),\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, csse = True, dropblock = False)\n",
    "    seven_pad = ReflectionPadding2D(padding = (2, 2))(seven)\n",
    "    seven_f = conv_bn_relu(inp = seven_pad, is_training = is_training, \n",
    "                       kernel_size = 5, scope =  'down1_f',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = False,\n",
    "                       use_bias = False, batch_norm = True, csse = False, dropblock = False)\n",
    "    \n",
    "    print(\"Seven: {}\".format(seven.shape))\n",
    "    print(\"Seven f: {}\".format(seven_f.shape))\n",
    "    \n",
    "    five_pad = ReflectionPadding2D(padding = (1, 1))(seven)\n",
    "    five = conv_bn_relu(inp = five_pad, is_training = is_training,  stride = (2, 2),\n",
    "                       kernel_size = 3, scope =  'down2',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, csse = True, dropblock = False)\n",
    "    \n",
    "    five_pad2 = ReflectionPadding2D(padding = (1, 1))(five)\n",
    "    five_f = conv_bn_relu(inp = five_pad2, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'down2_f',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = False,\n",
    "                       use_bias = False, batch_norm = True, csse = False, dropblock = False)\n",
    "    print(\"Five: {}\".format(five.shape))\n",
    "    print(\"Five_F: {}\".format(five_f.shape))\n",
    "    '''\n",
    "    three_pad = ReflectionPadding2D(padding = (1, 1))(five)\n",
    "    three = conv_bn_relu(inp = three_pad, is_training = is_training,  stride = (2, 2),\n",
    "                       kernel_size = 3, scope =  'down3',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, csse = True, dropblock = False)\n",
    "    \n",
    "    three_pad2 = ReflectionPadding2D(padding = (1, 1))(three)\n",
    "    three_f = conv_bn_relu(inp = three_pad2, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'down3_f',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = False,\n",
    "                       use_bias = False, batch_norm = True, csse = True, dropblock = False)\n",
    "        \n",
    "    \n",
    "    if upsample == 'upconv' or 'bilinear':\n",
    "        three_up = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'bilinear')(three_f)\n",
    "        if upsample == 'upconv':\n",
    "            three_up = ReflectionPadding2D((1, 1,))(three_up)\n",
    "            three_up = conv_bn_relu(inp = three_up, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'upconv1',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True,\n",
    "                       csse = False, dropblock = False)\n",
    "            \n",
    "            # 4x4\n",
    "            three_up = tf.nn.relu(tf.add(three_up, five_f))\n",
    "    '''        \n",
    "    \n",
    "    if upsample == 'upconv' or \"bilinear\":\n",
    "        five_up = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(five)\n",
    "        if upsample == 'upconv':\n",
    "            five_up = ReflectionPadding2D((1, 1,))(five_up)\n",
    "            five_up = conv_bn_relu(inp = five_up, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'upconv2',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, \n",
    "                       csse = False, dropblock = False)\n",
    "            five_up = tf.nn.relu(tf.add(five_up, seven_f))\n",
    "            \n",
    "    if upsample == 'upconv' or \"bilinear\":\n",
    "        seven_up = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(five_up)\n",
    "        if upsample == 'upconv':\n",
    "            seven_up = ReflectionPadding2D((1, 1,))(seven_up)\n",
    "            seven_up = conv_bn_relu(inp = seven_up, is_training = is_training, \n",
    "                       kernel_size = 3, scope =  'upconv3',\n",
    "                       filters = filter_count, clipping_params = clipping_params,\n",
    "                       keep_rate = keep_rate, activation = True,\n",
    "                       use_bias = False, batch_norm = True, \n",
    "                       csse = False, dropblock = False)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    print(\"One: {}\".format(one.shape))\n",
    "    \n",
    "    \n",
    "   # print(\"Three: {}\".format(three.shape))\n",
    "    #print(\"Three_f: {}\".format(three_f.shape))\n",
    "    #print(\"Three_up: {}\".format(three_up.shape))\n",
    "    print(\"Five_up: {}\".format(five_up.shape))\n",
    "    print(\"Seven_up: {}\".format(seven_up.shape))\n",
    "    \n",
    "    # top block\n",
    "\n",
    "    #pooled = tf.keras.layers.GlobalAveragePooling2D()(inp)\n",
    "    #one_top = conv_bn_relu(inp = tf.reshape(pooled, (-1, 1, 1, pooled.shape[-1])),\n",
    "    #                       is_training = is_training, \n",
    "    #                   kernel_size = 1, scope =  'topconv',\n",
    "    #                   filters = filter_count, clipping_params = clipping_params,\n",
    "    #                   keep_rate = keep_rate, activation = False,\n",
    "    #                   use_bias = False, batch_norm = True, \n",
    "    #                   csse = False, dropblock = False)\n",
    "    #one_top = conv_bn_relu(tf.reshape(pooled, (-1, 1, 1, pooled.shape[-1])),\n",
    "    ##                      is_training, 1, 'top1', filter_count, pad = False)\n",
    "    #four_top = tf.keras.layers.UpSampling2D((16, 16))(one_top)\n",
    "    \n",
    "    #seven_up = tf.multiply(one, seven_up)\n",
    "    out = tf.nn.relu(tf.multiply(seven_up, one))\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bands = 16 # 16 for master model\n",
    "reg = keras.regularizers.l2(L2_REG) # for GRU\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 24, IMAGE_SIZE, IMAGE_SIZE, n_bands))\n",
    "length = tf.placeholder(tf.int32, shape = (None, 1))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 14, 14))#, 1))\n",
    "keep_rate = tf.placeholder_with_default(1.0, ()) # For DropBlock\n",
    "length2 = tf.reshape(length, (-1,)) # Remove\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training') # For BN, DropBlock\n",
    "alpha = tf.placeholder(tf.float32, shape = ()) # For loss scheduling\n",
    "ft_lr = tf.placeholder_with_default(0.001, shape = ()) # For loss scheduling\n",
    "loss_weight = tf.placeholder_with_default(1.0, shape = ())\n",
    "beta_ = tf.placeholder_with_default(0.0, shape = ())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax = tf.placeholder(tf.float32, shape = ())\n",
    "rmin = tf.placeholder(tf.float32, shape = ())\n",
    "dmax = tf.placeholder(tf.float32, shape = ())\n",
    "\n",
    "clipping_params = {\n",
    "    'rmax': rmax,\n",
    "    'rmin': rmin,\n",
    "    'dmax': dmax\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU input shape (?, 24, 16, 16, 15), zoneout: 0.2\n",
      "(3, 3, 47, 64)\n",
      "(3, 3, 47, 64)\n",
      "Down block output shape (?, 16, 16, 64)\n",
      "forward1 1 Conv 2D Batch Renorm Linear No CSSE NoBias NoDrop\n",
      "down1 5 Conv 2D Batch Renorm RELU CSSE NoBias NoDrop\n",
      "down1_f 5 Conv 2D Batch Renorm Linear No CSSE NoBias NoDrop\n",
      "Seven: (?, 8, 8, 28)\n",
      "Seven f: (?, 8, 8, 28)\n",
      "down2 3 Conv 2D Batch Renorm RELU CSSE NoBias NoDrop\n",
      "down2_f 3 Conv 2D Batch Renorm Linear No CSSE NoBias NoDrop\n",
      "Five: (?, 4, 4, 28)\n",
      "Five_F: (?, 4, 4, 28)\n",
      "upconv2 3 Conv 2D Batch Renorm RELU No CSSE NoBias NoDrop\n",
      "upconv3 3 Conv 2D Batch Renorm RELU No CSSE NoBias NoDrop\n",
      "One: (?, 16, 16, 28)\n",
      "Five_up: (?, 8, 8, 28)\n",
      "Seven_up: (?, 16, 16, 28)\n",
      "outconv2 3 Conv 2D Batch Renorm RELU No CSSE NoBias NoDrop\n",
      "Initializing last sigmoid bias with -2.94 constant\n"
     ]
    }
   ],
   "source": [
    "# Split out slope for temporal modeling\n",
    "inp_first_half = inp[:, :, :, :, :10]\n",
    "inp_second_half = inp[:, :, :, :, 11:]\n",
    "no_dem = tf.concat([inp_first_half, inp_second_half], axis = -1)\n",
    "dem = tf.reshape(tf.reduce_mean(inp[:, :, :, :, 10], axis = 1), (-1, 16, 16, 1))\n",
    "gru_out, steps = gru_block(inp = no_dem, length = length2, \n",
    "                            size = [16, 16], \n",
    "                            flt = gru_flt, \n",
    "                            scope = 'down_16', \n",
    "                            train = is_training)\n",
    "\n",
    "#steps = tf.reduce_mean(steps, axis = 1)\n",
    "#mean = tf.reduce_mean(inp, axis = 1)\n",
    "#print(\"Mean: \", mean.shape)\n",
    "gru_out = tf.concat([gru_out, dem], axis = -1)\n",
    "\n",
    "# CSSE, Drop\n",
    "csse1 = csse_block(gru_out, 'csse1')\n",
    "drop_block1 = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "csse1 = drop_block1(csse1, is_training)\n",
    "\n",
    "# FPA, CSSE, 4x4 Drop block\n",
    "fpa1 = fpa(csse1, is_training, fpa_flt, clipping_params, keep_rate)\n",
    "csse2 = csse_block(fpa1, 'csse2')\n",
    "\n",
    "drop_block2 = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "csse2 = drop_block2(csse2, is_training)\n",
    "\n",
    "\n",
    "# Skip connect\n",
    "x = tf.concat([csse2, csse1], axis = -1)\n",
    "\n",
    "x = conv_bn_relu(inp = x, \n",
    "                 is_training = is_training,\n",
    "                 kernel_size = 3,\n",
    "                 scope = \"outconv2\", \n",
    "                 filters = out_conv_flt, \n",
    "                 clipping_params = clipping_params,\n",
    "                 activation = True,\n",
    "                 keep_rate = keep_rate, \n",
    "                 use_bias = False, dropblock = False,\n",
    "                 batch_norm = True, csse = False)\n",
    "\n",
    "print(\"Initializing last sigmoid bias with -2.94 constant\")\n",
    "init = tf.constant_initializer([-np.log(0.7/0.3)]) # For focal loss\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1), \n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid',\n",
    "            bias_initializer = init,\n",
    "           )(x) # For focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 210969 parameters\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(\"This model has {} parameters\".format(total_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "*  Load in CSV data from Collect Earth\n",
    "*  Reconstruct the X, Y grid for the Y data per sample\n",
    "*  Calculate NDVI, EVI, SAVI, BI, MSAVI2, and SI\n",
    "*  Stack X, Y, length data\n",
    "*  Apply median filter to DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x = np.load(\"../tile_data/processed/data_x_l2a_processed.npy\")\n",
    "train_y = np.load(\"../tile_data/processed/data_y_l2a_processed.npy\")\n",
    "train_l = np.load(\"../tile_data/processed/length_l2a_processed.npy\")\n",
    "\n",
    "train_x = np.delete(train_x, 14, -1) # test not deleting the SI inde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_delete = [139, 630, 1100, 1474, 1964, 669]\n",
    "#train_x = np.delete(train_x, to_delete, 0)\n",
    "#train_y = np.delete(train_y, to_delete, 0)\n",
    "#train_l = np.delete(train_l, to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd52919b38>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.heatmap(train_x[22, 23, :, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9c67a9321d40a99a60628be635c5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1517), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1517, 24, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "holdout_for_vis = np.copy(train_x[65, 0, :, :, 10])\n",
    "for sample in tnrange(0, len(train_x)):\n",
    "    filtered = median_filter(train_x[sample, 0, :, :, 10], size = 5)\n",
    "    filtered = np.reshape(filtered, (8, 2, 8, 2))\n",
    "    filtered = np.mean(filtered, axis = (1, 3))\n",
    "    filtered = resize(filtered, (16, 16), 0)\n",
    "    train_x[sample, :, :, :, 10] = np.stack([filtered] * 24)\n",
    "    \n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbcf7754630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(train_x[65, 0, :, :, 10], vmax = 0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "*  Identify and remove samples with time steps / channels that have a 0. or 1. value, which indicates missing data\n",
    "*  Identify and remove samples with time steps / channels with no variation, which indicates missing data\n",
    "*  Identify and remove samples with values above or below the allowable values for the band\n",
    "*  Identify and remove samples with null data, or samples with extreme band 0 data (which squash all the \"clean\" samples)\n",
    "*  Smooth per-pixel temporal data with Whittaker smoother, d = 2, lambda = 0.5 to reduce sample noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 18 outlying training data points\n",
      "\n",
      "\n",
      "[700, 703, 717, 718, 865, 874, 900, 1047, 1102, 1127, 1129, 1139, 1323, 1330, 1352, 1448, 1461, 1469]\n"
     ]
    }
   ],
   "source": [
    "below_1 = [i for i, val in enumerate(train_x[:, :, :, :, :10]) if np.min(val) < -2]\n",
    "above_1 = [i for i, val in enumerate(train_x[:, :, :, :, :10]) if np.max(val) > 2]\n",
    "min_vals = [np.min(val) for i, val in enumerate(train_x[:, :, :, :, :10]) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(train_x[:, :, :, :, :10]) if np.max(val) > 1.5]\n",
    "nans = [i for i, val in enumerate(train_x) if np.sum(np.isnan(val)) > 100]\n",
    "oob_vals = [i for i, val in enumerate(train_x) if np.max(val[:, :, :, 0]) > 0.7]\n",
    "\n",
    "outliers = below_1 + above_1 + nans + oob_vals\n",
    "outliers = list(set(outliers))\n",
    "print(\"Removing {} outlying training data points\".format(len(outliers)))\n",
    "print(\"\\n\")\n",
    "print(sorted(outliers))\n",
    "train_x = train_x[[x for x in range(0, len(train_x)) if x not in outliers]]\n",
    "train_y = train_y[[x for x in range(0, len(train_y)) if x not in outliers]]\n",
    "train_l = train_l[[x for x in range(0, len(train_l)) if x not in outliers]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4800ae942843d6ba81f9527ccf8fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The data has been scaled to [-1.0000000000000002, 1.0000000000000002]\n",
      "[0.016768555792030362, 0.031859364002449986, 0.018888066882654337, 0.08300588143157157, 0.04900411763090337, 0.07196114637821546, 0.0790915859490633, 0.08027978003529285, 0.05206992316991091, 0.033226898834616644, 0.0, 0.0029407649199765626, -0.026773188909673434, 0.0032562207477167242, 0.006299999542534351, 4.999999873689376e-05] [0.21292338743805878, 0.29813900702779483, 0.4300807791948318, 0.5124803858995437, 0.4764584118127815, 0.4890428495407102, 0.5156670875445272, 0.5284151314082131, 0.6588925588130947, 0.6016234779357905, 0.37872035768296985, 0.7223387521306766, 0.40211242556571936, 0.6531514992624433, 0.7853250503540039, 0.15389999747276306]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_all = [0.016768555792030362,\n",
    " 0.031859364002449986,\n",
    " 0.018888066882654337,\n",
    " 0.08300588143157157,\n",
    " 0.04900411763090337,\n",
    " 0.07196114637821546,\n",
    " 0.0790915859490633,\n",
    " 0.08027978003529285,\n",
    " 0.05206992316991091,\n",
    " 0.033226898834616644,\n",
    " 0.0,\n",
    " 0.0029407649199765626,\n",
    " -0.026773188909673434,\n",
    " 0.0032562207477167242,\n",
    " 0.006299999542534351,\n",
    " 4.999999873689376e-05]\n",
    "\n",
    "max_all = [0.21292338743805878,\n",
    " 0.29813900702779483,\n",
    " 0.4300807791948318,\n",
    " 0.5124803858995437,\n",
    " 0.4764584118127815,\n",
    " 0.4890428495407102,\n",
    " 0.5156670875445272,\n",
    " 0.5284151314082131,\n",
    " 0.6588925588130947,\n",
    " 0.6016234779357905,\n",
    " 0.37872035768296985,\n",
    " 0.7223387521306766,\n",
    " 0.40211242556571936,\n",
    " 0.6531514992624433,\n",
    " 0.7853250503540039,\n",
    " 0.15389999747276306]\n",
    "#\n",
    "#min_all = []\n",
    "#max_all = []\n",
    "#\n",
    "for band in tnrange(0, train_x.shape[-1]):\n",
    "   # mins = np.percentile(train_x[:, :, :, :, band], 1)\n",
    "   # maxs = np.percentile(train_x[:, :, :, :, band], 99)\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    #print(mins1 - mins, maxs1 - maxs)\n",
    "    train_x[:, :, :, :, band] = np.clip(train_x[:, :, :, :, band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (train_x[:, :, :, :, band] - midrange) / (rng / 2)\n",
    "    train_x[:, :, :, :, band] = standardized\n",
    "    \n",
    "    #min_all.append(mins)\n",
    "    #max_all.append(maxs)\n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(train_x), np.max(train_x)))\n",
    "print(min_all, max_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd52953ac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(train_x[12, 5, :, :, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment training data\n",
    "\n",
    "Horizontal and vertical flips for 4x augmentation.\n",
    "\n",
    "**To do**\n",
    "*  Random guassian noise\n",
    "*  Brightness, contrast\n",
    "*  Region swaps (randomply position positive samples at different locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 outliers: [105]\n",
      "\n",
      "\n",
      "[] []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187b22a400cb41d69469624f6b27c0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=129), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The data has been scaled to [-1.0000000000000002, 1.0000000000000002]\n",
      "(129, 24, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "test_x = np.load(\"../tile_data/processed/test_x_l2a_processed.npy\")\n",
    "test_y = np.load(\"../tile_data/processed/test_y_l2a_processed.npy\")\n",
    "test_lengths = np.load(\"../tile_data/processed/test_length_l2a_processed.npy\")\n",
    "\n",
    "\n",
    "#test_x = np.delete(test_x, [975, 1026], 0)\n",
    "#test_y = np.delete(test_y, [975, 1026], 0)\n",
    "#test_lengths = np.delete(test_lengths, [975, 1026], 0)\n",
    "\n",
    "test_x = np.delete(test_x, 14, -1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.66]\n",
    "above_1 = [i for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.66]\n",
    "min_vals = [np.min(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(test_x[:, :, :, :, :-2]) if np.max(val) > 1.5]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "#outliers = [593, 546, 571]\n",
    "print(\"There are {} outliers: {}\".format(len(outliers), outliers))\n",
    "print(\"\\n\")\n",
    "print(min_vals, max_vals)\n",
    "\n",
    "        \n",
    "test_x = test_x[[x for x in range(0, len(test_x)) if x not in outliers]]\n",
    "test_y = test_y[[x for x in range(0, len(test_y)) if x not in outliers]]\n",
    "test_lengths = test_lengths[[x for x in range(0, len(test_lengths)) if x not in outliers]]\n",
    "\n",
    "for sample in tnrange(0, len(test_x)):\n",
    "    filtered = median_filter(test_x[sample, 0, :, :, 10], size = 5)\n",
    "    filtered = np.reshape(filtered, (8, 2, 8, 2))\n",
    "    filtered = np.mean(filtered, axis = (1, 3))\n",
    "    filtered = resize(filtered, (16, 16), 0)\n",
    "    test_x[sample, :, :, :, 10] = np.stack([filtered] * 24)\n",
    "    \n",
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[:, :, :, :, band] = np.clip(test_x[:, :, :, :, band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[:, :, :, :, band] - midrange) / (rng / 2)\n",
    "    test_x[:, :, :, :, band] = standardized\n",
    "    \n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(test_x), np.max(test_x)))\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test characteristics:\n",
      "Train mean Y 78.10852713178295\n",
      "Test STD Y 69.61335525323862\n",
      "Train mean NDVI\n",
      "Test mean NDVI\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and test characteristics:\")\n",
    "print(\"Train mean Y {}\".format(np.mean([np.sum(x) for x in test_y])))\n",
    "print(\"Test STD Y {}\".format(np.std([np.sum(x) for x in test_y])))\n",
    "#print(\"Train number with zero trees {}\".format(0.2*len([x for x in data_y[train_ids] if np.sum(x) == 0])))\n",
    "#print(\"Test number with zero trees {}\".format(0.8*len([x for x in data_y[test_ids] if np.sum(x) == 0])))\n",
    "print(\"Train mean NDVI\")\n",
    "print(\"Test mean NDVI\")\n",
    "#print(\"There are {} train and {} test samples\".format(len(train_ids), len(test_ids)))\n",
    "#print(\"There is {} overlap between train and test\".format(len([x for x in train_ids if x in test_ids])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equibatch creation\n",
    "\n",
    "The modelling approach uses equibatch sampling to ensure that there is a near constant standard deviation of the percent tree cover in the output labels for each batch. This helps ensure that the model performs equally well across gradients of tree cover, by mitigating the random possibility that many batches in a row near the end of sampling may be randomly biased towards a tree cover range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.0, 29.0, 52.0, 79.0, 115.0, 161.0, 194.31999999999994, 196.0]\n",
      "There are 263 zeros\n"
     ]
    }
   ],
   "source": [
    "sums = np.sum(train_y, axis = (1, 2))\n",
    "percents = [np.percentile(sums, x) for x in range(30, 100, 9)]\n",
    "print(percents)\n",
    "print(\"There are {} zeros\".format(len(np.argwhere(sums == 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "percents = [14, 29, 56, 83, 122, 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308, 104, 92, 86, 67, 122, 134, 168, 418]\n",
      "1499\n"
     ]
    }
   ],
   "source": [
    "train_ids = [x for x in range(0, len(train_y))]\n",
    "\n",
    "def multiplot(matrices):\n",
    "    '''Plot multiple heatmaps with subplots\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list of arrays):\n",
    "\n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4)\n",
    "    fig.set_size_inches(20, 4)\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        sns.heatmap(data = matrix, ax = axs[i], vmin = 0, vmax = 0.9)\n",
    "        axs[i].set_xlabel(\"\")\n",
    "        axs[i].set_ylabel(\"\")\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_xticks([])\n",
    "\n",
    "def equibatch(train_ids, p = percents):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          train_ids (list):\n",
    "          p (list):\n",
    "\n",
    "         Returns:\n",
    "          equibatches (list):\n",
    "    '''\n",
    "    ##percents = [7.0, 15.0, 25.0, 40.0, 60.0, 90.0, 140.0] # overall #0, 3, 7, 12, 20, 30, 50, 70\n",
    "    percents = [9.0, 18.0, 27.0, 36.0, 54.0, 81.0, 135.0] # sept 16\n",
    "    percents = [9.0, 19.0, 29.0, 40.0, 64.0, 95.0, 145.0] # sept 28\n",
    "   # percents =  [7.0, 13.0, 21.0, 33.0, 50.0, 80.0, 130.0] # overall\n",
    "    #percents = [12.0, 24.0, 36.0, 60.0, 86.0, 125., 170.0] # finetuning\n",
    "    np.random.shuffle(train_ids)\n",
    "    ix = train_ids\n",
    "    percs = [np.sum(x) for x in train_y[ix]]\n",
    "    ids0 = [x for x, z in zip(ix, percs) if z <= 2]\n",
    "    ids30 = [x for x, z in zip(ix, percs) if 2 < z <= percents[0]]\n",
    "    ids40 = [x for x, z in zip(ix, percs) if percents[0] < z <= percents[1]]\n",
    "    ids50 = [x for x, z in zip(ix, percs) if percents[1] < z <= percents[2]]\n",
    "    ids60 = [x for x, z in zip(ix, percs) if percents[2] < z <= percents[3]]\n",
    "    ids70 = [x for x, z in zip(ix, percs) if percents[3] < z <= percents[4]]\n",
    "    ids80 = [x for x, z in zip(ix, percs) if percents[4] < z <= percents[5]]\n",
    "    ids90 = [x for x, z in zip(ix, percs) if percents[5] < z <= percents[6]]\n",
    "    ids100 = [x for x, z in zip(ix, percs) if percents[6] < z]\n",
    "    \n",
    "    new_batches = []\n",
    "    maxes = [len(ids0), len(ids30), len(ids40), len(ids50), len(ids60), len(ids70),\n",
    "             len(ids80), len(ids90), len(ids100)]\n",
    "    print(maxes)\n",
    "    print(sum(maxes))\n",
    "    cur_ids = [0] * len(maxes)\n",
    "    iter_len = len(train_ids)//(len(maxes))\n",
    "    for i in range(0, iter_len):\n",
    "        for i, val in enumerate(cur_ids):\n",
    "            if val > maxes[i] - 1:\n",
    "                cur_ids[i] = 0\n",
    "        if cur_ids[0] >= (maxes[0] - 2):\n",
    "            cur_ids[0] = 0\n",
    "        to_append = [ids0[cur_ids[0]],\n",
    "                    ids30[cur_ids[1]], ids40[cur_ids[2]],\n",
    "                    ids50[cur_ids[3]],\n",
    "                    ids60[cur_ids[4]], ids70[cur_ids[5]], ids80[cur_ids[6]],\n",
    "                    ids90[cur_ids[7]], ids100[cur_ids[8]]]\n",
    "        \n",
    "        np.random.shuffle(to_append)\n",
    "        new_batches.append(to_append)\n",
    "        cur_ids = [x + 1 for x in cur_ids]\n",
    "        #cur_ids[0] += 1\n",
    "        \n",
    "    new_batches = [item for sublist in new_batches for item in sublist]\n",
    "    return new_batches\n",
    "\n",
    "batch = equibatch(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_size_inches(15, 6)\n",
    "sns.distplot(np.sum(train_y, axis = (1, 2)), bins = 50, kde = False, ax = ax1)\n",
    "ax1.set_title('Original distribution')\n",
    "ax2.set_title('Equibatch distribution')\n",
    "sns.distplot(np.sum(train_y[batch], axis = (1, 2)),\n",
    "             bins = 50, kde = False, ax = ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example equibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[4:8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADxCAYAAABMFyuKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHs9JREFUeJzt3X+o5fld3/HXezduHFopq2sLs7uNm3ZDjRW0phtBRoJtki0FN61aVqHEUjoVskVaFDYgtqwI+o9S6BYdaEAKdhsVZGgDS9q4OP0RnbWNDbuycTJKd2YKxWzUf6bOzr2f/jFn483N7M69Z76fez+f7308wiH3nvM953zPzJznnHnv5/u91VoLAAAAAGO757h3AAAAAIA7M8QBAAAAmIAhDgAAAMAEDHEAAAAAJmCIAwAAADABQxwAAACACRjiwESq6vGqeqWqLlXV07e5/R1V9Z+r6n9V1QtV9dCe2z5cVb+7uXz4aPccWBs9AkagRcAIjrJF1Vpbev+BDqrq3iSfS/L+JFeSXEzy/a21l/ds80tJ/kNr7Req6ruS/IPW2t+vqq9N8mKS9yRpSX4rybe11r541K8DmJ8eASPQImAER90iK3FgHo8ludRau9xau5HkuSRP7Nvm3Uk+tfn61/bc/sEkn2ytvbYJwieTPH4E+wyskx4BI9AiYARH2qK3HWbPXv+Dy6tdtnPq9Jnj3gUmcfPG1TrM9od539z39X/pHyc5u+eqc621c5uvH0zy6p7briR5776H+O0kfzfJv0zyd5J8TVV93Zvc98GD7tdo3nbfg6tt0Zpdv3bhuHfhQGb5++AYW5ToURIt4mC2bd+2LTrq1n7VA+/UomOmRXCyPhcdaogD9LWJwbk7bvjmfiTJv6qqH0zy60muJtlZYNeAE2SBFiV6BNwlLQJGMFqLDHGgt93FPidcTfLwnu8f2lz3Ja21a7k14U1V/dkk39Na+8Oquprkffvu+8JSOwZMYLkWJXoEbEuLgBFM3CLnxIHedm4e/PLWLiZ5tKoeqar7kjyZ5PzeDarqgap643390SQf23z9fJIPVNX9VXV/kg9srgNOiuValOgRsC0tAkYwcYsMcaCz1nYPfHnrx2k3kzyVW2/q30ny8dbaS1X1TFV992az9yV5pao+l+QvJPnJzX1fS/ITuRWYi0me2VwHnBBLtejWY+kRsB0tAkYwc4sO9SPGndgYDn/SrBtXPnvwk2Y99M2HeuyTygn85uTExsvSouOnRRyEExt/OS1anhbByfpc5Jw40NsBprcA3WkRMAItAkYwcYsMcaC3ZU+aBbAdLQJGoEXACCZukSEO9DbxlBdYES0CRqBFwAgmbpEhDnTWDnZGc4CutAgYgRYBI5i5RYY40NvuvFNeYEW0CBiBFgEjmLhFhjjQ28RL9YAV0SJgBFoEjGDiFhniQG8TnzQLWBEtAkagRcAIJm6RIQ70NvGUF1gRLQJGoEXACCZukSEO9DbxSbOAFdEiYARaBIxg4hYNO8Q5dfrMce8CLGPik2bBzPw9so8WwbE46hZt+3zXr11YeE/ehBYBI5i4RcMOcWAtWpv3eEtgPbQIGIEWASOYuUWGONDbxMdbAiuiRcAItAgYwcQtMsSB3iZeqgesiBYBI9AiYAQTt8gQB3qbeMoLrIgWASPQImAEE7fIEAd623n9uPcAQIuAMWgRMIKJW2SIA71NvFQPWBEtAkagRcAIJm6RIQ70NvFSPWBFtAgYgRYBI5i4RYY40NvEU15gRbQIGIEWASOYuEWGONDbxIEAVkSLgBFoETCCiVtkiAOdtYlPmgWshxYBI9AiYAQzt8gQB3qb+HhLYEW0CBiBFgEjmLhFhjjQ28RL9YAV0SJgBFoEjGDiFhniQG8TT3mBFdEiYARaBIxg4hYZ4kBvE095gRXRImAEWgSMYOIWGeJAbxNPeYEV0SJgBFoEjGDiFh1qiHPq9Jle+7GY69cubHW/GV7bLPwe7HPz5nHvASxq2/c4x0yL4Fj4XLSPFgEjmLhFVuJAbxNPeYEV0SJgBFoEjGDiFt1z3DsAq7e7e/DLHVTV41X1SlVdqqqnb3P7z1bVZzaXz1XVH+65bWfPbecXfpXA6BZsUaJHwJa0CBjBxC2yEgd6W2jKW1X3Jnk2yfuTXElysarOt9Ze/tJTtfZP92z/T5J8656HuN5a+5ZFdgaYz4L/xUmPgK1pETCCiVtkJQ70ttyU97Ekl1prl1trN5I8l+SJt9j++5P8u4VeBTC7Zf+Lkx4B29EiYAQTt8gQB3pruwe/vLUHk7y65/srm+u+QlW9I8kjST615+qvrqoXq+rTVfWhu3lJwISWa1GiR8C2tAgYwcQtcjgV9HaIM59X1dkkZ/dcda61dm6LZ30yyS+31nb2XPeO1trVqnpnkk9V1Wdba5/f4rGBGR1PixI9AvbSImAEE7fIEAd6a+0Qm7ZzSd4sCFeTPLzn+4c2193Ok0k+su+xr27+/3JVvZBbx2H6oAInxXItSvQI2JYWASOYuEUOp4Leljve8mKSR6vqkaq6L7cC8BVnL6+qv5Lk/iT/fc9191fV2zdfP5DkO5K8vP++wIote+y3HgHb0SJgBBO3yEoc6O2AP5buTlprN6vqqSTPJ7k3ycdaay9V1TNJXmytvRGKJ5M819qXjZe/McnPV9Vubg1vf2rv2dKBE2ChFiV6BNwFLQJGMHGLDHGgtwV/fF1r7RNJPrHvuh/f9/2/uM39/luSb15sR4D5LNiiRI+ALWkRMIKJW2SIA73t7Nx5G4DetAgYgRYBI5i4RYY40NuCS/UAtqZFwAi0CBjBxC0yxIHeJg4EsCJaBIxAi4ARTNwiQxzobeHjLQG2okXACLQIGMHELVrdEOfU6TPHvQsn3ra/B9evXTjS5zsqbbfdeSOAzrQI5rLt56LRaRFH4ajfP6P/e4SvNHOLVjfEgeFMvFQPWBEtAkagRcAIJm6RIQ70NvGZz4EV0SJgBFoEjGDiFhniQG8TT3mBFdEiYARaBIxg4hYZ4kBvEwcCWBEtAkagRcAIJm6RIQ701uY9aRawIloEjECLgBFM3CJDHOht4ikvsCJaBIxAi4ARTNwiQxzobeIfXwesiBYBI9AiYAQTt8gQB3qb+MznwIpoETACLQJGMHGLDHGgszbxUj1gPbQIGIEWASOYuUWGONDbxEv1gBXRImAEWgSMYOIWGeJAb23eKS+wIloEjECLgBFM3CJDHOht4ikvsCJaBIxAi4ARTNwiQxzo7ea8J80CVkSLgBFoETCCiVtkiAO9TbxUD1gRLQJGoEXACCZukSEO9DbxUj1gRbQIGIEWASOYuEWrG+Jcv3bhuHehm1Onzxz3LnS11tc384+vY/2OsplrfY/PQouAEWgRR8Fnjq+07We+tf5aztyi1Q1xYDgTT3mBFdEiYARaBIxg4hYZ4kBvEwcCWBEtAkagRcAIJm6RIQ70tjPvmc+BFdEiYARaBIxg4hYZ4kBnbeIpL7AeWgSMQIuAEczcIkMc6G3iQAArokXACLQIGMHELTLEgd4mPvM5sCJaBIxAi4ARTNwiQxzobeIpL7AiWgSMQIuAEUzconuOewdg9XbbwS93UFWPV9UrVXWpqp5+k23+XlW9XFUvVdUv7rn+w1X1u5vLhxd8hcAMFmxRokfAlrQIGMHELbISBzprO8ss1auqe5M8m+T9Sa4kuVhV51trL+/Z5tEkH03yHa21L1bVn99c/7VJ/nmS9yRpSX5rc98vLrJzwPCWalGiR8D2tAgYwcwtshIHeltuyvtYkkuttcuttRtJnkvyxL5t/lGSZ99407fW/u/m+g8m+WRr7bXNbZ9M8vhirxEY37L/xUmPgO1oETCCiVtkiAOdtd124EtVna2qF/dczu55qAeTvLrn+yub6/Z6V5J3VdV/rapPV9Xjh7gvsGILtijRI2BLWgSMYOYWOZwKejvgcZRJ0lo7l+TcXTzb25I8muR9SR5K8utV9c138XjAWhxtixI9Am5Hi4ARTNwiK3Ggt91DXN7a1SQP7/n+oc11e11Jcr619npr7feSfC63YnGQ+wJrtlyLEj0CtqVFwAgmbpEhDnTWbu4e+HIHF5M8WlWPVNV9SZ5Mcn7fNr+aW9PdVNUDubVs73KS55N8oKrur6r7k3xgcx1wQizYokSPgC1pETCCmVvkcCrobaETn7fWblbVU7n1pr43ycdaay9V1TNJXmytnc+fRuDlJDtJfrS19oUkqaqfyK3AJMkzrbXXltkzYArL/RAGPQK2p0XACCZuUbV28GPB3nbfgwff+Jhcv3bhSJ/v1Okzh77Ptvu4zXOxvJs3rtZhtv/i973vwO+b+3/phUM99kk1Q4uO2lG2T4vGoEXHT4vo6ag/L277fF/1wDu16Ji9/geXtWgfn1VOnpP0uchKHOhtwSkvwNa0CBiBFgEjmLhFhjjQWTvEmc8BetEiYARaBIxg5hYZ4kBvE095gRXRImAEWgSMYOIWGeJAZ+3mce8BgBYBY9AiYAQzt8gQBzprE095gfXQImAEWgSMYOYWGeJAbxMHAlgRLQJGoEXACCZukSEOdDbzlBdYDy0CRqBFwAhmbpEhDnQ2cyCA9dAiYARaBIxg5hYZ4kBnbaeOexcAtAgYghYBI5i5RYY40NnMU15gPbQIGIEWASOYuUWGONBZ2513ygushxYBI9AiYAQzt8gQBzqbecoLrIcWASPQImAEM7fIEAc6a23eKS+wHloEjECLgBHM3CJDHOhs5ikvsB5aBIxAi4ARzNyi1Q1xTp0+c9y7cEcz7CPL2Z34zOccvevXLhzp8+nRyaFFMJej7vO2z3fzxtVDba9FHIWj/jy1LZ/Djs/MLVrdEAdGM/NJs4D10CJgBFoEjGDmFhniQGczBwJYDy0CRqBFwAhmbpEhDnTW2nHvAYAWAWPQImAEM7fIEAc6m3nKC6yHFgEj0CJgBDO3yBAHOpv5x9cB66FFwAi0CBjBzC0yxIHOdiY+8zmwHloEjECLgBHM3CJDHOhs5ikvsB5aBIxAi4ARzNwiQxzobObjLYH10CJgBFoEjGDmFhniQGczn/kcWA8tAkagRcAIZm6RIQ50NvOUF1gPLQJGoEXACGZukSEOdLaze89x7wKAFgFD0CJgBDO3yBAHOpt5qR6wHloEjECLgBHM3KJ5x08wid1WB77cSVU9XlWvVNWlqnr6Lbb7nqpqVfWezfffUFXXq+ozm8vPLfgSgQks2aJEj4DtaBEwgplbZCUOdLbUj6+rqnuTPJvk/UmuJLlYVedbay/v2+5rkvxwkt/Y9xCfb619yyI7A0xnyR+lqUfAtrQIGMHMLbISBzpr7eCXO3gsyaXW2uXW2o0kzyV54jbb/USSn07y/xZ9IcDUFmxRokfAlrQIGMHMLbISBzo76BK8JKmqs0nO7rnqXGvt3ObrB5O8uue2K0neu+/+fy3Jw621/1hVP7rv4R+pqv+Z5I+T/Fhr7cKBd4xDu37NLy9jWbBFiR5xAq2966dOnzmS59GiMRzV7/cb1v7+OUrb/loe9e/5to7qz8rMLTLEgc4Oc+bzTQzO3XHD26iqe5L8TJIfvM3N/yfJX2ytfaGqvi3Jr1bVN7XW/nib5wLmc1QtSvQIeHNaBIxg5hY5nAo6a4e43MHVJA/v+f6hzXVv+JokfzXJC1X1+0m+Pcn5qnpPa+1PWmtfSJLW2m8l+XySd93FywIms2CLEj0CtqRFwAhmbpGVONDZYZbq3cHFJI9W1SO5FYUnk/zAGze21v4oyQNvfF9VLyT5kdbai1X19Ulea63tVNU7kzya5PJSOwaMb8EWJXoEbEmLgBHM3CJDHOhsqTOft9ZuVtVTSZ5Pcm+Sj7XWXqqqZ5K82Fo7/xZ3/84kz1TV60l2k/xQa+21RXYMmMKSP4VBj4BtaREwgplbZIgDne0u+FittU8k+cS+6378TbZ9356vfyXJryy4K8BklmxRokfAdrQIGMHMLTLEgc5aFl2qB7AVLQJGoEXACGZukSEOdHZz2eMtAbaiRcAItAgYwcwtMsSBzmae8gLroUXACLQIGMHMLTLEgc6WPt4SYBtaBIxAi4ARzNwiQxzobOYpL7AeWgSMQIuAEczcIkMc6GzmKS+wHloEjECLgBHM3CJDHOhsZ+IpL7AeWgSMQIuAEczcIkMc6Gx33j4AK6JFwAi0CBjBzC0yxIHOdiee8gLroUXACLQIGMHMLTLEmcj1axeO9PlOnT6z1f223c9tn2907bh3gBNhre8flqNFcHeOurNH/bnvqGjRGNb+eX2W/Vzr+3wGM7fIEAc6m/mkWcB6aBEwAi0CRjBziwxxoLPdmnepHrAeWgSMQIuAEczcIkMc6GznuHcAIFoEjEGLgBHM3CJDHOhs5jOfA+uhRcAItAgYwcwtMsSBzmY+8zmwHloEjECLgBHM3CJDHOhs5jOfA+uhRcAItAgYwcwtMsSBzmZeqgeshxYBI9AiYAQzt8gQBzqb+cfXAeuhRcAItAgYwcwtMsSBznYmnvIC66FFwAi0CBjBzC0yxIHOZp7yAuuhRcAItAgYwcwtMsSBzmYOBLAeWgSMQIuAEczcIkMc6KxNvFQPWA8tAkagRcAIZm6RIQ50NvOUF1gPLQJGoEXACGZukSEOdLZz3DsAEC0CxqBFwAhmbpEhDnS2O/FSPWA9tAgYgRYBI5i5RYY4d+n6tQuHvs+p02c67Mk4tn192/xa3s3zHZWZl+qNats/K0dp9D+XnDxaBCfD6H//aNHytvk9n+GzFGM46n+jbXu/mzeuHmr7mVtkiAOdzRwIYD20CBiBFgEjmLlF9xz3DsDatUNc7qSqHq+qV6rqUlU9fZvbf6iqPltVn6mq/1JV795z20c393ulqj64wEsDJrJkixI9ArajRcAIZm6RlTjQ2VLHW1bVvUmeTfL+JFeSXKyq8621l/ds9outtZ/bbP/dSX4myeObSDyZ5JuSnE7yn6rqXa21mc/pBRzCksd+6xGwLS0CRjBzi6zEgc52DnG5g8eSXGqtXW6t3UjyXJIn9m7QWvvjPd/+mfzp8PiJJM+11v6ktfZ7SS5tHg84IRZsUaJHwJa0CBjBzC2yEgc62z3wIrykqs4mObvnqnOttXObrx9M8uqe264kee9tHuMjSf5ZkvuSfNee+356330fPPCOAdNbsEWJHgFb0iJgBDO3yBAHOjvMSbM2MTh3xw3f+jGeTfJsVf1Akh9L8uG7eTxgHY66RZvH0SPgy2gRMIKZW+RwKuhswZNmXU3y8J7vH9pc92aeS/KhLe8LrMzCJ/DTI2ArWgSMYOYWGeJAZ7uHuNzBxSSPVtUjVXVfbp0A6/zeDarq0T3f/u0kv7v5+nySJ6vq7VX1SJJHk/zm1i8KmM6CLUr0CNiSFgEjmLlFDqeCzm7WwY+3fCuttZtV9VSS55Pcm+RjrbWXquqZJC+21s4neaqq/maS15N8MZslepvtPp7k5SQ3k3zET1+Ak2WpFiV6BGxPi4ARzNwiQxzobLk8JK21TyT5xL7rfnzP1z/8Fvf9ySQ/ueDuABNZskWJHgHb0SJgBDO3yBAHOjvMSbMAetEiYARaBIxg5hYZ4kBnh/nxdQC9aBEwAi0CRjBziwxxoLN58wCsiRYBI9AiYAQzt8gQBzqbeakesB5aBIxAi4ARzNwiQ5y7dOr0mVU+13HY9vVdv3bhyJ5rGztTz3lZ+/uOk0OL4O5s83kj8ffIflq0vG3/bI7+XMnR/vvgbmy7n9vcb5bXNrqZW2SIA53NPOUF1kOLgBFoETCCmVtkiAOdtYmnvMB6aBEwAi0CRjBziwxxoLOZp7zAemgRMAItAkYwc4sMcaCzmX98HbAeWgSMQIuAEczcIkMc6GzePABrokXACLQIGMHMLTLEgc5uTp0IYC20CBiBFgEjmLlFhjjQ2cwnzQLWQ4uAEWgRMIKZW2SIA53NfNIsYD20CBiBFgEjmLlFhjjQ2cxTXmA9tAgYgRYBI5i5RYY40NnMU15gPbQIGIEWASOYuUWGONDZTpt3ygushxYBI9AiYAQzt8gQBzrbnXipHrAeWgSMQIuAEczcIkMc6Gzm4y2B9dAiYARaBIxg5hYZ4kBnMx9vCayHFgEj0CJgBDO3yBAHOpt5qR6wHloEjECLgBHM3KLuQ5zr1y5sdb9Tp88svCes1eh/VmZeqgeshxbB3dn284bPwl9OizgKa33/JOt+bUdp5hZZiQOdzXzmc2A9tAgYgRYBI5i5RYY40NnMS/WA9dAiYARaBIxg5hYZ4kBnM580C1gPLQJGoEXACGZukSEOdDbz8ZbAemgRMAItAkYwc4sMcaCzmZfqAeuhRcAItAgYwcwtMsSBztrEJ80C1kOLgBFoETCCmVt0z3HvAKzdTtqBL3dSVY9X1StVdamqnr7N7d9ZVf+jqm5W1ffuu22nqj6zuZxf8CUCE1iyRYkeAdvRImAEM7fIShzobKmlelV1b5Jnk7w/yZUkF6vqfGvt5T2b/e8kP5jkR27zENdba9+yyM4A01ly2bAeAdvSImAEM7fIEAc6W3Cp3mNJLrXWLidJVT2X5IkkX4pDa+33N7fNfMJ1oIOFlw3rEbAVLQJGMHOLHE4Fne2mHfhyBw8meXXP91c21x3UV1fVi1X16ar60GFfBzC3BVuU6BGwJS0CRjBzi6zEgc4O8+PrqupskrN7rjrXWju30K68o7V2taremeRTVfXZ1trnF3psYHADtSjRIzixtAgYwcwtMsSBznYOsVRvE4M3C8LVJA/v+f6hzXUHfeyrm/+/XFUvJPnWJD6owAmxYIsSPQK2pEXACGZukcOpoLMFl+pdTPJoVT1SVfcleTLJgX6SQlXdX1Vv33z9QJLvyJ5jNIH1W3jZsB4BW9EiYAQzt8gQBzpbKhCttZtJnkryfJLfSfLx1tpLVfVMVX13klTVX6+qK0m+L8nPV9VLm7t/Y5IXq+q3k/xakp/ad7Z0YOWW/LCiR8C2tAgYwcwtqsOclflt9z146FM4X7924bB3uSunTp850uc76td3lNb8a3k3r+3mjat1mO2//fT7Dvy++fS1Fw712CfV639wedHTyb+Vo34fwEFp0fHb5nMR89r2c8ra/x7RouN3lJ+Ljtra3z/bdGXtvybbOkktck4c6OyAS/AAutIiYARaBIxg5hYZ4kBnhznzOUAvWgSMQIuAEczcIkMc6Gyn7R73LgBoETAELQJGMHOLDHGgs8OcdwqgFy0CRqBFwAhmbpEhDnQ28/GWwHpoETACLQJGMHOLDHGgs5mPtwTWQ4uAEWgRMIKZW2SIA53tTrxUD1gPLQJGoEXACGZukSEOdDbzlBdYDy0CRqBFwAhmbpEhDnQ285nPgfXQImAEWgSMYOYWGeJAZzMv1QPWQ4uAEWgRMIKZW2SIA53NvFQPWA8tAkagRcAIZm6RIQ50NvOUF1gPLQJGoEXACGZukSEOdDbzlBdYDy0CRqBFwAhmbpEhDnS203aOexcAtAgYghYBI5i5RYY40FmbeKkesB5aBIxAi4ARzNyi7kOcU6fP9H6KE2PbX8vr1y4svCd9rPXPyu7ES/WA9dAiuGWWz0VrpUWs0bZdWeu/f2Ywc4usxIHOZp7yAuuhRcAItAgYwcwtMsSBzmY+8zmwHloEjECLgBHM3CJDHOhs5jOfA+uhRcAItAgYwcwtMsSBznba7nHvAoAWAUPQImAEM7fIEAc6m/l4S2A9tAgYgRYBI5i5RYY40NnMx1sC66FFwAi0CBjBzC0yxIHOZp7yAuuhRcAItAgYwcwtMsSBznYnPmkWsB5aBIxAi4ARzNwiQxzobOYpL7AeWgSMQIuAEczcIkMc6GzmM58D66FFwAi0CBjBzC0yxIHOZj5pFrAeWgSMQIuAEczcIkMc6GzmpXrAemgRMAItAkYwc4vuOe4dgLVrh/jfnVTV41X1SlVdqqqnb3P726vq329u/42q+oY9t310c/0rVfXBRV8kMLwlW5ToEbAdLQJGMHOLDHGgs9bagS9vparuTfJskr+V5N1Jvr+q3r1vs3+Y5Iuttb+c5GeT/PTmvu9O8mSSb0ryeJJ/vXk84IRYqkWJHgHb0yJgBDO3yBAHOttt7cCXO3gsyaXW2uXW2o0kzyV5Yt82TyT5hc3Xv5zkb1RVba5/rrX2J62130tyafN4wAmxYIsSPQK2pEXACGZu0aHOiXPzxtU6zPYs6+aNq6t+vrU6zPumqs4mObvnqnOttXObrx9M8uqe264kee++h/jSNq21m1X1R0m+bnP9p/fd98GD7tdovuqBdx5Zi7wPWIsFW5ToURKfizgYf498OS1a3lF+Ljpqa3//rP31jWzmFjmxMQxkE4Nzd9wQoCMtAkagRcAIRmuRw6lgHleTPLzn+4c21912m6p6W5I/l+QLB7wvwEHpETACLQJGcKQtMsSBeVxM8mhVPVJV9+XWCbDO79vmfJIPb77+3iSfarfOxnU+yZObs6I/kuTRJL95RPsNrI8eASPQImAER9oih1PBJDbHTj6V5Pkk9yb5WGvtpap6JsmLrbXzSf5Nkn9bVZeSvJZbAclmu48neTnJzSQfaa3tHMsLAaanR8AItAgYwVG3qA7yI7MAAAAAOF4OpwIAAACYgCEOAAAAwAQMcQAAAAAmYIgDAAAAMAFDHAAAAIAJGOIAAAAATMAQBwAAAGAC/x+hoSN1PtydwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[8:12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[0:4]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight cross entropy by effective number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: 0.9999\n",
      "[23069.44444444  9466.55555556]\n",
      "[0.90044647 0.61198174]\n",
      "Neg and pos weights: [0.40463523 0.59536477]\n",
      "1.471361651453123\n"
     ]
    }
   ],
   "source": [
    "sum_pos = np.sum(train_y[batch])\n",
    "sum_neg = len(train_y[batch]) * 196 - sum_pos\n",
    "beta = 0.9999\n",
    "print(\"Beta: {}\".format(beta))\n",
    "samples_per_cls = np.array([sum_neg, sum_pos]) / 9\n",
    "print(samples_per_cls)\n",
    "effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "print(effective_num)\n",
    "weights = (1.0 - beta) / np.array(effective_num)\n",
    "weights = weights / np.sum(weights)\n",
    "print(\"Neg and pos weights: {}\".format(weights))\n",
    "weight = weights[1] / weights[0]\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120767.0 173037.0\n",
      "Beta: 0.999\n",
      "[19226.33333333 13418.55555556]\n",
      "[1.         0.99999852]\n",
      "Neg and pos weights: [0.49999963 0.50000037]\n",
      "1.0000014729141435\n",
      "2.36\n"
     ]
    }
   ],
   "source": [
    "sum_pos = np.sum(train_y)\n",
    "sum_neg = len(train_y) * 196 - sum_pos\n",
    "print(sum_pos, sum_neg)\n",
    "beta = 0.999\n",
    "print(\"Beta: {}\".format(beta))\n",
    "samples_per_cls = np.array([sum_neg, sum_pos]) / 9\n",
    "print(samples_per_cls)\n",
    "effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "print(effective_num)\n",
    "weights = (1.0 - beta) / np.array(effective_num)\n",
    "weights = weights / np.sum(weights)\n",
    "print(\"Neg and pos weights: {}\".format(weights))\n",
    "weight = weights[1] / weights[0]\n",
    "print(weight)\n",
    "weight = 2.36\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: The positive is: 0.4999996317717353\n",
      "Baseline: The negative is: 0.5000003682282647\n",
      "\n",
      "\n",
      "Balanced: The positive is: 0.4999996317717353\n",
      "Balanced: The negative is: 0.5000003682282647\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline: The positive is: {}\".format(weights[0]))\n",
    "print(\"Baseline: The negative is: {}\".format(weights[1]))\n",
    "print(\"\\n\")\n",
    "print(\"Balanced: The positive is: {}\".format(weight*weights[0]))\n",
    "print(\"Balanced: The negative is: {}\".format(weights[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Loss definition\n",
    "\n",
    "The current best loss is a combination of weighted binary cross entropy and per-image Lovasz-Softmax, with a loss schedule with the latter becoming more important each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "import math\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "\n",
    "def calc_mask(seg):\n",
    "\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "    loss_importance = np.array([x for x in range(0, 197, 1)])\n",
    "    loss_importance = loss_importance / 196\n",
    "    loss_importance = np.expm1(loss_importance)\n",
    "    loss_importance[:30] = 0.\n",
    "\n",
    "    if posmask.any():\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "        #res[np.where(res == 0)] = -1 * loss_importance[196 - sums]\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    res[np.logical_and(res < 2, res > 0)] = 0.75\n",
    "    res[np.logical_or(res >= 2, res <= 0)] = 1.\n",
    "\n",
    "    \n",
    "    return res# / max_value\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight, mask = True, smooth = 0.03):\n",
    "    '''Calculates the weighted binary cross entropy loss between y_true and\n",
    "       y_pred with optional masking and smoothing for regularization\n",
    "       \n",
    "       For smoothing, we want to weight false positives as less important than\n",
    "       false negatives, so we smooth false negatives 2x as much. \n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          weight (float):\n",
    "          mask (arr):\n",
    "          smooth (float):\n",
    "\n",
    "         Returns:\n",
    "          loss (float):\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    y_true = K.clip(y_true, smooth, 1. - smooth)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        y_true,\n",
    "        logit_y_pred,\n",
    "        weight,\n",
    "    )\n",
    "    return loss\n",
    "    #return tf.reduce_mean(loss)\n",
    "\n",
    "def calc_dist_map(seg):\n",
    "    '''Utility function for calc_dist_map_batch that calculates the loss\n",
    "       importance per pixel based on the surface distance function\n",
    "    \n",
    "         Parameters:\n",
    "          seg (arr):\n",
    "          \n",
    "         Returns:\n",
    "          res (arr):\n",
    "    '''\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "    loss_importance = np.array([x for x in range(0, 197, 1)])\n",
    "    loss_importance = loss_importance / 196\n",
    "    loss_importance[:20] = 0.\n",
    "    loss_importance[20:60] = np.arange(0, 40, 1) / 40\n",
    "    loss_importance[60:] = 1.\n",
    "\n",
    "    mults = np.ones_like(seg)\n",
    "    ones = np.ones_like(seg)\n",
    "    for x in range(1, res.shape[0] -1 ):\n",
    "        for y in range(1, res.shape[0] - 1):\n",
    "            if seg[x, y] == 1:\n",
    "                l = seg[x - 1, y]\n",
    "                r = seg[x + 1, y]\n",
    "                u = seg[x, y + 1]\n",
    "                d = seg[x, y - 1]\n",
    "                lu = seg[x - 1, y + 1]\n",
    "                ru = seg[x + 1, y + 1]\n",
    "                rd = seg[x + 1, y - 1]\n",
    "                ld = seg[x -1, y - 1]\n",
    "                \n",
    "                sums = (l + r + u + d)\n",
    "                sums2 = (l + r + u + d + lu + ru +rd + ld)\n",
    "                if sums >= 2:\n",
    "                    mults[x, y] = 1.25\n",
    "                if sums2 <= 1:\n",
    "                    ones[x - 1, y] = 0.33\n",
    "                    ones[x + 1, y] = 0.33\n",
    "                    ones[x, y + 1] = 0.33\n",
    "                    ones[x, y - 1] = 0.33\n",
    "                    ones[x - 1, y + 1] = 0.33\n",
    "                    ones[x + 1, y + 1] = 0.33\n",
    "                    ones[x + 1, y - 1] = 0.33\n",
    "                    ones[x -1, y - 1] = 0.33\n",
    "\n",
    "    if posmask.any():\n",
    "        \n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "        sums = int(np.sum(seg))\n",
    "        # When % = 1, 0 -> 1.75\n",
    "        # When % = 100, 0 -> 0\n",
    "        res = np.round(res, 0)\n",
    "        res[np.where(np.isclose(res, -.41421356, rtol = 1e-2))] = -1\n",
    "        res[np.where(res == -1)] = -1 * mults[np.where(res == -1)]\n",
    "        res[np.where(res == 0)] = -1  * mults[np.where(res == 0)]# * loss_importance[196 - sums]\n",
    "        # When % = 1, 1 -> 0\n",
    "        # When % = 100, 1 -> 1.75\n",
    "        res[np.where(res == 1)] = 1 * ones[np.where(res == 1)]\n",
    "        res[np.where(res == 1)] *= 0.67\n",
    "        #res[np.where(np.isclose(res, 1.41421356, rtol = 1e-2))] = loss_importance[sums]\n",
    "        \n",
    "    res[np.where(res < -3)] = -3\n",
    "    res[np.where(res > 3)] = 3\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "        res *= -1\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    return res# / max_value\n",
    "\n",
    "def calc_lovasz_weight(y_true):\n",
    "    if np.sum(y_true) > 12:\n",
    "        return np.array(1., dtype = np.float32)\n",
    "    else:\n",
    "        return np.array(0., dtype = np.float32)\n",
    "    \n",
    "def calc_bce_weight(y_true):\n",
    "    if np.sum(y_true) <= 12:\n",
    "        return np.array(1., dtype = np.float32)\n",
    "    else:\n",
    "        return np.array(0., dtype = np.float32)\n",
    "    \n",
    "def calc_lovasz_weight_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    lovasz_batch = np.array([calc_lovasz_weight(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "    return lovasz_batch\n",
    "\n",
    "def calc_bce_weight_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    bce_batch = np.array([calc_bce_weight(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "    return bce_batch\n",
    "    \n",
    "    \n",
    "\n",
    "def calc_dist_map_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    return np.array([calc_dist_map(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "\n",
    "def surface_loss(y_true, y_pred):\n",
    "    '''Calculates the mean surface loss for the input batch\n",
    "       by multiplying the distance map by y_pred\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "        \n",
    "         References:\n",
    "          https://arxiv.org/abs/1812.07032\n",
    "    '''\n",
    "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
    "                                     inp=[y_true],\n",
    "                                     Tout=tf.float32)\n",
    "    y_true_dist_map = tf.stack(y_true_dist_map, axis = 0)\n",
    "    multipled = y_pred * y_true_dist_map\n",
    "    #loss = tf.reduce_mean(multipled, axis = (1, 2, 3))\n",
    "    loss = K.mean(multipled)\n",
    "    return loss\n",
    "\n",
    "def dice_surf(y_true, y_pred, alpha, weight, batch_size):\n",
    "    bce =  weighted_bce_loss(y_true, y_pred, weight, smooth = 0.03)\n",
    "    \n",
    "    def _bce():\n",
    "        return bce\n",
    "    \n",
    "    dices = []\n",
    "    for x in range(batch_size):\n",
    "        dice = 1 - dice_loss_tolerance(y_true[x], y_pred[x])\n",
    "        dices.append(dice)\n",
    "    dices = tf.reduce_mean(dices)\n",
    "    surf = surface_loss(y_true, y_pred)\n",
    "    \n",
    "    def _surf():\n",
    "        return ( (1-alpha)*dices + (alpha * surf) )\n",
    "    \n",
    "    result = tf.cond(alpha < 0.1, lambda: _bce(), lambda: _surf() )\n",
    "    return result\n",
    "    \n",
    "def bce_surf(y_true, y_pred, alpha, weight, smooth = 0.03, mask = None, ):\n",
    "    '''Calculates the weighted combination of binary cross entropy and surface loss\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          alpha (float):\n",
    "          smooth (float):\n",
    "          weight (float):\n",
    "          mask (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "\n",
    "    bce =  weighted_bce_loss(y_true, y_pred, weight, smooth = 0.03)\n",
    "    bce = tf.reduce_mean(bce)\n",
    "    print(\"BCE\", bce.shape)\n",
    "    surf = surface_loss(y_true, y_pred)\n",
    "    print(\"SURF\", surf.shape)\n",
    "    return ( (1-alpha)*bce + (alpha * surf) )#global_loss #+ regional_loss\n",
    "\n",
    "\n",
    "def lovasz_surf(y_true, y_pred, alpha, weight, beta):\n",
    "    \n",
    "    lv = lovasz_softmax(probas = y_pred,\n",
    "                        labels = tf.reshape(y_true, (-1, 14, 14)), \n",
    "                        classes=[1],\n",
    "                        per_image=True) \n",
    "    print(\"Lovasz Shape: \", lv.shape)\n",
    "    \n",
    "    bce =  weighted_bce_loss(y_true = y_true, \n",
    "                             y_pred = y_pred, \n",
    "                             weight = weight,\n",
    "                             smooth = 0.03)\n",
    "    print(\"BCE Shape: \", bce.shape)\n",
    "    #return tf.reduce_mean(bce)\n",
    "\n",
    "    \n",
    "    bce = tf.reduce_mean(bce, axis = (1, 2, 3))\n",
    "    print(\"BCE Shape: \", bce.shape)\n",
    "    surface = surface_loss(y_true, y_pred)\n",
    "    \n",
    "    lv_mask = tf.math.reduce_sum(y_true, axis = (1, 2, 3))\n",
    "    lv_mask = tf.cast(lv_mask, tf.float32)\n",
    "    lv_mask = tf.math.greater_equal(lv_mask, tf.constant([25.]))\n",
    "    lv_mask = tf.cast(lv_mask, tf.float32)\n",
    "\n",
    "    \n",
    "    bce_mask = tf.math.reduce_sum(y_true, axis = (1, 2, 3))\n",
    "    bce_mask = tf.cast(bce_mask, tf.float32)\n",
    "    bce_mask = tf.math.less(bce_mask, tf.constant([25.]))\n",
    "    bce_mask = tf.cast(bce_mask, tf.float32)\n",
    "    \n",
    "    \n",
    "    lovasz = (lv * lv_mask) + (bce * bce_mask)\n",
    "    lovasz = tf.reduce_mean(lovasz)\n",
    "    bce = tf.reduce_mean(bce)\n",
    "    \n",
    "\n",
    "    lovasz_portion = (1 - alpha) * lovasz\n",
    "    lovasz_portion = lovasz_portion * beta\n",
    "    bce_portion = (1 - alpha) * bce\n",
    "    bce_portion = bce_portion * (1 - beta)\n",
    "    surface_portion = alpha * surface\n",
    "    \n",
    "    #lovasz_portion = (tf.constant([1.]) - (tf.constant([2.]) * alpha)) * lovasz\n",
    "    #surface_portion = (tf.constant([2.]) * alpha) * surface\n",
    "    #non_bce = (alpha) * (lovasz_portion + surface_portion)\n",
    "    \n",
    "    result = lovasz_portion + surface_portion + bce_portion\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_dist_map(test_y[77])[12, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_size_inches(14, 5)\n",
    "sns.heatmap(calc_dist_map(test_y[77]), ax = ax1)\n",
    "ax2.set_title('Ground truth Y')\n",
    "ax1.set_title('Boundary loss mask')\n",
    "sns.heatmap(test_y[77], ax = ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {'africaeast-test': [0, 34],\n",
    " 'africawest-test': [35, 96],\n",
    " 'cameroon-test': [97, 135],\n",
    " 'ethiopia-test': [136, 248],\n",
    " 'ghana-test': [249, 282],\n",
    " 'ghana-test-large': [283, 318],\n",
    " 'global-test': [319, 460],\n",
    " 'india-test': [461, 511],\n",
    " 'kenya-test': [512, 600],\n",
    " 'lac-north-test': [601, 641],\n",
    " 'lac-south-test': [642, 683], 'all': [0, 683]}\n",
    "\n",
    "countries = {'all': [0, 1150]}\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    '''Calculates the dice score of ground truth and prediction arrays\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          \n",
    "         Returns:\n",
    "          metric (arr):\n",
    "    '''\n",
    "    numerator = 2 * np.sum(y_true * y_pred, axis=-1)\n",
    "    denominator = np.sum(y_true + y_pred, axis=-1)\n",
    "    return (numerator + 1) / (denominator + 1)\n",
    "\n",
    "def dice_loss_tolerance(y_true, y_pred):\n",
    "    numerator_data = np.zeros_like(y_true)\n",
    "    for x in range(y_true.shape[0]):\n",
    "        for y in range(y_true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([y_true.shape[0], y+2])\n",
    "            max_x = np.min([y_true.shape[0], x+2])\n",
    "            if y_true[x, y] == 1:\n",
    "                numerator_data[x, y] = np.max(y_pred[min_x:max_x, min_y:max_y])\n",
    "                \n",
    "    numerator = 2 * np.sum(y_true * numerator_data, axis=-1)\n",
    "    denominator = np.sum(y_true + y_pred, axis=-1)\n",
    "    return (numerator + 1) / (denominator + 1)\n",
    "                    \n",
    "            \n",
    "        \n",
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    precision =  np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def recover_patches(arr, thresh_p):\n",
    "    sum1 = np.sum(arr)\n",
    "    thresh = thresh_p / 2\n",
    "\n",
    "    for window_x in range(2, arr.shape[0]-2, 1):\n",
    "        for window_y in range(2, arr.shape[1]-2, 1):\n",
    "            l, r, u, d =  False, False, False, False\n",
    "            cur_window = arr[window_x-2:window_x+3, window_y-2:window_y+3]\n",
    "            hor_vert_neighbors = False\n",
    "            if (cur_window[2, 2] > thresh and\n",
    "                cur_window[2, 2] < thresh_p):\n",
    "                if cur_window[3, 2] > thresh * 2 and cur_window[4, 2] < thresh * 2 :\n",
    "                    hor_vert_neighbors = True\n",
    "                    r = True\n",
    "                if cur_window[1, 2] > thresh * 2 and cur_window[2, 0] < thresh * 2:\n",
    "                    hor_vert_neighbors = True\n",
    "                    l = True\n",
    "                if cur_window[2, 3] > thresh * 2 and cur_window[2, 4] < thresh * 2:\n",
    "                    hor_vert_neighbors = True\n",
    "                    d = True\n",
    "                if cur_window[2, 1] > thresh * 2 and cur_window[2, 0] < thresh * 2:\n",
    "                    hor_vert_neighbors = True\n",
    "                    u = True\n",
    "            passes = False\n",
    "            if r and not l:\n",
    "                passes = True\n",
    "            if l and not r:\n",
    "                passes = True\n",
    "            if d and not u:\n",
    "                passes = True\n",
    "            if u and not d:\n",
    "                passes = True\n",
    "\n",
    "            if passes:\n",
    "                if r:\n",
    "                    if cur_window[1, 1] < thresh * 2 and cur_window[1, 3] < thresh * 2:\n",
    "                        arr[window_x, window_y] = (thresh_p + 0.01)\n",
    "\n",
    "                if l:\n",
    "                    if cur_window[3, 1] < thresh * 2 and cur_window[3, 3] < thresh * 2:\n",
    "                        arr[window_x, window_y] = (thresh_p + 0.01)\n",
    "\n",
    "                if u:\n",
    "                    if cur_window[1, 3] < thresh * 2 and cur_window[3, 3] < thresh * 2:\n",
    "                        arr[window_x, window_y] = (thresh_p + 0.01)\n",
    "\n",
    "                if d:\n",
    "                    if cur_window[1, 1] < thresh * 2 and cur_window[3, 1] < thresh * 2:\n",
    "                        arr[window_x, window_y] = (thresh_p + 0.01)\n",
    "    return arr\n",
    "\n",
    "def calculate_metrics(country, al = 0.4, canopy_thresh = 100):\n",
    "    '''Calculates the following metrics for an input country, based on\n",
    "       indexing of the country dictionary:\n",
    "       \n",
    "         - Loss\n",
    "         - F1\n",
    "         - Precision\n",
    "         - Recall\n",
    "         - Dice\n",
    "         - Mean surface distance\n",
    "         - Average error\n",
    "    \n",
    "         Parameters:\n",
    "          country (str):\n",
    "          al (float):\n",
    "          \n",
    "         Returns:\n",
    "          val_loss (float):\n",
    "          best_dice (float):\n",
    "          error (float):\n",
    "    '''\n",
    "    print(canopy_thresh)\n",
    "    start_idx = countries[country][0]\n",
    "    stop_idx = countries[country][1]\n",
    "    best_f1 = 0\n",
    "    best_dice = 0\n",
    "    best_thresh = 0\n",
    "    hausdorff = 0\n",
    "    relaxed_f1 = 0\n",
    "    p = 0\n",
    "    r = 0\n",
    "    error = 0\n",
    "    d = 0\n",
    "    ys = []\n",
    "    vls = []\n",
    "    t_alls = []\n",
    "    test_ids = [x for x in range(len(test_x))]\n",
    "    for test_sample in test_ids[start_idx:stop_idx]:\n",
    "        if np.sum(test_y[test_sample]) < ((canopy_thresh/100) * 197) :\n",
    "            y, vl = sess.run([fm, test_loss], feed_dict={inp: test_x[test_sample].reshape(1, 24, 16, 16, n_bands),\n",
    "                                              length: test_lengths[test_sample].reshape(1, 1),\n",
    "                                              is_training: False,\n",
    "                                              clipping_params['rmax']: rmax_epoch,\n",
    "                                              clipping_params['rmin']: rmin_epoch,\n",
    "                                              clipping_params['dmax']: dmax_epoch,\n",
    "                                              labels: test_y[test_sample, :, :].reshape(1, 14, 14),\n",
    "                                              loss_weight: 1.0,\n",
    "                                              alpha: al,\n",
    "                                              })\n",
    "            ys.append(y.reshape((14, 14)))\n",
    "            vls.append(vl)\n",
    "            t = test_y[test_sample].reshape((14, 14))\n",
    "            t_alls.append(t)\n",
    "    dice_losses = []\n",
    "    for thresh in range(8, 13):\n",
    "        all_preds, all_trues = [], []\n",
    "        tps, fps, fns = [], [], []\n",
    "        tps_relaxed, fps_relaxed, fns_relaxed = [], [], []\n",
    "        abs_error, haus = [], []\n",
    "        trues, preds = [], []\n",
    "        val_loss = []\n",
    "        for sample in range(len(ys)):\n",
    "            pred = np.copy(ys[sample])\n",
    "            true = t_alls[sample]\n",
    "            vl = vls[sample]\n",
    "            if thresh == 8:\n",
    "                dice_losses.append(dice_loss_tolerance(np.array(true), np.array(pred)))\n",
    "            #pred = recover_patches(pred, thresh*0.05)\n",
    "            pred[np.where(pred >= thresh*0.05)] = 1\n",
    "            pred[np.where(pred < thresh*0.05)] = 0\n",
    "            \n",
    "            dists = compute_surface_distances(np.array(true).reshape(14, 14, 1).astype(int),\n",
    "                                              np.array(pred).reshape(14, 14, 1).astype(int),\n",
    "                                              [1, 1, 1])\n",
    "            \n",
    "            true_s = np.sum(true[1:-1])\n",
    "            pred_s = np.sum(pred[1:-1])\n",
    "            abs_error.append(abs(pred_s - true_s))\n",
    "            p_error = np.around(((abs(pred_s - true_s))/196), 3)\n",
    "            tp_relaxed, fp_relaxed, fn_relaxed = compute_f1_score_at_tolerance(true, pred)\n",
    "            tps_relaxed.append(tp_relaxed)\n",
    "            fps_relaxed.append(fp_relaxed)\n",
    "            fns_relaxed.append(fn_relaxed)\n",
    "            trues.append(true_s)\n",
    "            preds.append(pred_s)\n",
    "            all_trues.append(true.flatten())\n",
    "            all_preds.append(pred.flatten())\n",
    "            if np.sum(true + pred) > 0:\n",
    "                haus_i = compute_robust_hausdorff(dists, 50)\n",
    "                if not np.isinf(haus_i):\n",
    "                    haus.append(haus_i)\n",
    "            if np.sum(true + pred) == 0:\n",
    "                dice_losses.append(1.)\n",
    "                haus.append(0.)\n",
    "            val_loss.append(np.mean(vl))\n",
    "        oa_error = np.mean(abs_error)\n",
    "\n",
    "        precision_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fps_relaxed))\n",
    "        recall_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fns_relaxed))\n",
    "        f1_r = 2*((precision_r* recall_r) / (precision_r + recall_r))\n",
    "        haus = np.mean(haus)\n",
    "        dices = np.mean(dice_losses)\n",
    "        if f1_r > best_f1:\n",
    "            best_dice = dices\n",
    "            best_f1 = f1_r\n",
    "            p = precision_r\n",
    "            r = recall_r\n",
    "            error = oa_error\n",
    "            to_save_trues = all_trues\n",
    "            to_save_preds = all_preds\n",
    "            best_thresh = thresh*0.05\n",
    "            best_haus = haus\n",
    "            preds_return = all_preds\n",
    "            trues_return = all_trues\n",
    "    print(\"{}: Val loss: {} Thresh: {} F1: {}\"\n",
    "          \" R: {} P: {} D: {} H: {} Error: {}\".format(country, \n",
    "                                                     np.around(np.mean(val_loss), 3),\n",
    "                                                     np.around(best_thresh, 2),\n",
    "                                                     np.around(best_f1, 3), np.around(p, 3), np.around(r, 3), \n",
    "                                                     np.mean(best_dice), np.around(best_haus, 3),\n",
    "                                                     np.around(error, 3)))\n",
    "    return np.mean(val_loss), best_f1, error, best_haus, np.mean(best_dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_batch(batch_ids, batch_size):\n",
    "    '''Performs random flips and rotations of the X and Y\n",
    "       data for a total of 4 x augmentation\n",
    "    \n",
    "         Parameters:\n",
    "          batch_ids (list):\n",
    "          batch_size (int):\n",
    "          \n",
    "         Returns:\n",
    "          x_batch (arr):\n",
    "          y_batch (arr):\n",
    "    '''\n",
    "    x = train_x[batch_ids, :, :, :]\n",
    "    y = train_y[batch_ids, :, :]\n",
    "    x_batch = np.zeros_like(x)\n",
    "    y_batch = np.zeros_like(y)\n",
    "    flips = np.random.choice(np.array([0, 1, 2, 3]), batch_size, replace = True)\n",
    "    for i in range(x.shape[0]):\n",
    "        current_flip = flips[i]\n",
    "        if current_flip == 0:\n",
    "            x_batch[i, :, :, :] = x[i]\n",
    "            y_batch[i, :, :] = y[i]\n",
    "        if current_flip == 1:\n",
    "            x_batch[i, :, :, :] = np.flip(x[i], 1)\n",
    "            y_batch[i, :, :] = np.flip(y[i], 0)\n",
    "        if current_flip == 2:\n",
    "            x_batch[i, :, :, :] = np.flip(x[i], [2, 1])\n",
    "            y_batch[i, :, :] = np.flip(y[i], [1, 0])\n",
    "        if current_flip == 3:\n",
    "            x_batch[i, :, :, :] = np.flip(x[i], 2)\n",
    "            y_batch[i, :, :] = np.flip(y[i], 1)\n",
    "\n",
    "    y_batch = y_batch.reshape((batch_size, 14, 14))\n",
    "    return x_batch, y_batch\n",
    "\n",
    "x_batch_test, y_batch_test = augment_batch([0, 1], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model with: \n",
      " 0.2 zone out \n",
      " 0.0 l2 \n",
      " 0.0001 initial LR \n",
      " 0.02 final LR \n",
      " 210969 parameters\n",
      "Restarting training from scratch on 1499 train and 129 test samples, total 374.75\n",
      "(?,)\n",
      "Lovasz Shape:  (?,)\n",
      "BCE Shape:  (?, 14, 14, 1)\n",
      "BCE Shape:  (?,)\n",
      "(?,)\n",
      "Lovasz Shape:  (?,)\n",
      "BCE Shape:  (?, 14, 14, 1)\n",
      "BCE Shape:  (?,)\n",
      "The graph has been finalized\n"
     ]
    }
   ],
   "source": [
    "FRESH_START = True\n",
    "best_val = 0.2\n",
    "\n",
    "START_EPOCH = 1\n",
    "END_EPOCH = 100\n",
    "LEARNING_RATE = 3e-3\n",
    "test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "print(\"Starting model with: \\n {} zone out \\n {} l2 \\n {} initial LR \\n {} final LR \\n {} parameters\"\n",
    "     .format(ZONE_OUT_PROB, L2_REG, INITIAL_LR, FINAL_LR, total_parameters))\n",
    "        \n",
    "    \n",
    "if FRESH_START:\n",
    "    print(\"Restarting training from scratch on {} \"\n",
    "          \"train and {} test samples, total {}\".format(len(train_ids), len(test_ids), len(train_ids)/4))\n",
    "\n",
    "    optimizer = AdaBoundOptimizer(6e-5, 6e-3)\n",
    "    #optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "    train_loss = lovasz_surf(tf.reshape(labels, (-1, 14, 14, 1)), fm, weight = loss_weight, alpha = alpha, beta = beta_)\n",
    "    #train_loss = bce_surf(tf.reshape(labels, (-1, 14, 14, 1)), fm, \n",
    "    #                      smooth = 0.03, \n",
    "    #                      weight = loss_weight,\n",
    "    #                      alpha = alpha)\n",
    "    #l2_loss = tf.losses.get_regularization_l05oss()\n",
    "    #train_loss += l2_loss\n",
    "\n",
    "    ft_optimizer = tf.train.GradientDescentOptimizer(ft_lr)\n",
    "    test_loss = lovasz_surf(tf.reshape(labels, (-1, 14, 14, 1)), fm, weight = loss_weight, alpha = alpha, beta = beta_)\n",
    "    ##test_loss = bce_surf(tf.reshape(labels, (-1, 14, 14, 1)), fm,\n",
    "    #                     weight = loss_weight, \n",
    "    #                     smooth = 0.03, \n",
    "    #                     alpha = alpha)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(train_loss)   \n",
    "        ft_op = ft_optimizer.minimize(train_loss)\n",
    "        \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    saver = tf.train.Saver(max_to_keep = 75)\n",
    "    \n",
    "print(\"The graph has been finalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "f1s = []\n",
    "dices = []\n",
    "errors = []\n",
    "hausdorff = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should be run to do fine-tuning, if commented - train from scratch\n",
    "# The master model right now is \"../models/march-31-2e2/75-67-2/\"\n",
    "# The finetune 75 alpha model is \"../models/april-1-finetune/alpha-75/84-67-6/\"\n",
    "# The finetune 50 alpha model is \"../models/april-1-finetune/alpha-50/91-67-8/\"\n",
    "# The finetune 90 alpha model is not good. Alpha should be less than 0.9\n",
    "#path = \"../models/5e-5/10-92-0/\"\n",
    "#path = \"../models/tropics/2e-5/\"\n",
    "#path = \"../models/5e-5/1-05bce/10-90-8/\"\n",
    "#path = \"../models/april-27-ft/master/\"\n",
    "#path = \"../models/lac-new/157-82-6/\"\n",
    "#path = '../models/sept-22/27-82-5/'\n",
    "#new_saver = tf.train.import_meta_graph(path + 'model.meta')\n",
    "#saver.restore(sess, tf.train.latest_checkpoint(path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ((c1r1, c1r2, c1r3), (c2r1, c2r2, c2r3)) = plt.subplots(2, 3, sharey=False)\n",
    "f.set_size_inches(15, 12)\n",
    "\n",
    "c1r1.set_title(\"Train losses - 0.5 a, 1.05 w, 6 e-5\")\n",
    "sns.scatterplot(y = np.array(train_losses[:]),\n",
    "                x = np.array([x for x in range(len(train_losses[:]))]),\n",
    "               ax = c1r1)\n",
    "\n",
    "c1r2.set_title(\"F1 score\")\n",
    "sns.scatterplot(y = np.array(f1s[:]),\n",
    "                x = np.array([x for x in range(len(f1s[:]))]),\n",
    "               ax = c1r2)\n",
    "\n",
    "c2r1.set_title(\"Test losses\")\n",
    "sns.scatterplot(y = np.array(test_losses[:]),\n",
    "                x = np.array([x for x in range(len(test_losses[:]))]),\n",
    "               ax = c2r1)\n",
    "\n",
    "c2r2.set_title(\"Errors\")\n",
    "sns.scatterplot(y = np.array(errors[:]),\n",
    "                x = np.array([x for x in range(len(errors[:]))]),\n",
    "               ax = c2r2)\n",
    "\n",
    "c2r3.set_title(\"Hausdorff\")\n",
    "sns.scatterplot(y = np.array(hausdorff[:]),\n",
    "                x = np.array([x for x in range(len(errors[:]))]),\n",
    "               ax = c2r3)\n",
    "\n",
    "c1r3.set_title(\"Dice\")\n",
    "sns.scatterplot(y = np.array(dices[:]),\n",
    "                x = np.array([x for x in range(len(dices[:]))]),\n",
    "               ax = c1r3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308, 104, 92, 86, 67, 122, 134, 168, 418]\n",
      "1499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27e9a79a6ea4cb3994b7d4f217f9fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=74), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61b46671d024f4ea1169aad82d5e4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=74), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No equibatch SD: 543.2790555628795\n",
      "Equibatch SD: 107.96937381952475\n"
     ]
    }
   ],
   "source": [
    "# Make sure that the equibatch is working with the augmentation\n",
    "randomize = equibatch(train_ids)\n",
    "sum_no_equibatch = []\n",
    "sum_equibatch = []\n",
    "for k in tnrange(int(len(randomize) // 20)):\n",
    "    rand = [x for x in range(len(randomize))]\n",
    "    batch_ids = rand[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "    _, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "    sum_no_equibatch.append(np.sum(y_batch))\n",
    "    \n",
    "for k in tnrange(int(len(randomize) // 20)):\n",
    "    batch_ids = randomize[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "    _, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "    sum_equibatch.append(np.sum(y_batch))\n",
    "    \n",
    "print(\"No equibatch SD: {}\".format(np.std(np.array(sum_no_equibatch))))\n",
    "print(\"Equibatch SD: {}\".format(np.std(np.array(sum_equibatch))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1499"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [x for x in range(len(train_y))]\n",
    "#train_ids = [x for x in range(440, 505)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# September changes\n",
    "- Implement equibatch\n",
    "- Implement 4x4 FPA, with CSSE in middle blocks\n",
    "- Reduce label smoothing from 0.08 to 0.03\n",
    "- reduce dropblock to 0.95 from 0.8\n",
    "\n",
    "# Things to test\n",
    "- Concatenating mean after GRU\n",
    "- Turning of sse in GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308, 104, 92, 86, 67, 122, 134, 168, 418]\n",
      "1499\n",
      "starting epoch 1, alpha: 0.0, beta: 0.0 drop: 0.9925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c7d6561c954211b077a290a903f7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=74), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Loss 0.5329999923706055\n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:74: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: Val loss: 0.20100000500679016 Thresh: 0.4 F1: 0.839 R: 0.911 P: 0.777 D: 0.6161643171472898 H: 0.957 Error: 18.139\n",
      "Saving model with 0.6161643171472898\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/sept-29/1-83-8/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d5ab12c95528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.0065\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving model with {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../models/sept-29/{}-{}-{}/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../models/sept-29/{}-{}-{}/model\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/sept-29/1-83-8/'"
     ]
    }
   ],
   "source": [
    "### import scipy\n",
    "best_val = 0.5\n",
    "fine_tune = False\n",
    "countries['all'] = [0, len(test_x)]\n",
    "ft_epochs = 0\n",
    "ft_learning_rate = 5e-3\n",
    "\n",
    "for i in range(1, 100):\n",
    "    #al = 0.33\n",
    "    al = np.min( [0.015 * (i - 1), 0.5] )\n",
    "    be = 0.0\n",
    "    #be = np.max([((i / 100) - 0.33 ) + ((i - 33) * 0.02), 0])\n",
    "    #al = np.min([0.0 + (i - 50) * 0.02, 0.8])\n",
    "    #al = 1.0\n",
    "    if al < 0.8:\n",
    "        test_al = 0.5\n",
    "    else:\n",
    "        test_al = al\n",
    "    if fine_tune == True:\n",
    "        op = ft_op\n",
    "        ft_epochs += 1\n",
    "        if ft_epochs % 25 == 0:\n",
    "            ft_learning_rate /= 2\n",
    "        print(\"FINE TUNING WITH {} LR\".format(ft_learning_rate))\n",
    "        \n",
    "    else:\n",
    "        op = op = train_op\n",
    "    randomize = equibatch(train_ids)\n",
    "    print(\"starting epoch {}, alpha: {}, beta: {} drop: {}\".format(i, al, be, np.max((1. - (i*0.0075), 0.80))))\n",
    "   # print(f\"BCE: {1 - al}, LOVASZ: {al * (1 - 2*al)}, SURFACE: {al * (2*al)}\")\n",
    "    #print(np.max([1.9 - (i * 0.015), 1.3]))\n",
    "    \n",
    "    loss = train_loss\n",
    "    BATCH_SIZE = 20\n",
    "    test_ids = [x for x in range(0, len(test_x))]\n",
    "    losses = []\n",
    "    \n",
    "    for k in tnrange(int(len(randomize) // BATCH_SIZE)):\n",
    "        rmax_epoch, dmax_epoch, rmin_epoch = calc_renorm_params(i, 5000, 20, k)\n",
    "        if k % 8 == 0:\n",
    "            sleep(1)\n",
    "        batch_ids = randomize[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "        x_batch, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "        opt, tr = sess.run([op, loss],\n",
    "                          feed_dict={inp: x_batch,\n",
    "                                     length: train_l[batch_ids].reshape((-1, 1)),\n",
    "                                     labels: y_batch,\n",
    "                                     is_training: True,\n",
    "                                     clipping_params['rmax']: rmax_epoch,\n",
    "                                     clipping_params['rmin']: rmin_epoch,\n",
    "                                     clipping_params['dmax']: dmax_epoch,\n",
    "                                     loss_weight: 1.00,\n",
    "                                     #loss_weight: np.max([1.9 - (i * 0.015), 1.3]), \n",
    "                                     keep_rate: np.max((1. - (i * 0.0075), 0.8)),\n",
    "                                     alpha: al,\n",
    "                                     beta_: be,\n",
    "                                     ft_lr: ft_learning_rate,\n",
    "                                     })\n",
    "        losses.append(tr)\n",
    "    \n",
    "    print(\"Epoch {}: Loss {}\".format(i, np.around(np.mean(losses[:-1]), 3)))\n",
    "    \n",
    "    # _, _, _, _, _, _ = calculate_metrics(\"global-test\", al = al)\n",
    "    val_loss, f1, error, haus, dice = calculate_metrics('all', al = test_al, canopy_thresh = 75)\n",
    "    train_losses.append(np.mean(losses[:-1]))\n",
    "    test_losses.append(val_loss)\n",
    "    f1s.append(f1)\n",
    "    dices.append(dice)\n",
    "    errors.append(error)\n",
    "    hausdorff.append(haus)\n",
    "    if f1 > (best_val - 0.0065):\n",
    "        print(\"Saving model with {}\".format(dice))\n",
    "        os.mkdir(\"../models/sept-29/{}-{}-{}/\".format(str(i), str(f1*100)[:2], str(f1*100)[3]))\n",
    "        save_path = saver.save(sess, \"../models/sept-29/{}-{}-{}/model\".format(str(i), str(f1*100)[:2], str(f1*100)[3]))\n",
    "        if f1 > best_val:\n",
    "            best_val = f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_renorm_params(30, 5000, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100% Surf =  -0.165\n",
    "# 100% LOV = 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_loss, f1, error, haus, dice = calculate_metrics('all', al = test_al, canopy_thresh = 75)\n",
    "os.mkdir(\"../models/5e-5/1-10bce/{}-{}-{}\".format(str(34), str(f1*100)[:2], str(f1*100)[3]))\n",
    "save_path = saver.save(sess, \"../models/5e-5/1-10bce/{}-{}-{}/model\".format(str(34), str(f1*100)[:2], str(f1*100)[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation and sanity checks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = np.concatenate(preds).flatten()\n",
    "trues2 = np.concatenate(trues).flatten()\n",
    "tp = preds2 * trues2\n",
    "fn = [1 if x > y else 0 for (x, y) in zip(trues2, preds2)]\n",
    "fp = [1 if y > x else 0 for (x, y) in zip(trues2, preds2)]\n",
    "tn = (len(test_y) * 196) - np.sum(tp) - np.sum(fn) - np.sum(fp)\n",
    "print(\"TP {}, FN {}, FP {}, TN {}\".format(np.sum(tp), sum(fn), np.sum(fp), tn))\n",
    "print(len(preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps = []\n",
    "fns = []\n",
    "fps = []\n",
    "for i in range(0, len(test_y)*196, 196):\n",
    "    tps.append(np.sum(tp[i:i+196]))\n",
    "    fns.append(np.sum(fn[i:i+196]))\n",
    "    fps.append(np.sum(fp[i:i+196]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "true_canopy = []\n",
    "error_canopy = []\n",
    "pred_canopy = []\n",
    "f1_hard = []\n",
    "tp_softs = []\n",
    "fp_softs = []\n",
    "fn_softs = []\n",
    "for i in range(len(trues)):\n",
    "    true_canopy.append(np.sum(trues[i]) / 1.96)\n",
    "    error_canopy.append(abs(np.sum(preds[i]) - np.sum(trues[i])) / 1.96)\n",
    "    pred_canopy.append(np.sum(preds[i]) / 1.96)\n",
    "    f1_hard.append(f1_score(trues[i], preds[i]))\n",
    "    tp_soft, fp_soft, fn_soft = compute_f1_score_at_tolerance(np.array(trues[i].reshape((14, 14))),\n",
    "                                                 np.array(preds[i].reshape((14, 14))))\n",
    "    tp_softs.append(tp_soft)\n",
    "    fp_softs.append(fp_soft)\n",
    "    fn_softs.append(fn_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.sum(tp_softs) / (np.sum(tp_softs) + np.sum(fp_softs))\n",
    "recall = np.sum(tp_softs) / (np.sum(tp_softs) + np.sum(fn_softs))\n",
    "print(precision, recall, np.mean(error_canopy), np.mean(true_canopy), np.mean(pred_canopy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ids_loaded = np.load(\"../data/metrics/plotids.npy\")\n",
    "plot_ids_loaded = np.delete(plot_ids_loaded, outliers, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame({'true': true_canopy,\n",
    "                        'pred': pred_canopy,\n",
    "                        'f1_hard': f1_hard,\n",
    "                        'error': error_canopy,\n",
    "                        'tp': tps,\n",
    "                        'fp': fps,\n",
    "                        'fn': fns,\n",
    "                        'tp_soft': tp_softs,\n",
    "                        'fp_soft': fp_softs,\n",
    "                        'fn_soft': fn_softs,\n",
    "                       })\n",
    "\n",
    "res = map(lambda x: int(math.floor(np.min([x, 90]) / 10.0)) * 10, true_canopy)\n",
    "res = [x for x in res]\n",
    "metrics['group'] = res\n",
    "metrics['model'] = 'proposed'\n",
    "#metrics['slope'] = slopes\n",
    "metrics['plot_id'] = plot_ids_loaded\n",
    "metrics.to_csv(\"../data/metrics/proposed-sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(\"../data/metrics/proposed-sample.csv\")\n",
    "continents = pd.read_csv(\"../data/latlongs/test_continents.csv\")\n",
    "continents = continents.join(metrics, how = 'inner')\n",
    "continents.groupby(\"CONTINENT\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_precisions = metrics.groupby('group').apply(lambda x: (np.sum(x.tp) / np.sum(x.tp + x.fp)))\n",
    "hard_recalls = metrics.groupby('group').apply(lambda x: (np.sum(x.tp) / np.sum(x.tp + x.fn)))\n",
    "errors = metrics.groupby('group').apply(lambda x: np.mean(x.error))\n",
    "hard_f1 = 2 *  ((hard_precisions * hard_recalls) / (hard_precisions + hard_recalls))\n",
    "\n",
    "precisions = metrics.groupby('group').apply(lambda x: (np.sum(x.tp_soft) / np.sum(x.tp_soft + x.fp_soft)))\n",
    "recalls = metrics.groupby('group').apply(lambda x: (np.sum(x.tp_soft) / np.sum(x.tp_soft + x.fn_soft)))\n",
    "soft_f1 = 2 *  ((precisions * recalls) / (precisions + recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metrics = pd.DataFrame({'group': [x for x in range(0, 100, 10)],\n",
    "                            'hard_rec': hard_recalls,\n",
    "                            'soft_rec': recalls,\n",
    "                            'hard_prec': hard_precisions,\n",
    "                            'soft_prec': precisions,\n",
    "                            'hard_f1': hard_f1,\n",
    "                            'soft_f1': soft_f1,\n",
    "                            'error': errors,\n",
    "                            'model': 'proposed'\n",
    "                           })\n",
    "\n",
    "#new_metrics.to_csv(\"../data/metrics/proposed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pd.read_csv(\"../data/metrics/rf.csv\")\n",
    "svm = pd.read_csv(\"../data/metrics/svm.csv\")\n",
    "unet = pd.read_csv(\"../data/metrics/unet.csv\")\n",
    "new_metrics = pd.read_csv(\"../data/metrics/proposed.csv\")\n",
    "metrics = pd.concat([new_metrics, unet, svm, rf])\n",
    "\n",
    "#rf = pd.read_csv(\"../data/metrics/random_forest.csv\")\n",
    "svm = pd.read_csv(\"../data/metrics/svm-sample.csv\")\n",
    "unet = pd.read_csv(\"../data/metrics/unet-sample.csv\")\n",
    "proposed = pd.read_csv(\"../data/metrics/proposed-sample.csv\")\n",
    "rf = pd.read_csv(\"../data/metrics/rf-sample.csv\")\n",
    "#metrics['model'] = 'proposed'\n",
    "sample = pd.concat([proposed, unet, svm, rf])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hard F1, Soft F1, Error\n",
    "f, ((c1r1, c1r2, c1r3)) = plt.subplots(1, 3, sharey=False)\n",
    "f.set_size_inches(20, 8.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale = 1.5)\n",
    "\n",
    "c1r1.set_title(\"User's accuracy\")\n",
    "one = sns.pointplot(x = 'group', y= 'soft_prec',\n",
    "    data=metrics, hue = 'model', ax = c1r1)#, style = 'variable')\n",
    "one.set_xticklabels(rotation=45, labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59',\n",
    "                     '60-69', '70-79', '80-89', '90-100'])\n",
    "one.set(xlabel='Tree cover (of 140 x 140 m plot)', ylabel = \"User's accuracy\")\n",
    "one.set_yticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "one.legend(fontsize='small')\n",
    "\n",
    "c1r2.set_title(\"Producer's accuracy\")\n",
    "two = sns.pointplot(x = 'group', y= 'soft_rec',\n",
    "    data=metrics, hue = 'model', ax = c1r2)\n",
    "two.set_xticklabels(rotation=45, labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59',\n",
    "                     '60-69', '70-79', '80-89', '90-100'])\n",
    "two.set(xlabel='Tree cover (of 140 x 140 m plot)', ylabel = \"Producer's accuracy\")\n",
    "two.set_yticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "\n",
    "c1r3.set_title(\"Absolute % Error\")\n",
    "three = sns.pointplot(x = 'group', y= 'error',\n",
    "    data=sample, hue = 'model', ax = c1r3)#, style = 'variable')\n",
    "three.set_xticklabels(rotation=45, labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59',\n",
    "                     '60-69', '70-79', '80-89', '90-100'])\n",
    "three.set(xlabel='Tree cover (of 140 x 140 m plot)', ylabel = \"Absolute error (%)\")\n",
    "three.set_yticks([0, 5, 10, 15, 20, 25, 30,35, 40,45, 50])\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "two.legend_.remove()\n",
    "three.legend_.remove()\n",
    "#plt.show()\n",
    "fig1 = plt.gcf()\n",
    "plt.show()\n",
    "plt.draw()\n",
    "fig1.savefig('../references/pdf/figure9.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = [x for x in range(len(test_x))]\n",
    "diffs = []\n",
    "for idx in tnrange(len(test_ids)):\n",
    "    y = sess.run([fm], feed_dict={inp: test_x[idx].reshape(1, 24, IMAGE_SIZE, IMAGE_SIZE, n_bands),\n",
    "                                  length: test_lengths[idx].reshape(1, 1),\n",
    "                                  is_training: False,\n",
    "                                  clipping_params['rmax']: rmax_epoch,\n",
    "                                  clipping_params['rmin']: rmin_epoch,\n",
    "                                  clipping_params['dmax']: dmax_epoch,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    y[np.where(y > 0.5)] = 1.0\n",
    "    y[np.where(y < 0.5)] = 0.\n",
    "    diff = np.sum(y) - np.sum(test_y[idx])\n",
    "    diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "\n",
    "test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list):\n",
    "          nrows (int):\n",
    "          \n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(20, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_alignment(true, pred, wsize = 3, difference = 0.2):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          true (arr):\n",
    "          pred (arr):\n",
    "          wsize (int):\n",
    "          difference (float):\n",
    "          \n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    n_single_trees = 0\n",
    "    for x in range(1, true.shape[0] - 1, 1):\n",
    "        for y in range(1, true.shape[1] - 1, 1):\n",
    "            wind_true = true[x-1:x+2, y-1:y+2]\n",
    "            wind_pred = pred[x-1:x+2, y-1:y+2]\n",
    "            if wind_true[1, 1] == 1:\n",
    "                if np.sum(wind_true) == 1:\n",
    "                    n_single_trees += 1\n",
    "                    pred_place = np.argmax(wind_pred.flatten())\n",
    "                    diff = wind_pred.flatten()[pred_place] - wind_pred.flatten()[4]\n",
    "                    if pred_place != 4:\n",
    "                        if diff > difference:\n",
    "                            x_lv = pred_place // 3\n",
    "                            y_lv = pred_place % 3\n",
    "                            print(x_lv, y_lv)\n",
    "                            proposed = wind_true[x_lv - 1:x_lv+2, y_lv-1:y_lv+2]\n",
    "                            if np.sum(proposed) == 0:\n",
    "                                print(\"There is a missed position at {} x, {} y: {}\".format(x, y, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_maxes(y_true, y_pred):\n",
    "    y_out = np.copy(y_pred)\n",
    "    change_map = np.zeros((14, 14))\n",
    "    for x in range(y_true.shape[0]):\n",
    "        for y in range(y_true.shape[0]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([y_true.shape[1], y+2])\n",
    "            max_x = np.min([y_true.shape[1], x+2])\n",
    "            \n",
    "            y_true_sum = np.sum(y_true[min_x:max_x, min_y:max_y])\n",
    "            y_pred_max = np.max(y_pred[min_x:max_x, min_y:max_y])\n",
    "            y_pred_min = np.min(y_pred[min_x:max_x, min_y:max_y])\n",
    "            \n",
    "    \n",
    "            if y_true[x, y] == 1: # if positive and unsure\n",
    "                if y_true_sum < 9: # if edge and there is a candidate\n",
    "                    diffs = y_pred_max - y_pred[x, y]\n",
    "                    percentage = np.min([1/(1 + np.exp(-(diffs * 10 - 5))), 0.5])\n",
    "                    y_out[x, y] += percentage\n",
    "                    change_map[x, y] = percentage\n",
    "            if y_true[x, y] == 0:# and y_pred[x, y] > 0.75: # if negative and unsure\n",
    "                if y_true_sum > 0: #and y_pred_min < 0.25: # if edge and there is a candidate\n",
    "                    diffs = y_pred[x, y] - y_pred_min\n",
    "                    percentage = np.min([1/(1 + np.exp(-(diffs * 10 - 5))), 0.5])\n",
    "                    y_out[x, y] -= percentage #= np.min(y_pred[min_x:max_x, min_y:max_y])\n",
    "                    change_map[x, y] = -percentage\n",
    "    return y_out, change_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(start/len(test_ids))\n",
    "test_ids = sorted(test_ids)\n",
    "#start = 8\n",
    "to_test = [681, 684, 689, 732, 791, 798, 802, 877, 905, 947, 951, 964, 965, 966, 997, 1094, 1101]\n",
    "matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3],\n",
    "              test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "#matrix_ids = np.argwhere(abs(np.array(diffs)) > 100)[8 + 8 + 8 + 8 : 8 + 8 + 8 + 8 + 8]\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    #print(plot_ids_loaded[i])\n",
    "    idx = i\n",
    "    y = sess.run([fm], feed_dict={inp: test_x[idx].reshape(1, 24, IMAGE_SIZE, IMAGE_SIZE, n_bands),\n",
    "                                  length: train_l[idx].reshape(1, 1),\n",
    "                                  is_training: False,\n",
    "                                  clipping_params['rmax']: rmax_epoch,\n",
    "                                  clipping_params['rmin']: rmin_epoch,\n",
    "                                  clipping_params['dmax']: dmax_epoch,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    #y, mapshape = aggregate_maxes(test_y[idx], y)\n",
    "    preds.append(y)\n",
    "    y2 = np.copy(y)\n",
    "    print(np.mean(dice_loss(test_y[idx], y)), np.mean(dice_loss_tolerance(test_y[idx], y)))\n",
    "    #surf_distances = \n",
    "    #y[np.where(y > 0.4)] = 1.0\n",
    "    #y[np.where(y < 0.4)] = 0.\n",
    "    #y[np.where(y >= 0.4)] = 1.\n",
    "    #dc = np.around(dice_loss(test_y[idx].flatten(), y2.flatten()), 3)\n",
    "    true = test_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "\n",
    "\n",
    "start = start + 8 \n",
    "\n",
    "\n",
    "\n",
    "# 220, \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    true = true.reshape((14, 14))\n",
    "    pred = pred.reshape((14, 14))\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if pred[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1\n",
    "    precision =  np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    recall = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for idx in tnrange(len(train_ids)):\n",
    "    y = sess.run([fm], feed_dict={inp: train_x[idx].reshape(1, 24, IMAGE_SIZE, IMAGE_SIZE, n_bands),\n",
    "                                  length: train_l[idx].reshape(1, 1),\n",
    "                                  is_training: False,\n",
    "                                  clipping_params['rmax']: rmax_epoch,\n",
    "                                  clipping_params['rmin']: rmin_epoch,\n",
    "                                  clipping_params['dmax']: dmax_epoch,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    y[np.where(y > 0.5)] = 1.0\n",
    "    y[np.where(y < 0.5)] = 0.\n",
    "    diff = np.sum(y) - np.sum(train_y[idx])\n",
    "    diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [x for x in range(train_x.shape[0])]\n",
    "train_ids = sorted(train_ids)\n",
    "start = len(train_ids) - 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##matrix_ids = [70, 139, 456, 630, 718, 800, 835, 1101]\n",
    "#matrix_ids = np.argwhere(abs(np.array(diffs)) > 75)[8 + 8 + 8 + 8 + 8 + 8 + 8 +8 +8 + 8 + 8 + 8 + 8 + 8:\n",
    "#                                                    8 + 8 + 8 + 8 + 8 + 8 + 8 + 8 + 8 + 8 + 8+ 8 + 8 + 8 + 8]\n",
    "\n",
    "matrix_ids = [train_ids[start], train_ids[start + 1], train_ids[start + 2],\n",
    "              train_ids[start + 3], train_ids[start + 4],\n",
    "             train_ids[start + 5], train_ids[start + 6], train_ids[start + 7]]\n",
    "#matrix_ids = [358, 425, 459, 516, 625, 705, 1065]\n",
    "preds = []\n",
    "trues = []\n",
    "#print(start//4)\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    y = sess.run([fm], feed_dict={inp: train_x[idx].reshape(1, 24, IMAGE_SIZE, IMAGE_SIZE, n_bands),\n",
    "                                  length: train_l[idx].reshape(1, 1),\n",
    "                                  is_training: False,\n",
    "                                  clipping_params['rmax']: rmax_epoch,\n",
    "                                  clipping_params['rmin']: rmin_epoch,\n",
    "                                  clipping_params['dmax']: dmax_epoch,\n",
    "                                    })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    \n",
    "    #y, _ = aggregate_maxes(train_y[idx], y)\n",
    "    \n",
    "    preds.append(y)\n",
    "    true = train_y[idx].reshape(14, 14)\n",
    "    #print(np.mean(dice_loss(train_y[idx], y)), np.mean(dice_loss_tolerance(train_y[idx], y)))\n",
    "    #identify_alignment(true, y)\n",
    "    \n",
    "    trues.append(true)\n",
    "    \n",
    "start += 8\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "\n",
    "[1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-toolkit",
   "language": "python",
   "name": "policy-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
