{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants, DataSource, CustomUrlParam\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage.transform import resize\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import splu\n",
    "\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "        key = (yaml.safe_load(stream))\n",
    "        API_KEY = key['key'] \n",
    "        \n",
    "%run ../src/slope.py\n",
    "%run ../src/utils-bilinear.py\n",
    "%run ../src/dsen2/utils/DSen2Net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ('2018-12-15', '2020-01-15')\n",
    "EPSG = CRS.WGS84\n",
    "IMSIZE = 48\n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions (to be moved to a utils file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic Model Created.\n"
     ]
    }
   ],
   "source": [
    "def calculate_proximal_steps_index(date, satisfactory):\n",
    "    arg_before = None\n",
    "    arg_after = None\n",
    "    if date > 0:\n",
    "        idx_before = satisfactory - date\n",
    "        arg_before = idx_before[np.where(idx_before < 0, idx_before, -np.inf).argmax()]\n",
    "    if date < np.max(satisfactory):\n",
    "        idx_after = satisfactory - date\n",
    "        arg_after = idx_after[np.where(idx_after > 0, idx_after, np.inf).argmin()]\n",
    "    if not arg_after and not arg_before:\n",
    "        arg_after = date\n",
    "        arg_before = date\n",
    "    if not arg_after:\n",
    "        arg_after = arg_before\n",
    "    if not arg_before:\n",
    "        arg_before = arg_after\n",
    "    return arg_before, arg_after\n",
    "\n",
    "def speyediff(N, d, format = 'csc'):\n",
    "    shape = (N-d, N)\n",
    "    diagonals = np.zeros(2*d + 1)\n",
    "    diagonals[d] = 1.\n",
    "    for i in range(d):\n",
    "        diff = diagonals[:-1] - diagonals[1:]\n",
    "        diagonals = diff\n",
    "    offsets = np.arange(d+1)\n",
    "    spmat = sparse.diags(diagonals, offsets, shape, format = format)\n",
    "    return spmat\n",
    "\n",
    "def smooth(y, lmbd, d = 2):\n",
    "    m = len(y)\n",
    "    E = sparse.eye(m, format = 'csc')\n",
    "    D = speyediff(m, d, format = 'csc')\n",
    "    coefmat = E + lmbd * D.conj().T.dot(D)\n",
    "    z = splu(coefmat).solve(y)\n",
    "    return z\n",
    "\n",
    "MDL_PATH = \"../src/dsen2/models/\"\n",
    "\n",
    "input_shape = ((4, None, None), (6, None, None))\n",
    "model = s2model(input_shape, num_layers=6, feature_size=128)\n",
    "predict_file = MDL_PATH+'s2_032_lr_1e-04.hdf5'\n",
    "print('Symbolic Model Created.')\n",
    "\n",
    "model.load_weights(predict_file)\n",
    "\n",
    "def DSen2(d10, d20):\n",
    "    test = [d10, d20]\n",
    "    input_shape = ((4, None, None), (6, None, None))\n",
    "    prediction = _predict(test, input_shape, deep=False)\n",
    "    #prediction *= 5\n",
    "    return prediction\n",
    "\n",
    "def _predict(test, input_shape, model = model, deep=False, run_60=False):\n",
    "    \n",
    "    print(\"Predicting using file: {}\".format(predict_file))\n",
    "    prediction = model.predict(test, verbose=1)\n",
    "    return prediction\n",
    "\n",
    "c_arr = np.array([[1, 1, 1, 1, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 2, 3, 2, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 1, 1, 1, 1,],])\n",
    "                  \n",
    "c_arr = c_arr / 3\n",
    "o_arr = 1 - c_arr\n",
    "c_arr = np.tile(c_arr[:, :, np.newaxis], (1, 1, 11))\n",
    "o_arr = np.tile(o_arr[:, :, np.newaxis], (1, 1, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCoords(xy, src='', targ=''):\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])\n",
    "\n",
    "def calc_bbox(plot_id, df):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    # TOP, LEFT, BOTTOM, RIGHT\n",
    "    # (min x, min y), (max x, max y)\n",
    "    return [(min(subs['LON']), min(subs['LAT'])),\n",
    "            (max(subs['LON']), max(subs['LAT']))]\n",
    "\n",
    "def bounding_box(points, expansion = 160):\n",
    "    # LONG, LAT FOR SOME REASON\n",
    "    bl = list(points[0])\n",
    "    tr = list(points[1])\n",
    "    \n",
    "    if 78 <= tr[0] <= 84:\n",
    "        epsg = 32644 if tr[1] > 0 else 32744\n",
    "    if 72 <= tr[0] <= 78:\n",
    "        epsg = 32643 if tr[1] > 0 else 32743\n",
    "    if 66 <= tr[0] <= 72:\n",
    "        epsg = 32642 if tr[1] > 0 else 32742\n",
    "    if 60 <= tr[0] <= 66:\n",
    "        epsg = 32641 if tr[1] > 0 else 32741\n",
    "    if 54 <= tr[0] <= 60:\n",
    "        epsg = 32640 if tr[1] > 0 else 32740\n",
    "    if 48 <= tr[0] <= 54:\n",
    "        epsg = 32639 if tr[1] > 0 else 32739\n",
    "    if 42 <= tr[0] <= 48:\n",
    "        epsg = 32638 if tr[1] > 0 else 32738\n",
    "    if 36 <= tr[0] <= 42:\n",
    "        epsg = 32637 if tr[1] > 0 else 32737\n",
    "    if 30 <= tr[0] <= 36:\n",
    "        epsg = 32636 if tr[1] > 0 else 32736\n",
    "    if 24 <= tr[0] <= 30:\n",
    "        epsg = 32635 if tr[1] > 0 else 32735\n",
    "    if 18 <= tr[0] <= 24:\n",
    "        epsg = 32634 if tr[1] > 0 else 32734\n",
    "    if 12 <= tr[0] <= 18:\n",
    "        epsg = 32633 if tr[1] > 0 else 32733\n",
    "    if 6 <= tr[0] <= 12:\n",
    "        epsg = 32632 if tr[1] > 0 else 32732\n",
    "    if 0 <= tr[0] <= 6:\n",
    "        epsg = 32631 if tr[1] > 0 else 32731\n",
    "    if -6 <= tr[0] <= 0:\n",
    "        epsg = 32630 if tr[1] > 0 else 32730\n",
    "    if -12 <= tr[0] <= -6:\n",
    "        epsg = 32629 if tr[1] > 0 else 32729\n",
    "    if -18 <= tr[0] <= -12:\n",
    "        epsg = 32628 if tr[1] > 0 else 32728\n",
    "    if -24 <= tr[0] <= -18:\n",
    "        epsg = 32627 if tr[1] > 0 else 32727\n",
    "    if -30 <= tr[0] <= -24:\n",
    "        epsg = 32626 if tr[1] > 0 else 32726\n",
    "    if -36 <= tr[0] <= -30:\n",
    "        epsg = 32625 if tr[1] > 0 else 32725\n",
    "    if -42 <= tr[0] <= -36:\n",
    "        epsg = 32624 if tr[1] > 0 else 32724\n",
    "    if -48 <= tr[0] <= -42:\n",
    "        epsg = 32623 if tr[1] > 0 else 32723\n",
    "    if -54 <= tr[0] <= -48:\n",
    "        epsg = 32622 if tr[1] > 0 else 32722\n",
    "    if -60 <= tr[0] <= -54:\n",
    "        epsg = 32621 if tr[1] > 0 else 32721\n",
    "    if -66 <= tr[0] <= -60:\n",
    "        epsg = 32620 if tr[1] > 0 else 32720\n",
    "    if -72 <= tr[0] <= -66:\n",
    "        epsg = 32619 if tr[1] > 0 else 32719\n",
    "    if -78 <= tr[0] <= -72:\n",
    "        epsg = 32618 if tr[1] > 0 else 32718\n",
    "    if -84 <= tr[0] <= -78:\n",
    "        epsg = 32617 if tr[1] > 0 else 32717\n",
    "    if -90 <= tr[0] <= -84:\n",
    "        epsg = 32616 if tr[1] > 0 else 32716\n",
    "    if -96 <= tr[0] <= -90:\n",
    "        epsg = 32615 if tr[1] > 0 else 32715\n",
    "    if -102 <= tr[0] <= -96:\n",
    "        epsg = 32614 if tr[1] > 0 else 32714\n",
    "    if -108 <= tr[0] <= -102:\n",
    "        epsg = 32613 if tr[1] > 0 else 32713\n",
    "    print(bl)\n",
    "    bl = convertCoords(bl, 4326, epsg)\n",
    "    tr = convertCoords(tr, 4326, epsg)\n",
    "    init = [b - a for a,b in zip(bl, tr)]\n",
    "    distance1 = tr[0] - bl[0]\n",
    "    distance2 = tr[1] - bl[1]\n",
    "    expansion1 = (expansion - distance1)/2\n",
    "    expansion2 = (expansion - distance2)/2\n",
    "    bl = [bl[0] - expansion1, bl[1] - expansion2]\n",
    "    tr = [tr[0] + expansion1, tr[1] + expansion2]\n",
    "\n",
    "    after = [b - a for a,b in zip(bl, tr)]   \n",
    "    print(after)\n",
    "    if max(init) > 130:\n",
    "        print(\"ERROR: Initial field greater than 130m\")\n",
    "    if min(init) < 120:\n",
    "        print(\"ERROR: Initial field less than 130m\")\n",
    "        \n",
    "    if min(after) < (expansion - 4.5):\n",
    "        print(\"ERROR\")\n",
    "    if max(after) > (expansion + 5):\n",
    "        print(\"ERROR\")\n",
    "    diffs = [b - a for b, a in zip(after, init)]\n",
    "\n",
    "    bl = convertCoords(bl, epsg, 4326)\n",
    "    tr = convertCoords(tr, epsg, 4326)\n",
    "    return bl, tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_clouds(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        cloud_request = WmsRequest(\n",
    "            layer='CLOUD_DETECTION',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=IMSIZE,\n",
    "            height=IMSIZE,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.75,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        cloud_img = cloud_request.get_data()\n",
    "        cloud_probs = cloud_detector.get_cloud_probability_maps(np.array(cloud_img))\n",
    "        means = np.mean(cloud_probs, (1, 2))\n",
    "        clean_steps = [i for i, val in enumerate(means) if val < 0.20]\n",
    "        return clean_steps, means, cloud_probs\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(val, df, epsg = EPSG, ):\n",
    "    location = calc_bbox(val, df = df)\n",
    "    bbox = bounding_box(location, expansion = (IMSIZE+2)*10)\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=IMSIZE+2,\n",
    "                         height=IMSIZE+2,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, IMSIZE+2, IMSIZE+2)),\n",
    "                  np.full((IMSIZE+2, IMSIZE+2), 10), np.full((IMSIZE+2, IMSIZE+2), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((IMSIZE+2, IMSIZE+2, 1))\n",
    "    dem_image = dem_image[1:IMSIZE+1, 1:IMSIZE+1, :]\n",
    "    return dem_image\n",
    "\n",
    "def check_zenith(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        zenith = WmsRequest(\n",
    "            layer='ZENITH',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=IMSIZE,\n",
    "            height=IMSIZE,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.75,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        zenith = zenith.get_data()\n",
    "        return zenith\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "        \n",
    "def download_layer(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A20',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        img_20 = np.stack(img_bands)\n",
    "        img_20 = resize(img_20, (img_20.shape[0], IMSIZE, IMSIZE, img_20.shape[-1]), order = 0)\n",
    "        \n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A10',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'BICUBIC',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        img_bands = image_request.get_data()\n",
    "        img_10 = np.stack(img_bands)\n",
    "        print(\"Original size: {}\".format(img_10.shape))\n",
    "        img_10 = resize(img_10, (img_10.shape[0], IMSIZE, IMSIZE, img_10.shape[-1]), order = 0)\n",
    "        shadows = img_10[:, :, :, -1]\n",
    "        img_10 = img_10[:, :, :, :-1]\n",
    "        \n",
    "        shadows[np.where(shadows != 3)] = 0\n",
    "        shadows[np.where(shadows == 3)] = 1\n",
    "        shadows_sums = np.sum(shadows, axis = 0)\n",
    "        before = np.sum(shadows)\n",
    "        #shadows[np.where(shadows_sums > shadows.shape[0]/2)] = 0.\n",
    "        print(\"Difference: {}\".format(np.sum(shadows) - before))\n",
    "        print(\"Shadows: {}\".format(shadows.shape))\n",
    "        shadow_sum = np.sum(shadows, axis = (1, 2))\n",
    "        shadow_steps = np.argwhere(shadow_sum > (IMSIZE*IMSIZE) / 5)\n",
    "        \n",
    "        img = np.concatenate([img_10, img_20], axis = -1)\n",
    "        return img, image_request, shadows, shadow_steps\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud and shadow removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cloud_and_shadows(tiles, probs, shadows, image_dates, wsize = 5):\n",
    "    c_probs = np.copy(probs)\n",
    "    c_probs = c_probs - np.min(c_probs, axis = 0)\n",
    "    c_probs[np.where(c_probs > 0.33)] = 1.\n",
    "    c_probs[np.where(c_probs < 0.33)] = 0.\n",
    "    c_probs = np.reshape(c_probs, [c_probs.shape[0], int(IMSIZE/8), 8, int(IMSIZE/8), 8])\n",
    "    c_probs = np.sum(c_probs, (2, 4))\n",
    "    c_probs = resize(c_probs, (c_probs.shape[0], IMSIZE, IMSIZE), 0)\n",
    "    c_probs[np.where(c_probs < 12)] = 0.\n",
    "    c_probs[np.where(c_probs >= 12)] = 1.\n",
    "    c_probs += shadows\n",
    "    c_probs[np.where(c_probs >= 1.)] = 1.\n",
    "    n_interp = 0\n",
    "    for cval in range(0, IMSIZE - 4, 1):\n",
    "        for rval in range(0, IMSIZE - 4, 1):\n",
    "            subs = c_probs[:, cval:cval + wsize, rval:rval+wsize]\n",
    "            satisfactory = [x for x in range(c_probs.shape[0]) if np.sum(subs[x, :, :]) < 10]\n",
    "            satisfactory = np.array(satisfactory)\n",
    "            for date in range(0, tiles.shape[0]):\n",
    "                if np.sum(subs[date, :, :]) > 10:\n",
    "                    n_interp += 1\n",
    "                    before, after = calculate_proximal_steps_index(date, satisfactory)\n",
    "                    before = date + before\n",
    "                    after = date + after\n",
    "                    bef = tiles[before, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    aft = tiles[after, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    before = image_dates[before]\n",
    "                    after = image_dates[after]\n",
    "                    before_diff = abs(image_dates[date] - before)\n",
    "                    after_diff = abs(image_dates[date] - after)\n",
    "                    bef_wt = 1 - before_diff / (before_diff + after_diff)\n",
    "                    aft_wt = 1 - bef_wt\n",
    "                    candidate = bef_wt*bef + aft_wt*aft\n",
    "                    candidate = candidate*c_arr + tiles[date, cval:cval+wsize, rval:rval+wsize, : ]*o_arr\n",
    "                    tiles[date, cval:cval+wsize, rval:rval+wsize, : ] = candidate  \n",
    "    print(\"Interpolated {} px\".format(n_interp))\n",
    "    return tiles\n",
    "\n",
    "def remove_missed_clouds(img):\n",
    "    iqr = np.percentile(img[:, :, :, 3].flatten(), 75) - np.percentile(img[:, :, :, 3].flatten(), 25)\n",
    "    thresh_t = np.percentile(img[:, :, :, 3].flatten(), 75) + iqr*2\n",
    "    thresh_b = np.percentile(img[:, :, :, 3].flatten(), 25) - iqr*2\n",
    "    diffs_fw = np.diff(img, 1, axis = 0)\n",
    "    diffs_fw = np.mean(diffs_fw, axis = (1, 2, 3))\n",
    "    diffs_fw = np.array([0] + list(diffs_fw))\n",
    "    diffs_bw = np.diff(np.flip(img, 0), 1, axis = 0)\n",
    "    diffs_bw = np.flip(np.mean(diffs_bw, axis = (1, 2, 3)))\n",
    "    diffs_bw = np.array(list(diffs_bw) + [0])\n",
    "    diffs = abs(diffs_fw - diffs_bw) * 100 # 3, -3 -> 6, -3, 3 -> 6, -3, -3\n",
    "    #diffs = [int(x) for x in diffs]\n",
    "    outlier_percs = []\n",
    "    for step in range(img.shape[0]):\n",
    "        bottom = len(np.argwhere(img[step, :, :, 3].flatten() > thresh_t))\n",
    "        top = len(np.argwhere(img[step, :, :, 3].flatten() < thresh_b))\n",
    "        p = 100* ((bottom + top) / (IMSIZE*IMSIZE))\n",
    "        outlier_percs.append(p)\n",
    "    to_remove = np.argwhere(np.array(outlier_percs) > 15)\n",
    "    print([int(x) for x in outlier_percs])\n",
    "    return to_remove\n",
    "\n",
    "def threshold_shadows(arr):\n",
    "    arr = np.copy(arr)\n",
    "    iqr = np.percentile(arr.flatten(), 75) - np.percentile(arr.flatten(), 25)\n",
    "    low = np.percentile(arr.flatten(), 25)\n",
    "    #high = np.percentile(arr.flatten(), 75)\n",
    "    thresh_low = low - 1.5*iqr\n",
    "    #thresh_high = high + 2*iqr\n",
    "    #arr[np.where(arr > thresh_high)] = 1.\n",
    "    arr[np.where(arr < thresh_low)] = 1.\n",
    "    arr[np.where(arr < 1)] = 0.\n",
    "    arr = np.reshape(arr, (arr.shape[0], 6, 8, 6, 8))\n",
    "    arr = np.sum(arr, axis = (2, 4))\n",
    "    arr = resize(arr, (arr.shape[0], 48, 48), 0)\n",
    "    fake_shadows = np.zeros((arr.shape[0], arr.shape[1], arr.shape[2]))\n",
    "    for step in range(arr.shape[0]):\n",
    "        if step > 0:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        before = arr[step - 1, x, y]\n",
    "                        if abs(before - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "                            \n",
    "    for step in range(arr.shape[0]):\n",
    "        if step < arr.shape[0] - 1:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        after = arr[step + 1, x, y]\n",
    "                        if abs(after - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "    arr[np.where(arr > 5)] = 1.\n",
    "    arr[np.where(arr < 5)] = 0.\n",
    "    before = np.sum(arr)\n",
    "    arr[np.where(fake_shadows == 1)] = 0.\n",
    "    after = np.sum(arr)\n",
    "    \n",
    "    print(\"Removed {} fake shadows, leaving {}\".format(before - after, after))\n",
    "    print(\"The total percent shadow cover is: {}%\".format(100*(after/(arr.shape[0]*arr.shape[1]*arr.shape[2]))))\n",
    "    for step in range(arr.shape[0]):\n",
    "        for x in range(1, arr.shape[1] -1):\n",
    "            for y in range(1, arr.shape[2] - 1):\n",
    "                if np.sum(arr[step, x-1:x+2, y-1:y+2]) == 1:\n",
    "                    if arr[step, x, y] != 0:\n",
    "                        print(\"Removing: {} {} {} {}\".format(step, x, y, np.sum(arr[step, x-1:x+2, y-1:y+2])))\n",
    "                        arr[step, x, y] = 0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_best_images(img_bands, image_dates):\n",
    "    # This function interpolates data to 5 day windows linearly\n",
    "\n",
    "    biweekly_dates = [day for day in range(0, 360, 5)] # ideal imagery dates are every 15 days\n",
    "    \n",
    "    # Clouds have been removed at this step, so all steps are satisfactory\n",
    "    satisfactory_ids = [x for x in range(0, img_bands.shape[0])]\n",
    "    satisfactory_dates = [value for idx, value in enumerate(image_dates) if idx in satisfactory_ids]\n",
    "    \n",
    "    \n",
    "    selected_images = {}\n",
    "    for i in biweekly_dates:\n",
    "        distances = [abs(date - i) for date in satisfactory_dates]\n",
    "        closest = np.min(distances)\n",
    "        closest_id = np.argmin(distances)\n",
    "        # If there is imagery within 5 days, select it\n",
    "        if closest < 8:\n",
    "            date = satisfactory_dates[closest_id]\n",
    "            image_idx = int(np.argwhere(np.array(image_dates) == date)[0])\n",
    "            selected_images[i] = {'image_date': [date], 'image_ratio': [1], 'image_idx': [image_idx]}\n",
    "        # If there is not imagery within 7 days, look for the closest above and below imagery\n",
    "        else:\n",
    "            distances = np.array([(date - i) for date in satisfactory_dates])\n",
    "            # Number of days above and below the selected date of the nearest clean imagery\n",
    "            above = distances[np.where(distances < 0, distances, -np.inf).argmax()]\n",
    "            below = distances[np.where(distances > 0, distances, np.inf).argmin()]\n",
    "            if abs(above) > 240: # If date is the last date, occassionally argmax would set above to - number\n",
    "                above = below\n",
    "            if abs(below) > 240:\n",
    "                below = above\n",
    "            if above != below:\n",
    "                below_ratio = above / (above - below)\n",
    "                above_ratio = 1 - below_ratio\n",
    "            else:\n",
    "                above_ratio = below_ratio = 0.5\n",
    "                \n",
    "            # Extract the image date and imagery index for the above and below values\n",
    "            above_date = i + above\n",
    "            above_image_idx = int(np.argwhere(np.array(image_dates) == above_date)[0])\n",
    "            \n",
    "            below_date = i + below\n",
    "            below_image_idx = int(np.argwhere(np.array(image_dates) == below_date)[0])\n",
    "            \n",
    "            selected_images[i] = {'image_date': [above_date, below_date], 'image_ratio': [above_ratio, below_ratio],\n",
    "                                 'image_idx': [above_image_idx, below_image_idx]}\n",
    "                               \n",
    "    max_distance = 0\n",
    "    \n",
    "    for i in selected_images.keys():\n",
    "        #print(i, selected_images[i])\n",
    "        if len(selected_images[i]['image_date']) == 2:\n",
    "            dist = selected_images[i]['image_date'][1] - selected_images[i]['image_date'][0]\n",
    "            if dist > max_distance:\n",
    "                max_distance = dist\n",
    "    \n",
    "    print(\"Maximum time distance: {}\".format(max_distance))\n",
    "        \n",
    "    # Compute the weighted average of the selected imagery for each time step\n",
    "    keep_steps = []\n",
    "    use_median = False\n",
    "    for i in selected_images.keys():\n",
    "        step1_additional = None\n",
    "        step2_additional = None\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "        if len(info['image_idx']) == 2:\n",
    "            step1 = img_bands[info['image_idx'][0]] # * info['image_ratio'][0]\n",
    "            step2 = img_bands[info['image_idx'][1]]\n",
    "            #if info['image_idx'][0] == 0:\n",
    "            #    step1_additional = img_bands[-1]\n",
    "            #    print(\"Using last step\")\n",
    "            #if info['image_idx'][1] == (img_bands.shape[0] - 1):\n",
    "            #    step2_additional = img_bands[0]\n",
    "            ##    print(\"Using first step\")\n",
    "            #if step1_additional is None and step2_additional is None:\n",
    "            step = step1 * 0.5 + step2 * 0.5\n",
    "            #if step1_additional is not None:\n",
    "            #    print(\"Echo\")\n",
    "            #    step = (step1 + step2 + step1_additional) * (1/3)\n",
    "            #if step2_additional is not None:\n",
    "             #   print(\"Echo\")\n",
    "            #    step = (step1 + step2 + step2_additional) * (1/3)\n",
    "        keep_steps.append(step)\n",
    "    '''\n",
    "    for i in selected_images.keys():\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "            use_median = False\n",
    "        if len(info['image_idx']) == 2:\n",
    "            difference = np.max([abs(info['image_date'][0] - int(i)),\n",
    "                                 abs(info['image_date'][1] - int(i))]) \n",
    "            step1 = img_bands[info['image_idx'][0]] # * info['image_ratio'][0]\n",
    "            step2_idx = info['image_idx'][0] - 1\n",
    "            if step2_idx < 0:\n",
    "                step2_idx = (img_bands.shape[0] - 1)\n",
    "            step2 = img_bands[step2_idx]\n",
    "            step3 = img_bands[info['image_idx'][1]]\n",
    "            step4_idx = info['image_idx'][1] + 1\n",
    "            if step4_idx > (img_bands.shape[0] - 1):\n",
    "                step4_idx = 0\n",
    "            step4 = img_bands[step4_idx]\n",
    "            #step2 = img_bands[info['image_idx'][1]] * 0.5 # info['image_ratio'][1]\n",
    "            if difference > 100 or use_median == True:\n",
    "                print(\"Median, {}\".format(difference))\n",
    "                use_median = True\n",
    "                stacked = np.stack([step1, step2, step3, step4])\n",
    "                step = np.median(stacked, axis = 0)\n",
    "            else:\n",
    "                use_median = False\n",
    "                step = step1 * 0.5 + step3 * 0.5\n",
    "        '''\n",
    "        #keep_steps.append(step)\n",
    "        \n",
    "    keep_steps = np.stack(keep_steps)\n",
    "    return keep_steps, max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  31  59  90 120 151 181 212 243 273 304 334]\n"
     ]
    }
   ],
   "source": [
    "days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "starting_days = np.cumsum(days_per_month)\n",
    "print(starting_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "super_resolve = True\n",
    "year = 2019\n",
    "\n",
    "DATA_LOCATION = '../data/ghana-test.csv'\n",
    "OUTPUT_FOLDER = '../data/test-smooth-200/'\n",
    "\n",
    "\n",
    "def download_plots(data_location = DATA_LOCATION, output_folder = OUTPUT_FOLDER):\n",
    "    df = pd.read_csv(data_location)\n",
    "    df = df.drop('IMAGERY_TITLE', axis = 1)\n",
    "    df = df.dropna(axis = 0)\n",
    "    plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "    existing = [int(x[:-4]) for x in os.listdir(output_folder) if \".DS\" not in x]\n",
    "    to_download = [x for x in plot_ids if x not in existing]\n",
    "    print(\"STARTING DOWNLOAD OF {} plots from {} to {}\".format(len(to_download), data_location, output_folder))\n",
    "    errors = []\n",
    "    for i, val in enumerate(to_download):\n",
    "        print(i, val)\n",
    "        print(\"Downloading {}/{}, {}\".format(i+1, len(to_download), val))\n",
    "        location = calc_bbox(val, df = df)\n",
    "        location = bounding_box(location, expansion = IMSIZE*10)\n",
    "        try:\n",
    "            # Identify cloud steps, download DEM, and download L2A series\n",
    "            clean_steps, means, probs = identify_clouds(location)\n",
    "            dem = download_dem(val, df = df)\n",
    "            img, image_request, shadows, shadow_steps = download_layer(location)\n",
    "\n",
    "            # Subset zenith < 70\n",
    "            zenith = check_zenith(location)\n",
    "            zenith = np.mean(np.stack(zenith), axis = (1, 2))\n",
    "            zenith_outliers = np.argwhere(zenith > 70)\n",
    "            if len(zenith_outliers) > 0:\n",
    "                print(\"Zenith outlier: {}\".format(zenith_outliers))\n",
    "\n",
    "            # Calculate imagery dates\n",
    "            image_dates = []\n",
    "            for date in image_request.get_dates():\n",
    "                if date.year == year - 1:\n",
    "                    image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "                if date.year == year:\n",
    "                    image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "                if date.year == year + 1:\n",
    "                    image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "            image_dates = np.array(image_dates)\n",
    "            print(image_dates)\n",
    "\n",
    "            # Remove imagery where >4% is clouds, and where there is null data\n",
    "            args = np.array([len(np.argwhere(probs[x].flatten() > 0.3)) for x in range(probs.shape[0])])\n",
    "            dirty_steps = np.argwhere(args > (IMSIZE)*(IMSIZE) / 5)\n",
    "            missing_images = [np.argwhere(img[x, :, : :].flatten() == 0.0) for x in range(img.shape[0])]\n",
    "            missing_images = np.array([len(x) for x in missing_images])\n",
    "            missing_images_p = [np.argwhere(img[x, :, : :].flatten() >= 1) for x in range(img.shape[0])]\n",
    "            missing_images_p = np.array([len(x) for x in missing_images_p])\n",
    "            missing_images += missing_images_p\n",
    "            missing_images = list(np.argwhere(missing_images >= 25))\n",
    "            to_remove = np.unique(np.array(list(dirty_steps) + list(missing_images) + list(zenith_outliers) + list(shadow_steps)))\n",
    "\n",
    "            # Remove null steps\n",
    "            print(\"There are {}/{} dirty steps: {} cloud, {} missing, {} zenith, {} shadows\".format(len(to_remove),\n",
    "                                                                                        len(img), len(dirty_steps),\n",
    "                                                                                        len(missing_images),\n",
    "                                                                                        len(zenith_outliers),\n",
    "                                                                                        len(shadow_steps)))\n",
    "\n",
    "            img = np.delete(img, to_remove, 0)\n",
    "            probs = np.delete(probs, to_remove, 0)\n",
    "            shadows = np.delete(shadows, to_remove, 0)\n",
    "            image_dates = np.delete(image_dates, to_remove)\n",
    "\n",
    "            to_remove = remove_missed_clouds(img)\n",
    "            img = np.delete(img, to_remove, 0)\n",
    "            shadows = np.delete(shadows, to_remove, 0)\n",
    "            probs = np.delete(probs, to_remove, 0)\n",
    "            image_dates = np.delete(image_dates, to_remove)\n",
    "            print(\"Removing {} steps based on ratio\".format(len(to_remove)))\n",
    "\n",
    "\n",
    "            # Concatenate DEM\n",
    "            dem = np.tile(dem.reshape((1, IMSIZE, IMSIZE, 1)), (img.shape[0], 1, 1, 1))\n",
    "            tiles = np.concatenate([img, dem], axis = -1)\n",
    "            tiles[:, :, :, -1] /= 90\n",
    "\n",
    "            new_shadows = threshold_shadows(tiles[:, :, :, 3])\n",
    "            x = remove_cloud_and_shadows(tiles, probs, new_shadows, image_dates)\n",
    "            if super_resolve:\n",
    "                x = x[:, 8:40, 8:40, :]\n",
    "                print(\"Before super: {}\".format(x.shape))\n",
    "\n",
    "                d10 = x[:, :, :, 0:4]\n",
    "                d20 = x[:, :, :, 4:10]\n",
    "\n",
    "                d10 = np.swapaxes(d10, 1, -1)\n",
    "                d10 = np.swapaxes(d10, 2, 3)\n",
    "                d20 = np.swapaxes(d20, 1, -1)\n",
    "                d20 = np.swapaxes(d20, 2, 3)\n",
    "                superresolved = DSen2(d10, d20)\n",
    "                superresolved = np.swapaxes(superresolved, 1, -1)\n",
    "                superresolved = np.swapaxes(superresolved, 1, 2)\n",
    "                print(superresolved.shape)\n",
    "                print(x.shape)\n",
    "\n",
    "                # returns band IDXs 3, 4, 5, 7, 8, 9\n",
    "                x[:, :, :, 4:10] = superresolved\n",
    "                x = x[:, 8:24, 8:24, :]\n",
    "                print(\"After super shape: {}\".format(x.shape))\n",
    "            else:\n",
    "                bottom = int(IMSIZE/2 - 8)\n",
    "                top = int(IMSIZE/2 + 8)\n",
    "                x = x[:, bottom:top, bottom:top, :]\n",
    "\n",
    "            # Calculate indices\n",
    "            tiles, amin = evi(x, True)\n",
    "            # Where evi is OOB, remove (likely cloud cover missed)\n",
    "            #if len(amin) > 0:\n",
    "            #    satisfactory = [x for x in range(tiles.shape[0]) if x not in amin]\n",
    "            ##    for i in amin:\n",
    "            #        before, after = calculate_proximal_steps_index(i, satisfactory)\n",
    "            #        print(\"Interpolating {} with {} and {}\".format(i, before, after))\n",
    "            #        bef = tiles[before, :, :, :]\n",
    "            #        aft = tiles[after, :, :, :]\n",
    "            #        tiles[i, :, :, :] = (bef + aft) / 2\n",
    "\n",
    "            tiles = bi(tiles, True)\n",
    "            tiles = msavi2(tiles, True)\n",
    "            x = si(tiles, True)\n",
    "\n",
    "            print(\"Clean: {}\".format(x.shape))\n",
    "            \n",
    "            missing_pixels = 0\n",
    "            for band in range(0, 15):\n",
    "                for time in range(0, x.shape[0]):\n",
    "                    x_i = x[time, :, :, band]\n",
    "                    missing_pixels += len(np.argwhere(np.isnan(x_i)))\n",
    "                    x_i[np.argwhere(np.isnan(x_i))] = np.mean(x_i)\n",
    "                    x[time, :, :, band] = x_i\n",
    "            print(\"There are {} missing pixels\".format(missing_pixels))\n",
    "\n",
    "            # Interpolate linearly to 5 day frequency\n",
    "            tiles, max_distance = calculate_and_save_best_images(x, image_dates) # 22, 16, 16, 10\n",
    "\n",
    "            # Smooth linear interpolation\n",
    "            for row in range(0, 16):\n",
    "                for column in range(0, 16):\n",
    "                    for band in [x for x in range(0, 15) if x != 10]:\n",
    "                        sm = smooth(tiles[:, row, column, band], 800, d = 2)\n",
    "                        tiles[:, row, column, band] = sm\n",
    "\n",
    "            # Retain only iamgery every 15 days\n",
    "            biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "            to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "            tiles = np.delete(tiles, to_remove, 0)\n",
    "            print(tiles.shape)\n",
    "\n",
    "            if max_distance <= 240:\n",
    "                np.save(output_folder + str(val), tiles)\n",
    "                print(\"\\n\")\n",
    "            else:\n",
    "                print(\"Skipping {} because there is a {} distance\".format(val, max_distance))\n",
    "                print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.fatal(e, exc_info=True)\n",
    "            errors.append(img)\n",
    "            #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING DOWNLOAD OF 28 plots from ../data/train-csv/rwanda-train.csv to ../data/train-super/\n",
      "0 135542618\n",
      "Downloading 1/28, 135542618\n",
      "[30.084223046117305, -2.573445834341374]\n",
      "[480.0, 480.0]\n",
      "[30.084223046117305, -2.573445834341374]\n",
      "[500.0, 500.0]\n",
      "Original size: (46, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (46, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 163 168 173 178 183 193 198 203 208 218 223 228 233 238 243 248 253\n",
      " 258 263 278 288 298 313 348 353 358 378]\n",
      "There are 24/46 dirty steps: 19 cloud, 2 missing, 0 zenith, 6 shadows\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 320.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 241 px\n",
      "Before super: (22, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "22/22 [==============================] - 1s 29ms/step\n",
      "(22, 32, 32, 6)\n",
      "(22, 32, 32, 11)\n",
      "After super shape: (22, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (22, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 50\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "1 135542619\n",
      "Downloading 2/28, 135542619\n",
      "[30.507291388791476, -2.496357186440153]\n",
      "[480.0, 480.0]\n",
      "[30.507291388791476, -2.496357186440153]\n",
      "[500.0, 500.0]\n",
      "Original size: (49, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (49, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 143 153 163 168 173 178 183 193 198 203 208 218 223 228 233 238 243\n",
      " 248 253 258 263 278 288 298 313 348 353 358 363 378]\n",
      "There are 33/49 dirty steps: 30 cloud, 7 missing, 0 zenith, 4 shadows\n",
      "[0, 1, 12, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 392 px\n",
      "Before super: (16, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "16/16 [==============================] - 0s 28ms/step\n",
      "(16, 32, 32, 6)\n",
      "(16, 32, 32, 11)\n",
      "After super shape: (16, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (16, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 85\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "2 135542620\n",
      "Downloading 3/28, 135542620\n",
      "[29.56091897420297, -1.9482975388555432]\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "[29.56091897420297, -1.9482975388555432]\n",
      "[500.0, 500.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "Original size: (46, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (46, 48, 48)\n",
      "[ -2   3   8  13  23  28  33  38  43  58  63  68  78  88  93  98 108 118\n",
      " 123 128 163 168 173 183 193 198 203 208 218 223 228 233 238 243 248 253\n",
      " 258 263 278 288 313 348 353 358 368 378]\n",
      "There are 34/46 dirty steps: 26 cloud, 6 missing, 0 zenith, 10 shadows\n",
      "[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0]\n",
      "Removing 1 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 35 px\n",
      "Before super: (11, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "11/11 [==============================] - 0s 28ms/step\n",
      "(11, 32, 32, 6)\n",
      "(11, 32, 32, 11)\n",
      "After super shape: (11, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (11, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 150\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "3 135542624\n",
      "Downloading 4/28, 135542624\n",
      "[30.20800523129628, -2.4399292879332872]\n",
      "[480.0, 480.0]\n",
      "[30.20800523129628, -2.4399292879332872]\n",
      "[500.0, 500.0]\n",
      "Original size: (47, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (47, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 163 168 173 178 183 193 198 203 208 218 223 228 233 238 243 248 253\n",
      " 258 263 278 288 298 313 348 353 358 363 378]\n",
      "There are 22/47 dirty steps: 21 cloud, 5 missing, 0 zenith, 1 shadows\n",
      "[0, 1, 2, 0, 10, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 1, 52, 33]\n",
      "Removing 2 steps based on ratio\n",
      "Removed 640.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 297 px\n",
      "Before super: (23, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "23/23 [==============================] - 1s 29ms/step\n",
      "(23, 32, 32, 6)\n",
      "(23, 32, 32, 11)\n",
      "After super shape: (23, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (23, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 65\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "4 135542625\n",
      "Downloading 5/28, 135542625\n",
      "[30.601471779193893, -2.3958296507017427]\n",
      "[480.0, 480.0]\n",
      "[30.601471779193893, -2.3958296507017427]\n",
      "[500.0, 500.0]\n",
      "Original size: (51, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (51, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 130 140 143 153 163 168 173 178 183 193 198 203 208 218 223 228 233\n",
      " 238 243 248 253 258 263 278 288 298 313 348 353 358 363 378]\n",
      "There are 27/51 dirty steps: 24 cloud, 9 missing, 0 zenith, 2 shadows\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 0, 3]\n",
      "Removing 1 steps based on ratio\n",
      "Removed 1600.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 129 px\n",
      "Before super: (23, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "23/23 [==============================] - 1s 30ms/step\n",
      "(23, 32, 32, 6)\n",
      "(23, 32, 32, 11)\n",
      "After super shape: (23, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (23, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 50\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "5 135542626\n",
      "Downloading 6/28, 135542626\n",
      "[30.743385273758708, -1.6780414324082906]\n",
      "[480.0, 480.0]\n",
      "[30.743385273758708, -1.6780414324082906]\n",
      "[500.0, 500.0]\n",
      "Original size: (43, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (43, 48, 48)\n",
      "[ -2   3   8  13  23  28  33  58  68  78  88  93  98 118 123 128 153 163\n",
      " 173 178 183 198 208 213 218 223 228 233 248 253 258 263 268 288 298 308\n",
      " 313 323 348 353 358 363 378]\n",
      "There are 20/43 dirty steps: 19 cloud, 2 missing, 0 zenith, 1 shadows\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 361 px\n",
      "Before super: (23, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "23/23 [==============================] - 1s 28ms/step\n",
      "(23, 32, 32, 6)\n",
      "(23, 32, 32, 11)\n",
      "After super shape: (23, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (23, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 50\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "6 135542627\n",
      "Downloading 7/28, 135542627\n",
      "[29.527849901989747, -1.7461081118252852]\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "[29.527849901989747, -1.7461081118252852]\n",
      "[500.0, 500.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "Original size: (41, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (41, 48, 48)\n",
      "[ -2   3   8  13  23  28  33  43  58  63  68  78  88  93  98 108 118 123\n",
      " 128 163 168 173 183 198 203 208 218 223 228 248 253 258 263 278 288 298\n",
      " 313 348 353 358 363]\n",
      "There are 33/41 dirty steps: 22 cloud, 8 missing, 0 zenith, 14 shadows\n",
      "[0, 0, 0, 6, 0, 0, 0, 8]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 133 px\n",
      "Before super: (8, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "8/8 [==============================] - 0s 29ms/step\n",
      "(8, 32, 32, 6)\n",
      "(8, 32, 32, 11)\n",
      "After super shape: (8, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (8, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 145\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "7 135542629\n",
      "Downloading 8/28, 135542629\n",
      "[30.928381140666485, -2.6569078874693166]\n",
      "[480.0, 480.0]\n",
      "[30.928381140666485, -2.6569078874693166]\n",
      "[500.0, 500.0]\n",
      "Original size: (43, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (43, 48, 48)\n",
      "[-15 -10  -5   5  10  20  30  35  40  45  50  70  75  90  95 105 115 130\n",
      " 140 145 150 160 165 170 180 185 195 200 205 210 215 220 225 230 235 245\n",
      " 260 280 305 325 355 365 380]\n",
      "There are 22/43 dirty steps: 19 cloud, 6 missing, 0 zenith, 1 shadows\n",
      "[5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 1008 px\n",
      "Before super: (21, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "21/21 [==============================] - 1s 28ms/step\n",
      "(21, 32, 32, 6)\n",
      "(21, 32, 32, 11)\n",
      "After super shape: (21, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (21, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "8 135542632\n",
      "Downloading 9/28, 135542632\n",
      "[30.19508963226985, -1.838463172127896]\n",
      "[480.0, 480.0]\n",
      "[30.19508963226985, -1.838463172127896]\n",
      "[500.0, 500.0]\n",
      "Original size: (49, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (49, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 153 163 168 173 178 183 198 203 208 218 223 228 233 238 243 248 253\n",
      " 258 263 268 278 288 298 308 313 348 353 358 363 378]\n",
      "There are 29/49 dirty steps: 19 cloud, 2 missing, 0 zenith, 11 shadows\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 9, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Removing 1 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 639 px\n",
      "Before super: (19, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "19/19 [==============================] - 1s 28ms/step\n",
      "(19, 32, 32, 6)\n",
      "(19, 32, 32, 11)\n",
      "After super shape: (19, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (19, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 60\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "9 135542633\n",
      "Downloading 10/28, 135542633\n",
      "[30.928785532472922, -2.065511556225424]\n",
      "[480.0, 480.0]\n",
      "[30.928785532472922, -2.065511556225424]\n",
      "[500.0, 500.0]\n",
      "Original size: (43, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (43, 48, 48)\n",
      "[-15 -10  -5   5  10  20  30  35  40  45  50  70  75  90  95 105 115 130\n",
      " 140 145 150 160 165 170 180 185 195 200 205 210 215 220 225 230 235 245\n",
      " 260 280 305 325 355 365 380]\n",
      "There are 27/43 dirty steps: 23 cloud, 5 missing, 0 zenith, 5 shadows\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 970 px\n",
      "Before super: (16, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "16/16 [==============================] - 0s 28ms/step\n",
      "(16, 32, 32, 6)\n",
      "(16, 32, 32, 11)\n",
      "After super shape: (16, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (16, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 150\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "10 135542634\n",
      "Downloading 11/28, 135542634\n",
      "[29.549121345249908, -1.8476720072608557]\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "[29.549121345249908, -1.8476720072608557]\n",
      "[500.0, 500.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "Original size: (48, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (48, 48, 48)\n",
      "[ -2   3   8  13  23  28  33  38  43  58  63  68  78  88  93  98 108 118\n",
      " 123 128 163 168 173 183 193 198 203 208 218 223 228 233 238 243 248 253\n",
      " 258 263 278 288 298 313 348 353 358 363 368 378]\n",
      "There are 36/48 dirty steps: 28 cloud, 11 missing, 0 zenith, 10 shadows\n",
      "[14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 353 px\n",
      "Before super: (12, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "12/12 [==============================] - 0s 29ms/step\n",
      "(12, 32, 32, 6)\n",
      "(12, 32, 32, 11)\n",
      "After super shape: (12, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (12, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 95\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "11 135542635\n",
      "Downloading 12/28, 135542635\n",
      "[30.53936801673033, -2.6486856671873773]\n",
      "[480.0, 480.0]\n",
      "[30.53936801673033, -2.6486856671873773]\n",
      "[500.0, 500.0]\n",
      "Original size: (49, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (49, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 143 153 163 168 173 178 183 193 198 203 208 218 223 228 233 238 243\n",
      " 248 253 258 263 278 288 298 313 348 353 358 363 378]\n",
      "There are 29/49 dirty steps: 23 cloud, 4 missing, 0 zenith, 6 shadows\n",
      "[0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 3]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 320.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 179 px\n",
      "Before super: (20, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "20/20 [==============================] - 1s 30ms/step\n",
      "(20, 32, 32, 6)\n",
      "(20, 32, 32, 11)\n",
      "After super shape: (20, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (20, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 90\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "12 135542637\n",
      "Downloading 13/28, 135542637\n",
      "[30.401461212460447, -2.840705438109795]\n",
      "[480.0, 480.0]\n",
      "[30.401461212460447, -2.840705438109795]\n",
      "[500.0, 500.0]\n",
      "Original size: (55, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (55, 48, 48)\n",
      "[-12  -2   3   8  13  18  23  28  33  38  43  58  63  68  73  78  88  93\n",
      "  98 108 113 118 123 128 143 158 163 168 173 178 183 193 198 203 208 213\n",
      " 218 223 228 233 238 243 248 253 258 263 278 288 298 313 343 348 353 358\n",
      " 378]\n",
      "There are 28/55 dirty steps: 23 cloud, 2 missing, 0 zenith, 5 shadows\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 1430 px\n",
      "Before super: (27, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "27/27 [==============================] - 1s 34ms/step\n",
      "(27, 32, 32, 6)\n",
      "(27, 32, 32, 11)\n",
      "After super shape: (27, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (27, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 60\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "13 135542638\n",
      "Downloading 14/28, 135542638\n",
      "[29.348279262451896, -2.4836947945729886]\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "[29.348279262451896, -2.4836947945729886]\n",
      "[500.0, 500.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "Original size: (47, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (47, 48, 48)\n",
      "[ -2   3   8  13  23  28  33  38  43  58  63  68  78  88  93  98 108 118\n",
      " 123 128 163 168 173 183 193 198 203 208 218 223 228 233 238 243 248 253\n",
      " 258 263 278 288 313 348 353 358 363 368 378]\n",
      "There are 31/47 dirty steps: 30 cloud, 6 missing, 0 zenith, 3 shadows\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 6]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 921 px\n",
      "Before super: (16, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "16/16 [==============================] - 0s 29ms/step\n",
      "(16, 32, 32, 6)\n",
      "(16, 32, 32, 11)\n",
      "After super shape: (16, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (16, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 90\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "14 135542639\n",
      "Downloading 15/28, 135542639\n",
      "[30.507170767603032, -2.480222512609882]\n",
      "[480.0, 480.0]\n",
      "[30.507170767603032, -2.480222512609882]\n",
      "[500.0, 500.0]\n",
      "Original size: (49, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (49, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 143 153 163 168 173 178 183 193 198 203 208 218 223 228 233 238 243\n",
      " 248 253 258 263 278 288 298 313 348 353 358 363 378]\n",
      "There are 32/49 dirty steps: 25 cloud, 5 missing, 0 zenith, 7 shadows\n",
      "[0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 980 px\n",
      "Before super: (17, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "17/17 [==============================] - 0s 29ms/step\n",
      "(17, 32, 32, 6)\n",
      "(17, 32, 32, 11)\n",
      "After super shape: (17, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (17, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 70\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "15 135542640\n",
      "Downloading 16/28, 135542640\n",
      "[30.306584544653717, -2.4602552753491964]\n",
      "[480.0, 480.0]\n",
      "[30.306584544653717, -2.4602552753491964]\n",
      "[500.0, 500.0]\n",
      "Original size: (49, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (49, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 143 153 163 168 173 178 183 193 198 203 208 218 223 228 233 238 243\n",
      " 248 253 258 263 278 288 298 313 348 353 358 363 378]\n",
      "There are 28/49 dirty steps: 17 cloud, 5 missing, 0 zenith, 12 shadows\n",
      "[0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 320.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 1287 px\n",
      "Before super: (21, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "21/21 [==============================] - 1s 29ms/step\n",
      "(21, 32, 32, 6)\n",
      "(21, 32, 32, 11)\n",
      "After super shape: (21, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (21, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "16 135542642\n",
      "Downloading 17/28, 135542642\n",
      "[30.640091536499163, -1.6704452077712122]\n",
      "[480.0, 480.0]\n",
      "[30.640091536499163, -1.6704452077712122]\n",
      "[500.0, 500.0]\n",
      "Original size: (48, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (48, 48, 48)\n",
      "[ -2   3   8  13  23  28  33  58  68  78  88  93  98 108 118 123 128 153\n",
      " 163 168 173 178 183 198 203 208 213 218 223 228 233 243 248 253 258 263\n",
      " 268 278 288 298 308 313 323 348 353 358 363 378]\n",
      "There are 28/48 dirty steps: 21 cloud, 4 missing, 0 zenith, 8 shadows\n",
      "[0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 320.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 727 px\n",
      "Before super: (20, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "20/20 [==============================] - 1s 28ms/step\n",
      "(20, 32, 32, 6)\n",
      "(20, 32, 32, 11)\n",
      "After super shape: (20, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (20, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 50\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "17 135542643\n",
      "Downloading 18/28, 135542643\n",
      "[30.60149050561622, -2.531489663142997]\n",
      "[480.0, 480.0]\n",
      "[30.60149050561622, -2.531489663142997]\n",
      "[500.0, 500.0]\n",
      "Original size: (94, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (94, 48, 48)\n",
      "[-15 -12 -10  -5  -2   3   5   8  10  13  20  23  28  30  33  35  40  43\n",
      "  45  50  58  68  70  75  78  88  90  93  95  98 105 108 115 118 123 128\n",
      " 130 140 143 145 150 153 160 163 165 168 170 173 178 180 183 185 193 195\n",
      " 198 200 203 205 208 210 215 218 220 223 225 228 230 233 235 238 240 243\n",
      " 245 248 253 258 260 263 278 280 288 298 300 305 313 325 348 353 355 358\n",
      " 363 365 378 380]\n",
      "There are 62/94 dirty steps: 46 cloud, 8 missing, 0 zenith, 17 shadows\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 88, 0, 0, 0, 7]\n",
      "Removing 1 steps based on ratio\n",
      "Removed 960.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 1300 px\n",
      "Before super: (31, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "31/31 [==============================] - 1s 28ms/step\n",
      "(31, 32, 32, 6)\n",
      "(31, 32, 32, 11)\n",
      "After super shape: (31, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (31, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 60\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "18 135542645\n",
      "Downloading 19/28, 135542645\n",
      "[30.548534934977496, -2.099544032165268]\n",
      "[480.0, 480.0]\n",
      "[30.548534934977496, -2.099544032165268]\n",
      "[500.0, 500.0]\n",
      "Original size: (48, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (48, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 143 153 163 168 173 178 183 198 203 208 218 223 228 233 238 243 248\n",
      " 253 258 263 278 288 298 313 348 353 358 363 378]\n",
      "There are 32/48 dirty steps: 25 cloud, 7 missing, 0 zenith, 10 shadows\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 1011 px\n",
      "Before super: (16, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "16/16 [==============================] - 0s 31ms/step\n",
      "(16, 32, 32, 6)\n",
      "(16, 32, 32, 11)\n",
      "After super shape: (16, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (16, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 90\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "19 135542647\n",
      "Downloading 20/28, 135542647\n",
      "[30.038742556524877, -2.47234911973034]\n",
      "[480.0, 480.0]\n",
      "[30.038742556524877, -2.47234911973034]\n",
      "[500.0, 500.0]\n",
      "Original size: (47, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (47, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 163 168 173 178 183 193 198 203 208 218 223 228 233 238 243 248 253\n",
      " 258 263 278 288 298 313 348 353 358 363 378]\n",
      "There are 23/47 dirty steps: 21 cloud, 5 missing, 0 zenith, 2 shadows\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 310 px\n",
      "Before super: (24, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "24/24 [==============================] - 1s 28ms/step\n",
      "(24, 32, 32, 6)\n",
      "(24, 32, 32, 11)\n",
      "After super shape: (24, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (24, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 60\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "20 135542653\n",
      "Downloading 21/28, 135542653\n",
      "[29.53976512952688, -1.8640248153608727]\n",
      "[480.0, 480.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "[29.53976512952688, -1.8640248153608727]\n",
      "[500.0, 500.0]\n",
      "ERROR: Initial field greater than 130m\n",
      "Original size: (48, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (48, 48, 48)\n",
      "[ -2   3   8  13  23  28  33  38  43  58  63  68  78  88  93  98 108 118\n",
      " 123 128 163 168 173 183 193 198 203 208 218 223 228 233 238 243 248 253\n",
      " 258 263 278 288 298 313 348 353 358 363 368 378]\n",
      "There are 44/48 dirty steps: 31 cloud, 8 missing, 0 zenith, 17 shadows\n",
      "[0, 0, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 35 px\n",
      "Before super: (4, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "4/4 [==============================] - 0s 29ms/step\n",
      "(4, 32, 32, 6)\n",
      "(4, 32, 32, 11)\n",
      "After super shape: (4, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (4, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 165\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "21 135542658\n",
      "Downloading 22/28, 135542658\n",
      "[30.68878394805253, -2.1585863724877985]\n",
      "[480.0, 480.0]\n",
      "[30.68878394805253, -2.1585863724877985]\n",
      "[500.0, 500.0]\n",
      "Original size: (90, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (90, 48, 48)\n",
      "[-15 -12 -10  -5  -2   3   5   8  10  13  20  23  28  30  33  35  40  43\n",
      "  45  50  58  68  70  75  78  88  90  93  95  98 105 108 115 118 123 128\n",
      " 130 140 143 145 150 153 160 163 165 168 170 173 178 180 183 185 195 198\n",
      " 200 203 205 208 210 215 218 220 223 225 228 230 235 238 243 245 248 253\n",
      " 258 260 263 278 280 288 298 305 313 325 348 353 355 358 363 365 378 380]\n",
      "There are 57/90 dirty steps: 49 cloud, 12 missing, 0 zenith, 8 shadows\n",
      "[0, 0, 0, 0, 67, 0, 1, 9, 14, 0, 3, 1, 0, 0, 0, 6, 12, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 5]\n",
      "Removing 1 steps based on ratio\n",
      "Removed 1280.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 1114 px\n",
      "Before super: (32, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "32/32 [==============================] - 1s 29ms/step\n",
      "(32, 32, 32, 6)\n",
      "(32, 32, 32, 11)\n",
      "After super shape: (32, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (32, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 95\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "22 135542663\n",
      "Downloading 23/28, 135542663\n",
      "[30.75572968679519, -1.933791126593516]\n",
      "[480.0, 480.0]\n",
      "[30.75572968679519, -1.933791126593516]\n",
      "[500.0, 500.0]\n",
      "Original size: (90, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (90, 48, 48)\n",
      "[-15 -12 -10  -5  -2   3   5   8  10  13  20  23  28  30  33  35  40  43\n",
      "  45  50  58  68  70  75  78  88  90  93  95  98 105 108 115 118 123 128\n",
      " 130 140 143 145 150 153 160 163 165 168 170 173 178 180 183 185 195 198\n",
      " 200 203 205 208 210 215 218 220 223 225 228 230 235 238 243 245 248 253\n",
      " 258 260 263 278 280 288 298 305 313 325 348 353 355 358 363 365 378 380]\n",
      "There are 42/90 dirty steps: 34 cloud, 7 missing, 0 zenith, 7 shadows\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Removing 0 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n",
      "Interpolated 956 px\n",
      "Before super: (48, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "48/48 [==============================] - 1s 28ms/step\n",
      "(48, 32, 32, 6)\n",
      "(48, 32, 32, 11)\n",
      "After super shape: (48, 16, 16, 11)\n",
      "There are: 0 out of bounds EVI\n",
      "Clean: (48, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 55\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "23 135542666\n",
      "Downloading 24/28, 135542666\n",
      "[30.519822865505688, -2.105181501068388]\n",
      "[480.0, 480.0]\n",
      "[30.519822865505688, -2.105181501068388]\n",
      "[500.0, 500.0]\n",
      "Original size: (48, 48, 48, 5)\n",
      "Difference: 0.0\n",
      "Shadows: (48, 48, 48)\n",
      "[-12  -2   3   8  13  23  28  33  43  58  68  78  88  93  98 108 118 123\n",
      " 128 143 153 163 168 173 178 183 198 203 208 218 223 228 233 238 243 248\n",
      " 253 258 263 278 288 298 313 348 353 358 363 378]\n",
      "There are 33/48 dirty steps: 24 cloud, 6 missing, 0 zenith, 14 shadows\n",
      "[25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Removing 1 steps based on ratio\n",
      "Removed 0.0 fake shadows, leaving 0.0\n",
      "The total percent shadow cover is: 0.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated 0 px\n",
      "Before super: (14, 32, 32, 11)\n",
      "Predicting using file: ../src/dsen2/models/s2_032_lr_1e-04.hdf5\n",
      "14/14 [==============================] - 0s 28ms/step\n",
      "(14, 32, 32, 6)\n",
      "(14, 32, 32, 11)\n",
      "After super shape: (14, 16, 16, 11)\n",
      "There are: 1 out of bounds EVI\n",
      "()\n",
      "evis error: 0.02079608663916588, 25.122291564941406, 1 steps, clipping to -1.5, 1.5\n",
      "Clean: (14, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 85\n",
      "(24, 16, 16, 15)\n",
      "\n",
      "\n",
      "24 135542668\n",
      "Downloading 25/28, 135542668\n",
      "[30.94939533020045, -1.69565992853899]\n",
      "[480.0, 480.0]\n",
      "[30.94939533020045, -1.69565992853899]\n",
      "[500.0, 500.0]\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(\"../data/train-csv\"):\n",
    "    if \"rwanda\" in i:\n",
    "        download_plots(\"../data/train-csv/\" + i, \"../data/train-super/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
