{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "from sentinelhub import DataSource\n",
    "import scipy.sparse as sparse\n",
    "import scipy\n",
    "from scipy.sparse.linalg import splu\n",
    "from skimage.transform import resize\n",
    "from sentinelhub import CustomUrlParam\n",
    "from time import time as timer\n",
    "from time import sleep as sleep\n",
    "import multiprocessing\n",
    "import math\n",
    "import reverse_geocoder as rg\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "import hickle as hkl\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import math\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "    key = (yaml.safe_load(stream))\n",
    "    API_KEY = key['key']\n",
    "    AWSKEY = key['awskey']\n",
    "    AWSSECRET = key['awssecret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run ../src/utils/slope.py\n",
    "%run ../src/utils/utils-bilinear.py\n",
    "%run ../src/dsen2/utils/DSen2Net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ('2018-12-15', '2020-01-15')\n",
    "SIZE = 9*5\n",
    "IMSIZE = (SIZE * 14)+2\n",
    "\n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tile_data/guatemala-coban/ (-90.8, 15.3)\n"
     ]
    }
   ],
   "source": [
    "landscapes = {\n",
    "    'ethiopia-tigray': (13.540810, 38.177220),\n",
    "    'kenya-makueni-2': (-1.817109, 37.44563),\n",
    "    'ghana': (9.259359, -0.83375),\n",
    "    'niger-koure': (13.18158, 2.478),\n",
    "    'cameroon-farnorth': (10.596, 14.2722),\n",
    "    'mexico-campeche': (18.232495, -92.1234215),\n",
    "    'malawi-rumphi': (-11.044, 33.818),\n",
    "    'ghana-sisala-east': (10.385, -1.765),\n",
    "    'ghana-west-mamprusi': (10.390084, -0.846330),\n",
    "    'ghana-kwahu': (6.518909, -0.826008),\n",
    "    'senegal-16b': (15.82585, -15.34166),\n",
    "    'india-kochi': (9.909, 76.254),\n",
    "    'india-sidhi': (24.0705, 81.607),\n",
    "    'brazil-esperito-santo': (-20.147, -40.837),\n",
    "    'brazil-paraiba': (-22.559943, -44.186629),\n",
    "    'brazil-goias': (-14.905595, -48.907399),\n",
    "    'colombia-talima': (4.179529, -74.889171),\n",
    "    'drc-kafubu': (-11.749636, 27.586622),\n",
    "    'thailand-khon-kaen': (15.709725, 102.546518),\n",
    "    'indonesia-west-java': (-6.721101, 108.280949),\n",
    "    'madagascar': (-18.960152, 47.469587),\n",
    "    'tanzania': (-6.272258, 36.679824),\n",
    "    'chile': (-36.431237, -71.872030),\n",
    "    'indonesia-jakarta': (-6.352580, 106.677072),\n",
    "    'caf-baboua': (5.765917, 14.791618),   \n",
    "    'honduras': (14.096664, -88.720304),\n",
    "    'nicaragua': (12.398014, -86.963042),\n",
    "    'china': (26.673679, 107.464231),\n",
    "    'australia-west': (-32.666762, 117.411197),\n",
    "    'mexico-sonora': (29.244288, -111.243230),\n",
    "    'south-africa': (-30.981698, 28.727301),\n",
    "    'maldonado-uraguay': (-34.629250, -55.004331),\n",
    "    'dominican-rep-la-salvia': (18.872589, -70.462961),\n",
    "    'guatemala-coban': (15.3, -90.8),\n",
    "    'senegal-tucker-a': (15.350595, -15.459789),\n",
    "}\n",
    "\n",
    "landscape = 'guatemala-coban'\n",
    "\n",
    "#coords = (7.702058, -0.709011) # brong ahafo, bono east\n",
    "#coords = (7.398111, -1.269223) # cocoa\n",
    "#coords = (16.032170, -90.144511) # Guatemala\n",
    "#coords = (13.757749, -90.004949) # elsalvador imposible\n",
    "#coords = (13.727334, -90.015579) # elsalvador imposible2\n",
    "#coords = (13.933745, -84.690842) # Bonanza, Nicaragua\n",
    "\n",
    "OUTPUT_FOLDER = '../tile_data/{}/'.format(landscape)\n",
    "coords = landscapes[landscape]\n",
    "coords = (coords[1], coords[0])\n",
    "print(OUTPUT_FOLDER, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "landscape_df = pd.DataFrame({'landscape': [x for x in landscapes.keys()], \n",
    "                             'latitude': [x[0] for x in landscapes.values()],\n",
    "                             'longitude': [x[1] for x in landscapes.values()]\n",
    "})\n",
    "\n",
    "landscape_df.to_csv(\"../data/latlongs/landscapes.csv\", index=False)\n",
    "print(len(landscape_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions (to be moved to a utils file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSG = CRS.WGS84\n",
    "GRID_SIZE_X = 1\n",
    "GRID_SIZE_Y = 1\n",
    "\n",
    "IMAGE_X = 14*GRID_SIZE_X\n",
    "IMAGE_Y = 14*GRID_SIZE_Y\n",
    "\n",
    "TEST_X = 5\n",
    "TEST_Y = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These arrays are for smoothly overlapping the cloud and shadow interpolation\n",
    "c_arr = np.array([[1, 1, 1, 1, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 2, 3, 2, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 1, 1, 1, 1,],])\n",
    "                  \n",
    "c_arr = c_arr / 3\n",
    "o_arr = 1 - c_arr\n",
    "c_arr = np.tile(c_arr[:, :, np.newaxis], (1, 1, 10))\n",
    "o_arr = np.tile(o_arr[:, :, np.newaxis], (1, 1, 10))\n",
    "\n",
    "def convertCoords(xy, src='', targ=''):\n",
    "    \"\"\" Converts coords from one EPSG to another\n",
    "\n",
    "        Parameters:\n",
    "         xy (tuple): input longitiude, latitude tuple\n",
    "         src (str): EPSG code associated with xy\n",
    "         targ (str): EPSG code of target output\n",
    "    \n",
    "        Returns:\n",
    "         pt (tuple): (x, y) tuple of xy in targ EPSG\n",
    "    \"\"\"\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_epsg(points):\n",
    "    \"\"\" Calculates the UTM EPSG of an input WGS 84 lon, lat\n",
    "\n",
    "        Parameters:\n",
    "         points (tuple): input longitiude, latitude tuple\n",
    "    \n",
    "        Returns:\n",
    "         epsg_code (int): integer form of associated UTM EPSG\n",
    "    \"\"\"\n",
    "    lon, lat = points[0], points[1]\n",
    "    utm_band = str((math.floor((lon + 180) / 6 ) % 60) + 1)\n",
    "    if len(utm_band) == 1:\n",
    "        utm_band = '0'+utm_band\n",
    "    if lat >= 0:\n",
    "        epsg_code = '326' + utm_band\n",
    "    else:\n",
    "        epsg_code = '327' + utm_band\n",
    "    return int(epsg_code)\n",
    "\n",
    "def PolygonArea(corners):\n",
    "    n = len(corners) # of corners\n",
    "    area = 0.0\n",
    "    for i in range(n):\n",
    "        j = (i + 1) % n\n",
    "        area += corners[i][0] * corners[j][1]\n",
    "        area -= corners[j][0] * corners[i][1]\n",
    "    area = abs(area)\n",
    "    return area\n",
    "    \n",
    "def offset_x(coord, offset):\n",
    "    ''' Converts a WGS 84 to UTM, adds meters, and converts back'''\n",
    "    epsg = calculate_epsg(coord)\n",
    "    coord = convertCoords(coord, 4326, epsg)\n",
    "    coord[0] += offset\n",
    "    coord = convertCoords(coord, epsg, 4326)\n",
    "    return coord\n",
    "    \n",
    "def offset_y(coord, offset):\n",
    "    ''' Converts a WGS 84 to UTM, adds meters, and converts back'''\n",
    "    epsg = calculate_epsg(coord)\n",
    "    coord = convertCoords(coord, 4326, epsg)\n",
    "    coord[1] += offset\n",
    "    coord = convertCoords(coord, epsg, 4326)\n",
    "    return coord\n",
    "\n",
    "def calculate_area(bbx):\n",
    "    '''\n",
    "    Calculates the area in ha of a [(min_x, min_y), (max_x, max_y)] bbx\n",
    "    '''\n",
    "\n",
    "    epsg = calculate_epsg(bbx[0])\n",
    "    \n",
    "    mins = convertCoords(bbx[0], 4326, epsg)\n",
    "    maxs = convertCoords(bbx[1], 4326, epsg)\n",
    "    area = PolygonArea([(mins[0], mins[1]), # BL\n",
    "                        (mins[0], maxs[1]), # BR\n",
    "                        (maxs[0], mins[1]), # TL\n",
    "                        (maxs[0], mins[1]) # TR\n",
    "                        ])\n",
    "    hectares = math.floor(area / 1e4)\n",
    "    print(hectares)\n",
    "    \n",
    "\n",
    "def calculate_bbx(coord, step_x, step_y, expansion, multiplier = 1.):\n",
    "    ''' Calculates the four corners of a bounding box of step_x * step_y offset from coord'''\n",
    "    coord_bl = np.copy(coord)\n",
    "    coord1 = offset_x(coord_bl, 6300*step_x - expansion)\n",
    "    coord1 = offset_y(coord1 , 6300*step_y - expansion)\n",
    "    \n",
    "    coord_tr = np.copy(coord)\n",
    "    coord2 = offset_x(coord_tr, 6300*(step_x + multiplier) + expansion)\n",
    "    coord2 = offset_y(coord2, 6300*(step_y + multiplier) + expansion)\n",
    "    bbx = (coord2, coord1)\n",
    "    return bbx\n",
    "\n",
    "def pts_in_geojson(lats, longs, geojson):  \n",
    "    polys = geopandas.read_file(geojson)['geometry']\n",
    "    polys = geopandas.GeoSeries(polys)\n",
    "    pnts = [Point(x, y) for x, y in zip(list(lats), list(longs))]\n",
    "    \n",
    "    def _contains(pt):\n",
    "        return polys.contains(pt)[0]\n",
    "\n",
    "    if any([_contains(pt) for pt in pnts]):\n",
    "        return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_clouds_new(bbox, epsg = EPSG, dates = dates):\n",
    "\n",
    "    #for try_ in range(0, 5):\n",
    "        #try:\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    cloud_request = WmsRequest(\n",
    "        layer='CLOUD_NEW',\n",
    "        bbox=box,\n",
    "        time=dates,\n",
    "        width=(5*9*14)+2,\n",
    "        height=(5*9*14)+2,\n",
    "        image_format = MimeType.TIFF_d32f,\n",
    "        maxcc=0.7,\n",
    "        instance_id=API_KEY,\n",
    "        custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "        time_difference=datetime.timedelta(hours=48),\n",
    "    )\n",
    "\n",
    "\n",
    "    shadow_request = WmsRequest(\n",
    "        layer='SHADOW',\n",
    "        bbox=box,\n",
    "        time=dates,\n",
    "        width=(5*9*14)+2,\n",
    "        height=(5*9*14)+2,\n",
    "        image_format =  MimeType.TIFF_d16,\n",
    "        maxcc=0.7,\n",
    "        instance_id=API_KEY,\n",
    "        custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "        time_difference=datetime.timedelta(hours=48))\n",
    "\n",
    "    cloud_img = cloud_request.get_data()\n",
    "    cloud_img = np.array(cloud_img)\n",
    "    cloud_probs = cloud_img / 255\n",
    "    print(\"Cloud_probs shape: {}\".format(cloud_probs.shape))\n",
    "\n",
    "    shadow_img = shadow_request.get_data()\n",
    "    shadow_img = np.array(shadow_img)\n",
    "    print(\"Shadows_shape: {}\".format(shadow_img.shape))\n",
    "    print(np.max(shadow_img))\n",
    "    shadow_img = shadow_img / 65535\n",
    "    print(np.max(shadow_img))\n",
    "\n",
    "\n",
    "    shadows = mcm_shadow_mask(np.array(shadow_img), cloud_probs)\n",
    "    print(\"Cloud probs: {}\".format(cloud_probs.shape))\n",
    "    return cloud_img, cloud_probs, shadows\n",
    "       # except Exception as e:\n",
    "            #logging.fatal(e, exc_info=True)\n",
    "            #sleep(30)\n",
    "    \n",
    "    \n",
    "def download_dem(bbox, epsg = EPSG):\n",
    "    #@valid\n",
    "    for try_ in range(0, 5):\n",
    "        try:\n",
    "            box = BBox(bbox, crs = epsg)\n",
    "            dem_s = (630)+4\n",
    "            dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                                 layer='DEM',\n",
    "                                 bbox=box,\n",
    "                                 width=dem_s,\n",
    "                                 height=dem_s,\n",
    "                                 instance_id=API_KEY,\n",
    "                                 image_format=MimeType.TIFF_d32f,\n",
    "                                 custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "            dem_image = dem_request.get_data()[0]\n",
    "            dem_image = calcSlope(dem_image.reshape((1, dem_s, dem_s)),\n",
    "                          np.full((dem_s, dem_s), 10), np.full((dem_s, dem_s), 10), zScale = 1, minSlope = 0.02)\n",
    "            dem_image = dem_image.reshape((dem_s,dem_s, 1))\n",
    "            dem_image = dem_image[1:dem_s-1, 1:dem_s-1, :]\n",
    "            return dem_image #/ np.max(dem_image)\n",
    "        except Exception as e:\n",
    "            #logging.fatal(e, exc_info=True)\n",
    "            sleep((try_+1)*30)\n",
    "            pass\n",
    "\n",
    "def download_layer(bbox, epsg = EPSG, dates = dates, year = 2019):\n",
    "    \"\"\" Downloads the L2A sentinel layer with 10 and 20 meter bands\n",
    "        \n",
    "        Parameters:\n",
    "         bbox (list): output of calc_bbox\n",
    "         epsg (float): EPSG associated with bbox \n",
    "         time (tuple): YY-MM-DD - YY-MM-DD bounds for downloading \n",
    "    \n",
    "        Returns:\n",
    "         img (arr):\n",
    "         img_request (obj): \n",
    "    \"\"\"\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    image_request = WcsRequest(\n",
    "            layer='L2A20',\n",
    "            bbox=box,\n",
    "            time=dates,\n",
    "            image_format = MimeType.TIFF_d16,\n",
    "            maxcc=0.7,\n",
    "            resx='10m', resy='10m',\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=48),\n",
    "        )\n",
    "    print(\"Downloading L2A 20m layer\")\n",
    "    img_bands = image_request.get_data()\n",
    "    img_20 = np.stack(img_bands)\n",
    "    print(\"Original 20 meter bands size: {}\".format(img_20.shape))\n",
    "    img_20 = resize(img_20, (img_20.shape[0], 632, 632, img_20.shape[-1]), order = 0)\n",
    "\n",
    "    image_request = WcsRequest(\n",
    "            layer='L2A10',\n",
    "            bbox=box,\n",
    "            time=dates,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.7,\n",
    "            resx='10m', resy='10m',\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'BICUBIC',\n",
    "                                constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "            time_difference=datetime.timedelta(hours=48),\n",
    "    )\n",
    "    print(\"Downloading L2A 10m layer\")\n",
    "    img_bands = image_request.get_data()\n",
    "    img_10 = np.stack(img_bands)\n",
    "    print(\"Original 10 meter bands size: {}\".format(img_10.shape))\n",
    "    img_10 = resize(img_10, (img_10.shape[0], 632, 632, img_10.shape[-1]), order = 0)\n",
    "\n",
    "    img = np.concatenate([img_10, img_20], axis = -1)\n",
    "\n",
    "    image_dates = []\n",
    "    for date in image_request.get_dates():\n",
    "        if date.year == year - 1:\n",
    "            image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year:\n",
    "            image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year + 1:\n",
    "            image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "    image_dates = np.array(image_dates)\n",
    "\n",
    "    return img, image_dates#, shadows, shadow_steps\n",
    "        #except Exception as e:\n",
    "            #logging.fatal(e, exc_info=True)\n",
    "            #sleep((try_+1)*30)\n",
    "        \n",
    "        \n",
    "def download_sentinel_1(bbox, epsg = EPSG, imsize = 632, \n",
    "                        dates = dates, layer = \"SENT\", year = 2019):\n",
    "    #for try_ in range(5):\n",
    "        #try:\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    image_request = WcsRequest(\n",
    "            layer=layer,\n",
    "            bbox=box,\n",
    "            time=dates,\n",
    "            image_format = MimeType.TIFF_d16,\n",
    "            maxcc=1.0,\n",
    "            resx='5m', resy='5m',\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=48),\n",
    "        )\n",
    "    img_bands = image_request.get_data()\n",
    "    s1 = np.stack(img_bands)\n",
    "    s1 = resize(s1, (s1.shape[0], imsize*2, imsize*2, s1.shape[-1]), order = 0)\n",
    "    s1 = np.reshape(s1, (s1.shape[0], s1.shape[1]//2, 2, s1.shape[2] // 2, 2, s1.shape[-1]))\n",
    "    s1 = np.mean(s1, (2, 4))\n",
    "    #s1 = s1[:, 8:24, 8:24, :]\n",
    "\n",
    "    image_dates = []\n",
    "    for date in image_request.get_dates():\n",
    "        if date.year == year - 1:\n",
    "            image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year:\n",
    "            image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year + 1:\n",
    "            image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "    image_dates = np.array(image_dates)\n",
    "    s1c = np.copy(s1)\n",
    "    s1c[np.where(s1c < 1.)] = 0\n",
    "    n_pix_oob = np.sum(s1c, axis = (1, 2, 3))\n",
    "    to_remove = np.argwhere(n_pix_oob > (imsize*2*imsize*2)/50)\n",
    "    s1 = np.delete(s1, to_remove, 0)\n",
    "    image_dates = np.delete(image_dates, to_remove)\n",
    "    return s1, image_dates\n",
    "\n",
    "        #except Exception as e:\n",
    "            #logging.fatal(e, exc_info=True)\n",
    "            #sleep((try_+1)*30)\n",
    "\n",
    "def identify_s1_layer(coords):\n",
    "    results = rg.search(coords)\n",
    "    country = results[-1]['cc']\n",
    "    continent_name = pc.country_alpha2_to_continent_code(country)\n",
    "    if continent_name in ['AF', 'OC']:\n",
    "        layer = \"SENT\"\n",
    "    if continent_name in ['SA']:\n",
    "        if coords[0] > -7.11:\n",
    "            layer = \"SENT\"\n",
    "        else:\n",
    "            layer = \"SENT_DESC\"\n",
    "    if continent_name in ['AS']:\n",
    "        if coords[0] > 23.3:\n",
    "            layer = \"SENT\"\n",
    "        else:\n",
    "            layer = \"SENT_DESC\"\n",
    "    if continent_name in ['NA']:\n",
    "        layer = \"SENT_DESC\"\n",
    "    print(continent_name)\n",
    "    print(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud and shadow removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cloud_and_shadows(tiles, c_probs, shadows, image_dates):\n",
    "    \"\"\" Interpolates clouds and shadows for each time step with \n",
    "        linear combination of proximal clean time steps for each\n",
    "        region of specified window size\n",
    "        \n",
    "        Parameters:\n",
    "         tiles (arr):\n",
    "         probs (arr): \n",
    "         shadows (arr):\n",
    "         image_dates (list):\n",
    "         wsize (int): \n",
    "    \n",
    "        Returns:\n",
    "         tiles (arr): \n",
    "    \"\"\"\n",
    "    wsize = 5\n",
    "    c_probs = c_probs - np.min(c_probs, axis = 0)\n",
    "    c_probs[np.where(c_probs > 0.33)] = 1.\n",
    "    c_probs[np.where(c_probs < 0.33)] = 0.\n",
    "    c_probs = np.reshape(c_probs, (c_probs.shape[0], 632//8, 8, 632//8, 8))\n",
    "    c_probs = np.sum(c_probs, (2, 4))\n",
    "    c_probs = resize(c_probs, (c_probs.shape[0], 632, 632), 0)\n",
    "    c_probs[np.where(c_probs < 16)] = 0\n",
    "    c_probs[np.where(c_probs >= 16)] = 1\n",
    "    secondary_c_probs = np.copy(c_probs)\n",
    "    c_probs += shadows\n",
    "    c_probs[np.where(c_probs >= 1.)] = 1.\n",
    "    number_interpolated = 0\n",
    "    for cval in tnrange(0, IMSIZE - 4, 2):\n",
    "        for rval in range(0, IMSIZE - 4, 2):\n",
    "            subs = c_probs[:, cval:cval + wsize, rval:rval+wsize]\n",
    "            sums = np.sum(subs, axis = (1, 2))\n",
    "            satisfactory = [x for x in range(c_probs.shape[0]) if sums[x] < 8]\n",
    "            if len(satisfactory) == 0:\n",
    "                satisfactory = [x for x in range(c_probs.shape[0])]\n",
    "            satisfactory = np.array(satisfactory)\n",
    "            for date in range(0, tiles.shape[0]):\n",
    "                if np.sum(subs[date, :, :]) > 8:\n",
    "                    number_interpolated += 1\n",
    "                    before, after = calculate_proximal_steps(date, satisfactory)\n",
    "                    before = date + before\n",
    "                    after = date + after\n",
    "                    bef = tiles[before, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    aft = tiles[after, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    before = image_dates[before]\n",
    "                    after = image_dates[after]\n",
    "                    before_diff = abs(image_dates[date] - before)\n",
    "                    after_diff = abs(image_dates[date] - after)\n",
    "                    bef_wt = 1 - before_diff / (before_diff + after_diff)\n",
    "                    aft_wt = 1 - bef_wt\n",
    "                    candidate = bef_wt*bef + aft_wt*aft\n",
    "                    candidate = candidate*c_arr + tiles[date, cval:cval+wsize, rval:rval+wsize, : ]*o_arr\n",
    "                    tiles[date, cval:cval+wsize, rval:rval+wsize, : ] = candidate \n",
    "    print(\"A total of {} pixels were interpolated\".format(number_interpolated))\n",
    "    return tiles, c_probs, secondary_c_probs\n",
    "\n",
    "def remove_missed_clouds(img):\n",
    "    iqr = np.percentile(img[:, :, :, 3].flatten(), 75) - np.percentile(img[:, :, :, 3].flatten(), 25)\n",
    "    thresh_t = np.percentile(img[:, :, :, 3].flatten(), 75) + iqr*2\n",
    "    thresh_b = np.percentile(img[:, :, :, 3].flatten(), 25) - iqr*2\n",
    "    diffs_fw = np.diff(img, 1, axis = 0)\n",
    "    diffs_fw = np.mean(diffs_fw, axis = (1, 2, 3))\n",
    "    diffs_fw = np.array([0] + list(diffs_fw))\n",
    "    diffs_bw = np.diff(np.flip(img, 0), 1, axis = 0)\n",
    "    diffs_bw = np.flip(np.mean(diffs_bw, axis = (1, 2, 3)))\n",
    "    diffs_bw = np.array(list(diffs_bw) + [0])\n",
    "    diffs = abs(diffs_fw - diffs_bw) * 100\n",
    "    #diffs = [int(x) for x in diffs]\n",
    "    outlier_percs = []\n",
    "    for step in range(img.shape[0]):\n",
    "        bottom = len(np.argwhere(img[step, :, :, 3].flatten() > thresh_t))\n",
    "        top = len(np.argwhere(img[step, :, :, 3].flatten() < thresh_b))\n",
    "        p = 100* ((bottom + top) / (IMSIZE*IMSIZE))\n",
    "        outlier_percs.append(p)\n",
    "    to_remove = np.argwhere(np.array(outlier_percs) > 20)\n",
    "    return to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data interpolation\n",
    "\n",
    "Because the `smooth` function is called 5.6 million times on each 4000 hectare array, most of the computations are done outside of the function with the predefined `lmbd` and `d`, and then passed in as the `coefmat`, to avoid needless recomputation. This saves 141 CPU minutes per 4000 hectare array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbd = 800\n",
    "diagonals = np.zeros(2*2+1)\n",
    "diagonals[2] = 1.\n",
    "for i in range(2):\n",
    "    diff = diagonals[:-1] - diagonals[1:]\n",
    "    diagonals = diff\n",
    "offsets = np.arange(2+1)\n",
    "shape = (70, 72)\n",
    "E = sparse.eye(72, format = 'csc')\n",
    "D = scipy.sparse.diags(diagonals, offsets, shape)\n",
    "D = D.conj().T.dot(D) * lmbd\n",
    "coefmat = E + D\n",
    "\n",
    "def smooth(y, coefmat = coefmat):\n",
    "    ''' \n",
    "    Apply whittaker smoothing to a 1-dimensional array, returning a 1-dimensional array\n",
    "    '''\n",
    "    return splu(coefmat).solve(np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7676013989985222\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def unpacking_apply_along_axis(all_args):\n",
    "    (func1d, axis, arr, args, kwargs) = all_args\n",
    "    return np.apply_along_axis(func1d, axis, arr)\n",
    "\n",
    "def parallel_apply_along_axis(func1d, axis, arr, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Like numpy.apply_along_axis(), but takes advantage of multiple\n",
    "    cores.\n",
    "    \"\"\"        \n",
    "    # Effective axis where apply_along_axis() will be applied by each\n",
    "    # worker (any non-zero axis number would work, so as to allow the use\n",
    "    # of `np.array_split()`, which is only done on axis 0):\n",
    "    effective_axis = 1 if axis == 0 else axis\n",
    "    if effective_axis != axis:\n",
    "        arr = arr.swapaxes(axis, effective_axis)\n",
    "\n",
    "    # Chunks for the mapping (only a few chunks):\n",
    "    chunks = [(func1d, effective_axis, sub_arr, args, kwargs)\n",
    "              for sub_arr in np.array_split(arr, 4)]\n",
    "\n",
    "    pool = multiprocessing.Pool(4)\n",
    "    individual_results = pool.map(unpacking_apply_along_axis, chunks)\n",
    "    # Freeing the workers:\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    individual_results = np.concatenate(individual_results)\n",
    "    if effective_axis != axis:\n",
    "        individual_results = individual_results.swapaxes(axis, effective_axis)\n",
    "    return np.concatenate(individual_results)\n",
    "\n",
    "test = np.ones((72, 10000))\n",
    "s = timer()\n",
    "x = parallel_apply_along_axis(smooth, 0, test)\n",
    "e = timer()\n",
    "print(e - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5413372619987058\n"
     ]
    }
   ],
   "source": [
    "test = np.ones((72, 10000))\n",
    "s = timer()\n",
    "x = np.apply_along_axis(smooth, 0, test)\n",
    "e = timer()\n",
    "print(e - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_best_images(img_bands, image_dates):\n",
    "    \"\"\" Interpolate input data of (Time, X, Y, Band) to a constant\n",
    "        (72, X, Y, Band) shape with one time step every five days\n",
    "        \n",
    "        Parameters:\n",
    "         img_bands (arr):\n",
    "         image_dates (list):\n",
    "         \n",
    "        Returns:\n",
    "         keep_steps (arr):\n",
    "         max_distance (int)\n",
    "    \"\"\"\n",
    "\n",
    "    biweekly_dates = [day for day in range(0, 360, 5)] # ideal imagery dates are every 15 days\n",
    "    \n",
    "    # Identify the dates where there is < 20% cloud cover\n",
    "    #satisfactory_ids = list(np.argwhere(np.array(means) < 4.).reshape(-1, )) \n",
    "    satisfactory_ids = [x for x in range(0, img_bands.shape[0])]\n",
    "    satisfactory_dates = [value for idx, value in enumerate(image_dates) if idx in satisfactory_ids]\n",
    "    \n",
    "    \n",
    "    selected_images = {}\n",
    "    for i in biweekly_dates:\n",
    "        distances = [abs(date - i) for date in satisfactory_dates]\n",
    "        closest = np.min(distances)\n",
    "        closest_id = np.argmin(distances)\n",
    "        # If there is imagery within 8 days, select it\n",
    "        if closest < 8:\n",
    "            date = satisfactory_dates[closest_id]\n",
    "            image_idx = int(np.argwhere(np.array(image_dates) == date)[0])\n",
    "            selected_images[i] = {'image_date': [date], 'image_ratio': [1], 'image_idx': [image_idx]}\n",
    "        # If there is not imagery within 8 days, look for the closest above and below imagery\n",
    "        else:\n",
    "            distances = np.array([(date - i) for date in satisfactory_dates])\n",
    "            # Number of days above and below the selected date of the nearest clean imagery\n",
    "            above = distances[np.where(distances < 0, distances, -np.inf).argmax()]\n",
    "            below = distances[np.where(distances > 0, distances, np.inf).argmin()]\n",
    "            if abs(above) > 240: # If date is the last date, occassionally argmax would set above to - number\n",
    "                above = below\n",
    "            if abs(below) > 240:\n",
    "                below = above\n",
    "            if above != below:\n",
    "                below_ratio = above / (above - below)\n",
    "                above_ratio = 1 - below_ratio\n",
    "            else:\n",
    "                above_ratio = below_ratio = 0.5\n",
    "                \n",
    "            # Extract the image date and imagery index for the above and below values\n",
    "            above_date = i + above\n",
    "            above_image_idx = int(np.argwhere(np.array(image_dates) == above_date)[0])\n",
    "            \n",
    "            below_date = i + below\n",
    "            below_image_idx = int(np.argwhere(np.array(image_dates) == below_date)[0])\n",
    "            \n",
    "            selected_images[i] = {'image_date': [above_date, below_date], 'image_ratio': [above_ratio, below_ratio],\n",
    "                                 'image_idx': [above_image_idx, below_image_idx]}\n",
    "                            \n",
    "    max_distance = 0\n",
    "    \n",
    "    for i in selected_images.keys():\n",
    "        if len(selected_images[i]['image_date']) == 2:\n",
    "            dist = selected_images[i]['image_date'][1] - selected_images[i]['image_date'][0]\n",
    "            if dist > max_distance:\n",
    "                max_distance = dist\n",
    "    \n",
    "    print(\"Maximum time distance: {}\".format(max_distance))\n",
    "        \n",
    "    keep_steps = []\n",
    "    for i in selected_images.keys():\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "        if len(info['image_idx']) == 2:\n",
    "            step1 = img_bands[info['image_idx'][0]] * 0.5#info['image_ratio'][0]\n",
    "            step2 = img_bands[info['image_idx'][1]] * 0.5 #info['image_ratio'][1]\n",
    "            step = step1 + step2\n",
    "        keep_steps.append(step)\n",
    "        \n",
    "    keep_steps = np.stack(keep_steps)\n",
    "    return keep_steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiling and coordinate selection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic Model Created.\n"
     ]
    }
   ],
   "source": [
    "MDL_PATH = \"../src/dsen2/models/\"\n",
    "\n",
    "input_shape = ((4, None, None), (6, None, None))\n",
    "model = s2model(input_shape, num_layers=6, feature_size=128)\n",
    "predict_file = MDL_PATH+'s2_032_lr_1e-04.hdf5'\n",
    "print('Symbolic Model Created.')\n",
    "\n",
    "model.load_weights(predict_file)\n",
    "\n",
    "def DSen2(d10, d20):\n",
    "    \"\"\"Super resolves 20 meter bans using the DSen2 convolutional\n",
    "       neural network, as specified in Lanaras et al. 2018\n",
    "       https://github.com/lanha/DSen2\n",
    "\n",
    "        Parameters:\n",
    "         d10 (arr): (4, X, Y) shape array with 10 meter resolution\n",
    "         d20 (arr): (6, X, Y) shape array with 20 meter resolution\n",
    "\n",
    "        Returns:\n",
    "         prediction (arr): (6, X, Y) shape array with 10 meter superresolved\n",
    "                          output of DSen2 on d20 array\n",
    "    \"\"\"\n",
    "    test = [d10, d20]\n",
    "    input_shape = ((4, None, None), (6, None, None))\n",
    "    prediction = _predict(test, input_shape, deep=False)\n",
    "    #prediction *= 5\n",
    "    return prediction\n",
    "\n",
    "def _predict(test, input_shape, model = model, deep=False, run_60=False):\n",
    "    \n",
    "    prediction = model.predict(test, verbose=1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "starting_days = np.cumsum(days_per_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proximal_steps(date, satisfactory):\n",
    "    arg_before = None\n",
    "    arg_after = None\n",
    "    if date > 0:\n",
    "        idx_before = satisfactory - date\n",
    "        arg_before = idx_before[np.where(idx_before < 0, idx_before, -np.inf).argmax()]\n",
    "    if date < np.max(satisfactory):\n",
    "        idx_after = satisfactory - date\n",
    "        arg_after = idx_after[np.where(idx_after > 0, idx_after, np.inf).argmin()]\n",
    "    if not arg_after and not arg_before:\n",
    "        arg_after = date\n",
    "        arg_before = date\n",
    "    if not arg_after:\n",
    "        arg_after = arg_before\n",
    "    if not arg_before:\n",
    "        arg_before = arg_after\n",
    "    #print(arg_before, date, arg_after)\n",
    "    return arg_before, arg_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mcm_shadow_mask(arr, c_probs):\n",
    "    \"\"\" Calculates the multitemporal shadow mask for Sentinel-2 using\n",
    "        the methods from Candra et al. 2020 on L1C images and matching\n",
    "        outputs to the s2cloudless cloud probabilities\n",
    "\n",
    "        Parameters:\n",
    "         arr (arr): (Time, X, Y, Band) array of L1C data scaled from [0, 1]\n",
    "         c_probs (arr): (Time, X, Y) array of S2cloudless cloud probabilities\n",
    "    \n",
    "        Returns:\n",
    "         shadows_new (arr): cloud mask after Candra et al. 2020 and cloud matching \n",
    "         shadows_original (arr): cloud mask after Candra et al. 2020\n",
    "    \"\"\"\n",
    "    def _rank_array(arr):\n",
    "        order = arr.argsort()\n",
    "        ranks = order.argsort()\n",
    "        return ranks\n",
    "    mean_c_probs = np.mean(c_probs, axis = (1, 2))\n",
    "    cloudy_steps = np.argwhere(mean_c_probs > 0.25)\n",
    "    images_clean = np.delete(arr, cloudy_steps, 0)\n",
    "    cloud_ranks = _rank_array(mean_c_probs)\n",
    "    diffs = abs(np.sum(arr - np.mean(images_clean, axis = 0), axis = (1, 2, 3)))\n",
    "    diff_ranks = _rank_array(diffs)\n",
    "    overall_rank = diff_ranks + cloud_ranks\n",
    "    reference_idx = np.argmin(overall_rank)\n",
    "    ri = arr[reference_idx]\n",
    "        \n",
    "    shadows = np.zeros((arr.shape[0], 632, 632))    \n",
    "    # Candra et al. 2020\n",
    "    \n",
    "    for time in tnrange(arr.shape[0]):\n",
    "        for x in range(arr.shape[1]):\n",
    "            for y in range(arr.shape[2]):\n",
    "                ti_slice = arr[time, x, y]\n",
    "                ri_slice = ri[x, y]\n",
    "                deltab2 = ti_slice[0] - ri_slice[0]\n",
    "                deltab8a = ti_slice[1] - ri_slice[1]\n",
    "                deltab11 = ti_slice[2] - ri_slice[2]\n",
    "\n",
    "                if deltab2 < 0.10: #(1000/65535):\n",
    "                    if deltab8a < -0.04: #(-400/65535):\n",
    "                        if deltab11 < -0.04: #(-400/65535):\n",
    "                            if ti_slice[0] < 0.095: #(950/65535):\n",
    "                                shadows[time, x, y] = 1.\n",
    "                                                       \n",
    "                            \n",
    "    # Remove shadows if cannot coreference a cloud\n",
    "    shadow_large = np.reshape(shadows, (shadows.shape[0], 79, 8, 79, 8))\n",
    "    shadow_large = np.sum(shadow_large, axis = (2, 4))\n",
    "    \n",
    "    cloud_large = np.copy(c_probs)\n",
    "    cloud_large[np.where(c_probs > 0.33)] = 1.\n",
    "    cloud_large[np.where(c_probs < 0.33)] = 0.\n",
    "    cloud_large = np.reshape(cloud_large, (shadows.shape[0], 79, 8, 79, 8))\n",
    "    cloud_large = np.sum(cloud_large, axis = (2, 4))\n",
    "    for time in tnrange(shadow_large.shape[0]):\n",
    "        for x in range(shadow_large.shape[1]):\n",
    "            x_low = np.max([x - 8, 0])\n",
    "            x_high = np.min([x + 8, shadow_large.shape[1] - 1])\n",
    "            for y in range(shadow_large.shape[2]):\n",
    "                y_low = np.max([y - 8, 0])\n",
    "                y_high = np.min([y + 8, shadow_large.shape[1] - 1])\n",
    "                if shadow_large[time, x, y] < 8:\n",
    "                    shadow_large[time, x, y] = 0.\n",
    "                if shadow_large[time, x, y] >= 8:\n",
    "                    shadow_large[time, x, y] = 1.\n",
    "                c_prob_window = cloud_large[time, x_low:x_high, y_low:y_high]\n",
    "                if np.max(c_prob_window) < 16:\n",
    "                    shadow_large[time, x, y] = 0.\n",
    "                    \n",
    "    shadow_large = resize(shadow_large, (shadow_large.shape[0], 632, 632), order = 0)\n",
    "    shadows *= shadow_large\n",
    "    \n",
    "    # Go through and aggregate the shadow map to an 80m grid, and extend it one grid size around\n",
    "    # any positive ID\n",
    "    \n",
    "    shadows = np.reshape(shadows, (shadows.shape[0], 79, 8, 79, 8))\n",
    "    shadows = np.sum(shadows, axis = (2, 4))\n",
    "    shadows[np.where(shadows < 12)] = 0.\n",
    "    shadows[np.where(shadows >= 12)] = 1.\n",
    "    \n",
    "    shadows = resize(shadows, (shadows.shape[0], 632, 632), order = 0)\n",
    "    shadows = np.reshape(shadows, (shadows.shape[0], 632//4, 4, 632//4, 4))\n",
    "    shadows = np.max(shadows, (2, 4))\n",
    "    \n",
    "    shadows_new = np.zeros_like(shadows)\n",
    "    for time in range(shadows.shape[0]):\n",
    "        for x in range(shadows.shape[1]):\n",
    "            for y in range(shadows.shape[2]):\n",
    "                if shadows[time, x, y] == 1:\n",
    "                    min_x = np.max([x - 1, 0])\n",
    "                    max_x = np.min([x + 2, 157])\n",
    "                    min_y = np.max([y - 1, 0])\n",
    "                    max_y = np.min([y + 2, 157])\n",
    "                    for x_idx in range(min_x, max_x):\n",
    "                        for y_idx in range(min_y, max_y):\n",
    "                            shadows_new[time, x_idx, y_idx] = 1.\n",
    "    shadows_new = resize(shadows_new, (shadows.shape[0], 632, 632), order = 0)\n",
    "    return shadows_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_output_and_temp_folders(idx, output_folder = OUTPUT_FOLDER):\n",
    "    \n",
    "    def _find_and_make_dirs(dirs):\n",
    "        if not os.path.exists(os.path.realpath(dirs)):\n",
    "            os.makedirs(os.path.realpath(dirs))\n",
    "            \n",
    "    _find_and_make_dirs(output_folder + \"raw/\")\n",
    "    _find_and_make_dirs(output_folder + \"raw/clouds/\")\n",
    "    _find_and_make_dirs(output_folder + \"raw/s1/\")\n",
    "    _find_and_make_dirs(output_folder + \"raw/s2/\")\n",
    "    _find_and_make_dirs(output_folder + \"raw/misc/\")\n",
    "    _find_and_make_dirs(output_folder + \"processed/\")\n",
    "    \n",
    "\n",
    "def check_contains(coord, step_x, step_y, folder = OUTPUT_FOLDER, year = 2019, s1_layer = \"SENT\"):\n",
    "    bbx = calculate_bbx(coord, step_x, step_y, expansion = 10)\n",
    "    if os.path.exists(folder):\n",
    "        if any([x.endswith(\".geojson\") for x in os.listdir(folder)]):\n",
    "            geojson_path = folder + [x for x in os.listdir(folder) if x.endswith(\".geojson\")][0]\n",
    "            contains = pts_in_geojson([bbx[0][0], bbx[1][0]],\n",
    "                                      [bbx[0][1], bbx[1][1]],\n",
    "                                      geojson_path)\n",
    "    else:\n",
    "        contains = True\n",
    "    return contains\n",
    "\n",
    "def download_large_tile(coord, step_x, step_y, folder = OUTPUT_FOLDER, year = 2019, s1_layer = \"SENT\"):\n",
    "\n",
    "    bbx = calculate_bbx(coord, step_x, step_y, expansion = 10)\n",
    "    dem_bbx = calculate_bbx(coord, step_x, step_y, expansion = 20)\n",
    "    idx = str(step_y) + \"_\" + str(step_x)\n",
    "    print(idx)\n",
    "    idx = str(idx)\n",
    "    make_output_and_temp_folders(idx)\n",
    "\n",
    "    print(\"Calculating cloud cover\")\n",
    "    if not os.path.exists(folder + \"processed/\" + str(((step_y+1)*5)-1) + \"/\" + str(((step_x+1)*5)-1) + \".hkl\"):\n",
    "        if not os.path.exists(folder + \"raw/clouds/clouds_{}.hkl\".format(idx)):\n",
    "            l1c, cloud_probs, shadows = identify_clouds_new(bbx)\n",
    "            hkl.dump(cloud_probs, folder + \"raw/clouds/clouds_{}.hkl\".format(idx), mode='w', compression='gzip')\n",
    "            hkl.dump(shadows, folder + \"raw/clouds/shadows_{}.hkl\".format(idx), mode='w', compression='gzip')\n",
    "\n",
    "        if not os.path.exists(folder + \"raw/s1/{}.hkl\".format(idx)):\n",
    "            print(\"Downloading S1\")\n",
    "            s1_layer = identify_s1_layer((coord[1], coord[0]))\n",
    "            s1, s1_dates = download_sentinel_1(bbx, layer = s1_layer)\n",
    "            s1 = process_sentinel_1_tile(s1, s1_dates)\n",
    "            hkl.dump(s1, folder + \"raw/s1/{}.hkl\".format(idx), mode='w', compression='gzip')\n",
    "            hkl.dump(s1_dates, folder + \"raw/misc/s1_dates_{}.hkl\".format(idx), mode='w', compression='gzip')\n",
    "\n",
    "        if not os.path.exists(folder + \"raw/s2/{}.hkl\".format(idx)):\n",
    "            print(\"Downloading S2\")\n",
    "            s2, s2_dates = download_layer(bbx)\n",
    "            hkl.dump(s2, folder + \"raw/s2/{}.hkl\".format(idx), mode='w', compression='gzip')\n",
    "            hkl.dump(s2_dates, folder + \"raw/misc/s2_dates_{}.hkl\".format(idx), mode='w', compression='gzip')\n",
    "\n",
    "        if not os.path.exists(folder + \"raw/misc/dem_{}.hkl\".format(idx)):\n",
    "            print(\"Downloading DEM\")\n",
    "            dem = download_dem(dem_bbx) # get the DEM BBOX\n",
    "            hkl.dump(dem, folder + \"raw/misc/dem_{}.hkl\".format(idx), mode='w', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bad_steps(sentinel2, clouds):\n",
    "    n_cloud_px = np.array([len(np.argwhere(clouds[x, :, :].reshape((632)*(632)) > 0.33)) for x in range(clouds.shape[0])])\n",
    "    cloud_steps = np.argwhere(n_cloud_px > 632**2 / 5)\n",
    "    missing_images = [np.argwhere(sentinel2[x, :, : :10].flatten() == 0.0) for x in range(sentinel2.shape[0])]\n",
    "    missing_images = np.array([len(x) for x in missing_images])\n",
    "    missing_images_p = [np.argwhere(sentinel2[x, :, : :10].flatten() >= 1) for x in range(sentinel2.shape[0])]\n",
    "    missing_images_p = np.array([len(x) for x in missing_images_p])\n",
    "    missing_images += missing_images_p\n",
    "    missing_images = np.argwhere(missing_images >= (632**2) / 50)\n",
    "    to_remove = np.unique(np.concatenate([cloud_steps.flatten(), missing_images.flatten()]))\n",
    "    return to_remove\n",
    "\n",
    "def superresolve(sentinel2):\n",
    "    d10 = sentinel2[:, :, :, 0:4]\n",
    "    d20 = sentinel2[:, :, :, 4:10]\n",
    "\n",
    "    d10 = np.swapaxes(d10, 1, -1)\n",
    "    d10 = np.swapaxes(d10, 2, 3)\n",
    "    d20 = np.swapaxes(d20, 1, -1)\n",
    "    d20 = np.swapaxes(d20, 2, 3)\n",
    "    superresolved = DSen2(d10, d20)\n",
    "    superresolved = np.swapaxes(superresolved, 1, -1)\n",
    "    superresolved = np.swapaxes(superresolved, 1, 2)\n",
    "    return superresolved # returns band IDXs 3, 4, 5, 7, 8, 9\n",
    "\n",
    "def process_sentinel_1_tile(sentinel1, dates):\n",
    "    s1 = calculate_and_save_best_images(sentinel1, dates)\n",
    "    # Retain only iamgery every 15 days\n",
    "    biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "    to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "    s1 = np.delete(s1, to_remove, 0)\n",
    "    return s1\n",
    "\n",
    "\n",
    "def interpolate_array_master(x):\n",
    "    no_dem = np.delete(x, 10, -1)\n",
    "    no_dem = np.reshape(no_dem, (72, 128*128*14))\n",
    "    no_dem = parallel_apply_along_axis(smooth, 0, no_dem)\n",
    "    #no_dem = np.apply_along_axis(smooth, 0, no_dem)\n",
    "    no_dem = np.reshape(no_dem, (72, 128, 128, 14))\n",
    "    x[:, :, :, :10] = no_dem[:, :, :, :10]\n",
    "    x[:, :, :, 11:] = no_dem[:, :, :, 10:]\n",
    "\n",
    "    biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "    to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "    x = np.delete(x, to_remove, 0)\n",
    "    return x\n",
    "    \n",
    "        \n",
    "\n",
    "def interpolate_array(x):\n",
    "    no_dem = np.delete(x, 10, -1)\n",
    "    no_dem = np.reshape(no_dem, (72, 128*128*14))\n",
    "    no_dem = np.swapaxes(no_dem, 0, 1)\n",
    "\n",
    "    pool = multiprocessing.Pool(6)\n",
    "    no_dem = pool.map(smooth, no_dem)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    no_dem = np.swapaxes(no_dem, 0, 1)\n",
    "    no_dem = np.reshape(no_dem, (72, 128, 128, 14))\n",
    "    x[:, :, :, :10] = no_dem[:, :, :, :10]\n",
    "    x[:, :, :, 11:] = no_dem[:, :, :, 10:]\n",
    "\n",
    "    biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "    to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "    x = np.delete(x, to_remove, 0)\n",
    "    return x\n",
    "\n",
    "def process_large_tile(coord, step_x, step_y, folder = OUTPUT_FOLDER):\n",
    "    bbx = calculate_bbx(coord, step_x, step_y, expansion = 10)\n",
    "    idx = str(step_y) + \"_\" + str(step_x)\n",
    "    x_vals = []\n",
    "    y_vals = []\n",
    "    # save to disk\n",
    "    for i in range(25):\n",
    "        y_val = (24 - i) // 5\n",
    "        x_val = 5 - ((25 - i) % 5)\n",
    "        x_val = 0 if x_val == 5 else x_val\n",
    "        x_vals.append(x_val)\n",
    "        y_vals.append(y_val)\n",
    "\n",
    "    y_vals = [i + (5*step_y) for i in y_vals]\n",
    "    x_vals = [i + (5*step_x) for i in x_vals]\n",
    "\n",
    "    processed = True\n",
    "    for x, y in zip(x_vals, y_vals):\n",
    "        if not os.path.exists(folder + \"processed/{}/{}.hkl\".format(str(y), str(x))):\n",
    "            processed = False\n",
    "    if not processed:\n",
    "\n",
    "        clouds = hkl.load(folder + \"raw/clouds/clouds_{}.hkl\".format(idx))\n",
    "        sentinel1 = hkl.load(folder + \"raw/s1/{}.hkl\".format(idx))\n",
    "        radar_dates = hkl.load(folder + \"raw/misc/s1_dates_{}.hkl\".format(idx))\n",
    "        sentinel2 = hkl.load(folder + \"raw/s2/{}.hkl\".format(idx))\n",
    "        dem = hkl.load(folder + \"raw/misc/dem_{}.hkl\".format(idx))\n",
    "        image_dates = hkl.load(folder + \"raw/misc/s2_dates_{}.hkl\".format(idx))\n",
    "        if os.path.exists(folder + \"raw/clouds/shadows_{}.hkl\".format(idx)):\n",
    "            shadows = hkl.load(folder + \"raw/clouds/shadows_{}.hkl\".format(idx))\n",
    "        else:\n",
    "            print(\"No shadows file, so calculating shadows with L2A\")\n",
    "            shadows = mcm_shadow_mask(sentinel2, clouds)\n",
    "        print(\"The files have been loaded\")\n",
    "\n",
    "        #sentinel1 = process_sentinel_1_tile(sentinel1, radar_dates)\n",
    "        to_remove = calculate_bad_steps(sentinel2, clouds)\n",
    "        sentinel2 = np.delete(sentinel2, to_remove, axis = 0)\n",
    "        clouds = np.delete(clouds, to_remove, axis = 0)\n",
    "        shadows = np.delete(shadows, to_remove, axis = 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        print(\"Cloudy and missing images removed, radar processed\")\n",
    "\n",
    "        to_remove = remove_missed_clouds(sentinel2)\n",
    "        sentinel2 = np.delete(sentinel2, to_remove, axis = 0)\n",
    "        clouds = np.delete(clouds, to_remove, axis = 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        shadows = np.delete(shadows, to_remove, axis = 0)\n",
    "        print(\"Missed cloudy images removed\")\n",
    "\n",
    "        x, _, _ = remove_cloud_and_shadows(sentinel2, clouds, shadows, image_dates)\n",
    "        print(\"Clouds and shadows interpolated\")\n",
    "\n",
    "        index = 0\n",
    "        for start_x, end_x in zip(range(0, 633, 126), range(128, 633, 126)):\n",
    "            for start_y, end_y in zip(range(0, 633, 126), range(128, 633, 126)):\n",
    "                print(index)\n",
    "                if not os.path.exists(folder + \"processed/{}/{}.hkl\".format(str(y_vals[index]), str(x_vals[index]))):\n",
    "                    subtile = x[:, start_x:end_x, start_y:end_y, :]\n",
    "                    resolved = superresolve(subtile)\n",
    "                    subtile[:, :, :, 4:10] = resolved\n",
    "                    \n",
    "                    dem_i = np.tile(dem[np.newaxis, start_x:end_x, start_y:end_y, :], (x.shape[0], 1, 1, 1))\n",
    "                    subtile = np.concatenate([subtile, dem_i / 90], axis = -1)\n",
    "                    t2 = timer()\n",
    "                    subtile, amin = evi(subtile, verbose = True)\n",
    "                    subtile = bi(subtile, verbose = True)\n",
    "                    subtile = msavi2(subtile, verbose = True)\n",
    "                    subtile = si(subtile, verbose = True)\n",
    "                    t3 = timer()\n",
    "                    print(\"Indices: {}\".format(t3 - t2))\n",
    "\n",
    "                    subtile = calculate_and_save_best_images(subtile, image_dates)\n",
    "                    subtile = interpolate_array_master(subtile)\n",
    "                    t5 = timer()\n",
    "                    print(\"Interpolate: {}\".format(t5 - t3))\n",
    "                    subtile = np.concatenate([subtile, sentinel1[:, start_x:end_x,\n",
    "                                                                start_y:end_y, :]], axis = -1)\n",
    "                    \n",
    "\n",
    "                    out_y_folder = folder + \"processed/{}/\".format(str(y_vals[index]))\n",
    "                    if not os.path.exists(os.path.realpath(out_y_folder)):\n",
    "                        os.makedirs(os.path.realpath(out_y_folder))\n",
    "                    sleep(2)\n",
    "                    hkl.dump(subtile,\n",
    "                             folder + \"processed/{}/{}.hkl\".format(str(y_vals[index]), str(x_vals[index])),\n",
    "                             mode='w', compression='gzip')\n",
    "                    #np.save(folder + \"processed/{}/{}.npy\".format(str(y_vals[index]), str(x_vals[index])), subtile)\n",
    "                index += 1\n",
    "            \n",
    "def clean_up_folders():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3969\n"
     ]
    }
   ],
   "source": [
    "coord1 = offset_x(coords, 6300)\n",
    "coord1 = offset_y(coord1 , 6300)\n",
    "calculate_area([coords, coord1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 0 Y:6\n",
      "Downloaded 1\n",
      "6_0\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 0 Y:7\n",
      "Downloaded 2\n",
      "7_0\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 0 Y:8\n",
      "Downloaded 3\n",
      "8_0\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 0 Y:9\n",
      "Downloaded 4\n",
      "9_0\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 0 Y:10\n",
      "Downloaded 5\n",
      "10_0\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 0 Y:11\n",
      "Downloaded 6\n",
      "11_0\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 1 Y:6\n",
      "Downloaded 7\n",
      "6_1\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 1 Y:7\n",
      "Downloaded 8\n",
      "7_1\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 1 Y:8\n",
      "Downloaded 9\n",
      "8_1\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 1 Y:9\n",
      "Downloaded 10\n",
      "9_1\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 1 Y:10\n",
      "Downloaded 11\n",
      "10_1\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 1 Y:11\n",
      "Downloaded 12\n",
      "11_1\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 1 Y:12\n",
      "Downloaded 13\n",
      "12_1\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 2 Y:4\n",
      "Downloaded 14\n",
      "4_2\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 2 Y:5\n",
      "Downloaded 15\n",
      "5_2\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 2 Y:6\n",
      "Downloaded 16\n",
      "6_2\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 2 Y:7\n",
      "Downloaded 17\n",
      "7_2\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 2 Y:8\n",
      "Downloaded 18\n",
      "8_2\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 2 Y:9\n",
      "Downloaded 19\n",
      "9_2\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 2 Y:10\n",
      "Downloaded 20\n",
      "10_2\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 2 Y:11\n",
      "Downloaded 21\n",
      "11_2\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 2 Y:12\n",
      "Downloaded 22\n",
      "12_2\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:3\n",
      "Downloaded 23\n",
      "3_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:4\n",
      "Downloaded 24\n",
      "4_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:5\n",
      "Downloaded 25\n",
      "5_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:6\n",
      "Downloaded 26\n",
      "6_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:7\n",
      "Downloaded 27\n",
      "7_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:8\n",
      "Downloaded 28\n",
      "8_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:9\n",
      "Downloaded 29\n",
      "9_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:10\n",
      "Downloaded 30\n",
      "10_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:11\n",
      "Downloaded 31\n",
      "11_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 3 Y:12\n",
      "Downloaded 32\n",
      "12_3\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:2\n",
      "Downloaded 33\n",
      "2_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:3\n",
      "Downloaded 34\n",
      "3_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:4\n",
      "Downloaded 35\n",
      "4_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:5\n",
      "Downloaded 36\n",
      "5_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:6\n",
      "Downloaded 37\n",
      "6_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:7\n",
      "Downloaded 38\n",
      "7_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:8\n",
      "Downloaded 39\n",
      "8_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:9\n",
      "Downloaded 40\n",
      "9_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:10\n",
      "Downloaded 41\n",
      "10_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:11\n",
      "Downloaded 42\n",
      "11_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 4 Y:12\n",
      "Downloaded 43\n",
      "12_4\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:1\n",
      "Downloaded 44\n",
      "1_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:2\n",
      "Downloaded 45\n",
      "2_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:3\n",
      "Downloaded 46\n",
      "3_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:4\n",
      "Downloaded 47\n",
      "4_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:5\n",
      "Downloaded 48\n",
      "5_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:6\n",
      "Downloaded 49\n",
      "6_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:7\n",
      "Downloaded 50\n",
      "7_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:8\n",
      "Downloaded 51\n",
      "8_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:9\n",
      "Downloaded 52\n",
      "9_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:10\n",
      "Downloaded 53\n",
      "10_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 5 Y:11\n",
      "Downloaded 54\n",
      "11_5\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 6 Y:1\n",
      "Downloaded 55\n",
      "1_6\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 6 Y:2\n",
      "Downloaded 56\n",
      "2_6\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 6 Y:3\n",
      "Downloaded 57\n",
      "3_6\n",
      "Calculating cloud cover\n",
      "\n",
      "\n",
      "X: 6 Y:4\n",
      "Downloaded 58\n",
      "4_6\n",
      "Calculating cloud cover\n",
      "Cloud_probs shape: (54, 632, 632)\n",
      "Shadows_shape: (54, 632, 632, 3)\n",
      "65535\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0f4f11a9b54cdca2568720c4919aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d21a59f8c9d4f90a582b0bd42821e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cloud probs: (54, 632, 632)\n",
      "Downloading S1\n",
      "Loading formatted geocoded file...\n",
      "NA\n",
      "SENT_DESC\n",
      "Maximum time distance: 0\n",
      "Downloading S2\n",
      "Downloading L2A 20m layer\n",
      "Original 20 meter bands size: (54, 627, 639, 6)\n",
      "Downloading L2A 10m layer\n",
      "Original 10 meter bands size: (54, 627, 639, 4)\n",
      "Downloading DEM\n",
      "The files have been loaded\n",
      "Cloudy and missing images removed, radar processed\n",
      "Missed cloudy images removed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faea34cb829a4910b8d8be98515e2fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=314), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A total of 114908 pixels were interpolated\n",
      "Clouds and shadows interpolated\n",
      "0\n",
      "14/14 [==============================] - 9s 654ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.17543517000012798\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.355052962997433\n",
      "1\n",
      "14/14 [==============================] - 9s 637ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.13022384199939552\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.682074887001363\n",
      "2\n",
      "14/14 [==============================] - 9s 678ms/step\n",
      "There are: 3 out of bounds EVI\n",
      "Indices: 0.14015607799956342\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.894170686999132\n",
      "3\n",
      "14/14 [==============================] - 9s 641ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.12743489100103034\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.416753993002203\n",
      "4\n",
      "14/14 [==============================] - 9s 662ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.1291959729969676\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.71248386300067\n",
      "5\n",
      "14/14 [==============================] - 9s 656ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.13021905999994488\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.890205033996608\n",
      "6\n",
      "14/14 [==============================] - 9s 666ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.12822587999835378\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.406043609000335\n",
      "7\n",
      "14/14 [==============================] - 9s 658ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.14651162699738052\n",
      "Maximum time distance: 75\n",
      "Interpolate: 10.309791953000968\n",
      "8\n",
      "14/14 [==============================] - 9s 658ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.1346608180028852\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.225431554998067\n",
      "9\n",
      "14/14 [==============================] - 9s 662ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.13521982399834087\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.651441048001288\n",
      "10\n",
      "14/14 [==============================] - 9s 668ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.12679785300133517\n",
      "Maximum time distance: 75\n",
      "Interpolate: 10.079857934000756\n",
      "11\n",
      "14/14 [==============================] - 9s 668ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.14194204199884553\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.751611727002455\n",
      "12\n",
      "14/14 [==============================] - 9s 631ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.1367374209985428\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.94000583000161\n",
      "13\n",
      "14/14 [==============================] - 9s 655ms/step\n",
      "There are: 13 out of bounds EVI\n",
      "Indices: 0.13920570900154416\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.77937557399855\n",
      "14\n",
      "14/14 [==============================] - 9s 618ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.1308407070027897\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.552464925996901\n",
      "15\n",
      "14/14 [==============================] - 9s 628ms/step\n",
      "There are: 35 out of bounds EVI\n",
      "Indices: 0.17106115999922622\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.780040973000723\n",
      "16\n",
      "14/14 [==============================] - 8s 605ms/step\n",
      "There are: 10 out of bounds EVI\n",
      "Indices: 0.12971294399903854\n",
      "Maximum time distance: 75\n",
      "Interpolate: 9.686063688001013\n",
      "17\n",
      "14/14 [==============================] - 9s 656ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.1189422370007378\n",
      "Maximum time distance: 75\n",
      "Interpolate: 7.4811319450018345\n",
      "18\n",
      "14/14 [==============================] - 7s 508ms/step\n",
      "There are: 56 out of bounds EVI\n",
      "Indices: 0.11697307899885345\n",
      "Maximum time distance: 75\n",
      "Interpolate: 7.550247536000825\n",
      "19\n",
      "14/14 [==============================] - 7s 500ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.11486753399731242\n",
      "Maximum time distance: 75\n",
      "Interpolate: 7.256972090999625\n",
      "20\n",
      "14/14 [==============================] - 7s 505ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.11241508199964301\n",
      "Maximum time distance: 75\n",
      "Interpolate: 7.279008402001637\n",
      "21\n",
      "14/14 [==============================] - 7s 500ms/step\n",
      "There are: 3 out of bounds EVI\n",
      "Indices: 0.11586715900193667\n",
      "Maximum time distance: 75\n",
      "Interpolate: 7.185989525998593\n",
      "22\n",
      "14/14 [==============================] - 7s 513ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.11221899500014842\n",
      "Maximum time distance: 75\n",
      "Interpolate: 7.471697214001324\n",
      "23\n",
      "14/14 [==============================] - 7s 503ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.11716102499849512\n",
      "Maximum time distance: 75\n",
      "Interpolate: 7.248111750999669\n",
      "24\n",
      "14/14 [==============================] - 7s 507ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.11601876599888783\n",
      "Maximum time distance: 75\n",
      "Interpolate: 7.383550275000744\n",
      "\n",
      "\n",
      "X: 6 Y:5\n",
      "Downloaded 59\n",
      "5_6\n",
      "Calculating cloud cover\n",
      "Cloud_probs shape: (54, 632, 632)\n",
      "Shadows_shape: (54, 632, 632, 3)\n",
      "65535\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701262c409fb403689d04340b8a0be49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845368611a3441d3b2e9fcd0aa1522b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cloud probs: (54, 632, 632)\n",
      "Downloading S1\n",
      "NA\n",
      "SENT_DESC\n",
      "Maximum time distance: 0\n",
      "Downloading S2\n",
      "Downloading L2A 20m layer\n",
      "Original 20 meter bands size: (54, 627, 639, 6)\n",
      "Downloading L2A 10m layer\n",
      "Original 10 meter bands size: (54, 627, 639, 4)\n",
      "Downloading DEM\n",
      "The files have been loaded\n",
      "Cloudy and missing images removed, radar processed\n",
      "Missed cloudy images removed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cdac0393e2401c859bf47feeea9737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=314), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A total of 135908 pixels were interpolated\n",
      "Clouds and shadows interpolated\n",
      "0\n",
      "18/18 [==============================] - 11s 600ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.17408046099808416\n",
      "Maximum time distance: 45\n",
      "Interpolate: 8.275531731000228\n",
      "1\n",
      "18/18 [==============================] - 11s 614ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.12362675399708678\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.958466318999854\n",
      "2\n",
      "18/18 [==============================] - 11s 591ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.11549525999726029\n",
      "Maximum time distance: 45\n",
      "Interpolate: 8.051151643001504\n",
      "3\n",
      "18/18 [==============================] - 11s 595ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.13018270199972903\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.4399353220032935\n",
      "4\n",
      "18/18 [==============================] - 10s 551ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.11897216099896468\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.40272186799848\n",
      "5\n",
      "18/18 [==============================] - 11s 601ms/step\n",
      "There are: 3 out of bounds EVI\n",
      "Indices: 0.1378372280014446\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.717715883998608\n",
      "6\n",
      "18/18 [==============================] - 11s 612ms/step\n",
      "There are: 3 out of bounds EVI\n",
      "Indices: 0.13792688099783845\n",
      "Maximum time distance: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/Documents/GitHub/restoration-mapper/src/utils/utils-bilinear.py:90: RuntimeWarning: invalid value encountered in power\n",
      "  sis = np.power( (1-BLUE) * (1 - GREEN) * (1 - RED), 1/3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolate: 7.342348281999875\n",
      "7\n",
      "18/18 [==============================] - 10s 566ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.11830411499977345\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.241058103998512\n",
      "8\n",
      "18/18 [==============================] - 10s 556ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.12725506400238373\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.327655840999796\n",
      "9\n",
      "18/18 [==============================] - 10s 555ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.12173402700136648\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.381595749000553\n",
      "10\n",
      "18/18 [==============================] - 11s 600ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.13808470300136833\n",
      "Maximum time distance: 45\n",
      "Interpolate: 8.050090711996745\n",
      "11\n",
      "18/18 [==============================] - 10s 581ms/step\n",
      "There are: 1 out of bounds EVI\n",
      "Indices: 0.13296559899754357\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.602878527002758\n",
      "12\n",
      "18/18 [==============================] - 11s 605ms/step\n",
      "There are: 1 out of bounds EVI\n",
      "Indices: 0.13988642199910828\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.516298463000567\n",
      "13\n",
      "18/18 [==============================] - 12s 643ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.12763109400111716\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.8918900360004045\n",
      "14\n",
      "18/18 [==============================] - 11s 622ms/step\n",
      "There are: 1 out of bounds EVI\n",
      "Indices: 0.13395229500019923\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.767619143000047\n",
      "15\n",
      "18/18 [==============================] - 11s 585ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.12872770000103628\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.5421642159999465\n",
      "16\n",
      "18/18 [==============================] - 10s 567ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.13127480399998603\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.6402938709979935\n",
      "17\n",
      "18/18 [==============================] - 11s 603ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.14050069500081008\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.756865052000649\n",
      "18\n",
      "18/18 [==============================] - 10s 573ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.12757169000178692\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.904910213997937\n",
      "19\n",
      "18/18 [==============================] - 11s 630ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.13342739300060202\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.325111616999493\n",
      "20\n",
      "18/18 [==============================] - 11s 596ms/step\n",
      "There are: 1 out of bounds EVI\n",
      "Indices: 0.13205660799940233\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.619024278999859\n",
      "21\n",
      "18/18 [==============================] - 11s 592ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.11939128000085475\n",
      "Maximum time distance: 45\n",
      "Interpolate: 8.280932985999243\n",
      "22\n",
      "18/18 [==============================] - 10s 568ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.13138696199894184\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.633520176001184\n",
      "23\n",
      "18/18 [==============================] - 11s 611ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.15211744000043836\n",
      "Maximum time distance: 45\n",
      "Interpolate: 8.074238459998014\n",
      "24\n",
      "18/18 [==============================] - 11s 584ms/step\n",
      "There are: 1 out of bounds EVI\n",
      "Indices: 0.1434164519996557\n",
      "Maximum time distance: 45\n",
      "Interpolate: 7.893396684998152\n",
      "\n",
      "\n",
      "X: 6 Y:6\n",
      "Downloaded 60\n",
      "6_6\n",
      "Calculating cloud cover\n",
      "Cloud_probs shape: (54, 632, 632)\n",
      "Shadows_shape: (54, 632, 632, 3)\n",
      "65535\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0f6ad4d3ba4cadbac5741c60d0386c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55ce8c1f1324f8c8e30cf5c96b7ca1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cloud probs: (54, 632, 632)\n",
      "Downloading S1\n",
      "NA\n",
      "SENT_DESC\n",
      "Maximum time distance: 0\n",
      "Downloading S2\n",
      "Downloading L2A 20m layer\n",
      "Original 20 meter bands size: (54, 627, 639, 6)\n",
      "Downloading L2A 10m layer\n",
      "Original 10 meter bands size: (54, 627, 639, 4)\n",
      "Downloading DEM\n",
      "The files have been loaded\n",
      "Cloudy and missing images removed, radar processed\n",
      "Missed cloudy images removed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1295f61fc22b4852ac4bfe353534c744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=314), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A total of 452197 pixels were interpolated\n",
      "Clouds and shadows interpolated\n",
      "0\n",
      "27/27 [==============================] - 16s 588ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.13769441899785306\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.6622492330025125\n",
      "1\n",
      "27/27 [==============================] - 16s 593ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.15258280299894977\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.989470249998703\n",
      "2\n",
      "27/27 [==============================] - 16s 576ms/step\n",
      "There are: 1 out of bounds EVI\n",
      "Indices: 0.15543416800210252\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.550438866997865\n",
      "3\n",
      "27/27 [==============================] - 16s 584ms/step\n",
      "There are: 3 out of bounds EVI\n",
      "Indices: 0.18885002699971665\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.663007057002687\n",
      "4\n",
      "27/27 [==============================] - 15s 556ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.1486846699990565\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.971395996002684\n",
      "5\n",
      "27/27 [==============================] - 17s 633ms/step\n",
      "There are: 8 out of bounds EVI\n",
      "Indices: 0.1964485889984644\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.918712177000998\n",
      "6\n",
      "27/27 [==============================] - 16s 593ms/step\n",
      "There are: 1 out of bounds EVI\n",
      "Indices: 0.1595014570011699\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.708063523998135\n",
      "7\n",
      "27/27 [==============================] - 17s 616ms/step\n",
      "There are: 4 out of bounds EVI\n",
      "Indices: 0.1910377799977141\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.736875660000806\n",
      "8\n",
      "27/27 [==============================] - 16s 595ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.15531148100126302\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.67831808900155\n",
      "9\n",
      "27/27 [==============================] - 16s 595ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.16941246499845874\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.678379238001071\n",
      "10\n",
      "27/27 [==============================] - 16s 593ms/step\n",
      "There are: 4 out of bounds EVI\n",
      "Indices: 0.1607363049988635\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.750707705999957\n",
      "11\n",
      "27/27 [==============================] - 18s 679ms/step\n",
      "There are: 42 out of bounds EVI\n",
      "Indices: 0.19443415200294112\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.91679637299967\n",
      "12\n",
      "27/27 [==============================] - 17s 624ms/step\n",
      "There are: 1 out of bounds EVI\n",
      "Indices: 0.1667478529998334\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.330300909998186\n",
      "13\n",
      "27/27 [==============================] - 17s 642ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.18072170699815615\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.391314782002155\n",
      "14\n",
      "27/27 [==============================] - 18s 658ms/step\n",
      "There are: 0 out of bounds EVI\n",
      "Indices: 0.168764256999566\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.682979029999842\n",
      "15\n",
      "27/27 [==============================] - 17s 621ms/step\n",
      "There are: 34 out of bounds EVI\n",
      "Indices: 0.16461945999981253\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.166178953000781\n",
      "16\n",
      "27/27 [==============================] - 17s 633ms/step\n",
      "There are: 40 out of bounds EVI\n",
      "Indices: 0.18559763300072518\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.995935087998078\n",
      "17\n",
      "27/27 [==============================] - 17s 647ms/step\n",
      "There are: 55 out of bounds EVI\n",
      "Indices: 0.18730462199891917\n",
      "Maximum time distance: 35\n",
      "Interpolate: 7.7432804759991996\n",
      "18\n",
      "27/27 [==============================] - 17s 623ms/step\n",
      "There are: 9 out of bounds EVI\n",
      "Indices: 0.18320624899934046\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.04963732500255\n",
      "19\n",
      "27/27 [==============================] - 17s 623ms/step\n",
      "There are: 48 out of bounds EVI\n",
      "Indices: 0.18045568899833597\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.11092315499991\n",
      "20\n",
      "27/27 [==============================] - 17s 623ms/step\n",
      "There are: 82 out of bounds EVI\n",
      "Indices: 0.16833272199801286\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.085130949999439\n",
      "21\n",
      "27/27 [==============================] - 17s 618ms/step\n",
      "There are: 14 out of bounds EVI\n",
      "Indices: 0.17546824499731883\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.405495161001454\n",
      "22\n",
      "27/27 [==============================] - 17s 645ms/step\n",
      "There are: 1 out of bounds EVI\n",
      "Indices: 0.1671090820018435\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.274224296998\n",
      "23\n",
      "27/27 [==============================] - 17s 647ms/step\n",
      "There are: 2 out of bounds EVI\n",
      "Indices: 0.168458093998197\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.615834847998485\n",
      "24\n",
      "27/27 [==============================] - 18s 651ms/step\n",
      "There are: 37 out of bounds EVI\n",
      "Indices: 0.1637046130017552\n",
      "Maximum time distance: 35\n",
      "Interpolate: 8.417140328998357\n",
      "\n",
      "\n",
      "X: 6 Y:7\n",
      "Downloaded 61\n",
      "7_6\n",
      "Calculating cloud cover\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bf6cdb84c5b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mdownloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloaded {downloaded}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mdownload_large_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_tile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mprocess_large_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-a3baef0a3c16>\u001b[0m in \u001b[0;36mdownload_large_tile\u001b[0;34m(coord, step_x, step_y, folder, year, s1_layer)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"processed/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".hkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"raw/clouds/clouds_{}.hkl\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0ml1c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloud_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentify_clouds_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"raw/clouds/clouds_{}.hkl\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshadows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"raw/clouds/shadows_{}.hkl\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-616126589e1e>\u001b[0m in \u001b[0;36midentify_clouds_new\u001b[0;34m(bbox, epsg, dates)\u001b[0m\n\u001b[1;32m     30\u001b[0m         time_difference=datetime.timedelta(hours=48))\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mcloud_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloud_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mcloud_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcloud_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloud_img\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sentinelhub/data_request.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, save_data, data_filter, redownload, max_threads, raise_download_errors)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_data_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_download_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_saved_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_download_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sentinelhub/data_request.py\u001b[0m in \u001b[0;36m_execute_data_download\u001b[0;34m(self, data_filter, redownload, max_threads, raise_download_errors)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_download_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSHConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_timeout_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sentinelhub/download.py\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m(request_list, redownload, max_threads)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_threads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_download_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequest_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "downloaded = 0\n",
    "for x_tile in range(0, 15):\n",
    "    for y_tile in range(0, 15):\n",
    "        contains = check_contains(coords, x_tile, y_tile)\n",
    "        if contains:\n",
    "            print(\"X: {} Y:{}\".format(x_tile, y_tile))\n",
    "            downloaded += 1\n",
    "            print(f\"Downloaded {downloaded}\")\n",
    "            download_large_tile(coord = coords, step_x = x_tile, step_y = y_tile)\n",
    "            process_large_tile(coords, x_tile, y_tile)\n",
    "            print(\"\\n\")\n",
    "            #clean_up_folders(x_tile, y_tile)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
