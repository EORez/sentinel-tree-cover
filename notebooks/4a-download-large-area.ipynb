{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This Jupyter notebook downloads and preprocesses Sentinel 1 and 2 tiles for large areas (at least 40 sq km). The workflow entails generating the tile coordinates, downloading the raw data, and processing (cloud and shadow removal, gap interpolation, indices, and superresolution).\n",
    "\n",
    "The notebook is broken down into the following sections:\n",
    "\n",
    "   * **Parameter definition**:\n",
    "   * **Projection functions**\n",
    "   * **Data download functions**\n",
    "   * **Cloud and shadow removal functions**\n",
    "   * **Superresoluttion functions**\n",
    "   * **Tile and folder management functions**\n",
    "   * **Function execution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are planning to download new Sentinel data, you need to have an API key to use the data provider [Sentinel Hub](https://www.sentinel-hub.com). If you do not have an API key but have access to sentinel imagery, the input data for this notebook is an entire year of:\n",
    "  * Cloud masks\n",
    "  * L1C bands 2, 8A, 11\n",
    "  * 10- and 20m L2A bands\n",
    "  * VV-VH Sentinel 1 bands\n",
    "  * Digital elevation model\n",
    "  \n",
    "  \n",
    "The data are tiled into 6300m x 6300m windows. An example of the raw data can be downloaded by running the following cell. This data can be preprocessed (cloud interpolation, super resolution, smoothing, etcetera) by running the rest of the notebook. It can then also be predicted by running `4b-predict-large-area`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using example raw data\n",
    "import os\n",
    "if not os.path.exists(\"../data/example/raw\"):\n",
    "    os.makedirs(\"../data/example/raw/\")\n",
    "    \n",
    "landscape = 'example'\n",
    "OUTPUT_FOLDER = '../data/{}/'.format(landscape)\n",
    "coords = (13.727334, -90.015579)\n",
    "coords = (coords[1], coords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      " 71  374M   71  266M    0     0  7524k      0  0:00:50  0:00:36  0:00:14 8022k^C\n",
      "Archive:  ../data/example/raw/data.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of ../data/example/raw/data.zip or\n",
      "        ../data/example/raw/data.zip.zip, and cannot find ../data/example/raw/data.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "# Download example raw data - only if you don't have an API key!\n",
    "!curl https://restoration-monitoring-external.s3.amazonaws.com/restoration-mapper/example/example.zip \\\n",
    "    -o ../data/example/raw/data.zip\n",
    "!unzip ../data/example/raw/data.zip -d ../data/example/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "from sentinelhub import DataSource\n",
    "import scipy.sparse as sparse\n",
    "import scipy\n",
    "from scipy.sparse.linalg import splu\n",
    "from skimage.transform import resize\n",
    "from sentinelhub import CustomUrlParam\n",
    "from time import time as timer\n",
    "from time import sleep as sleep\n",
    "import multiprocessing\n",
    "import math\n",
    "import reverse_geocoder as rg\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "import hickle as hkl\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import math\n",
    "import boto3\n",
    "from pyproj import Proj, transform\n",
    "from timeit import default_timer as timer\n",
    "from typing import Tuple, List\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../config.yaml\"):\n",
    "    with open(\"../config.yaml\", 'r') as stream:\n",
    "        key = (yaml.safe_load(stream))\n",
    "        API_KEY = key['key']\n",
    "        AWSKEY = key['awskey']\n",
    "        AWSSECRET = key['awssecret']\n",
    "else:\n",
    "    API_KEY = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/preprocessing/slope.py\n",
    "%run ../src/preprocessing/indices.py\n",
    "%run ../src/downloading/utils.py\n",
    "%run ../src/preprocessing/cloud_removal.py\n",
    "%run ../src/preprocessing/whittaker_smoother.py\n",
    "%run ../src/dsen2/utils/DSen2Net.py\n",
    "%run ../src/io/upload.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Constants and Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the only years that can be downloaded from Sentinel Hub are 2018 and 2019. 2017 has an ETA of Summer 2020.\n",
    "\n",
    "The `landscapes` dictionary has a key, value convention of the landscape name, and a `(lat, long)` tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "landscape = 'kenya-makueni'\n",
    "\n",
    "if year > 2017:\n",
    "    dates = (f'{str(year - 1)}-12-01' , f'{str(year + 1)}-02-01')\n",
    "else: \n",
    "    dates = (f'{str(year)}-01-01' , f'{str(year + 1)}-02-01')\n",
    "dates_sentinel_1 = (f'{str(year)}-01-01' , f'{str(year)}-12-31')\n",
    "SIZE = 9*5\n",
    "IMSIZE = (7*2) + (SIZE * 14)+2\n",
    "\n",
    "days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "starting_days = np.cumsum(days_per_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37.11402, -3.08768) ../project-monitoring//kenya/makueni/mtito-andei/2019/\n"
     ]
    }
   ],
   "source": [
    "database = pd.read_csv(\"../project-monitoring/database.csv\")\n",
    "coords = database[database['landscape'] == landscape]\n",
    "path = coords['path'].tolist()[0]\n",
    "coords = (float(coords['longitude']), float(coords['latitude']))\n",
    "\n",
    "IO_PARAMS = {'prefix': '../',\n",
    "             'bucket': 'restoration-monitoring',\n",
    "             'coords': coords,\n",
    "             'bucket-prefix': '',\n",
    "             'path': path}\n",
    "\n",
    "OUTPUT_FOLDER = IO_PARAMS['prefix'] + IO_PARAMS['path'] + str(year) + '/'\n",
    "print(coords, OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploader = FileUploader(awskey = AWSKEY, awssecret = AWSSECRET)\n",
    "#file = '../tile_data/processed/data_x_l2a_processed.hkl'\n",
    "#key = get_folder_prefix(coordinates) + '2018/raw/s2/0_0.hkl'\n",
    "#key = 'restoration-mapper/model-data/global/data_x_l2a_processed.hkl'\n",
    "#uploader.upload(bucket = 'restoration-monitoring', key = key, file = file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_append = pd.DataFrame({'landscape': ['kenya-makueni-3'], \n",
    "                             'latitude': ['-2.657604'],\n",
    "                             'longitude': ['38.044953'],\n",
    "                             'path': [get_folder_prefix((-2.657604, 38.044953),\n",
    "                                                        params = {'bucket-prefix': 'project-monitoring/'})]})\n",
    "database = database.append([to_append])\n",
    "database.to_csv(\"../project-monitoring/database.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Projection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pts_in_geojson(lats: List[float], longs: List[float], geojson: 'geojson') -> bool:  \n",
    "    \"\"\" Identifies whether candidate download tile is within an input geojson\n",
    "        \n",
    "        Parameters:\n",
    "         lats (list): list of latitudes\n",
    "         longs (list): list of longitudes\n",
    "         geojson (float): path to input geojson\n",
    "    \n",
    "        Returns:\n",
    "         bool \n",
    "    \"\"\"\n",
    "    polys = geopandas.read_file(geojson)['geometry']\n",
    "    polys = geopandas.GeoSeries(polys)\n",
    "    pnts = [Point(x, y) for x, y in zip(list(lats), list(longs))]\n",
    "    \n",
    "    def _contains(pt):\n",
    "        return polys.contains(pt)[0]\n",
    "\n",
    "    if any([_contains(pt) for pt in pnts]):\n",
    "        return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Data download functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using Sentinel hub, identify the following layers:\n",
    "  * CLOUD: return [CLP / 255]\n",
    "  * SHADOW: return [B02, B8A, B11]\n",
    "  * DEM: return [DEM]\n",
    "  * SENT: return [VV, VH]\n",
    "  * L2A10: return [B02,B03,B04, B08]\n",
    "  * L2A20: return [B05,B06,B07, B8A,B11,B12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_clouds(bbox: List[Tuple[float, float]],\n",
    "                        epsg: 'CRS', dates: dict = dates) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "    \"\"\" Downloads and calculates cloud cover and shadow\n",
    "        \n",
    "        Parameters:\n",
    "         bbox (list): output of calc_bbox\n",
    "         epsg (float): EPSG associated with bbox \n",
    "         dates (tuple): YY-MM-DD - YY-MM-DD bounds for downloading \n",
    "    \n",
    "        Returns:\n",
    "         cloud_img (np.array):\n",
    "         shadows (np.array): \n",
    "         clean_steps (np.array):\n",
    "    \"\"\"\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    cloud_request = WcsRequest(\n",
    "        layer='CLOUD_NEW',\n",
    "        bbox=box,\n",
    "        time=dates,\n",
    "        resx='160m', \n",
    "        resy='160m',\n",
    "        image_format = MimeType.TIFF_d8,\n",
    "        maxcc=0.7,\n",
    "        instance_id=API_KEY,\n",
    "        custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "        time_difference=datetime.timedelta(hours=72),\n",
    "    )\n",
    "\n",
    "    shadow_request = WcsRequest(\n",
    "        layer='SHADOW',\n",
    "        bbox=box,\n",
    "        time=dates,\n",
    "        resx='20m',\n",
    "        resy='20m',\n",
    "        image_format =  MimeType.TIFF_d16,\n",
    "        maxcc=0.7,\n",
    "        instance_id=API_KEY,\n",
    "        custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "        time_difference=datetime.timedelta(hours=72))\n",
    "\n",
    "    cloud_img = np.array(cloud_request.get_data())\n",
    "    \n",
    "    if np.max(cloud_img > 10):\n",
    "        cloud_img = cloud_img / 255\n",
    "        \n",
    "    assert np.max(cloud_img) <= 1., f'The max cloud probability is {np.max(cloud_img)}'\n",
    "    c_probs_pus = ((40*40)/(512*512)) *(1/3)*cloud_img.shape[0]\n",
    "    print(f\"Cloud_probs used {round(c_probs_pus, 1)} processing units\")\n",
    "    \n",
    "    cloud_img = resize(cloud_img, (cloud_img.shape[0], IMSIZE, IMSIZE), order = 0)\n",
    "    cloud_img_flat = cloud_img.reshape(cloud_img.shape[0], cloud_img.shape[1]*cloud_img.shape[2])\n",
    "    n_cloud_px = np.sum(cloud_img_flat > 0.30, axis = 1)\n",
    "    print(np.around(n_cloud_px / IMSIZE**2, 2))\n",
    "    cloud_steps = np.argwhere(n_cloud_px > IMSIZE**2 / 20)\n",
    "    clean_steps = [x for x in range(cloud_img.shape[0]) if x not in cloud_steps]\n",
    "    shadow_img = shadow_request.get_data(data_filter = clean_steps)\n",
    "    shadow_img = np.array(shadow_img)\n",
    "    shadow_pus = (shadow_img.shape[1]*shadow_img.shape[2])/(512*512) * shadow_img.shape[0]\n",
    "    shadow_img = resize(shadow_img, (shadow_img.shape[0], IMSIZE, IMSIZE, shadow_img.shape[-1]), order = 0)\n",
    "    \n",
    "    if np.max(shadow_img > 10):\n",
    "        print(f\"The max shadows is {np.max(shadow_img)}\")\n",
    "        shadow_img = shadow_img / 65535\n",
    " \n",
    "    cloud_img = np.delete(cloud_img, cloud_steps, 0)\n",
    "    shadows = mcm_shadow_mask(np.array(shadow_img), cloud_img) # Make usre this makes sense??\n",
    "    print(f\"Shadows ({shadows.shape}) used {round(shadow_pus, 1)} processing units\")\n",
    "    return cloud_img, shadows, clean_steps\n",
    "    \n",
    "def download_dem(bbox: List[Tuple[float, float]], epsg: 'CRS') -> np.ndarray:\n",
    "    \"\"\" Downloads the DEM layer from Sentinel hub\n",
    "        \n",
    "        Parameters:\n",
    "         bbox (list): output of calc_bbox\n",
    "         epsg (float): EPSG associated with bbox \n",
    "    \n",
    "        Returns:\n",
    "         dem_image (arr):\n",
    "    \"\"\"\n",
    "\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_s = (630)+4+8+8\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=dem_s,\n",
    "                         height=dem_s,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, dem_s, dem_s)),\n",
    "                  np.full((dem_s, dem_s), 10), np.full((dem_s, dem_s), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((dem_s,dem_s, 1))\n",
    "    dem_image = dem_image[1:dem_s-1, 1:dem_s-1, :]\n",
    "    print(f\"DEM used {round(((IMSIZE*IMSIZE)/(512*512))*2, 1)} processing units\")\n",
    "    return dem_image\n",
    " \n",
    "\n",
    "def download_layer(bbox: List[Tuple[float, float]],\n",
    "                   clean_steps: np.ndarray, epsg: 'CRS',\n",
    "                   dates: dict = dates, year: int = year) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\" Downloads the L2A sentinel layer with 10 and 20 meter bands\n",
    "        \n",
    "        Parameters:\n",
    "         bbox (list): output of calc_bbox\n",
    "         clean_steps (list): list of steps to filter download request\n",
    "         epsg (float): EPSG associated with bbox \n",
    "         time (tuple): YY-MM-DD - YY-MM-DD bounds for downloading \n",
    "    \n",
    "        Returns:\n",
    "         img (arr):\n",
    "         img_request (obj): \n",
    "    \"\"\"\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    image_request = WcsRequest(\n",
    "            layer='L2A20',\n",
    "            bbox=box,\n",
    "            time=dates,\n",
    "            image_format = MimeType.TIFF_d16,\n",
    "            maxcc=0.7,\n",
    "            resx='20m', resy='20m',\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=72),\n",
    "        )\n",
    "    img_bands = image_request.get_data(data_filter = clean_steps)\n",
    "    img_20 = np.stack(img_bands).astype(np.float32)\n",
    "    if np.max(img_20) >= 10:\n",
    "        img_20 = img_20 / 65535\n",
    "    assert np.max(img_20) <= 2.\n",
    "    \n",
    "    s2_20_usage = (img_20.shape[1]*img_20.shape[2])/(512*512) * (6/3) * img_20.shape[0]\n",
    "    print(f\"Original 20 meter bands size: {img_20.shape}, using {round(s2_20_usage, 1)} PU\")\n",
    "    img_20 = resize(img_20, (img_20.shape[0], IMSIZE, IMSIZE, img_20.shape[-1]), order = 0)\n",
    "\n",
    "    image_request = WcsRequest(\n",
    "            layer='L2A10',\n",
    "            bbox=box,\n",
    "            time=dates,\n",
    "            image_format = MimeType.TIFF_d16,\n",
    "            maxcc=0.7,\n",
    "            resx='10m', resy='10m',\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'BICUBIC',\n",
    "                                constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "            time_difference=datetime.timedelta(hours=72),\n",
    "    )\n",
    "    \n",
    "    img_bands = image_request.get_data(data_filter = clean_steps)\n",
    "    img_10 = np.stack(img_bands).astype(np.float32)\n",
    "    if np.max(img_10) >= 10:\n",
    "        img_10 = img_10 / 65535\n",
    "    assert np.max(img_10) <= 2.\n",
    "    \n",
    "    s2_10_usage = (img_10.shape[1]*img_10.shape[2])/(512*512) * (4/3) * img_10.shape[0]\n",
    "    print(f\"Original 10 meter bands size: {img_10.shape}, using {round(s2_10_usage, 1)} PU\")\n",
    "    img_10 = resize(img_10, (img_10.shape[0], IMSIZE, IMSIZE, img_10.shape[-1]), order = 0)\n",
    "    img = np.concatenate([img_10, img_20], axis = -1)\n",
    "    print(f\"Sentinel 2 used {round(s2_20_usage + s2_10_usage, 1)} PU\")\n",
    "\n",
    "    image_dates = []\n",
    "    for date in image_request.get_dates():\n",
    "        if date.year == year - 1:\n",
    "            image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year:\n",
    "            image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year + 1:\n",
    "            image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "    image_dates = [val for idx, val in enumerate(image_dates) if idx in clean_steps]\n",
    "    image_dates = np.array(image_dates, dtype = np.float32)\n",
    "    return img, image_dates\n",
    "\n",
    "        \n",
    "def download_sentinel_1(bbox: List[Tuple[float, float]],\n",
    "                        epsg: 'CRS', imsize: int = IMSIZE, \n",
    "                        dates: dict = dates_sentinel_1, layer: str = \"SENT\",\n",
    "                        year: int = year) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\" Downloads the GRD Sentinel 1 VV-VH layer from Sentinel Hub\n",
    "        \n",
    "        Parameters:\n",
    "         bbox (list): output of calc_bbox\n",
    "         epsg (float): EPSG associated with bbox \n",
    "         imsize (int):\n",
    "         dates (tuple): YY-MM-DD - YY-MM-DD bounds for downloading \n",
    "         layer (str):\n",
    "         year (int): \n",
    "    \n",
    "        Returns:\n",
    "         s1 (arr):\n",
    "         image_dates (arr): \n",
    "    \"\"\"\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    image_request = WcsRequest(\n",
    "            layer=layer,\n",
    "            bbox=box,\n",
    "            time=dates,\n",
    "            image_format = MimeType.TIFF_d16,\n",
    "            data_source=DataSource.SENTINEL1_IW,\n",
    "            maxcc=1.0,\n",
    "            resx='10m', resy='5m',\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=96),\n",
    "        )\n",
    "    data_filter = None\n",
    "    if len(image_request.download_list) > 50:\n",
    "        data_filter = [x for x in range(len(image_request.download_list)) if x % 2 == 0]\n",
    "    img_bands = image_request.get_data(data_filter = data_filter)\n",
    "    s1 = np.stack(img_bands).astype(np.float32)\n",
    "    if np.max(s1) >= 1000:\n",
    "            s1 = s1 / 65535.\n",
    "    \n",
    "    s1_usage = (2/3) * s1.shape[0] * ((s1.shape[1]*s1.shape[2]) / (512*512))\n",
    "    print(f\"Sentinel 1 used {round(s1_usage, 1)} PU for \\\n",
    "          {s1.shape[0]} out of {len(image_request.download_list)} images\")\n",
    "    s1 = resize(s1, (s1.shape[0], imsize*2, imsize*2, s1.shape[-1]), order = 0)\n",
    "    s1 = np.reshape(s1, (s1.shape[0], s1.shape[1]//2, 2, s1.shape[2] // 2, 2, s1.shape[-1]))\n",
    "    s1 = np.mean(s1, (2, 4))\n",
    "\n",
    "    image_dates = []\n",
    "    for date in image_request.get_dates():\n",
    "        if date.year == year - 1:\n",
    "            image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year:\n",
    "            image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "        if date.year == year + 1:\n",
    "            image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "    image_dates = np.array(image_dates)\n",
    "    s1c = np.copy(s1)\n",
    "    s1c[np.where(s1c < 1.)] = 0\n",
    "    n_pix_oob = np.sum(s1c, axis = (1, 2, 3))\n",
    "    to_remove = np.argwhere(n_pix_oob > (imsize*2*imsize*2)/50)\n",
    "    s1 = np.delete(s1, to_remove, 0)\n",
    "    image_dates = np.delete(image_dates, to_remove)\n",
    "    return s1, image_dates\n",
    "\n",
    "\n",
    "def identify_s1_layer(coords: Tuple[float, float]) -> str:\n",
    "    \"\"\" Identifies whether to download ascending or descending \n",
    "        sentinel 1 orbit based upon predetermined geographic coverage\n",
    "        \n",
    "        Reference: https://sentinel.esa.int/web/sentinel/missions/\n",
    "                   sentinel-1/satellite-description/geographical-coverage\n",
    "        \n",
    "        Parameters:\n",
    "         coords (tuple): \n",
    "    \n",
    "        Returns:\n",
    "         layer (str): either of SENT, SENT_DESC \n",
    "    \"\"\"\n",
    "    results = rg.search(coords)\n",
    "    country = results[-1]['cc']\n",
    "    continent_name = pc.country_alpha2_to_continent_code(country)\n",
    "    if continent_name in ['AF', 'OC']:\n",
    "        layer = \"SENT\"\n",
    "    if continent_name in ['SA']:\n",
    "        if coords[0] > -7.11:\n",
    "            layer = \"SENT\"\n",
    "        else:\n",
    "            layer = \"SENT_DESC\"\n",
    "    if continent_name in ['AS']:\n",
    "        if coords[0] > 23.3:\n",
    "            layer = \"SENT\"\n",
    "        else:\n",
    "            layer = \"SENT_DESC\"\n",
    "    if continent_name in ['NA']:\n",
    "        layer = \"SENT_DESC\"\n",
    "    print(f\"The continent is: {continent_name}, and the sentinel 1 orbit is {layer}\")\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Cloud and shadow removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missed_clouds(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Removes clouds that may have been missed by s2cloudless\n",
    "        by looking at a temporal change outside of IQR\n",
    "        \n",
    "        Parameters:\n",
    "         img (arr): \n",
    "    \n",
    "        Returns:\n",
    "         to_remove (arr): \n",
    "    \"\"\"\n",
    "    iqr = np.percentile(img[..., 0].flatten(), 75) - np.percentile(img[..., 0].flatten(), 25)\n",
    "    thresh_t = np.percentile(img[..., 0].flatten(), 75) + iqr*1.5\n",
    "    thresh_b = np.percentile(img[..., 0].flatten(), 25) - iqr*1.5\n",
    "    outlier_percs = []\n",
    "    for step in range(img.shape[0]):\n",
    "        bottom = len(np.argwhere(img[step, ..., 0].flatten() > thresh_t))\n",
    "        top = len(np.argwhere(img[step, ..., 0].flatten() < thresh_b))\n",
    "        p = 100 * ((bottom + top) / (img.shape[1]*img.shape[2]))\n",
    "        outlier_percs.append(p)\n",
    "    to_remove = np.argwhere(np.array(outlier_percs) > 10)\n",
    "    return to_remove\n",
    "\n",
    "\n",
    "def calculate_bad_steps(sentinel2: np.ndarray, clouds: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Calculates the timesteps to remove based upon cloud cover and missing data\n",
    "        \n",
    "        Parameters:\n",
    "         sentinel2 (arr): \n",
    "         clouds (arr):\n",
    "    \n",
    "        Returns:\n",
    "         to_remove (arr): \n",
    "    \"\"\"\n",
    "    n_cloud_px = np.array([len(np.argwhere(clouds[x, ...].reshape((IMSIZE)*(IMSIZE)) > 0.30)) for x in range(clouds.shape[0])])\n",
    "    cloud_steps = np.argwhere(n_cloud_px > IMSIZE**2 / 10)\n",
    "    missing_images = [np.argwhere(sentinel2[x, ..., :10].flatten() == 0.0) for x in range(sentinel2.shape[0])]\n",
    "    missing_images = np.array([len(x) for x in missing_images])\n",
    "    missing_images_p = [np.argwhere(sentinel2[x, ..., :10].flatten() >= 1) for x in range(sentinel2.shape[0])]\n",
    "    missing_images_p = np.array([len(x) for x in missing_images_p])\n",
    "    missing_images += missing_images_p\n",
    "    missing_images = np.argwhere(missing_images >= (IMSIZE**2) / 20)\n",
    "    to_remove = np.unique(np.concatenate([cloud_steps.flatten(), missing_images.flatten()]))\n",
    "    return to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Superresolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic Model Created.\n"
     ]
    }
   ],
   "source": [
    "MDL_PATH = \"../src/dsen2/models/\"\n",
    "\n",
    "input_shape = ((4, None, None), (6, None, None))\n",
    "model = s2model(input_shape, num_layers=6, feature_size=128)\n",
    "predict_file = MDL_PATH+'s2_032_lr_1e-04.hdf5'\n",
    "print('Symbolic Model Created.')\n",
    "\n",
    "model.load_weights(predict_file)\n",
    "\n",
    "def superresolve_tile(arr: np.ndarray, model) -> np.ndarray:\n",
    "    \"\"\"Superresolves each 56x56 subtile in a 646x646 input tile\n",
    "       by padding the subtiles to 64x64 and removing the pad after prediction,\n",
    "       eliminating boundary artifacts\n",
    "\n",
    "        Parameters:\n",
    "         arr (arr): (?, 646, 646, 10) array\n",
    "\n",
    "        Returns:\n",
    "         superresolved (arr): (?, 646, 646, 10) array\n",
    "    \"\"\"\n",
    "    print(f\"The input array to superresolve is {arr.shape}\")\n",
    "    #superresolved = np.copy(arr)\n",
    "    tiles = tile_window(646, 646, 56, 56)\n",
    "    for i in tnrange(len(tiles)):\n",
    "        subtile = tiles[i]\n",
    "        to_resolve = arr[:, subtile[0]:subtile[0]+56, subtile[1]:subtile[1]+56, :]\n",
    "        #to_resolve = np.pad(to_resolve, ((0, 0), (4, 4), (4, 4), (0, 0)), 'reflect')\n",
    "        resolved = superresolve(\n",
    "            np.pad(to_resolve, ((0, 0), (4, 4), (4, 4), (0, 0)), 'reflect'),\n",
    "            model)\n",
    "        resolved = resolved[:, 4:-4, 4:-4, :]\n",
    "        arr[:, subtile[0]:subtile[0]+56, subtile[1]:subtile[1]+56] = resolved\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Tiling and folder management functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_output_and_temp_folders(idx: str, output_folder: str = OUTPUT_FOLDER) -> None:\n",
    "    \"\"\"Makes necessary folder structures for IO of raw and processed data\n",
    "\n",
    "        Parameters:\n",
    "         idx (str)\n",
    "         output_folder (path)\n",
    "\n",
    "        Returns:\n",
    "         None\n",
    "    \"\"\"\n",
    "    def _find_and_make_dirs(dirs):\n",
    "        if not os.path.exists(os.path.realpath(dirs)):\n",
    "            os.makedirs(os.path.realpath(dirs))\n",
    "            \n",
    "    _find_and_make_dirs(output_folder + \"raw/\")\n",
    "    _find_and_make_dirs(output_folder + \"raw/clouds/\")\n",
    "    _find_and_make_dirs(output_folder + \"raw/s1/\")\n",
    "    _find_and_make_dirs(output_folder + \"raw/s2/\")\n",
    "    _find_and_make_dirs(output_folder + \"raw/misc/\")\n",
    "    _find_and_make_dirs(output_folder + \"processed/\")\n",
    "    _find_and_make_dirs(output_folder + \"interim/\")\n",
    "\n",
    "    \n",
    "def to_int32(array: np.array) -> np.array:\n",
    "    '''Converts a float32 array to int32, reducing storage costs by three-fold'''\n",
    "    return np.trunc(array * 65535).astype(np.int32)\n",
    "\n",
    "def to_int16(array: np.array) -> np.array:\n",
    "    '''Converts a float32 array to int16, reducing storage costs by three-fold'''\n",
    "    return np.trunc(array * 65535).astype(np.uint16)\n",
    "\n",
    "def to_float32(array: np.array) -> np.array:\n",
    "    #divide = 1. if ) < 100 else 65535\n",
    "    divide = 1. if isinstance(array.flat[0], np.floating) else 65535\n",
    "    print(divide, \"divide\")\n",
    "    return np.float32(array) / divide\n",
    "    \n",
    "\n",
    "def download_large_tile(coord: tuple,\n",
    "                        step_x: int,\n",
    "                        step_y: int,\n",
    "                        folder: str = OUTPUT_FOLDER, \n",
    "                        year: int = year,\n",
    "                        s1_layer: str = \"SENT\") -> None:\n",
    "    \"\"\"Wrapper function to download cloud probs, Sentinel 2, Sentinel 1, and DEM\n",
    "\n",
    "        Parameters:\n",
    "         coord (tuple):\n",
    "         step_x (int):\n",
    "         step_y (int):\n",
    "         folder (path):\n",
    "         year (int):\n",
    "         s1_layer (str):\n",
    "\n",
    "        Returns:\n",
    "         None\n",
    "    \"\"\"\n",
    "    bbx, epsg = calculate_bbx_pyproj(coord, step_x, step_y, expansion = 80)\n",
    "    dem_bbx, _ = calculate_bbx_pyproj(coord, step_x, step_y, expansion = 90)\n",
    "    idx = str(step_y) + \"_\" + str(step_x)\n",
    "    idx = str(idx)\n",
    "    make_output_and_temp_folders(idx)\n",
    "\n",
    "    if not os.path.exists(folder + \"output/\" + str(step_y*5) + \"/\" + str(step_x*5) + \".npy\"):\n",
    "        if not os.path.exists(folder + \"processed/\" + str(step_y*5) + \"/\" + str(step_x*5) + \".hkl\"):\n",
    "            clouds_file = f'{folder}raw/clouds/clouds_{idx}.hkl'\n",
    "            shadows_file = f'{folder}raw/clouds/shadows_{idx}.hkl'\n",
    "            s1_file = f'{folder}raw/s1/{idx}.hkl'\n",
    "            s1_dates_file = f'{folder}raw/misc/s1_dates_{idx}.hkl'\n",
    "            s2_file = f'{folder}raw/s2/{idx}.hkl'\n",
    "            s2_dates_file = f'{folder}raw/misc/s2_dates_{idx}.hkl'\n",
    "            clean_steps_file = f'{folder}raw/clouds/clean_steps_{idx}.hkl'\n",
    "            \n",
    "            if not os.path.exists(clouds_file):\n",
    "                # All this needs to be int16, copied to cloud with io.save_file\n",
    "                print(f\"Downloading clouds because {clouds_file} does not exist\")\n",
    "                cloud_probs, shadows, clean_steps = identify_clouds(bbx, epsg = epsg)\n",
    "                hkl.dump(cloud_probs, clouds_file, mode='w', compression='gzip')\n",
    "                hkl.dump(shadows, shadows_file, mode='w', compression='gzip')\n",
    "                hkl.dump(clean_steps, clean_steps_file, mode='w', compression='gzip')\n",
    "            \n",
    "            if not os.path.exists(s1_file):\n",
    "                # All this needs to be int16, copied to cloud with io.save_file\n",
    "                print(f\"Downloading S1 because {s1_file} does not exist\")\n",
    "                s1_layer = identify_s1_layer((coord[1], coord[0]))\n",
    "                s1, s1_dates = download_sentinel_1(bbx, layer = s1_layer, epsg = epsg)\n",
    "                if s1.shape[0] == 0:\n",
    "                    s1_layer = \"SENT_DESC\" if s1_layer == \"SENT\" else \"SENT\"\n",
    "                    print(f'Switching to {s1_layer}')\n",
    "                    s1, s1_dates = download_sentinel_1(bbx, layer = s1_layer, epsg = epsg)\n",
    "                s1 = process_sentinel_1_tile(s1, s1_dates)\n",
    "                hkl.dump(to_int16(s1), s1_file, mode='w', compression='gzip')\n",
    "                hkl.dump(s1_dates, s1_dates_file, mode='w', compression='gzip')\n",
    "\n",
    "            if not os.path.exists(s2_file):\n",
    "                # All this needs to be int16, copied to cloud with io.save_file\n",
    "                print(f\"Downloading S2 because {s2_file} does not exist\")\n",
    "                if 'clean_steps' not in globals() or locals():\n",
    "                    clean_steps = hkl.load(clean_steps_file)\n",
    "                s2, s2_dates = download_layer(bbx, clean_steps = clean_steps, epsg = epsg)\n",
    "                hkl.dump(to_int16(s2), s2_file, mode='w', compression='gzip')\n",
    "                hkl.dump(s2_dates, s2_dates_file, mode='w', compression='gzip')\n",
    "\n",
    "            if not os.path.exists(folder + \"raw/misc/dem_{}.hkl\".format(idx)):\n",
    "                # All this needs to be int16, copied to cloud with io.save_file\n",
    "                dem = download_dem(dem_bbx, epsg = epsg)\n",
    "                hkl.dump(dem, folder + \"raw/misc/dem_{}.hkl\".format(idx), mode='w', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data, m = 4):\n",
    "    d = data - np.median(data, axis = (0))\n",
    "    mdev = np.median(data, axis = 0)\n",
    "    s = d / mdev\n",
    "    n_changed = 0\n",
    "    for x in tnrange(data.shape[1]):\n",
    "        for y in range(data.shape[2]):\n",
    "            for band in range(data.shape[3]):\n",
    "                to_correct = np.where(s[:, x, y, band] > m) \n",
    "                data[to_correct, x, y, band] = mdev[x, y, band]\n",
    "                n_changed += len(to_correct[0])\n",
    "    print(f\"Rejected {n_changed} outliers\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentinel_1_tile(sentinel1: np.ndarray, dates: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Converts a (?, X, Y, 2) Sentinel 1 array to (24, X, Y, 2)\n",
    "\n",
    "        Parameters:\n",
    "         sentinel1 (np.array):\n",
    "         dates (np.array):\n",
    "\n",
    "        Returns:\n",
    "         s1 (np.array)\n",
    "    \"\"\"\n",
    "    s1, _ = calculate_and_save_best_images(sentinel1, dates)\n",
    "    biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "    to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "    s1 = np.delete(s1, to_remove, 0)\n",
    "    return s1\n",
    "\n",
    "\n",
    "def make_folder_names(step_x: int, step_y: int) -> (list, list):\n",
    "    '''Given an input tile location (step_x, step_y), identify the folder and file\n",
    "       names for each 5x5 subtile\n",
    "       \n",
    "       Parameters:\n",
    "         step_x (int):\n",
    "         step_y (int):\n",
    "\n",
    "        Returns:\n",
    "         x_vals (list)\n",
    "         y_vals (list)\n",
    "    '''\n",
    "    x_vals = []\n",
    "    y_vals = []\n",
    "    for i in range(25):\n",
    "        y_val = (24 - i) // 5\n",
    "        x_val = 5 - ((25 - i) % 5)\n",
    "        x_val = 0 if x_val == 5 else x_val\n",
    "        x_vals.append(x_val)\n",
    "        y_vals.append(y_val)\n",
    "    y_vals = [i + (5*step_y) for i in y_vals]\n",
    "    x_vals = [i + (5*step_x) for i in x_vals]\n",
    "    return x_vals, y_vals\n",
    "\n",
    "\n",
    "def process_large_tile(coord: tuple,\n",
    "                       step_x: int,\n",
    "                       step_y: int,\n",
    "                       folder: str = OUTPUT_FOLDER,\n",
    "                       model: 'model' = model) -> None:\n",
    "    '''Wrapper function to interpolate clouds and temporal gaps, superresolve tiles,\n",
    "       calculate relevant indices, and save analysis-ready data to the output folder\n",
    "       \n",
    "       Parameters:\n",
    "        coord (tuple)\n",
    "        step_x (int):\n",
    "        step_y (int):\n",
    "        foldre (str):\n",
    "\n",
    "       Returns:\n",
    "        None\n",
    "    '''\n",
    "    idx = str(step_y) + \"_\" + str(step_x)\n",
    "    x_vals, y_vals = make_folder_names(step_x, step_y)\n",
    "\n",
    "    processed = True\n",
    "    for x, y in zip(x_vals, y_vals):\n",
    "        folder_path = f\"{str(y)}/{str(x)}\"\n",
    "        processed_exists = os.path.exists(folder + \"processed/\" + folder_path + \".hkl\")\n",
    "        output_exists = os.path.exists(folder + \"output/\" + folder_path + \".npy\")\n",
    "        if not (processed_exists or output_exists):\n",
    "            processed = False\n",
    "    if not processed:\n",
    "        # All this needs to be converted to float32\n",
    "        clouds = hkl.load(f'{folder}raw/clouds/clouds_{idx}.hkl')\n",
    "        sentinel1 = to_float32(hkl.load(f'{folder}raw/s1/{idx}.hkl'))\n",
    "        radar_dates = hkl.load(f'{folder}raw/misc/s1_dates_{idx}.hkl')\n",
    "        sentinel2 = to_float32(hkl.load(f'{folder}raw/s2/{idx}.hkl'))\n",
    "        dem = hkl.load(f'{folder}raw/misc/dem_{idx}.hkl')\n",
    "        image_dates = hkl.load(f'{folder}raw/misc/s2_dates_{idx}.hkl')\n",
    "        print(image_dates)\n",
    "        if os.path.exists(f'{folder}raw/clouds/shadows_{idx}.hkl'):\n",
    "            shadows = hkl.load(f'{folder}raw/clouds/shadows_{idx}.hkl')\n",
    "        else:\n",
    "            print(\"No shadows file, so calculating shadows with L2A\")\n",
    "            shadows = mcm_shadow_mask(sentinel2, clouds)        \n",
    "        \n",
    "        to_remove = calculate_bad_steps(sentinel2, clouds)\n",
    "        sentinel2 = np.delete(sentinel2, to_remove, axis = 0)\n",
    "        clouds = np.delete(clouds, to_remove, axis = 0)\n",
    "        shadows = np.delete(shadows, to_remove, axis = 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        print(f\"{len(to_remove)} Cloudy and missing images removed, radar processed: {to_remove}\")\n",
    "        \n",
    "        to_remove = remove_missed_clouds(sentinel2)\n",
    "        sentinel2 = np.delete(sentinel2, to_remove, axis = 0)\n",
    "        clouds = np.delete(clouds, to_remove, axis = 0)\n",
    "        shadows = np.delete(shadows, to_remove, axis = 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        print(f\"{len(to_remove)} missed cloudy images were removed: {to_remove}\")\n",
    "        x, interp = remove_cloud_and_shadows(sentinel2, clouds, shadows, image_dates)\n",
    "        print(\"Clouds and shadows interpolated\")    \n",
    "                \n",
    "        to_remove = np.argwhere(np.mean(interp, axis = (1, 2, 3)) > 0.5)\n",
    "        print(f\"{len(to_remove)} steps removed because of >50% interpolation rate\")\n",
    "        x = np.delete(x, to_remove, axis = 0)\n",
    "        clouds = np.delete(clouds, to_remove, axis = 0)\n",
    "        shadows = np.delete(shadows, to_remove, axis = 0)\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "                \n",
    "        index = 0\n",
    "        print(\"Super resolving tile\")\n",
    "        x = np.float32(x)\n",
    "        x = superresolve_tile(x, model)\n",
    "        \n",
    "        dem_i = np.tile(dem[np.newaxis, 1:-1, 1:-1, :], (x.shape[0], 1, 1, 1))\n",
    "        x = np.concatenate([x, dem_i / 90], axis = -1)\n",
    "        x = evi(x, verbose = True)\n",
    "        x = bi(x, verbose = True)\n",
    "        x = msavi2(x, verbose = True)\n",
    "        x = si(x, verbose = True)\n",
    "\n",
    "        # spaghetti code to interpolate NA values induced in msavi2 ocassionally\n",
    "        for x_loc in range(x.shape[1]):\n",
    "            for y_loc in range(x.shape[2]):\n",
    "                n_na = np.sum(np.isnan(x[:, x_loc, y_loc, :]), axis = 1)\n",
    "                for date in range(x.shape[0]):\n",
    "                    if n_na.flatten()[date] > 0:\n",
    "                        before, after = calculate_proximal_steps(date, np.argwhere(n_na == 0))\n",
    "                        x[date, x_loc, y_loc, :] = (x[date + before, x_loc, y_loc] + x[date + after, x_loc, y_loc]) / 2\n",
    "        \n",
    "        numb_na = np.sum(np.isnan(x), axis = (1, 2, 3))\n",
    "        print(numb_na)\n",
    "\n",
    "        interim_file = f\"{folder}interim/{idx}.hkl\"\n",
    "        interim_dates = f\"{folder}interim/dates_{idx}.hkl\"\n",
    "        hkl.dump(np.float32(x), interim_file, mode = 'w', compression = 'gzip')\n",
    "        hkl.dump(image_dates, interim_dates, mode = 'w', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Function execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2019 for kenya-makueni\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "0 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "0 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "0 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "0 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "0 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "1 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "1 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "1 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "1 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "1 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "2 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "2 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "2 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "2 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "2 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "3 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "3 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "3 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "3 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "3 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "4 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "4 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "4 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "4 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "4 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "5 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "5 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "5 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "5 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "5 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "6 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "6 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "6 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "6 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "6 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "7 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "7 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "7 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "7 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "7 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "8 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "8 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "8 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "8 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "8 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "9 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "9 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "9 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "9 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "9 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "10 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "10 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "10 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "10 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "10 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "11 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "11 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "11 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "11 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "11 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "12 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "12 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "12 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "12 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "12 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "13 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "13 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "13 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "13 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "13 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "14 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "14 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "14 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "14 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "14 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "15 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "15 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "15 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "15 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "15 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "16 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "16 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "16 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "16 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "16 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "17 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "17 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "17 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "17 3 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "17 4 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "18 0 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "18 1 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "18 2 False 0\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "18 3 True 0\n",
      "Download 0/2500; X: 3 Y:18\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_18_3.hkl does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sentinelhub/data_request.py:47: SHDeprecationWarning: Parameter 'instance_id' is deprecated and will soon removed. Use parameter 'config' instead\n",
      "  category=SHDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud_probs used 0.1 processing units\n",
      "[0.45 0.97 0.38 0.38 0.06 0.88 0.16 0.05 0.   0.03 0.99 0.   0.17 0.13\n",
      " 0.   0.84 0.   0.23 0.71 0.01 0.05 0.22 0.31 0.44 0.37 0.75 0.46 0.57\n",
      " 1.   1.   0.58 1.   0.98 1.   0.93 0.03 0.77 0.   0.   0.88 1.   0.99\n",
      " 0.8  0.89 0.64 0.01 0.56 0.95 0.11 0.09 0.21 0.93 0.   0.4  0.98 0.96\n",
      " 0.79 0.19 0.65 0.75 0.76 1.   0.6  0.   0.89 0.32 0.55 0.7  0.   0.8 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ab89978cc740db8f8c17418f6c1a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c6dcee5a4b435582795030afca3966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((14, 646, 646)) used 5.6 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/18_3.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 57.3 PU for           27 out of 54 images\n",
      "Maximum time distance: 48\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/18_3.hkl does not exist\n",
      "Original 20 meter bands size: (14, 323, 323, 6), using 11.1 PU\n",
      "Original 10 meter bands size: (14, 646, 646, 4), using 29.7 PU\n",
      "Sentinel 2 used 40.9 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[ 19.  24.  34.  49.  59.  74.  79. 174. 199. 204. 244. 289. 354. 384.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "1 missed cloudy images were removed: [[6]]\n",
      "Interpolated 36171 px\n",
      "Clouds and shadows interpolated\n",
      "0 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (13, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc56799dfe0045ea8267eb893be67eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "18 4 True 1\n",
      "Download 1/2500; X: 4 Y:18\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_18_4.hkl does not exist\n",
      "Cloud_probs used 0.1 processing units\n",
      "[0.87 0.99 0.47 0.18 0.09 1.   0.29 0.15 0.06 0.04 0.53 0.   0.41 0.12\n",
      " 0.01 0.57 0.   0.34 0.87 0.01 0.11 0.21 0.18 0.58 0.34 0.69 0.7  0.61\n",
      " 0.98 1.   0.71 1.   0.73 1.   0.97 0.12 0.91 0.   0.   0.71 0.98 0.67\n",
      " 0.46 0.65 0.08 0.58 1.   0.21 0.09 0.29 0.54 0.   0.4  0.98 0.73 0.36\n",
      " 0.58 0.44 0.63 0.95 0.38 0.   0.99 0.23 0.57 0.69 0.06 0.82]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c05449405d4841805a2e66892545fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205ee66b13dd40b9a34ede446ffb339c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((9, 646, 646)) used 3.6 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/18_4.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 57.3 PU for           27 out of 54 images\n",
      "Maximum time distance: 48\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/18_4.hkl does not exist\n",
      "Original 20 meter bands size: (9, 323, 323, 6), using 7.2 PU\n",
      "Original 10 meter bands size: (9, 646, 646, 4), using 19.1 PU\n",
      "Sentinel 2 used 26.3 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[ 24.  34.  49.  59.  74. 199. 204. 289. 354.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "0 missed cloudy images were removed: []\n",
      "Interpolated 36829 px\n",
      "Clouds and shadows interpolated\n",
      "0 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (9, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2a2564e06840c986a66d879577d603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "19 0 False 2\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "19 1 False 2\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "19 2 True 2\n",
      "Download 2/2500; X: 2 Y:19\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_19_2.hkl does not exist\n",
      "Cloud_probs used 0.1 processing units\n",
      "[0.53 0.97 0.34 0.28 0.07 0.83 0.1  0.26 0.11 0.03 0.33 0.   0.5  0.31\n",
      " 0.   0.7  0.   0.17 0.07 0.15 0.   0.31 0.26 0.33 0.18 0.68 0.59 0.65\n",
      " 1.   1.   0.45 1.   0.98 0.88 0.99 0.   0.95 0.02 0.   0.96 1.   0.99\n",
      " 0.72 0.61 0.89 0.   0.56 0.98 0.05 0.24 0.36 0.87 0.   0.31 0.99 0.39\n",
      " 0.23 0.6  0.83 0.97 0.8  1.   0.42 0.   1.   0.04 0.25 0.74 0.62 0.98]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ca83efa9684f86a1090e40347bf5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc57823c5d4f443a93ca68d615a2ced4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((13, 646, 646)) used 5.2 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/19_2.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 57.3 PU for           27 out of 54 images\n",
      "Maximum time distance: 48\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/19_2.hkl does not exist\n",
      "Original 20 meter bands size: (13, 323, 323, 6), using 10.3 PU\n",
      "Original 10 meter bands size: (13, 646, 646, 4), using 27.6 PU\n",
      "Sentinel 2 used 37.9 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[ 24.  34.  49.  59.  79. 174. 199. 204. 244. 259. 289. 354. 369.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "0 missed cloudy images were removed: []\n",
      "Interpolated 95605 px\n",
      "Clouds and shadows interpolated\n",
      "1 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (12, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe5ec95758a4c57b1f995b04143b23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "19 3 True 3\n",
      "Download 3/2500; X: 3 Y:19\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_19_3.hkl does not exist\n",
      "Cloud_probs used 0.1 processing units\n",
      "[0.91 0.98 0.3  0.13 0.06 0.71 0.15 0.05 0.12 0.1  0.87 0.   0.08 0.05\n",
      " 0.   0.33 0.   0.45 0.85 0.19 0.03 0.15 0.3  0.22 0.51 0.94 0.61 0.66\n",
      " 0.98 1.   0.86 1.   0.96 1.   0.96 0.   0.95 0.08 0.   0.77 1.   0.99\n",
      " 0.6  0.82 0.89 0.03 0.54 0.99 0.16 0.45 0.24 0.89 0.   0.33 0.99 0.96\n",
      " 0.45 0.34 0.46 0.6  0.76 1.   0.07 0.   1.   0.08 0.57 0.88 0.07 0.99]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fe8a3715194320b8cf2391ed954e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f4e59ab7b1429dbefd61975fdf9e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((9, 646, 646)) used 3.6 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/19_3.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 57.3 PU for           27 out of 54 images\n",
      "Maximum time distance: 48\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/19_3.hkl does not exist\n",
      "Original 20 meter bands size: (9, 323, 323, 6), using 7.2 PU\n",
      "Original 10 meter bands size: (9, 646, 646, 4), using 19.1 PU\n",
      "Sentinel 2 used 26.3 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[ 34.  49.  59.  79. 174. 204. 244. 289. 354.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "2 missed cloudy images were removed: [[3]\n",
      " [6]]\n",
      "Interpolated 3036 px\n",
      "Clouds and shadows interpolated\n",
      "0 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (7, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a83840fe63e46f78fd7ace6277b69e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "19 4 True 4\n",
      "Download 4/2500; X: 4 Y:19\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_19_4.hkl does not exist\n",
      "Cloud_probs used 0.1 processing units\n",
      "[0.99 1.   0.35 0.14 0.26 1.   0.18 0.09 0.1  0.1  0.38 0.   0.2  0.21\n",
      " 0.   0.41 0.   0.47 0.66 0.03 0.07 0.13 0.3  0.43 0.32 0.44 0.78 0.56\n",
      " 0.98 1.   0.8  1.   0.47 1.   0.6  0.01 0.92 0.   0.   0.72 1.   0.27\n",
      " 0.56 0.78 0.08 0.63 0.89 0.13 0.15 0.24 0.56 0.   0.5  0.97 0.7  0.12\n",
      " 0.33 0.26 0.93 1.   0.27 0.   1.   0.19 0.63 0.6  0.01 0.95]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d07f5b2a02040e78ab7adba5fb21494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a2d501eeab4f21a83f2f78f89f396f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((10, 646, 646)) used 4.0 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/19_4.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 57.3 PU for           27 out of 54 images\n",
      "Maximum time distance: 48\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/19_4.hkl does not exist\n",
      "Original 20 meter bands size: (10, 323, 323, 6), using 8.0 PU\n",
      "Original 10 meter bands size: (10, 646, 646, 4), using 21.2 PU\n",
      "Sentinel 2 used 29.2 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[ 34.  49.  59.  74. 174. 199. 204. 289. 354. 384.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "1 missed cloudy images were removed: [[3]]\n",
      "Interpolated 21503 px\n",
      "Clouds and shadows interpolated\n",
      "0 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (9, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b0dc4e8a674dedbc38dd6d9d1d4506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "20 0 True 5\n",
      "Download 5/2500; X: 0 Y:20\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_20_0.hkl does not exist\n",
      "Cloud_probs used 0.1 processing units\n",
      "[0.95 0.45 0.49 0.03 1.   0.01 0.17 0.16 0.   0.26 0.   0.54 0.45 0.01\n",
      " 0.84 0.   0.19 0.06 0.13 0.16 0.26 0.39 0.26 0.37 0.08 0.61 0.83 1.\n",
      " 0.4  0.99 0.87 0.67 1.   0.06 0.91 0.   0.   0.77 0.86 0.95 0.35 0.33\n",
      " 0.65 0.17 0.8  0.98 0.   0.09 0.13 0.97 0.   0.24 0.91 0.32 0.87 0.53\n",
      " 0.67 1.   0.79 0.74 0.61 0.   0.97 0.37 0.3  0.55 0.55 0.58 0.98]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5c344a24ce41538f71396587e61576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a8c35e73ec438b9814c9d1c42109b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((11, 646, 646)) used 4.4 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/20_0.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 65.8 PU for           31 out of 61 images\n",
      "Maximum time distance: 0\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/20_0.hkl does not exist\n",
      "Original 20 meter bands size: (11, 323, 323, 6), using 8.8 PU\n",
      "Original 10 meter bands size: (11, 646, 646, 4), using 23.3 PU\n",
      "Sentinel 2 used 32.1 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[ -1.   9.  24.  34.  49.  59. 199. 204. 259. 289. 354.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "0 missed cloudy images were removed: []\n",
      "Interpolated 36707 px\n",
      "Clouds and shadows interpolated\n",
      "0 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (11, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3068d8ff4642e196353dd588d041e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "20 1 True 6\n",
      "Download 6/2500; X: 1 Y:20\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_20_1.hkl does not exist\n",
      "Cloud_probs used 0.2 processing units\n",
      "[1.   0.94 0.54 0.46 0.08 0.99 0.01 0.16 0.1  0.06 0.38 0.   0.41 0.28\n",
      " 0.01 0.8  0.   0.37 0.02 0.01 0.17 0.97 0.25 0.16 0.15 0.3  0.14 0.67\n",
      " 0.9  0.99 1.   0.2  1.   0.78 1.   1.   0.   1.   0.93 0.   0.   0.95\n",
      " 1.   0.96 0.7  0.5  0.83 0.03 0.66 1.   0.02 0.11 0.19 0.92 0.   0.21\n",
      " 0.99 0.29 0.39 0.81 0.42 1.   0.96 0.77 1.   0.67 0.   0.98 0.96 0.28\n",
      " 0.48 0.76 0.12 0.96]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db50f6e00c61442b9d63e666c626f069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3cbef1895d467c9f118f11f5cdd4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((13, 646, 646)) used 5.2 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/20_1.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 57.3 PU for           27 out of 54 images\n",
      "Maximum time distance: 48\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/20_1.hkl does not exist\n",
      "Original 20 meter bands size: (13, 323, 323, 6), using 10.3 PU\n",
      "Original 10 meter bands size: (13, 646, 646, 4), using 27.6 PU\n",
      "Sentinel 2 used 37.9 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[  9.  34.  49.  59.  69.  74. 174. 199. 204. 244. 259. 289. 354.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "0 missed cloudy images were removed: []\n",
      "Interpolated 44336 px\n",
      "Clouds and shadows interpolated\n",
      "0 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (13, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834e843cb99045c79026c8914f27d160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "20 2 True 7\n",
      "Download 7/2500; X: 2 Y:20\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_20_2.hkl does not exist\n",
      "Cloud_probs used 0.2 processing units\n",
      "[0.86 1.   0.11 0.31 0.08 0.9  0.11 0.5  0.2  0.12 0.64 0.   0.51 0.04\n",
      " 0.01 0.74 0.   0.59 0.02 0.05 0.11 0.93 0.22 0.52 0.13 0.4  0.35 0.73\n",
      " 0.8  0.95 1.   0.58 1.   0.86 1.   1.   0.   1.   0.97 0.05 0.   0.94\n",
      " 1.   0.97 0.71 0.75 0.9  0.01 0.76 0.99 0.01 0.24 0.29 0.99 0.   0.2\n",
      " 1.   0.39 0.43 0.53 0.12 1.   1.   0.88 1.   0.44 0.   0.97 1.   0.02\n",
      " 0.53 0.5  0.2  1.  ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05496306f21f473d9fc0d1783606a40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a2b863f7934d588ecd7f868ee73f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((13, 646, 646)) used 5.2 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/20_2.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 57.3 PU for           27 out of 54 images\n",
      "Maximum time distance: 48\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/20_2.hkl does not exist\n",
      "Original 20 meter bands size: (13, 323, 323, 6), using 10.3 PU\n",
      "Original 10 meter bands size: (13, 646, 646, 4), using 27.6 PU\n",
      "Sentinel 2 used 37.9 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[ 34.  44.  49.  59.  69. 174. 199. 204. 244. 259. 289. 354. 369.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "0 missed cloudy images were removed: []\n",
      "Interpolated 90522 px\n",
      "Clouds and shadows interpolated\n",
      "0 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (13, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3273b579d708452ca905d27e881c20c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "20 3 True 8\n",
      "Download 8/2500; X: 3 Y:20\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_20_3.hkl does not exist\n",
      "Cloud_probs used 0.2 processing units\n",
      "[0.84 0.95 0.35 0.16 0.06 0.98 0.06 0.1  0.07 0.1  0.29 0.   0.26 0.1\n",
      " 0.   0.46 0.   0.15 0.15 0.12 0.02 0.93 0.19 0.25 0.34 0.32 0.4  0.74\n",
      " 0.54 0.92 1.   0.94 1.   0.56 1.   0.92 0.05 1.   0.97 0.18 0.   0.77\n",
      " 1.   0.94 0.48 0.91 0.95 0.03 0.83 0.9  0.06 0.27 0.19 1.   0.   0.32\n",
      " 0.99 0.98 0.77 0.47 0.09 1.   0.89 0.81 1.   0.25 0.   1.   1.   0.06\n",
      " 0.47 0.8  0.22 0.94]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721c46d410344b97bf4a234a57d8ee00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8a1f13433f46f78de9738eb8ef20df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((9, 646, 646)) used 3.6 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/20_3.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 57.3 PU for           27 out of 54 images\n",
      "Maximum time distance: 48\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/20_3.hkl does not exist\n",
      "Original 20 meter bands size: (9, 323, 323, 6), using 7.2 PU\n",
      "Original 10 meter bands size: (9, 646, 646, 4), using 19.1 PU\n",
      "Sentinel 2 used 26.3 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[ 34.  49.  59.  79. 174. 204. 244. 289. 354.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "2 missed cloudy images were removed: [[3]\n",
      " [6]]\n",
      "Interpolated 15641 px\n",
      "Clouds and shadows interpolated\n",
      "0 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (7, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa282798c5343b1b734298fef5ee72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "20 4 True 9\n",
      "Download 9/2500; X: 4 Y:20\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_20_4.hkl does not exist\n",
      "Cloud_probs used 0.1 processing units\n",
      "[0.93 0.94 0.15 0.51 0.14 1.   0.18 0.04 0.01 0.32 0.28 0.   0.24 0.23\n",
      " 0.   0.33 0.   0.39 0.04 0.04 0.08 0.93 0.05 0.31 0.38 0.25 0.45 0.74\n",
      " 0.68 0.89 1.   0.8  1.   0.43 1.   0.37 0.05 1.   0.87 0.05 0.   0.75\n",
      " 0.98 0.07 0.76 0.76 0.03 0.56 0.75 0.06 0.15 0.14 0.89 0.   0.25 0.99\n",
      " 0.8  0.22 0.27 1.   0.49 0.96 1.   0.28 0.   1.   0.13 0.77 0.42 0.09\n",
      " 0.99]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44457c9f079f4f66914ca4099dcc9ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828c75fe0da646c1a797abc08ea757af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadows ((13, 646, 646)) used 5.2 processing units\n",
      "Downloading S1 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s1/20_4.hkl does not exist\n",
      "The continent is: AF, and the sentinel 1 orbit is SENT\n",
      "Sentinel 1 used 57.3 PU for           27 out of 54 images\n",
      "Maximum time distance: 48\n",
      "Downloading S2 because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/s2/20_4.hkl does not exist\n",
      "Original 20 meter bands size: (13, 323, 323, 6), using 10.3 PU\n",
      "Original 10 meter bands size: (13, 646, 646, 4), using 27.6 PU\n",
      "Sentinel 2 used 37.9 PU\n",
      "DEM used 3.2 processing units\n",
      "65535 divide\n",
      "65535 divide\n",
      "[ 14.  19.  34.  49.  59.  69.  74. 174. 199. 204. 244. 289. 354.]\n",
      "0 Cloudy and missing images removed, radar processed: []\n",
      "0 missed cloudy images were removed: []\n",
      "Interpolated 97430 px\n",
      "Clouds and shadows interpolated\n",
      "0 steps removed because of >50% interpolation rate\n",
      "Super resolving tile\n",
      "The input array to superresolve is (13, 646, 646, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9818c60d904083aedd7b88cceb8bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "21 0 True 10\n",
      "Download 10/2500; X: 0 Y:21\n",
      "Downloading clouds because ../project-monitoring//kenya/makueni/mtito-andei/2019/raw/clouds/clouds_21_0.hkl does not exist\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2509399a1fb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Download {downloaded}/{max_x*max_y}; X: {x_tile} Y:{y_tile}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdownloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mdownload_large_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_tile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mprocess_large_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-dee1ffc1594f>\u001b[0m in \u001b[0;36mdownload_large_tile\u001b[0;34m(coord, step_x, step_y, folder, year, s1_layer)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# All this needs to be int16, copied to cloud with io.save_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading clouds because {clouds_file} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mcloud_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentify_clouds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclouds_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshadows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadows_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-736d0ced9e57>\u001b[0m in \u001b[0;36midentify_clouds\u001b[0;34m(bbox, epsg, dates)\u001b[0m\n\u001b[1;32m     39\u001b[0m         time_difference=datetime.timedelta(hours=72))\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mcloud_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_img\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sentinelhub/data_request.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, save_data, redownload, data_filter, max_threads, decode_data, raise_download_errors)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         return self._execute_data_download(data_filter, redownload, max_threads, raise_download_errors,\n\u001b[0;32m--> 125\u001b[0;31m                                            decode_data=decode_data)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_download_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sentinelhub/data_request.py\u001b[0m in \u001b[0;36m_execute_data_download\u001b[0;34m(self, data_filter, redownload, max_threads, raise_download_errors, decode_data)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         )\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_download_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_repeating_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sentinelhub/download/client.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, download_requests, max_threads, decode_data)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_threads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             download_list = [\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdownload_requests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             ]\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "downloaded = 0\n",
    "\n",
    "if not os.path.exists(os.path.realpath(OUTPUT_FOLDER)):\n",
    "            os.makedirs(os.path.realpath(OUTPUT_FOLDER))\n",
    "        \n",
    "print(f\"Downloading {year} for {landscape}\")\n",
    "\n",
    "max_x = 50\n",
    "max_y = 50\n",
    "\n",
    "for y_tile in range(0, 25):\n",
    "    for x_tile in range(0, 5):\n",
    "        #contains = True\n",
    "        contains = check_contains(coords, x_tile, y_tile, OUTPUT_FOLDER)\n",
    "        print(y_tile, x_tile, contains, downloaded)\n",
    "        if contains:\n",
    "            print(f\"Download {downloaded}/{max_x*max_y}; X: {x_tile} Y:{y_tile}\")\n",
    "            downloaded += 1\n",
    "            download_large_tile(coord = coords, step_x = x_tile, step_y = y_tile)\n",
    "            process_large_tile(coords, x_tile, y_tile)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = \"/\".join(OUTPUT_FOLDER.split(\"/\")[:-2]) + \"/\"\n",
    "def process_multiple_years(coord: tuple,\n",
    "                       step_x: int,\n",
    "                       step_y: int,\n",
    "                       path: str = INPUT_FOLDER) -> None:\n",
    "    '''Wrapper function to interpolate clouds and temporal gaps, superresolve tiles,\n",
    "       calculate relevant indices, and save analysis-ready data to the output folder\n",
    "       \n",
    "       Parameters:\n",
    "        coord (tuple)\n",
    "        step_x (int):\n",
    "        step_y (int):\n",
    "        folder (str):\n",
    "\n",
    "       Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    idx = str(step_y) + \"_\" + str(step_x)\n",
    "    x_vals, y_vals = make_folder_names(step_x, step_y)\n",
    "    \n",
    "    d2017 = hkl.load(f\"{path}/2017/interim/dates_{idx}.hkl\")\n",
    "    d2018 = hkl.load(f\"{path}/2018/interim/dates_{idx}.hkl\")\n",
    "    d2019 = hkl.load(f\"{path}/2019/interim/dates_{idx}.hkl\")\n",
    "    \n",
    "    x2017 = hkl.load(f\"{path}/2017/interim/{idx}.hkl\").astype(np.float32)\n",
    "    x2018 = hkl.load(f\"{path}/2018/interim/{idx}.hkl\").astype(np.float32)\n",
    "    x2019 = hkl.load(f\"{path}/2019/interim/{idx}.hkl\").astype(np.float32)\n",
    "  \n",
    "    s1_all = np.empty((72, 646, 646, 2))\n",
    "    s1_2017 = hkl.load(f\"{path}/2017/raw/s1/{idx}.hkl\")\n",
    "    s1_all[:24] = s1_2017\n",
    "    s1_2018 = hkl.load(f\"{path}2018/raw/s1/{idx}.hkl\")\n",
    "    s1_all[24:48] = s1_2018\n",
    "    s1_2019 = hkl.load(f\"{path}2019/raw/s1/{idx}.hkl\")\n",
    "    s1_all[48:] = s1_2019\n",
    "    \n",
    "\n",
    "    index = 0\n",
    "    tiles = tile_window(IMSIZE, IMSIZE, window_size = 142)\n",
    "    for t in tiles:\n",
    "        start_x, start_y = t[0], t[1]\n",
    "        end_x = start_x + t[2]\n",
    "        end_y = start_y + t[3]\n",
    "        s2017 = x2017[:, start_x:end_x, start_y:end_y, :]\n",
    "        s2018 = x2018[:, start_x:end_x, start_y:end_y, :]\n",
    "        s2019 = x2019[:, start_x:end_x, start_y:end_y, :]\n",
    "        s2017, _  = calculate_and_save_best_images(s2017, d2017)\n",
    "        s2018, _ = calculate_and_save_best_images(s2018, d2018)\n",
    "        s2019, _ = calculate_and_save_best_images(s2019, d2019)\n",
    "        subtile = np.empty((72*3, 142, 142, 15))\n",
    "        subtile[:72] = s2017\n",
    "        subtile[72:144] = s2018\n",
    "        subtile[144:] = s2019\n",
    "        print(np.sum(np.isnan(subtile), axis = (1, 2, 3)))\n",
    "        out_17 = f\"{path}/2017/processed/{y_vals[index]}/{x_vals[index]}.hkl\"\n",
    "        out_18 = f\"{path}/2018/processed/{y_vals[index]}/{x_vals[index]}.hkl\"\n",
    "        out_19 = f\"{path}/2019/processed/{y_vals[index]}/{x_vals[index]}.hkl\"\n",
    "        \n",
    "        index += 1\n",
    "        print(f\"{index}: The output file is {out_17}\")\n",
    "        subtile = interpolate_array(subtile, dim = 142)\n",
    "        subtile = np.concatenate([subtile, s1_all[:, start_x:end_x, start_y:end_y, :]], axis = -1)\n",
    "        for folder in [out_17, out_18, out_19]:\n",
    "            output_folder = \"/\".join(folder.split(\"/\")[:-1])\n",
    "            if not os.path.exists(os.path.realpath(output_folder)):\n",
    "                os.makedirs(os.path.realpath(output_folder))\n",
    "        subtile = to_int32(subtile)\n",
    "        assert subtile.shape[1] == 142, f\"subtile shape is {subtile.shape}\"\n",
    "        \n",
    "        hkl.dump(subtile[:24], out_17, mode='w', compression='gzip')\n",
    "        hkl.dump(subtile[24:48], out_18, mode='w', compression='gzip')\n",
    "        hkl.dump(subtile[48:], out_19, mode='w', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-94c6cc125431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#contains = check_contains(coords, x_tile, y_tile, OUTPUT_FOLDER)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mprocess_multiple_years\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-374326e4f3d1>\u001b[0m in \u001b[0;36mprocess_multiple_years\u001b[0;34m(coord, step_x, step_y, path)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx2017\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/2017/interim/{idx}.hkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx2018\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/2018/interim/{idx}.hkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mx2019\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/2019/interim/{idx}.hkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/hickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fileobj, path, safe)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mpy_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0mpy_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hickle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mpy_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_container\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_root_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpy_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/hickle.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(py_container, h_group)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mh_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mh_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mpy_subcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_subcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0msub_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_subcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/hickle.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(py_container, h_group)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;31m# must be a dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0msubdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0mpy_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/hickle.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(h_node)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mload_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/loaders/load_numpy.py\u001b[0m in \u001b[0;36mload_ndarray_dataset\u001b[0;34m(h_node)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_ndarray_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mpy_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_type_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/helpers.py\u001b[0m in \u001b[0;36mget_type_and_data\u001b[0;34m(h_node)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"\"\" Helper function to return the py_type and data block for a HDF node \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpy_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#    if h_node.shape == ():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#        data = h_node.value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_x = 1\n",
    "max_y = 1\n",
    "\n",
    "for x_tile in range(1, 2):\n",
    "    for y_tile in range(0, max_y):\n",
    "        contains = True\n",
    "        #contains = check_contains(coords, x_tile, y_tile, OUTPUT_FOLDER)\n",
    "        if contains:\n",
    "            process_multiple_years(coords, x_tile, y_tile)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = \"/\".join(OUTPUT_FOLDER.split(\"/\")[:-2]) + \"/\"\n",
    "def process_single_year(coord: tuple,\n",
    "                       step_x: int,\n",
    "                       step_y: int,\n",
    "                       year = 2019,\n",
    "                       path: str = INPUT_FOLDER,\n",
    "                       delete = False) -> None:\n",
    "    '''Wrapper function to interpolate clouds and temporal gaps, superresolve tiles,\n",
    "       calculate relevant indices, and save analysis-ready data to the output folder\n",
    "       \n",
    "       Parameters:\n",
    "        coord (tuple)\n",
    "        step_x (int):\n",
    "        step_y (int):\n",
    "        folder (str):\n",
    "\n",
    "       Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    idx = str(step_y) + \"_\" + str(step_x)\n",
    "    x_vals, y_vals = make_folder_names(step_x, step_y)\n",
    "    d2019 = hkl.load(f\"{path}/{year}/interim/dates_{idx}.hkl\")\n",
    "    x2019 = hkl.load(f\"{path}/{year}/interim/{idx}.hkl\").astype(np.float32)\n",
    "    s1_2019 = hkl.load(f\"{path}/{year}/raw/s1/{idx}.hkl\")\n",
    "    \n",
    "\n",
    "    index = 0\n",
    "    tiles = tile_window(IMSIZE, IMSIZE, window_size = 142)\n",
    "    for t in tiles:\n",
    "        start_x, start_y = t[0], t[1]\n",
    "        end_x = start_x + t[2]\n",
    "        end_y = start_y + t[3]\n",
    "        s2019 = x2019[:, start_x:end_x, start_y:end_y, :]\n",
    "        subtile, _ = calculate_and_save_best_images(s2019, d2019)\n",
    "        print(np.sum(np.isnan(subtile), axis = (1, 2, 3)))\n",
    "        out_19 = f\"{path}/{year}/processed/{y_vals[index]}/{x_vals[index]}.hkl\"\n",
    "        \n",
    "        index += 1\n",
    "        print(f\"{index}: The output file is {out_19}\")\n",
    "        sm = Smoother(lmbd = 800, size = subtile.shape[0], nbands = 14, dim = subtile.shape[1])\n",
    "        subtile = sm.interpolate_array(subtile)\n",
    "        subtile = np.concatenate([subtile, s1_2019[:, start_x:end_x, start_y:end_y, :]], axis = -1)\n",
    "       # for folder in [out_17, out_18, out_19]:\n",
    "        output_folder = \"/\".join(out_19.split(\"/\")[:-1])\n",
    "        if not os.path.exists(os.path.realpath(output_folder)):\n",
    "            os.makedirs(os.path.realpath(output_folder))\n",
    "        subtile = np.float32(subtile)\n",
    "        print(np.max(subtile))\n",
    "        #subtile = to_int32(subtile)\n",
    "        #print(np.max(subtile))\n",
    "        assert subtile.shape[1] == 142, f\"subtile shape is {subtile.shape}\"\n",
    "        \n",
    "        hkl.dump(subtile, out_19, mode='w', compression='gzip')\n",
    "    if delete:\n",
    "        os.remove(f\"{path}/{year}/interim/{idx}.hkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n",
      "../project-monitoring//kenya/makueni/mtito-andei/2019/makueni.geojson\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '../project-monitoring//kenya/makueni/mtito-andei//2019/interim/20_0.hkl', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-08133c357c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcontains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_contains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mprocess_single_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2019\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-d775b9c64a7c>\u001b[0m in \u001b[0;36mprocess_single_year\u001b[0;34m(coord, step_x, step_y, year, path, delete)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mx_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_folder_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0md2019\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/{year}/interim/dates_{idx}.hkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx2019\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/{year}/interim/{idx}.hkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0ms1_2019\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/{year}/raw/s1/{idx}.hkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/hickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fileobj, path, safe)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mh5f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0mh_root_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/hickle/hickle.py\u001b[0m in \u001b[0;36mfile_opener\u001b[0;34m(f, mode, track_times)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_like_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mh5f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH5FileWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '../project-monitoring//kenya/makueni/mtito-andei//2019/interim/20_0.hkl', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "max_x = 5\n",
    "max_y = 25\n",
    "\n",
    "for x_tile in range(0, 1):\n",
    "    for y_tile in range(19, 21):\n",
    "        #contains = True\n",
    "        contains = check_contains(coords, x_tile, y_tile, OUTPUT_FOLDER)\n",
    "        if contains:\n",
    "            process_single_year(coords, x_tile, y_tile, year = 2019, delete = True)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
