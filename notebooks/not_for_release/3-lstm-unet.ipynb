{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import itertools\n",
    "from tflearn.layers.conv import global_avg_pool\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.layers import batch_normalization\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGRUCell(tf.nn.rnn_cell.RNNCell):\n",
    "  \"\"\"A GRU cell with convolutions instead of multiplications.\"\"\"\n",
    "\n",
    "  def __init__(self, shape, filters, kernel, padding = 'SAME', activation=tf.tanh, normalize=False, data_format='channels_last', reuse=None):\n",
    "    super(ConvGRUCell, self).__init__(_reuse=reuse)\n",
    "    self._filters = filters\n",
    "    self._kernel = kernel\n",
    "    self._activation = activation\n",
    "    self._normalize = normalize\n",
    "    self._padding = padding\n",
    "    if data_format == 'channels_last':\n",
    "        self._size = tf.TensorShape(shape + [self._filters])\n",
    "        self._feature_axis = self._size.ndims\n",
    "        self._data_format = None\n",
    "    elif data_format == 'channels_first':\n",
    "        self._size = tf.TensorShape([self._filters] + shape)\n",
    "        self._feature_axis = 0\n",
    "        self._data_format = 'NC'\n",
    "    else:\n",
    "        raise ValueError('Unknown data_format')\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._size\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._size\n",
    "\n",
    "  def call(self, x, h):\n",
    "    channels = x.shape[self._feature_axis].value\n",
    "\n",
    "    with tf.variable_scope('gates'):\n",
    "      inputs = tf.concat([x, h], axis=self._feature_axis)\n",
    "      n = channels + self._filters\n",
    "      m = 2 * self._filters if self._filters > 1 else 2\n",
    "      W = tf.get_variable('kernel', self._kernel + [n, m])\n",
    "      y = tf.nn.convolution(inputs, W, self._padding, data_format=self._data_format)\n",
    "      if self._normalize:\n",
    "        r, u = tf.split(y, 2, axis=self._feature_axis)\n",
    "        r = tf.contrib.layers.layer_norm(r)\n",
    "        u = tf.contrib.layers.layer_norm(u)\n",
    "      else:\n",
    "        y += tf.get_variable('bias', [m], initializer=tf.ones_initializer())\n",
    "        r, u = tf.split(y, 2, axis=self._feature_axis)\n",
    "      r, u = tf.sigmoid(r), tf.sigmoid(u)\n",
    "\n",
    "    with tf.variable_scope('candidate'):\n",
    "      inputs = tf.concat([x, r * h], axis=self._feature_axis)\n",
    "      n = channels + self._filters\n",
    "      m = self._filters\n",
    "      W = tf.get_variable('kernel', self._kernel + [n, m])\n",
    "      y = tf.nn.convolution(inputs, W, self._padding, data_format=self._data_format)\n",
    "      if self._normalize:\n",
    "        y = tf.contrib.layers.layer_norm(y)\n",
    "      else:\n",
    "        y += tf.get_variable('bias', [m], initializer=tf.zeros_initializer())\n",
    "      h = u * h + (1 - u) * self._activation(y)\n",
    "\n",
    "    return h, h\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "def norm(x, norm_type, is_train, G=32, esp=1e-5, scope = 'gn'):\n",
    "    with tf.variable_scope('{}_norm{}'.format(norm_type, scope)):\n",
    "        if norm_type == 'none':\n",
    "            output = x\n",
    "        elif norm_type == 'batch':\n",
    "            output = tf.contrib.layers.batch_norm(\n",
    "                x, center=True, scale=True, decay=0.999,\n",
    "                is_training=is_train, updates_collections=None\n",
    "            )\n",
    "        elif norm_type == 'group':\n",
    "            # normalize\n",
    "            # tranpose: [bs, h, w, c] to [bs, c, h, w] following the paper\n",
    "            x = tf.transpose(x, [0, 3, 1, 2])\n",
    "            N, C, H, W = x.get_shape().as_list()\n",
    "            G = min(G, C)\n",
    "            x = tf.reshape(x, [-1, G, C // G, H, W])\n",
    "            mean, var = tf.nn.moments(x, [2, 3, 4], keep_dims=True)\n",
    "            x = (x - mean) / tf.sqrt(var + esp)\n",
    "            # per channel gamma and beta\n",
    "            gamma = tf.Variable(tf.constant(1.0, shape=[C]), dtype=tf.float32, name='gamma')\n",
    "            beta = tf.Variable(tf.constant(0.0, shape=[C]), dtype=tf.float32, name='beta')\n",
    "            gamma = tf.reshape(gamma, [1, C, 1, 1])\n",
    "            beta = tf.reshape(beta, [1, C, 1, 1])\n",
    "\n",
    "            output = tf.reshape(x, [-1, C, H, W]) * gamma + beta\n",
    "            # tranpose: [bs, c, h, w, c] to [bs, h, w, c] following the paper\n",
    "            output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    return output\n",
    "\n",
    "def Batch_Normalization(x, training, scope):\n",
    "    return batch_normalization(inputs=x, momentum = 0.9, training=training, renorm = True, reuse=None, name = scope)\n",
    "        #return tf.cond(training,\n",
    "         #              lambda : batch_normalization(inputs=x, momentum = 0.9, training=True, reuse=None, name = scope),\n",
    "        #               lambda : batch_normalization(inputs=x, momentum=0.9, training=False, reuse=True, name = scope))\n",
    "\n",
    "        \n",
    "#def Batch_Normalization(x, training, groups, scope):\n",
    "#    print(x)\n",
    "#    return norm(x = x, norm_type = 'group', is_train = training, G = groups, scope = scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "weights = tf.ones([14, 14], tf.float32)\n",
    "weights = tf.pad(weights, [[1, 1], [1, 1]], 'constant')\n",
    "weights = tf.reshape(weights, (16*16,)) \n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 24, 16, 16, 13)\n",
      "WARNING:tensorflow:From <ipython-input-5-4f04eda3dec5>:49: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "FIRST GRU (?, 24, 16, 16, 24)\n",
      "DOWNSAMPLE (?, 24, 8, 8, 24)\n",
      "SECOND GRU (?, 8, 8, 36)\n",
      "THIRD GRU (?, 4, 4, 48)\n",
      "WARNING:tensorflow:From <ipython-input-2-a2481c416ae9>:96: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-4f04eda3dec5>:11: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "Down block conv (?, 4, 4, 30)\n",
      "Upblock 8 (?, 8, 8, 30)\n",
      "Up block 16 (?, 16, 16, 18)\n",
      "Up block conv 3 (?, 16, 16, 12)\n",
      "(?, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "reg = keras.regularizers.l2(0.01)\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 24, 14, 14, 13))\n",
    "length = tf.placeholder(tf.int32, shape = (None, 1))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 16, 16))#, 1))\n",
    "\n",
    "length2 = tf.reshape(length, (-1,))\n",
    "is_training = is_training = tf.placeholder_with_default(False, (), 'is_training')\n",
    "\n",
    "def Fully_connected(x, units, layer_name='fully_connected') :\n",
    "    with tf.name_scope(layer_name) :\n",
    "        return tf.layers.dense(inputs=x, use_bias=True, units=units)\n",
    "\n",
    "def Relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def Sigmoid(x):\n",
    "    return tf.nn.sigmoid(x)\n",
    "\n",
    "def Global_Average_Pooling(x):\n",
    "    return global_avg_pool(x, name='Global_avg_pooling')\n",
    "\n",
    "def Squeeze_excitation_layer(input_x, out_dim, ratio, layer_name):\n",
    "    with tf.name_scope(layer_name) :\n",
    "        squeeze = global_avg_pool(input_x)\n",
    "\n",
    "        excitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name+'_fully_connected1')\n",
    "        excitation = Relu(excitation)\n",
    "        excitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name+'_fully_connected2')\n",
    "        excitation = Sigmoid(excitation)\n",
    "\n",
    "        excitation = tf.reshape(excitation, [-1,1,1,out_dim])\n",
    "\n",
    "        scale = input_x * excitation\n",
    "\n",
    "        return scale\n",
    "    \n",
    "inp_pad = tf.pad(inp, [[0, 0], [0, 0], [1, 1], [1, 1], [0, 0]], \"CONSTANT\")\n",
    "print(inp_pad.shape)\n",
    "\n",
    "with tf.variable_scope('10'):\n",
    "    # Downsampling Block 1 (14 x 14)\n",
    "    cell_10 = ConvGRUCell(shape = [16, 16],\n",
    "                   filters = 12,\n",
    "                   kernel = [3,3],\n",
    "                   padding = 'SAME')\n",
    "\n",
    "    def convGRU(x, cell, ln):\n",
    "        output, final = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell, cell, x, ln, dtype=tf.float32)\n",
    "        output = tf.concat(output, -1)\n",
    "        final = tf.concat(final, -1)\n",
    "        return [output, final]\n",
    "\n",
    "# Return the final state and the output states\n",
    "first_conv = convGRU(inp_pad, cell_10, length2)\n",
    "print(\"FIRST GRU {}\".format(first_conv[0].shape))\n",
    "\n",
    "downsampled = TimeDistributed(MaxPool2D(pool_size = (2, 2)))(first_conv[0])\n",
    "print(\"DOWNSAMPLE {}\".format(downsampled.shape))\n",
    "\n",
    "# Downsampling block 2 (7 x 7)\n",
    "with tf.variable_scope('8'):\n",
    "    cell_7 = ConvGRUCell(shape = [8, 8],\n",
    "                   filters = 18,\n",
    "                   kernel = [3,3],\n",
    "                   padding = 'SAME')\n",
    "    state_7 = convGRU(downsampled, cell_7, length2)\n",
    "downsampled_4 = TimeDistributed(MaxPool2D(pool_size = (2, 2)))(state_7[0])\n",
    "print(\"SECOND GRU {}\".format(state_7[1].shape))\n",
    "\n",
    "with tf.variable_scope('4'):\n",
    "    cell_4 = ConvGRUCell(shape = [4, 4],\n",
    "                   filters = 24,\n",
    "                   kernel = [3,3],\n",
    "                   padding = 'SAME')\n",
    "    state_4 = convGRU(downsampled_4, cell_4, length2)\n",
    "print(\"THIRD GRU {}\".format(state_4[1].shape))\n",
    "\n",
    "# 4x4 - 4x4\n",
    "conv_block_7_u = Conv2D(filters = 30, kernel_size = (3, 3), padding = 'same', activity_regularizer=reg)(state_4[1])\n",
    "elu_7_u = ELU()(conv_block_7_u)\n",
    "x = Batch_Normalization(elu_7_u, training=is_training, scope = 'bn1')\n",
    "#x = batchnorm(elu_7_u, is_training, 'bn1')\n",
    "squeezed = Squeeze_excitation_layer(input_x = x, out_dim = 30, ratio = 4, layer_name = \"squeezed\")\n",
    "print(\"Down block conv {}\".format(elu_7_u.shape))\n",
    "\n",
    "# 4x4 - 8x8\n",
    "upsampling_8 = tf.keras.layers.Conv2DTranspose(filters = 30, kernel_size = (3, 3), strides=(2, 2), padding='same')(squeezed)\n",
    "concat_8 = Concatenate(axis = -1)([upsampling_8, state_7[1]])\n",
    "padded_8 = ReflectionPadding2D((1, 1))(concat_8)\n",
    "conv_8 = Conv2D(filters = 30,\n",
    "            kernel_size = (3, 3), \n",
    "            padding = 'valid',\n",
    "            activity_regularizer=reg,\n",
    "            )(padded_8)\n",
    "elu_8 = ELU()(conv_8)\n",
    "#bn_8 = batchnorm(elu_8, is_training, 'bn2')\n",
    "bn_8 = Batch_Normalization(elu_8, training=is_training, scope = 'bn8')\n",
    "squeeze_8 = Squeeze_excitation_layer(input_x = bn_8, out_dim = 30, ratio = 4, layer_name = \"squeezed_8\")\n",
    "print(\"Upblock 8 {}\".format(squeeze_8.shape))\n",
    "\n",
    "# 8x8 - 16 x 16\n",
    "upsampling_16 = tf.keras.layers.Conv2DTranspose(filters = 18, kernel_size = (3, 3), strides=(2, 2), padding='same')(squeeze_8)\n",
    "concat_16 = Concatenate(axis = -1)([upsampling_16, first_conv[1]])\n",
    "padded_16 = ReflectionPadding2D((1, 1))(concat_16)\n",
    "conv_16 = Conv2D(filters = 18,\n",
    "            kernel_size = (3, 3), \n",
    "            padding = 'valid',\n",
    "            activity_regularizer=reg,\n",
    "            )(padded_16)\n",
    "elu_16 = ELU()(conv_16)\n",
    "#bn_16 = batchnorm(elu_16, is_training, 'bn3')\n",
    "bn_16 = Batch_Normalization(elu_16, training=is_training, scope = 'bn16')\n",
    "squeezed_16 = Squeeze_excitation_layer(input_x = bn_16, out_dim = 18, ratio = 4, layer_name = \"squeezed_16\")\n",
    "print(\"Up block 16 {}\".format(squeezed_16.shape))\n",
    "\n",
    "padded = ReflectionPadding2D((1, 1))(squeezed_16)\n",
    "fm = Conv2D(filters = 12,\n",
    "            kernel_size = (3, 3), \n",
    "            padding = 'valid',\n",
    "            activity_regularizer=reg,\n",
    "            )(padded)\n",
    "elu = ELU()(fm)\n",
    "bn_final = Batch_Normalization(elu, training=is_training, scope = 'bnfinal')\n",
    "squeezed_16 = Squeeze_excitation_layer(input_x = bn_final, out_dim = 12, ratio = 4, layer_name = \"squeezed_final\")\n",
    "print(\"Up block conv 3 {}\".format(squeezed_16.shape))\n",
    "# Output layer\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1), \n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid'\n",
    "            )(squeezed_16)\n",
    "print(fm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400\n",
      "24\n",
      "2700\n",
      "12\n",
      "13608\n",
      "36\n",
      "6804\n",
      "18\n",
      "25920\n",
      "48\n",
      "12960\n",
      "24\n",
      "12960\n",
      "30\n",
      "30\n",
      "30\n",
      "210\n",
      "7\n",
      "210\n",
      "30\n",
      "8100\n",
      "30\n",
      "17820\n",
      "30\n",
      "30\n",
      "30\n",
      "210\n",
      "7\n",
      "210\n",
      "30\n",
      "4860\n",
      "18\n",
      "6804\n",
      "18\n",
      "18\n",
      "18\n",
      "72\n",
      "4\n",
      "72\n",
      "18\n",
      "1944\n",
      "12\n",
      "12\n",
      "12\n",
      "36\n",
      "3\n",
      "36\n",
      "12\n",
      "12\n",
      "1\n",
      "121540\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "0.4461283 0.822736\n",
      "0.5209696 0.9992913\n",
      "0.3871069 0.7687279\n",
      "0.33417815 0.80240464\n",
      "0.43925235 0.99593914\n",
      "0.4849003 0.77837324\n",
      "0.018518478 0.9987654\n",
      "0.13065934 0.9992756\n",
      "0.45570484 0.70296013\n",
      "0.47435188 0.97602654\n",
      "0.5119076 0.89559996\n",
      "0.46538663 0.8341109\n",
      "0.20434779 0.9995545\n",
      "0.13010052 0.5987441\n",
      "0.37679574 0.7240851\n",
      "0.4334727 0.67701864\n",
      "0.48435426 0.9996896\n",
      "0.44893616 0.99915755\n",
      "0.43766215 0.8044272\n",
      "0.43555382 0.8501582\n",
      "0.39542374 0.80423415\n",
      "0.5221932 0.93538916\n",
      "0.46930695 0.8748112\n",
      "0.45717004 0.7600787\n",
      "0.49347302 0.999159\n",
      "0.39788824 0.9997599\n",
      "0.48372936 0.96422374\n",
      "0.1746633 0.69592154\n",
      "0.47258085 0.91107\n",
      "0.46889305 0.7382716\n",
      "0.19358599 0.8195106\n",
      "0.48991695 0.85940486\n",
      "0.12084326 0.92077863\n",
      "0.43802115 0.77538574\n",
      "0.49526104 0.86184084\n",
      "0.0 0.7867664\n",
      "0.4694168 0.9035882\n",
      "0.3597304 0.99970436\n",
      "0.5541066 0.86154914\n",
      "0.42335027 0.8445461\n",
      "0.41079596 0.92014974\n",
      "0.5174932 0.9014919\n",
      "0.46615216 0.9996344\n",
      "0.49331236 0.99968636\n",
      "0.46103796 0.99967337\n",
      "0.15917441 0.7417355\n",
      "0.37985706 0.95710707\n",
      "0.46563378 0.6934734\n",
      "0.47342825 0.99978\n",
      "0.44059294 0.6406328\n",
      "0.5547088 0.9997597\n",
      "0.48246744 0.7548135\n",
      "0.39350766 0.7614286\n",
      "0.40996167 0.70857424\n",
      "0.49912235 0.8885666\n",
      "0.47344187 0.8224976\n",
      "0.47354335 0.9997204\n",
      "0.42835772 0.8248989\n",
      "0.53556955 0.9997759\n",
      "0.47958776 0.9993364\n",
      "0.48660293 0.8230834\n",
      "0.49268293 0.7240858\n",
      "0.44335297 0.9995671\n",
      "0.41246542 0.78322554\n",
      "0.0011723638 0.82293177\n",
      "0.44544926 0.7791262\n",
      "0.5446504 0.99977577\n",
      "0.3929752 0.91307104\n",
      "0.53227043 0.99968046\n",
      "0.39262325 0.7980964\n",
      "0.3776204 0.9644521\n",
      "0.40164763 0.7477907\n",
      "0.49816656 0.8073076\n",
      "0.53656405 0.91056335\n",
      "0.49271873 0.810616\n",
      "0.33007336 0.9286631\n",
      "0.45694277 0.8649974\n",
      "0.5370188 0.99978244\n",
      "0.4940438 0.85608006\n",
      "0.503531 0.99965894\n",
      "0.11907518 0.99972034\n",
      "0.41639972 0.884153\n",
      "0.008849531 0.9985528\n",
      "0.4009483 0.7887856\n",
      "0.5243352 0.88797677\n",
      "0.34591195 0.7211995\n",
      "0.486437 0.9981481\n",
      "0.46863 0.99941385\n",
      "0.11918369 0.9194037\n",
      "0.5008603 0.86504626\n",
      "0.47684714 0.99976575\n",
      "0.17464116 0.6536687\n",
      "0.48344034 0.99930507\n",
      "0.48387095 0.80874574\n",
      "0.44763973 0.8510215\n",
      "0.40687948 0.68994415\n",
      "0.4937354 0.99971354\n",
      "0.15258855 0.79844964\n",
      "0.54173356 0.9055863\n",
      "0.52506053 0.98254955\n",
      "0.47875062 0.7680702\n",
      "0.4501826 0.8869144\n",
      "0.49679857 0.84755915\n",
      "0.45309663 0.8564155\n",
      "0.34120172 0.8534653\n",
      "0.20760825 0.6463596\n",
      "0.4457541 0.8675023\n",
      "0.45248392 0.80397177\n",
      "0.4880854 0.78728604\n",
      "0.3575566 0.95917165\n",
      "0.46983933 0.96968037\n",
      "0.35229176 0.7330437\n",
      "0.41316652 0.9996828\n",
      "0.4213512 0.9651401\n",
      "0.46676525 0.9361702\n",
      "0.49551228 0.7384119\n",
      "0.48466843 0.7869457\n",
      "0.49506718 0.99966395\n",
      "0.47291324 0.78945696\n",
      "0.4700737 0.97119427\n",
      "0.474274 0.88769305\n",
      "0.50026894 0.9940594\n",
      "0.4256021 0.7035657\n",
      "0.5121568 0.9997492\n",
      "0.54440373 0.99948215\n",
      "0.3750346 0.99956524\n",
      "0.3451935 0.99916875\n",
      "0.4786851 0.8267001\n",
      "0.36870503 0.9391271\n",
      "0.2327852 0.8772289\n",
      "0.4578577 0.7871889\n",
      "0.44340485 0.99977046\n",
      "0.54969573 0.9996394\n",
      "0.44078735 0.87689227\n",
      "0.46058673 0.9988392\n",
      "0.51133466 0.9013033\n",
      "0.45181617 0.99973106\n",
      "0.42922115 0.7220598\n",
      "0.3505896 0.8847796\n",
      "0.2908061 0.9603509\n",
      "0.35864156 0.9130095\n",
      "0.058164984 0.7881137\n",
      "0.002123177 0.9966887\n",
      "22\n",
      "0.42097837 0.81372297\n",
      "22\n",
      "0.44332656 0.79227555\n",
      "0.026957601 0.59566075\n",
      "0.48461625 0.9996841\n",
      "0.34513515 0.87268615\n",
      "0.2733813 0.99783075\n",
      "0.27330512 0.774237\n",
      "0.2874962 0.88794166\n",
      "0.42823026 0.93936455\n",
      "0.44469664 0.88075376\n",
      "0.011627883 0.95928335\n",
      "0.35854858 0.88894653\n",
      "0.53506684 0.85627866\n",
      "0.48021203 0.9488506\n",
      "0.5003047 0.9954028\n",
      "0.4169708 0.9992652\n",
      "0.39818257 0.9996551\n",
      "0.29236668 0.86652124\n",
      "0.44245648 0.87192625\n",
      "0.35315984 0.81734294\n",
      "0.3148734 0.59085214\n",
      "0.35239017 0.57466173\n",
      "0.47205624 0.99981976\n",
      "0.08528033 0.8941959\n",
      "0.41423196 0.73013186\n",
      "0.35825163 0.81179065\n",
      "0.5105517 0.8270066\n",
      "0.564275 0.9997684\n",
      "0.41914257 0.9376266\n",
      "0.50204337 0.9997944\n",
      "0.45510834 0.8854629\n",
      "0.4359092 0.99977\n",
      "0.47857946 0.89571476\n",
      "0.505447 0.99970376\n",
      "0.42063648 0.7922607\n",
      "0.5158112 0.99873173\n",
      "0.52263266 0.9700465\n",
      "0.39672363 0.9969826\n",
      "0.24177504 0.8296616\n",
      "0.0020492077 0.99957097\n",
      "0.3860867 0.69430935\n",
      "0.47392964 0.9831933\n",
      "0.47110128 0.9997708\n",
      "0.4948332 0.9997797\n",
      "0.48431295 0.9997449\n",
      "0.49405515 0.8384568\n",
      "0.36997724 0.6635931\n",
      "0.553239 0.99981475\n",
      "0.4509981 0.87792355\n",
      "0.31139243 0.8998165\n",
      "0.4662255 0.8806141\n",
      "0.47595334 0.7870002\n",
      "0.27634314 0.8349357\n",
      "0.5334313 0.9860426\n",
      "0.4485526 0.99654984\n",
      "0.43989724 0.8919405\n",
      "0.43548387 0.8720355\n",
      "0.54158497 0.9445232\n",
      "0.4968502 0.9995817\n",
      "0.5014375 0.9998057\n",
      "0.56591386 0.991145\n",
      "0.42981 0.8534938\n",
      "0.55746305 0.9409689\n",
      "0.37368053 0.99973243\n",
      "0.44016573 0.8283092\n",
      "0.45386678 0.97761714\n",
      "0.24637681 0.8684056\n",
      "0.0010035336 0.9794378\n",
      "0.4491018 0.8530612\n",
      "0.49535474 0.9997689\n",
      "0.0014749467 0.7890809\n",
      "0.42649215 0.8914394\n",
      "0.40765485 0.72411895\n",
      "0.47774214 0.72687256\n",
      "0.50690395 0.99905705\n",
      "0.4959968 0.9997314\n",
      "0.002145946 0.90574193\n",
      "0.47677836 0.80197144\n",
      "0.42458868 0.9724269\n",
      "0.49855477 0.9166379\n",
      "0.40524098 0.999524\n",
      "0.3322259 0.6194545\n",
      "0.51026994 0.87061\n",
      "0.53413653 0.9273177\n",
      "0.0027100742 0.9180026\n",
      "0.5196748 0.96402884\n",
      "0.5143896 0.9998008\n",
      "0.4315746 0.99938154\n",
      "0.46151215 0.8146413\n",
      "0.4996642 0.9997833\n",
      "0.46085933 0.96252304\n",
      "0.49183977 0.9927536\n",
      "0.3935796 0.90282464\n",
      "0.5490942 0.9111793\n",
      "0.44727987 0.8468036\n",
      "0.38810697 0.90336645\n",
      "0.5525963 0.9273895\n",
      "0.468106 0.95584345\n",
      "0.54862195 0.9476956\n",
      "0.17859957 0.896322\n",
      "0.5452654 0.96532184\n",
      "0.4256606 0.8683647\n",
      "0.44747898 0.9996562\n",
      "0.3966127 0.8095238\n",
      "0.479393 0.79235196\n",
      "0.32804877 0.7641766\n",
      "0.5244428 0.9995911\n",
      "0.41906202 0.9997215\n",
      "0.44634312 0.8963855\n",
      "0.33768266 0.8025928\n",
      "0.44308278 0.82704544\n",
      "0.3407225 0.9053781\n",
      "0.41804937 0.9136059\n",
      "0.432341 0.9813582\n",
      "0.39136904 0.837016\n",
      "0.451065 0.9749692\n",
      "0.48179227 0.85910463\n",
      "0.4183647 0.9028379\n",
      "0.052631557 0.9997599\n",
      "0.30108422 0.99973947\n",
      "0.34247872 0.8023516\n",
      "0.45671505 0.9969558\n",
      "0.48653197 0.99817014\n",
      "0.42362526 0.9977011\n",
      "0.4327885 0.84383345\n",
      "0.45497793 0.9216663\n",
      "0.4256702 0.9707638\n",
      "0.45112413 0.91830707\n",
      "0.37931755 0.95168316\n",
      "0.47359625 0.9042455\n",
      "0.55086184 0.9672288\n",
      "0.46561465 0.8137139\n",
      "0.5556872 0.9290686\n",
      "0.51988786 0.9215355\n",
      "0.370058 0.99965906\n",
      "0.30796528 0.9963768\n",
      "0.37918216 0.94166666\n",
      "0.4778997 0.8955462\n",
      "0.56588924 0.9995416\n",
      "0.502569 0.93943954\n",
      "0.5505432 0.99970114\n",
      "0.4407583 0.99964666\n",
      "0.009478658 0.9333334\n",
      "0.4429128 0.9997393\n",
      "0.005333334 0.62720066\n",
      "0.4614105 0.92294586\n",
      "0.47645107 0.998703\n",
      "0.54189295 0.930838\n",
      "0.4576128 0.970883\n",
      "0.18671006 0.92557144\n",
      "0.5166115 0.8269836\n",
      "0.0020576417 0.891883\n",
      "0.47393572 0.8871684\n",
      "0.38951212 0.98844224\n",
      "0.36137527 0.62682295\n",
      "0.5 0.9931035\n",
      "0.41073766 0.8434899\n",
      "0.2875622 0.9582083\n",
      "0.4099333 0.83344835\n",
      "0.038724363 0.999354\n",
      "0.5086207 0.8378885\n",
      "0.49697605 0.99974775\n",
      "0.5283927 0.9525472\n",
      "0.5413599 0.87688696\n",
      "0.49547458 0.9948927\n",
      "0.45487693 0.9830111\n",
      "0.39895925 0.9099526\n",
      "0.40201926 0.93340456\n",
      "0.45386654 0.9998212\n",
      "0.5262627 0.9280541\n",
      "0.4313668 0.99961615\n",
      "0.002237171 0.97999996\n",
      "0.4583087 0.88966674\n",
      "0.36953807 0.9075041\n",
      "0.43942478 0.87137544\n",
      "0.08750105 0.88058853\n",
      "0.20780197 0.9509423\n",
      "0.4755719 0.92183924\n",
      "0.016949117 0.9994923\n",
      "0.4047085 0.9119431\n",
      "0.43021098 0.9874662\n",
      "0.4518246 0.9121742\n",
      "0.4379355 0.9997509\n",
      "0.43923557 0.8028057\n",
      "0.0 0.9580604\n",
      "0.43642244 0.99976826\n",
      "0.47960517 0.96467125\n",
      "0.4104421 0.71137756\n",
      "0.46925634 0.9283167\n",
      "0.53579056 0.9973861\n",
      "0.42328042 0.75827\n",
      "0.45766696 0.90058726\n",
      "0.47779834 0.94041866\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"../data/subplot.csv\")\n",
    "df1 = pd.read_csv(\"../data/subplot2.csv\")\n",
    "\n",
    "df = df.drop('IMAGERY_TITLE', axis = 1)\n",
    "df1 = df1.drop('IMAGERY_TITLE', axis = 1)\n",
    "df = pd.concat([df, df1], ignore_index = True)\n",
    "df = df.dropna(axis = 0)\n",
    "\n",
    "\n",
    "N_SAMPLES = int(df.shape[0]/196)\n",
    "print(N_SAMPLES)\n",
    "\n",
    "plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "\n",
    "def reconstruct_images(plot_id):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    rows = []\n",
    "    lats = reversed(sorted(subs['LAT'].unique()))\n",
    "    for i, val in enumerate(lats):\n",
    "        subs_lat = subs[subs['LAT'] == val]\n",
    "        subs_lat = subs_lat.sort_values('LON', axis = 0)\n",
    "        rows.append(list(subs_lat['TREE']))\n",
    "    return rows\n",
    "\n",
    "data = [reconstruct_images(x) for x in plot_ids]\n",
    "\n",
    "def remove_blank_steps(array):\n",
    "    to_update = {}\n",
    "    sets = []\n",
    "    for k in range(6):\n",
    "        for i in range(array.shape[0]):\n",
    "            for k in range(array.shape[-1]):\n",
    "                mean = (np.mean(array[i, :, :, k]))\n",
    "                if mean == 0:\n",
    "                    sets.append(i)\n",
    "                    if i < array.shape[0] - 1:\n",
    "                        array[i, :, :, k] = array[i + 1, :, :, k]\n",
    "                    else:\n",
    "                        array[i, :, :, k] = array[i - 1, :, :, k]\n",
    "                if mean == 1:\n",
    "                    sets.append(i)\n",
    "                    if i < array.shape[0] - 1:\n",
    "                        array[i, :, :, k] = array[i + 1, :, :, k]\n",
    "                    else:\n",
    "                        array[i, :, :, k] = array[i - 1, :, :, k]\n",
    "    for i in range(array.shape[0]):\n",
    "        for k in range(array.shape[-1]):\n",
    "            mean = (np.mean(array[i, :, :, k]))\n",
    "            if mean == 0:\n",
    "                if i < array.shape[0] - 2:\n",
    "                    array[i, :, :, k] = array[i + 2, :, :, k]\n",
    "                else:\n",
    "                    array[i, :, :, k] = array[i - 2, :, :, k]\n",
    "            if mean == 1:\n",
    "                if i < array.shape[0] - 2:\n",
    "                    array[i, :, :, k] = array[i + 2, :, :, k]\n",
    "                else:\n",
    "                    array[i, :, :, k] = array[i - 2, :, :, k]\n",
    "    return array\n",
    "\n",
    "import os\n",
    "image_size = 14\n",
    "\n",
    "def ndvi(x):\n",
    "    # (B8 - B4)/(B8 + B4)\n",
    "    ndvis = [(im[:, :, 6] - im[:, :, 2]) / (im[:, :, 6] + im[:, :, 2]) for im in x]\n",
    "    min_ndvi = min([np.min(x) for x in ndvis])\n",
    "    max_ndvi = max([np.max(x) for x in ndvis])\n",
    "    if min_ndvi < -1 or max_ndvi > 1:\n",
    "        print(\"ERROR\")\n",
    "    ndvis = [((x + 1) / 2) for x in ndvis]\n",
    "    min_ndvi = min([np.min(x) for x in ndvis])\n",
    "    max_ndvi = max([np.max(x) for x in ndvis])\n",
    "    print(min_ndvi, max_ndvi)\n",
    "    x_padding = np.zeros((x.shape[0], image_size, image_size, 1))\n",
    "    x = np.concatenate((x, x_padding), axis = 3)\n",
    "    # Iterate over each time step and add NDVI in as the 11th channel\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i, :, :, 10] = ndvis[i]\n",
    "    return x\n",
    "\n",
    "def evi(x):\n",
    "    # 2.5 x (08 - 04) / (08 + 6 * 04 - 7.5 * 02 + 1)\n",
    "    evis = [2.5 * ((im[:, :, 6] - im[:, :, 2]) / (im[:, :, 6] + 6 * im[:,:, 2] - 7.5 * im[:, :, 0] + 1)) for im in x]\n",
    "    x_padding = np.zeros((x.shape[0], image_size, image_size, 1))\n",
    "    x = np.concatenate((x, x_padding), axis = 3)\n",
    "    # Iterate over each time step and add NDVI in as the 11th channel\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i, :, :, 11] = evis[i]\n",
    "    return x\n",
    "    \n",
    "def savi(x):\n",
    "    # (1.5)(08 - 04)/ (08 + 04 + 0.5)\n",
    "    savis = [(1.5 * im[:, :, 6] - im[:, :, 2]) / (im[:, :, 6] + im[:, :, 2] + 0.5) for im in x]\n",
    "    x_padding = np.zeros((x.shape[0], image_size, image_size, 1))\n",
    "    x = np.concatenate((x, x_padding), axis = 3)\n",
    "    # Iterate over each time step and add NDVI in as the 11th channel\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i, :, :, 12] = savis[i]\n",
    "    return x\n",
    "\n",
    "# Initiate empty lists to store the X and Y data in\n",
    "data_x = []\n",
    "data_y = []\n",
    "binary_y = []\n",
    "data_location_x = []\n",
    "data_location_y = []\n",
    "lengths = []\n",
    "\n",
    "# Iterate over each plot\n",
    "pad = True\n",
    "flip = True\n",
    "for i in plot_ids:\n",
    "    # Load the sentinel imagery\n",
    "    x = np.load(\"../data/ids/\" + str(i) + \".npy\")\n",
    "    # Shape check\n",
    "    if x.shape[1] == image_size:\n",
    "        x = ndvi(x)                # calc NDVI\n",
    "        x = evi(x)\n",
    "        x = savi(x)\n",
    "        x = remove_blank_steps(x)\n",
    "        y = reconstruct_images(i)\n",
    "        if sum([sum(x) for x in y]) >= 1:\n",
    "            binary_y.append(1)\n",
    "        else:\n",
    "            binary_y.append(0)\n",
    "        lengths.append(x.shape[0])\n",
    "        #x = np.median(x, axis = 0) # and calculate the median over the time steps\n",
    "        if pad:\n",
    "            if x.shape[0] < 24:\n",
    "                print(x.shape[0])\n",
    "                padding = np.zeros((24 - x.shape[0], image_size, image_size, 13))\n",
    "                x = np.concatenate((x, padding), axis = 0)\n",
    "        data_x.append(x)\n",
    "        data_y.append(y)\n",
    "        if flip:\n",
    "                # FLIP HORIZONTAL\n",
    "            x1 = np.flip(x, 1)\n",
    "            data_x.append(x1)\n",
    "            data_y.append(np.flip(y, 0))\n",
    "            lengths.append(x.shape[0])\n",
    "    \n",
    "                # FLIP BOTH\n",
    "            x2 = np.flip(x, 2)\n",
    "            x2 = np.flip(x2, 1)\n",
    "            data_x.append(x2)\n",
    "            data_y.append(np.flip(y, [0, 1]))\n",
    "            lengths.append(x.shape[0])\n",
    "                # FLIP VERTICAL\n",
    "            x3 = np.flip(x, 2)\n",
    "            data_x.append(x3)\n",
    "            data_y.append(np.flip(y, 1))\n",
    "            lengths.append(x.shape[0])\n",
    "\n",
    "data_x = np.stack(data_x)\n",
    "data_y = np.stack(data_y)\n",
    "data_y = np.reshape(data_y, (N_SAMPLES*4, 14, 14, 1))\n",
    "binary_y = np.stack(binary_y)\n",
    "lengths = np.stack(lengths)\n",
    "lengths = np.reshape(lengths, (lengths.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_foc(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "\n",
    "        return -K.sum(0.5 * K.pow(1. - pt_1, 2) * K.log(pt_1)) \\\n",
    "               -K.sum((1 - 0.5) * K.pow(pt_0, 2) * K.log(1. - pt_0))  \n",
    "    \n",
    "def focal_loss(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    r\"\"\"Compute focal loss for predictions.\n",
    "        Multi-labels Focal loss formula:\n",
    "            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "    Args:\n",
    "     prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing the predicted logits for each class\n",
    "     target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing one-hot encoded classification targets\n",
    "     weights: A float tensor of shape [batch_size, num_anchors]\n",
    "     alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "     gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "    Returns:\n",
    "        loss: A (scalar) tensor representing the value of the loss function\n",
    "    \"\"\"\n",
    "    sigmoid_p = prediction_tensor\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "    \n",
    "    # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "    \n",
    "    # For negative prediction, only need consider back part loss, front part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return tf.reduce_sum(per_entry_cross_ent)\n",
    "\n",
    "def foc_lovasz(y_true, y_pred):\n",
    "    #jaccard_loss = jaccard_distance(y_true, y_pred)\n",
    "    lovasz = lovasz_hinge(y_pred, y_true)\n",
    "    #pred_reshape = tf.reshape(y_pred, (-1, 14, 14))\n",
    "    #true_reshape = tf.reshape(y_true, (-1, 14, 14))\n",
    "    focal_loss = bin_foc(y_true, y_pred)\n",
    "    summed = lovasz + np.log(focal_loss)\n",
    "    return summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thirty_meter(true, pred):\n",
    "    indices_x = [x for x in range(0, 13, 1)]\n",
    "    indices_y = [x for x in range(0, 13, 1)]\n",
    "    perms = [(y, x) for x, y in itertools.product(indices_y, indices_x)]\n",
    "    \n",
    "    #perms = ([list(zip(indices_x, p)) for p in itertools.permutations(indices_y)])\n",
    "    #perms = [item for sublist in perms for item in sublist]\n",
    "    #perms = list(set(perms))\n",
    "    indexes = [([a, a + 1], [b, b + 1]) for a,b in perms]\n",
    "    subs_true = []\n",
    "    subs_pred = []\n",
    "    for i in indexes:\n",
    "        true_i = true[i[0][0]:i[0][1], i[1][0]:i[1][1]]\n",
    "        pred_i = pred[i[0][0]:i[0][1], i[1][0]:i[1][1]]\n",
    "        subs_true.append(true_i)\n",
    "        subs_pred.append(pred_i)\n",
    "    pred = [np.sum(x) for x in subs_pred]\n",
    "    true = [np.sum(x) for x in subs_true]\n",
    "    true_positives = []\n",
    "    false_positives = []\n",
    "    false_negatives = []\n",
    "    for p, t in zip(pred, true):\n",
    "        if p > t:\n",
    "            tp = p - (p - t)\n",
    "            fp = p - tp\n",
    "            fn = 0\n",
    "        if t >= p:\n",
    "            tp = t\n",
    "            fp = 0\n",
    "            fn = t - p\n",
    "        true_positives.append(tp)\n",
    "        false_positives.append(fp)\n",
    "        false_negatives.append(fn)\n",
    "    prec = [x / (x + y) for x,y in zip(true_positives, false_positives) if (x+y) > 0]\n",
    "    prec = [x for x in prec if not np.isnan(x)]\n",
    "    rec = [x / (x + y) for x,y in zip(true_positives, false_negatives) if (x+y) > 0]\n",
    "    rec = [x for x in rec if not np.isnan(x)]\n",
    "    \n",
    "    #recall = [min(x / y, 1) for x, y in zip(pred, true) if y > 0]\n",
    "    #precision = [(y - x) / x for x, y in zip(pred, true)]\n",
    "    #print(precision)\n",
    "    return rec, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "# --------------------------- MULTICLASS LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None, order='BHWC'):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, H, W, C] or [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "      order: use BHWC or BCHW\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(prob_lab):\n",
    "            prob, lab = prob_lab\n",
    "            prob, lab = tf.expand_dims(prob, 0), tf.expand_dims(lab, 0)\n",
    "            prob, lab = flatten_probas(prob, lab, ignore, order)\n",
    "            return lovasz_softmax_flat(prob, lab, classes=classes)\n",
    "        losses = tf.map_fn(treat_image, (probas, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore, order), classes=classes)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, classes='present'):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "    \"\"\"\n",
    "    C = probas.shape[1]\n",
    "    losses = []\n",
    "    present = []\n",
    "    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n",
    "    for c in class_to_sum:\n",
    "        fg = tf.cast(tf.equal(labels, c), probas.dtype)  # foreground for class c\n",
    "        if classes == 'present':\n",
    "            present.append(tf.reduce_sum(fg) > 0)\n",
    "        if C == 1:\n",
    "            if len(classes) > 1:\n",
    "                raise ValueError('Sigmoid output possible only with 1 class')\n",
    "            class_pred = probas[:, 0]\n",
    "        else:\n",
    "            class_pred = probas[:, c]\n",
    "        errors = tf.abs(fg - class_pred)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort_{}\".format(c))\n",
    "        fg_sorted = tf.gather(fg, perm)\n",
    "        grad = lovasz_grad(fg_sorted)\n",
    "        losses.append(\n",
    "            tf.tensordot(errors_sorted, tf.stop_gradient(grad), 1, name=\"loss_class_{}\".format(c))\n",
    "                      )\n",
    "    if len(class_to_sum) == 1:  # short-circuit mean when only one class\n",
    "        return losses[0]\n",
    "    losses_tensor = tf.stack(losses)\n",
    "    if classes == 'present':\n",
    "        present = tf.stack(present)\n",
    "        losses_tensor = tf.boolean_mask(losses_tensor, present)\n",
    "    loss = tf.reduce_mean(losses_tensor)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None, order='BHWC'):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    if len(probas.shape) == 3:\n",
    "        probas, order = tf.expand_dims(probas, 3), 'BHWC'\n",
    "    if order == 'BCHW':\n",
    "        probas = tf.transpose(probas, (0, 2, 3, 1), name=\"BCHW_to_BHWC\")\n",
    "        order = 'BHWC'\n",
    "    if order != 'BHWC':\n",
    "        raise NotImplementedError('Order {} unknown'.format(order))\n",
    "    C = probas.shape[3]\n",
    "    probas = tf.reshape(probas, (-1, C))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vprobas = tf.boolean_mask(probas, valid, name='valid_probas')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vprobas, vlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = np.pad(data_y, [[0, 0], [1, 1], [1, 1], [0, 0]], 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 0.8139517307281494 Val: 0.600934624671936 P 0.5896696137738483 R 0.6586174242424242 F1 0.622239389419494\n",
      "Epoch 2: Loss 0.4770493805408478 Val: 0.38646334409713745 P 0.9023070350327542 R 0.5984848484848485 F1 0.7196428699796564\n",
      "Epoch 3: Loss 0.3798139691352844 Val: 0.34605973958969116 P 0.9209302325581395 R 0.5965119949494949 F1 0.7240419704608414\n",
      "Epoch 4: Loss 0.35712310671806335 Val: 0.32115769386291504 P 0.8432259781740751 R 0.6307607323232324 F1 0.7216806389354826\n",
      "Epoch 5: Loss 0.34868431091308594 Val: 0.32279810309410095 P 0.8664022972788186 R 0.6295770202020202 F1 0.7292440079125228\n",
      "Epoch 6: Loss 0.3402796983718872 Val: 0.3050217032432556 P 0.854138581827986 R 0.6395991161616161 F1 0.7314621338833197\n",
      "Epoch 7: Loss 0.3343500792980194 Val: 0.31565213203430176 P 0.9523523222606343 R 0.5946969696969697 F1 0.7321822815556313\n",
      "Epoch 8: Loss 0.32815682888031006 Val: 0.3000420928001404 P 0.898086463501063 R 0.6313920454545454 F1 0.7414875669906298\n",
      "Epoch 9: Loss 0.3275664150714874 Val: 0.37212058901786804 P 0.7295336787564767 R 0.7166193181818182 F1 0.7230188348922627\n",
      "Epoch 10: Loss 0.32982635498046875 Val: 0.316813588142395 P 0.9162689804772234 R 0.6268939393939394 F1 0.7444495501016724\n",
      "Epoch 11: Loss 0.32009509205818176 Val: 0.3449957072734833 P 0.6919296712897237 R 0.7293244949494949 F1 0.7101351328162214\n",
      "Epoch 12: Loss 0.32667645812034607 Val: 0.3047676384449005 P 0.9302598737336661 R 0.6169507575757576 F1 0.7418828726074541\n",
      "Epoch 13: Loss 0.3275275230407715 Val: 0.31386592984199524 P 0.777709586350804 R 0.6914457070707071 F1 0.7320450836448319\n",
      "Epoch 14: Loss 0.3116878569126129 Val: 0.30278196930885315 P 0.9345132743362832 R 0.6023516414141414 F1 0.7325375170594053\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "def weighted_cross_entropy(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "    y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(logits=y_pred, targets=y_true, pos_weight=2.)\n",
    "\n",
    "    # or reduce_sum and/or axis=-1\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def smooth_jaccard(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth\n",
    "\n",
    "def bce_jaccard(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, (-1, 16, 16, 1))\n",
    "    return binary_crossentropy(y_true, y_pred) + (0.5 * smooth_jaccard(y_true, y_pred))\n",
    "\n",
    "def bce_lovasz(y_true, y_pred):\n",
    "    return binary_crossentropy(tf.reshape(y_true, (-1, 14, 14, 1)), y_pred) + lovasz_softmax(y_pred, y_true, classes=[1], per_image=False)\n",
    "\n",
    "def foc_jaccard(y_true, y_pred):\n",
    "    print(y_true.shape)\n",
    "    y_true_r = tf.reshape(y_true, (-1, 16, 16, 1))\n",
    "    y_pred_r = tf.reshape(y_pred, (-1, 16, 16))\n",
    "    y_true_f = tf.reshape(y_true, (-1, 16*16, 1))\n",
    "    y_pred_f = tf.reshape(y_pred, (-1, 16*16, 1))\n",
    "    jac = smooth_jaccard(y_true_r, y_pred)\n",
    "    foc = focal_loss(y_pred_f, y_true_f, alpha=0.5, gamma=1.5, weights = weights)\n",
    "    return foc\n",
    "\n",
    "optimizer = AdaBoundOptimizer(learning_rate=1e-6, final_lr=5e-5, beta1=0.9, beta2=0.999, amsbound=True)\n",
    "loss2 = bce_jaccard(labels, fm)\n",
    "#\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = optimizer.minimize(loss2)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "saver = tf.train.Saver(max_to_keep = 2)\n",
    "\n",
    "# dev --> 225\n",
    "\n",
    "# Run training loop\n",
    "for i in range(100):\n",
    "    randomize = np.arange(1088)\n",
    "    np.random.shuffle(randomize)\n",
    "    test_randomize = np.arange(1088, 1344)\n",
    "    np.random.shuffle(test_randomize)\n",
    "\n",
    "    losses = []\n",
    "    val_loss = []\n",
    "\n",
    "    for k in range(68*4):\n",
    "        batch_ids = randomize[k*4:(k+1)*4]\n",
    "        op, tr = sess.run([train_op, loss2], feed_dict={inp: data_x[batch_ids, :, :, :],\n",
    "                                                        length: lengths[batch_ids],\n",
    "                                                        labels: data_y[batch_ids, :, :].reshape(4, 16, 16),\n",
    "                                                        is_training: True\n",
    "                                                        })\n",
    "        losses.append(tr)\n",
    "    for j in range(32):\n",
    "        batch_ids = test_randomize[j*8:(j+1)*8]\n",
    "        vl, y = sess.run([loss2, fm], feed_dict={inp: data_x[batch_ids, :, :, :],\n",
    "                                                 length: lengths[batch_ids],\n",
    "                                                 labels: data_y[batch_ids, :, :].reshape(8, 16, 16),\n",
    "                                                 is_training: False,\n",
    "                                                })\n",
    "        val_loss.append(vl)\n",
    "        \n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    for m in range(1088, 1344):\n",
    "        y = sess.run([fm], feed_dict={inp: data_x[m].reshape(1, 24, 14, 14, 13),\n",
    "                                  length: lengths[m].reshape(1, 1),\n",
    "                                  is_training: False,\n",
    "                                  })[0]\n",
    "        true = data_y[m].reshape((16, 16))\n",
    "        pred = y.reshape((16, 16))\n",
    "        pred = pred[1:15, 1:15]\n",
    "        true = true[1:15, 1:15]\n",
    "        #pred = np.sigmoid(pred)\n",
    "        pred[np.where(pred > 0.45)] = 1\n",
    "        pred[np.where(pred < 0.45)] = 0\n",
    "        rec, prec = thirty_meter(true, pred)\n",
    "        recalls.append(rec)\n",
    "        precisions.append(prec)\n",
    "    precisions = [item for sublist in precisions for item in sublist]\n",
    "    recalls = [item for sublist in recalls for item in sublist]\n",
    "    precision = np.mean(precisions)\n",
    "    recall = np.mean(recalls)\n",
    "    f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "    save_path = saver.save(sess, \"../models/dev/model\")\n",
    "    if np.mean(val_loss) < 0.27:\n",
    "        save_path = saver.save(sess, \"../models/dev_best/model\")\n",
    "    print(\"Epoch {}: Loss {} Val: {} P {} R {} F1 {}\".format(i + 1,\n",
    "                                                             np.mean(losses), np.mean(val_loss),\n",
    "                                                             precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a37c7b7f0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = int((len(data_x))*0.8) + 20# 105, 25, 215, 90, 140\n",
    "y = sess.run([fm], feed_dict={inp: data_x[idx].reshape(1, 24, 14, 14, 13),\n",
    "                              length: lengths[idx].reshape(1, 1),\n",
    "                              is_training: False,\n",
    "                              })\n",
    "\n",
    "sns.heatmap(data_y[idx][:, :, :].reshape(16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a37e76828>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = y[0][:, :, :].reshape(16, 16)\n",
    "#pred[np.where(pred > 0.3)] = 1\n",
    "sns.heatmap(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recalls = []\n",
    "precisions = []\n",
    "for i in range(1088, 1344):\n",
    "    y = sess.run([fm], feed_dict={inp: data_x[i].reshape(1, 24, 14, 14, 13),\n",
    "                              length: lengths[i].reshape(1, 1),\n",
    "                              is_training: False,\n",
    "                              })[0]\n",
    "    true = data_y[i].reshape((16, 16))\n",
    "    pred = y.reshape((16, 16))\n",
    "    pred = pred[1:15, 1:15]\n",
    "    true = true[1:15, 1:15]\n",
    "    pred[np.where(pred > 0.48)] = 1\n",
    "    pred[np.where(pred < 0.48)] = 0\n",
    "    rec, prec = thirty_meter(true, pred)\n",
    "    #rec, prec = half_hectare_accuracy(true, pred)\n",
    "    recalls.append(rec)\n",
    "    precisions.append(prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7482638888888888"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls = [item for sublist in recalls for item in sublist]\n",
    "np.mean(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7361449982572325"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions = [item for sublist in precisions for item in sublist]\n",
    "np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AdaBound for TensorFlow.\"\"\"\n",
    "\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import resource_variable_ops\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.ops import variable_scope\n",
    "from tensorflow.python.training import optimizer\n",
    "from tensorflow.python.ops.clip_ops import clip_by_value\n",
    "\n",
    "\"\"\"Implements AdaBound algorithm.\n",
    "    It has been proposed in `Adaptive Gradient Methods with Dynamic Bound of Learning Rate`_.\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): Adam learning rate (default: 1e-3)\n",
    "        betas (Tuple[float, float], optional): coefficients used for computing\n",
    "            running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        final_lr (float, optional): final (SGD) learning rate (default: 0.1)\n",
    "        gamma (float, optional): convergence speed of the bound functions (default: 1e-3)\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "        amsbound (boolean, optional): whether to use the AMSBound variant of this algorithm\n",
    "    .. Adaptive Gradient Methods with Dynamic Bound of Learning Rate:\n",
    "        https://openreview.net/forum?id=Bkg3g2R9FX\n",
    "    \"\"\"\n",
    "\n",
    "class AdaBoundOptimizer(optimizer.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, final_lr=0.1, beta1=0.9, beta2=0.999,\n",
    "                 gamma=1e-3, epsilon=1e-8, amsbound=False,\n",
    "                 use_locking=False, name=\"AdaBound\"):\n",
    "        super(AdaBoundOptimizer, self).__init__(use_locking, name)\n",
    "        self._lr = learning_rate\n",
    "        self._final_lr = final_lr\n",
    "        self._beta1 = beta1\n",
    "        self._beta2 = beta2\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "        self._gamma = gamma\n",
    "        self._amsbound = amsbound\n",
    "\n",
    "        self._lr_t = None\n",
    "        self._beta1_t = None\n",
    "        self._beta2_t = None\n",
    "        self._epsilon_t = None\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        first_var = min(var_list, key=lambda x: x.name)\n",
    "\n",
    "        graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "        create_new = self._get_non_slot_variable(\"beta1_power\", graph) is None\n",
    "        if not create_new and context.in_graph_mode():\n",
    "            create_new = (self._get_non_slot_variable(\"beta1_power\", graph).graph is not first_var.graph)\n",
    "\n",
    "        if create_new:\n",
    "            self._create_non_slot_variable(initial_value=self._beta1,\n",
    "                                           name=\"beta1_power\",\n",
    "                                           colocate_with=first_var)\n",
    "            self._create_non_slot_variable(initial_value=self._beta2,\n",
    "                                           name=\"beta2_power\",\n",
    "                                           colocate_with=first_var)\n",
    "            self._create_non_slot_variable(initial_value=self._gamma,\n",
    "                                           name=\"gamma_multi\",\n",
    "                                           colocate_with=first_var)\n",
    "        # Create slots for the first and second moments.\n",
    "        for v in var_list :\n",
    "            self._zeros_slot(v, \"m\", self._name)\n",
    "            self._zeros_slot(v, \"v\", self._name)\n",
    "            self._zeros_slot(v, \"vhat\", self._name)\n",
    "\n",
    "\n",
    "    def _prepare(self):\n",
    "        self._lr_t = ops.convert_to_tensor(self._lr)\n",
    "        self._base_lr_t = ops.convert_to_tensor(self._lr)\n",
    "        self._beta1_t = ops.convert_to_tensor(self._beta1)\n",
    "        self._beta2_t = ops.convert_to_tensor(self._beta2)\n",
    "        self._epsilon_t = ops.convert_to_tensor(self._epsilon)\n",
    "        self._gamma_t = ops.convert_to_tensor(self._gamma)\n",
    "\n",
    "    def _apply_dense(self, grad, var):\n",
    "        graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "        beta1_power = math_ops.cast(self._get_non_slot_variable(\"beta1_power\", graph=graph), var.dtype.base_dtype)\n",
    "        beta2_power = math_ops.cast(self._get_non_slot_variable(\"beta2_power\", graph=graph), var.dtype.base_dtype)\n",
    "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
    "        base_lr_t = math_ops.cast(self._base_lr_t, var.dtype.base_dtype)\n",
    "        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n",
    "        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n",
    "        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)\n",
    "        gamma_multi = math_ops.cast(self._get_non_slot_variable(\"gamma_multi\", graph=graph), var.dtype.base_dtype)\n",
    "\n",
    "        step_size = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n",
    "        final_lr = self._final_lr * lr_t / base_lr_t\n",
    "        lower_bound = final_lr * (1. - 1. / (gamma_multi + 1.))\n",
    "        upper_bound = final_lr * (1. + 1. / (gamma_multi))\n",
    "\n",
    "        # m_t = beta1 * m + (1 - beta1) * g_t\n",
    "        m = self.get_slot(var, \"m\")\n",
    "        m_scaled_g_values = grad * (1 - beta1_t)\n",
    "        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)\n",
    "\n",
    "        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
    "        v = self.get_slot(var, \"v\")\n",
    "        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n",
    "        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)\n",
    "\n",
    "        # amsgrad\n",
    "        vhat = self.get_slot(var, \"vhat\")\n",
    "        if self._amsbound :\n",
    "            vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n",
    "            v_sqrt = math_ops.sqrt(vhat_t)\n",
    "        else :\n",
    "            vhat_t = state_ops.assign(vhat, vhat)\n",
    "            v_sqrt = math_ops.sqrt(v_t)\n",
    "\n",
    "\n",
    "        # Compute the bounds\n",
    "        step_size_bound = step_size / (v_sqrt + epsilon_t)\n",
    "        bounded_lr = m_t * clip_by_value(step_size_bound, lower_bound, upper_bound)\n",
    "\n",
    "        var_update = state_ops.assign_sub(var, bounded_lr, use_locking=self._use_locking)\n",
    "        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "        beta1_power = math_ops.cast(self._get_non_slot_variable(\"beta1_power\", graph=graph), grad.dtype.base_dtype)\n",
    "        beta2_power = math_ops.cast(self._get_non_slot_variable(\"beta2_power\", graph=graph), grad.dtype.base_dtype)\n",
    "        lr_t = math_ops.cast(self._lr_t, grad.dtype.base_dtype)\n",
    "        base_lr_t = math_ops.cast(self._base_lr_t, var.dtype.base_dtype)\n",
    "        beta1_t = math_ops.cast(self._beta1_t, grad.dtype.base_dtype)\n",
    "        beta2_t = math_ops.cast(self._beta2_t, grad.dtype.base_dtype)\n",
    "        epsilon_t = math_ops.cast(self._epsilon_t, grad.dtype.base_dtype)\n",
    "        gamma_multi = math_ops.cast(self._get_non_slot_variable(\"gamma_multi\", graph=graph), var.dtype.base_dtype)\n",
    "\n",
    "        step_size = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n",
    "        final_lr = self._final_lr * lr_t / base_lr_t\n",
    "        lower_bound = final_lr * (1. - 1. / (gamma_multi + 1.))\n",
    "        upper_bound = final_lr * (1. + 1. / (gamma_multi))\n",
    "\n",
    "        # m_t = beta1 * m + (1 - beta1) * g_t\n",
    "        m = self.get_slot(var, \"m\")\n",
    "        m_scaled_g_values = grad * (1 - beta1_t)\n",
    "        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)\n",
    "\n",
    "        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
    "        v = self.get_slot(var, \"v\")\n",
    "        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n",
    "        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)\n",
    "\n",
    "        # amsgrad\n",
    "        vhat = self.get_slot(var, \"vhat\")\n",
    "        if self._amsbound:\n",
    "            vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n",
    "            v_sqrt = math_ops.sqrt(vhat_t)\n",
    "        else:\n",
    "            vhat_t = state_ops.assign(vhat, vhat)\n",
    "            v_sqrt = math_ops.sqrt(v_t)\n",
    "\n",
    "        # Compute the bounds\n",
    "        step_size_bound = step_size / (v_sqrt + epsilon_t)\n",
    "        bounded_lr = m_t * clip_by_value(step_size_bound, lower_bound, upper_bound)\n",
    "\n",
    "        var_update = state_ops.assign_sub(var, bounded_lr, use_locking=self._use_locking)\n",
    "\n",
    "        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n",
    "\n",
    "    def _apply_sparse_shared(self, grad, var, indices, scatter_add):\n",
    "        graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "        beta1_power = math_ops.cast(self._get_non_slot_variable(\"beta1_power\", graph=graph), var.dtype.base_dtype)\n",
    "        beta2_power = math_ops.cast(self._get_non_slot_variable(\"beta2_power\", graph=graph), var.dtype.base_dtype)\n",
    "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
    "        base_lr_t = math_ops.cast(self._base_lr_t, var.dtype.base_dtype)\n",
    "        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n",
    "        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n",
    "        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)\n",
    "        gamma_t = math_ops.cast(self._gamma_t, var.dtype.base_dtype)\n",
    "\n",
    "        step_size = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n",
    "        final_lr = self._final_lr * lr_t / base_lr_t\n",
    "        lower_bound = final_lr * (1. - 1. / (gamma_t + 1.))\n",
    "        upper_bound = final_lr * (1. + 1. / (gamma_t))\n",
    "\n",
    "        # m_t = beta1 * m + (1 - beta1) * g_t\n",
    "        m = self.get_slot(var, \"m\")\n",
    "        m_scaled_g_values = grad * (1 - beta1_t)\n",
    "        m_t = state_ops.assign(m, m * beta1_t, use_locking=self._use_locking)\n",
    "        with ops.control_dependencies([m_t]):\n",
    "            m_t = scatter_add(m, indices, m_scaled_g_values)\n",
    "\n",
    "        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
    "        v = self.get_slot(var, \"v\")\n",
    "        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n",
    "        v_t = state_ops.assign(v, v * beta2_t, use_locking=self._use_locking)\n",
    "        with ops.control_dependencies([v_t]):\n",
    "            v_t = scatter_add(v, indices, v_scaled_g_values)\n",
    "\n",
    "        # amsgrad\n",
    "        vhat = self.get_slot(var, \"vhat\")\n",
    "        if self._amsbound:\n",
    "            vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n",
    "            v_sqrt = math_ops.sqrt(vhat_t)\n",
    "        else:\n",
    "            vhat_t = state_ops.assign(vhat, vhat)\n",
    "            v_sqrt = math_ops.sqrt(v_t)\n",
    "\n",
    "        # Compute the bounds\n",
    "        step_size_bound = step_size / (v_sqrt + epsilon_t)\n",
    "        bounded_lr = m_t * clip_by_value(step_size_bound, lower_bound, upper_bound)\n",
    "\n",
    "        var_update = state_ops.assign_sub(var, bounded_lr, use_locking=self._use_locking)\n",
    "\n",
    "        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n",
    "\n",
    "    def _apply_sparse(self, grad, var):\n",
    "        return self._apply_sparse_shared(\n",
    "            grad.values, var, grad.indices,\n",
    "            lambda x, i, v: state_ops.scatter_add(  # pylint: disable=g-long-lambda\n",
    "                x, i, v, use_locking=self._use_locking))\n",
    "\n",
    "    def _resource_scatter_add(self, x, i, v):\n",
    "        with ops.control_dependencies(\n",
    "                [resource_variable_ops.resource_scatter_add(x, i, v)]):\n",
    "            return x.value()\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var, indices):\n",
    "        return self._apply_sparse_shared(\n",
    "            grad, var, indices, self._resource_scatter_add)\n",
    "\n",
    "    def _finish(self, update_ops, name_scope):\n",
    "        # Update the power accumulators.\n",
    "        with ops.control_dependencies(update_ops):\n",
    "            graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "            beta1_power = self._get_non_slot_variable(\"beta1_power\", graph=graph)\n",
    "            beta2_power = self._get_non_slot_variable(\"beta2_power\", graph=graph)\n",
    "            gamma_multi = self._get_non_slot_variable(\"gamma_multi\", graph=graph)\n",
    "            with ops.colocate_with(beta1_power):\n",
    "                update_beta1 = beta1_power.assign(\n",
    "                    beta1_power * self._beta1_t,\n",
    "                    use_locking=self._use_locking)\n",
    "                update_beta2 = beta2_power.assign(\n",
    "                    beta2_power * self._beta2_t,\n",
    "                    use_locking=self._use_locking)\n",
    "                update_gamma = gamma_multi.assign(\n",
    "                    gamma_multi + self._gamma_t,\n",
    "                    use_locking=self._use_locking)\n",
    "        return control_flow_ops.group(*update_ops + [update_beta1, update_beta2, update_gamma],\n",
    "                                      name=name_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
