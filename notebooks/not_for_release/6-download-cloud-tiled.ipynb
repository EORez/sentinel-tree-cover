{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "from sentinelhub import DataSource\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import splu\n",
    "\n",
    "\n",
    "from sentinelhub import CustomUrlParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "%run ../src/slope.py\n",
    "%run ../src/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSG = CRS.WGS84\n",
    "GRID_SIZE_X = 1\n",
    "GRID_SIZE_Y = 1\n",
    "\n",
    "IMAGE_X = 14*GRID_SIZE_X\n",
    "IMAGE_Y = 14*GRID_SIZE_Y\n",
    "\n",
    "TEST_X = 5\n",
    "TEST_Y = 5\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "    key = (yaml.safe_load(stream))\n",
    "    API_KEY = key['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2017-12-15', '2019-1-15')\n"
     ]
    }
   ],
   "source": [
    "year = 2018\n",
    "time = (str(year - 1) +'-12-15', str(year+1) +'-1-15')\n",
    "print(time)\n",
    "\n",
    "def convertCoords(xy, src='', targ=''):\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])\n",
    "\n",
    "def bounding_box(point, x_offset_max = 140, y_offset_max = 140, expansion = 10):\n",
    "    # LONG, LAT FOR SOME REASON\n",
    "    tl = point\n",
    "    \n",
    "    if 48 <= tl[0] <= 54:\n",
    "        epsg = 32639 if tl[1] > 0 else 32739\n",
    "    if 42 <= tl[0] <= 48:\n",
    "        epsg = 32638 if tl[1] > 0 else 32738\n",
    "    if 36 <= tl[0] <= 42:\n",
    "        epsg = 32637 if tl[1] > 0 else 32737\n",
    "    if 30 <= tl[0] <= 36:\n",
    "        epsg = 32636 if tl[1] > 0 else 32736\n",
    "    if 24 <= tl[0] <= 30:\n",
    "        epsg = 32635 if tl[1] > 0 else 32735\n",
    "    if 18 <= tl[0] <= 24:\n",
    "        epsg = 32634 if tl[1] > 0 else 32734\n",
    "\n",
    "    tl = convertCoords(tl, 4326, epsg)\n",
    "    \n",
    "    br = (tl[0], tl[1])\n",
    "    tl = ((tl[0] + (x_offset_max)), (tl[1] + (y_offset_max )))\n",
    "    distance1 = tl[0] - br[0]\n",
    "    distance2 = tl[1] - br[1]\n",
    "    #EXPANSION = (expansion - np.mean([distance1, distance2]))/2 # should this be 155 or 160?\n",
    "    \n",
    "    br = [a - expansion for a in br]\n",
    "    tl = [a + expansion for a in tl]\n",
    "    \n",
    "    after = [b - a for a,b in zip(br, tl)]\n",
    "    #br = (br[0] + 20, br[1] + 20)\n",
    "    #tl = (tl[0] - 20, tl[1] - 20)\n",
    "    br = convertCoords(br, epsg, 4326)\n",
    "    tl = convertCoords(tl, epsg, 4326)\n",
    "    \n",
    "    min_x = tl[0] # original X offset - 10 meters\n",
    "    max_x = br[0] # original X offset + 10*GRID_SIZE meters\n",
    "    \n",
    "    min_y = tl[1] # original Y offset - 10 meters\n",
    "    max_y = br[1] # original Y offset + 10 meters + 140 meters\n",
    "    # (min_x, min_y), (max_x, max_y)\n",
    "    # (bl, tr)\n",
    "    return [(min_x, min_y), (max_x, max_y)]\n",
    " \n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)\n",
    "\n",
    "def identify_clouds(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        cloud_request = WmsRequest(\n",
    "            layer='CLOUD_DETECTION',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=142,\n",
    "            height=142,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.5,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        cloud_img = cloud_request.get_data()\n",
    "        cloud_probs = cloud_detector.get_cloud_probability_maps(np.array(cloud_img))\n",
    "        means = np.mean(cloud_probs, (1, 2))\n",
    "        cloud_steps = [i for i, val in enumerate(means) if val > 0.20]\n",
    "        return cloud_steps, means, cloud_probs\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(bbox, epsg = EPSG):\n",
    "    #bbox = modify_bbox(bbox, expansion = 10)\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=144,\n",
    "                         height=144,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, 144, 144)),\n",
    "                  np.full((144, 144), 10), np.full((144, 144), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((144,144, 1))\n",
    "    dem_image = dem_image[1:143, 1:143, :]\n",
    "    return dem_image #/ np.max(dem_image)\n",
    "\n",
    "\n",
    "    \n",
    "def download_tiles(bbox, clean_steps, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        clean_steps = np.argwhere(clean_steps <= 0.2)\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WmsRequest(\n",
    "                layer='ALL_BANDS_NDVI',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                width=142,\n",
    "                height=142,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.50,\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        img_bands = np.array(img_bands)\n",
    "        print(\"There are {}/{} clean steps\".format(len(clean_steps), len(img_bands)))\n",
    "        num_broken_steps = 0\n",
    "        for date in range(img_bands.shape[0]):\n",
    "            if date in clean_steps:\n",
    "                for band in range(10):\n",
    "                    uniques = [len(np.unique(img_bands[i, :, :, band])) for i in range(img_bands.shape[0])]\n",
    "                    maxs = np.max(img_bands[date, :, :, band])\n",
    "                    mins = np.min(img_bands[date, :, :, band])\n",
    "                    if maxs >= 1.0 or mins <= 0.0:\n",
    "                        num_broken_steps += 1\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = img_bands[date + int(before), :, :, band]\n",
    "                        after = img_bands[date + int(after), :, :, band]\n",
    "                        img_bands[date, :, :, band] = (before + after) / 2\n",
    "                    if len(np.unique(img_bands[date, :, :, band])) <= 3:\n",
    "                        num_broken_steps += 1\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = img_bands[date + int(before), :, :, band]\n",
    "                        after = img_bands[date + int(after), :, :, band]\n",
    "                        img_bands[date, :, :, band] = (before + after) / 2\n",
    "        print(\"{} broken normal steps\".format(num_broken_steps))\n",
    "        return img_bands, image_request\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "        \n",
    "    \n",
    "def calculate_and_save_best_images(img_bands, image_request, means, year = year):\n",
    "    # Identify the date of the imagery\n",
    "    image_dates = []\n",
    "    for date in image_request.get_dates():\n",
    "        if date.year == year - 1:\n",
    "            image_dates.append(-360 + (date.month-1)*30 + date.day)\n",
    "        if date.year == year:\n",
    "            image_dates.append((date.month-1)*30 + date.day)\n",
    "        if date.year == year + 1:\n",
    "            image_dates.append(365 + (date.month-1)*30+date.day)\n",
    "        #image_dates.append((date.year - 2018)*395 + date.month*30 + date.day)\n",
    "    #print(image_dates)\n",
    "\n",
    "    biweekly_dates = [day for day in range(0, 360, 15)] # ideal imagery dates are every 15 days\n",
    "    \n",
    "    # Identify the dates where there is < 20% cloud cover\n",
    "    satisfactory_ids = list(np.argwhere(np.array(means) < 4.).reshape(-1, )) \n",
    "    satisfactory_dates = [value for idx, value in enumerate(image_dates) if idx in satisfactory_ids]\n",
    "    \n",
    "    \n",
    "    selected_images = {}\n",
    "    for i in biweekly_dates:\n",
    "        distances = [abs(date - i) for date in satisfactory_dates]\n",
    "        closest = np.min(distances)\n",
    "        closest_id = np.argmin(distances)\n",
    "        # If there is imagery within 8 days, select it\n",
    "        if closest < 8:\n",
    "            date = satisfactory_dates[closest_id]\n",
    "            image_idx = int(np.argwhere(np.array(image_dates) == date)[0])\n",
    "            selected_images[i] = {'image_date': [date], 'image_ratio': [1], 'image_idx': [image_idx]}\n",
    "        # If there is not imagery within 8 days, look for the closest above and below imagery\n",
    "        else:\n",
    "            distances = np.array([(date - i) for date in satisfactory_dates])\n",
    "            # Number of days above and below the selected date of the nearest clean imagery\n",
    "            above = distances[np.where(distances < 0, distances, -np.inf).argmax()]\n",
    "            below = distances[np.where(distances > 0, distances, np.inf).argmin()]\n",
    "            if abs(above) > 100: # If date is the last date, occassionally argmax would set above to - number\n",
    "                above = below\n",
    "            if abs(below) > 100:\n",
    "                below = above\n",
    "            if above != below:\n",
    "                below_ratio = above / (above - below)\n",
    "                above_ratio = 1 - below_ratio\n",
    "            else:\n",
    "                above_ratio = below_ratio = 0.5\n",
    "                \n",
    "            # Extract the image date and imagery index for the above and below values\n",
    "            above_date = i + above\n",
    "            above_image_idx = int(np.argwhere(np.array(image_dates) == above_date)[0])\n",
    "            \n",
    "            below_date = i + below\n",
    "            below_image_idx = int(np.argwhere(np.array(image_dates) == below_date)[0])\n",
    "            \n",
    "            selected_images[i] = {'image_date': [above_date, below_date], 'image_ratio': [above_ratio, below_ratio],\n",
    "                                 'image_idx': [above_image_idx, below_image_idx]}\n",
    "                            \n",
    "    #for i in selected_images.keys():\n",
    "    #    print(i, selected_images[i])\n",
    "        \n",
    "    keep_steps = []\n",
    "    for i in selected_images.keys():\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "        if len(info['image_idx']) == 2:\n",
    "            step1 = img_bands[info['image_idx'][0]] * info['image_ratio'][0]\n",
    "            step2 = img_bands[info['image_idx'][1]] * info['image_ratio'][1]\n",
    "            step = step1 + step2\n",
    "        keep_steps.append(step)\n",
    "        \n",
    "    keep_steps = np.stack(keep_steps)\n",
    "    return keep_steps\n",
    "\n",
    "def calc_best(tiles, cloud_probs, request, offset_x, offset_y):\n",
    "    c_probs = cloud_probs[:, offset_x:offset_x+16, offset_y:offset_y+16]\n",
    "    images = np.stack(tiles)[:, offset_x:offset_x+16, offset_y:offset_y+16]\n",
    "    mins = np.min(c_probs, axis = 0)\n",
    "    c_probs = c_probs - mins\n",
    "    # Calculating the number of pixels in the 16x16 window that are 0.3 above min cloud probability\n",
    "    args = np.array([len(np.argwhere(c_probs[x, :, :].reshape(16*16) > 0.3)) for x in range(c_probs.shape[0])])\n",
    "    print(len([x for x in args if x > 3]))\n",
    "    best = calculate_and_save_best_images(images, request, args)\n",
    "    return best\n",
    "\n",
    "def speyediff(N, d, format = 'csc'):\n",
    "    shape = (N-d, N)\n",
    "    diagonals = np.zeros(2*d + 1)\n",
    "    diagonals[d] = 1.\n",
    "    for i in range(d):\n",
    "        diff = diagonals[:-1] - diagonals[1:]\n",
    "        diagonals = diff\n",
    "    offsets = np.arange(d+1)\n",
    "    spmat = sparse.diags(diagonals, offsets, shape, format = format)\n",
    "    return spmat\n",
    "\n",
    "def smooth(y, lmbd, d = 2):\n",
    "    m = len(y)\n",
    "    E = sparse.eye(m, format = 'csc')\n",
    "    D = speyediff(m, d, format = 'csc')\n",
    "    coefmat = E + lmbd * D.conj().T.dot(D)\n",
    "    z = splu(coefmat).solve(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(38.306228099454614, 13.667784864997554), (38.17721999999999, 13.540809999999999)]\n"
     ]
    }
   ],
   "source": [
    "coords = (13.540810, 38.177220) # tigray\n",
    "#coords = (-1.726374, 37.440204) # makueni\n",
    "#coords = (-1.515869, 29.952997) # rwanda\n",
    "coords = (coords[1], coords[0])\n",
    "OUTPUT_FOLDER = '../data/tigray2/'\n",
    "#13.567962754335872\n",
    "\n",
    "borders = bounding_box(coords, 10*1400, 10*1400, expansion = 0)\n",
    "print(borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this needs the first coordinate to not be [coords] for different y steps\n",
    "\n",
    "def calculate_offset_coords(coords, x_step, y_step, number):\n",
    "    offset_coords = []\n",
    "    y_coord = bounding_box(coords, x_step, y_step, expansion = 0)\n",
    "    y_coord = y_coord[0][1]\n",
    "    for i in range(number):\n",
    "        bbx = bounding_box(coords, (i+1)*x_step, y_step, expansion = 10)\n",
    "        coord_x = bbx[0][0]\n",
    "        coord_y = y_coord\n",
    "        offset_coords.append((coord_x, coord_y))\n",
    "    coords = [(coords[0], y_coord)]\n",
    "    return coords + offset_coords\n",
    "\n",
    "corner_coordinates = []\n",
    "for row in range(0, 20):\n",
    "    temp = calculate_offset_coords(coords, x_step = 1400, \n",
    "                                            y_step = row*1400, \n",
    "                                            number = 20)\n",
    "    corner_coordinates.append([[x, [y, row]] for x, y in zip(temp, [col for col in range(0, 20)])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers(sample):\n",
    "    for date in range(24):\n",
    "        for band in range(10):\n",
    "            maxs = np.max(sample[date, :, :, band])\n",
    "            mins = np.min(sample[date, :, :, band])\n",
    "            if maxs == 1.0 or mins == 0.0:\n",
    "                print(\"Found null outlier\")\n",
    "                return True\n",
    "            if maxs == mins:\n",
    "                print(\"Found missing outlier\")\n",
    "                return True\n",
    "            if maxs >= 1.05 or mins <= -1.05:\n",
    "                print(\"Found range outlier\")\n",
    "                return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def calculate_proximal_steps(uniques, date, clean_steps):\n",
    "    arg_before = None\n",
    "    arg_after = None\n",
    "    uniques = np.array(uniques)\n",
    "    satisfactory = np.argwhere(uniques > 2)\n",
    "    satisfactory = np.array([x for x in satisfactory if x in clean_steps])\n",
    "    if date > 0:\n",
    "        idx_before = satisfactory - date\n",
    "        arg_before = idx_before[np.where(idx_before < 0, idx_before, -np.inf).argmax()]\n",
    "    if date < np.max(satisfactory):\n",
    "        idx_after = satisfactory - date\n",
    "        arg_after = idx_after[np.where(idx_after > 0, idx_after, np.inf).argmin()]\n",
    "    if not arg_after and not arg_before:\n",
    "        arg_after = date\n",
    "        arg_before = date\n",
    "    if not arg_after:\n",
    "        arg_after = arg_before\n",
    "    if not arg_before:\n",
    "        arg_before = arg_after\n",
    "    print(arg_before, date, arg_after)\n",
    "    return arg_before, arg_after\n",
    "\n",
    "def worker_download(coord, folder = OUTPUT_FOLDER):\n",
    "    idx_x = coord[1][0]\n",
    "    idx_y = coord[1][1]\n",
    "    print(\"Starting: {} {}\".format(idx_x, idx_y))\n",
    "    #coord = [x[0] for x in coord]\n",
    "    coord = coord[0]\n",
    "    output_folder = OUTPUT_FOLDER + \"{}/{}/\".format(str(idx_y), str(idx_x))\n",
    "    if not os.path.exists(os.path.realpath(output_folder)):\n",
    "        os.makedirs(os.path.realpath(output_folder))\n",
    "    tiled_bbx = bounding_box(coord, y_offset_max = 1400, x_offset_max = 1400, expansion = 10)\n",
    "    dem_bbx = bounding_box(coord, y_offset_max = 1400, x_offset_max = 1400, expansion = 20)\n",
    "    cloud_steps, means, cloud_probs = identify_clouds(tiled_bbx)\n",
    "    tiles, request = download_tiles(tiled_bbx, means)\n",
    "    dem = download_dem(dem_bbx)\n",
    "    dem = np.tile(dem.reshape((1, 142, 142, 1)), (24, 1, 1, 1))\n",
    "    \n",
    "    for x_offset, cval in enumerate([x for x in range(0, 140, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(0, 140, 14)]):\n",
    "            # Calculate the best 24-snapshot sequence for the 16x16 tile\n",
    "            x = calc_best(tiles, cloud_probs, request, cval, rval)\n",
    "            # Download and extract the DEM\n",
    "            dem_i = dem[:, cval:cval+16, rval:rval+16, 0]\n",
    "            x = np.concatenate([x, dem_i[:, :, :, np.newaxis]], axis = -1)\n",
    "            # Remove and copy blank time steps\n",
    "            x = remove_blank_steps(x)\n",
    "            if x.shape[1] != 16:\n",
    "                print(\"Image size error on {} {}\".format(idx_x, idx_y))\n",
    "            # Check for missing bands and copy the prior timestep forward if missing\n",
    "            for date in range(24):\n",
    "                for band in range(10):\n",
    "                    uniques = [len(np.unique(x[i, :, :, band])) for i in range(24)]\n",
    "                    clean_steps = [x for x in range(0, len(uniques))]\n",
    "                    maxs = np.max(x[date, :, :, band])\n",
    "                    mins = np.min(x[date, :, :, band])\n",
    "                    if maxs >= 1.0 or mins <= 0.0:\n",
    "                        print(\"Found null outlier at {} {}\".format(date, band))\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = x[date + int(before), :, :, band]\n",
    "                        after = x[date + int(after), :, :, band]\n",
    "                        x[date, :, :, band] = (before + after) / 2\n",
    "                    if len(np.unique(x[date, :, :, band])) <= 3:\n",
    "                        print(\"Found missing outlier at {} {}, {}\".format(date, band, maxs))\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = x[date + int(before), :, :, band]\n",
    "                        after = x[date + int(after), :, :, band]\n",
    "                        x[date, :, :, band] = (before + after) / 2\n",
    "            # Calculate spectral indices after dealing with missing data issues\n",
    "            x = evi(x, True)\n",
    "            #x = savi(x, True)\n",
    "            x = bi(x, True)\n",
    "            x = msavi2(x, True)\n",
    "            x = si(x, True)\n",
    "            \n",
    "            # Smooth all data except slope\n",
    "            x[:, :, :, 10] /= 90\n",
    "            for row in range(0, 16):\n",
    "                for column in range(0, 16):\n",
    "                    for band in [x for x in range(0, 15) if x != 10]:\n",
    "                        sm = smooth(x[:, row, column, band], 1.0, d = 2)\n",
    "                        x[:, row, column, band] = sm\n",
    "        \n",
    "            np.save(output_folder + str(x_offset*10+y_offset+1), x)\n",
    "    \n",
    "    # Do the same for the corner offset imagery\n",
    "    for x_offset, cval in enumerate([x for x in range(7, 133, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(7, 133, 14)]):\n",
    "            x = calc_best(tiles, cloud_probs, request, cval, rval)\n",
    "            dem_i = dem[:, cval:cval+16, rval:rval+16, 0]\n",
    "            x = np.concatenate([x, dem_i[:, :, :, np.newaxis]], axis = -1)\n",
    "            x = remove_blank_steps(x)\n",
    "            if x.shape[1] != 16:\n",
    "                print(\"Image size error on {} {}\".format(idx_x, idx_y))\n",
    "            for date in range(24):\n",
    "                for band in range(10):\n",
    "                    maxs = np.max(x[date, :, :, band])\n",
    "                    mins = np.min(x[date, :, :, band])\n",
    "                    uniques = [len(np.unique(x[i, :, :, band])) for i in range(24)]\n",
    "                    clean_steps = [x for x in range(0, len(uniques))]\n",
    "                    if maxs >= 1.0 or mins <= 0.0:\n",
    "                        print(\"Found null outlier at {} {}\".format(date, band))\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = x[date + int(before), :, :, band]\n",
    "                        after = x[date + int(after), :, :, band]\n",
    "                        x[date, :, :, band] = (before + after) / 2\n",
    "                    if len(np.unique(x[date, :, :, band])) <= 5:\n",
    "                        print(\"Found missing outlier at {} {}\".format(date, band))\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = x[date + int(before), :, :, band]\n",
    "                        after = x[date + int(after), :, :, band]\n",
    "                        x[date, :, :, band] = (before + after) / 2\n",
    "            x = evi(x, True)\n",
    "            x = bi(x, True)\n",
    "            x = msavi2(x, True)\n",
    "            x = si(x, True)\n",
    "            x[:, :, :, 10] /= 90\n",
    "            \n",
    "            for row in range(0, 16):\n",
    "                for column in range(0, 16):\n",
    "                    for band in [x for x in range(0, 15) if x != 10]:\n",
    "                        sm = smooth(x[:, row, column, band], 1.0, d = 2)\n",
    "                        x[:, row, column, band] = sm\n",
    "            np.save(output_folder + str(100+(x_offset*9+y_offset+1)), x)\n",
    "    \n",
    "    # Right offset\n",
    "    for x_offset, cval in enumerate([x for x in range(7, 133, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(0, 140, 14)]):\n",
    "            x = calc_best(tiles, cloud_probs, request, cval, rval)\n",
    "            dem_i = dem[:, cval:cval+16, rval:rval+16, 0]\n",
    "            x = np.concatenate([x, dem_i[:, :, :, np.newaxis]], axis = -1)\n",
    "            x = remove_blank_steps(x)\n",
    "            if x.shape[1] != 16:\n",
    "                print(\"Image size error on {} {}\".format(idx_x, idx_y))\n",
    "            for date in range(24):\n",
    "                for band in range(10):\n",
    "                    maxs = np.max(x[date, :, :, band])\n",
    "                    mins = np.min(x[date, :, :, band])\n",
    "                    uniques = [len(np.unique(x[i, :, :, band])) for i in range(24)]\n",
    "                    clean_steps = [x for x in range(0, len(uniques))]\n",
    "                    if maxs >= 1.0 or mins <= 0.0:\n",
    "                        print(\"Found null outlier at {} {}\".format(date, band))\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = x[date + int(before), :, :, band]\n",
    "                        after = x[date + int(after), :, :, band]\n",
    "                        x[date, :, :, band] = (before + after) / 2\n",
    "                    if len(np.unique(x[date, :, :, band])) <= 5:\n",
    "                        print(\"Found missing outlier at {} {}\".format(date, band))\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = x[date + int(before), :, :, band]\n",
    "                        after = x[date + int(after), :, :, band]\n",
    "                        x[date, :, :, band] = (before + after) / 2\n",
    "            x = evi(x, True)\n",
    "            x = bi(x, True)\n",
    "            x = msavi2(x, True)\n",
    "            x = si(x, True)\n",
    "            x[:, :, :, 10] /= 90\n",
    "            \n",
    "            for row in range(0, 16):\n",
    "                for column in range(0, 16):\n",
    "                    for band in [x for x in range(0, 15) if x != 10]:\n",
    "                        sm = smooth(x[:, row, column, band], 1.0, d = 2)\n",
    "                        x[:, row, column, band] = sm\n",
    "            np.save(output_folder + str(100+81+(x_offset*10+y_offset+1)), x)\n",
    "          \n",
    "    # Up offset\n",
    "    for x_offset, cval in enumerate([x for x in range(0, 140, 14)]):\n",
    "        for y_offset, rval in enumerate([x for x in range(7, 133, 14)]):\n",
    "            print(\"U: {} {}\".format(x_offset, y_offset))\n",
    "            x = calc_best(tiles, cloud_probs, request, cval, rval)\n",
    "            dem_i = dem[:, cval:cval+16, rval:rval+16, 0]\n",
    "            x = np.concatenate([x, dem_i[:, :, :, np.newaxis]], axis = -1)\n",
    "            x = remove_blank_steps(x)\n",
    "            if x.shape[1] != 16:\n",
    "                print(\"Image size error on {} {}\".format(idx_x, idx_y))\n",
    "            for date in range(24):\n",
    "                for band in range(10):\n",
    "                    maxs = np.max(x[date, :, :, band])\n",
    "                    mins = np.min(x[date, :, :, band])\n",
    "                    uniques = [len(np.unique(x[i, :, :, band])) for i in range(24)]\n",
    "                    clean_steps = [x for x in range(0, len(uniques))]\n",
    "                    if maxs >= 1.0 or mins <= 0.0:\n",
    "                        print(\"Found null outlier at {} {}\".format(date, band))\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = x[date + int(before), :, :, band]\n",
    "                        after = x[date + int(after), :, :, band]\n",
    "                        x[date, :, :, band] = (before + after) / 2\n",
    "                    if len(np.unique(x[date, :, :, band])) <= 5:\n",
    "                        print(\"Found missing outlier at {} {}\".format(date, band))\n",
    "                        before, after = calculate_proximal_steps(uniques, date, clean_steps)\n",
    "                        before = x[date + int(before), :, :, band]\n",
    "                        after = x[date + int(after), :, :, band]\n",
    "                        x[date, :, :, band] = (before + after) / 2\n",
    "            #x = ndvi(x, True)\n",
    "            x = evi(x, True)\n",
    "            #x = savi(x, True)\n",
    "            x = bi(x, True)\n",
    "            x = msavi2(x, True)\n",
    "            x = si(x, True)\n",
    "            x[:, :, :, 10] /= 90\n",
    "            \n",
    "            for row in range(0, 16):\n",
    "                for column in range(0, 16):\n",
    "                    for band in [x for x in range(0, 15) if x != 10]:\n",
    "                        sm = smooth(x[:, row, column, band], 1.0, d = 2)\n",
    "                        x[:, row, column, band] = sm\n",
    "            np.save(output_folder + str(100+81+90+(x_offset*9+y_offset+1)), x)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 3 0\n",
      "Starting: 0 0\n",
      "Starting: 1 0\n",
      "Starting: 4 0\n",
      "Starting: 2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-0d360512f429>\", line 10, in <module>\n",
      "    zip(*pool.map(worker_download, i[START_X:]))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 266, in map\n",
      "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 638, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 635, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 551, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "START_Y = 0\n",
    "START_X = 0\n",
    "\n",
    "import multiprocessing\n",
    "for i in corner_coordinates[START_Y:]:\n",
    "    try:\n",
    "        threads = 5\n",
    "        pool = multiprocessing.Pool(threads)\n",
    "        zip(*pool.map(worker_download, i[START_X:]))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    except Exception as e:\n",
    "        print(\"error\")\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 0 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8334e75c14df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mworker_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorner_coordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-844cc4692353>\u001b[0m in \u001b[0;36mworker_download\u001b[0;34m(coord, folder)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mtiled_bbx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbounding_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_offset_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpansion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mdem_bbx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbounding_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_offset_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpansion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mcloud_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloud_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentify_clouds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiled_bbx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mtiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_tiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiled_bbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mdem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdem_bbx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-77f86c5d7c6c>\u001b[0m in \u001b[0;36midentify_clouds\u001b[0;34m(bbox, epsg, time)\u001b[0m\n\u001b[1;32m     80\u001b[0m         )\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mcloud_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloud_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mcloud_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloud_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cloud_probability_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/sentinelhub/data_request.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, save_data, data_filter, redownload, max_threads, raise_download_errors)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_data_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_download_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_saved_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_download_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/sentinelhub/data_request.py\u001b[0m in \u001b[0;36m_execute_data_download\u001b[0;34m(self, data_filter, redownload, max_threads, raise_download_errors)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_download_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSHConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_timeout_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/sentinelhub/download.py\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m(request_list, redownload, max_threads)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_threads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_download_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequest_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for r in range(0, 10):\n",
    "    for c in range(0, 10):\n",
    "        worker_download(corner_coordinates[r][c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 0 0\n",
      "Starting: 11 0\n",
      "Starting: 12 0\n",
      "Starting: 13 0\n",
      "Starting: 14 0\n",
      "Starting: 15 0\n",
      "Starting: 16 0\n",
      "Starting: 17 0\n",
      "Starting: 18 0\n",
      "Starting: 19 0\n",
      "There are 64/74 clean steps\n",
      "0 broken normal steps\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (74,16,16) (142,142) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d6f70c139d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mworker_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorner_coordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-844cc4692353>\u001b[0m in \u001b[0;36mworker_download\u001b[0;34m(coord, folder)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m140\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# Calculate the best 24-snapshot sequence for the 16x16 tile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloud_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;31m# Download and extract the DEM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mdem_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5b30bbb5124e>\u001b[0m in \u001b[0;36mcalc_best\u001b[0;34m(tiles, cloud_probs, request, offset_x, offset_y)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mc_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_probs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_and_save_best_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (74,16,16) (142,142) "
     ]
    }
   ],
   "source": [
    "worker_download(corner_coordinates[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-toolkit",
   "language": "python",
   "name": "policy-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
