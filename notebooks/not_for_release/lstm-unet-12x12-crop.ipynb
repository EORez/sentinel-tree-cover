{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import itertools\n",
    "from tflearn.layers.conv import global_avg_pool\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.layers import batch_normalization\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGRUCell(tf.nn.rnn_cell.RNNCell):\n",
    "  \"\"\"A GRU cell with convolutions instead of multiplications.\"\"\"\n",
    "\n",
    "  def __init__(self, shape, filters, kernel, padding = 'SAME', activation=tf.tanh, normalize=False, data_format='channels_last', reuse=None):\n",
    "    super(ConvGRUCell, self).__init__(_reuse=reuse)\n",
    "    self._filters = filters\n",
    "    self._kernel = kernel\n",
    "    self._activation = activation\n",
    "    self._normalize = normalize\n",
    "    self._padding = padding\n",
    "    if data_format == 'channels_last':\n",
    "        self._size = tf.TensorShape(shape + [self._filters])\n",
    "        self._feature_axis = self._size.ndims\n",
    "        self._data_format = None\n",
    "    elif data_format == 'channels_first':\n",
    "        self._size = tf.TensorShape([self._filters] + shape)\n",
    "        self._feature_axis = 0\n",
    "        self._data_format = 'NC'\n",
    "    else:\n",
    "        raise ValueError('Unknown data_format')\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._size\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._size\n",
    "\n",
    "  def call(self, x, h):\n",
    "    channels = x.shape[self._feature_axis].value\n",
    "\n",
    "    with tf.variable_scope('gates'):\n",
    "      inputs = tf.concat([x, h], axis=self._feature_axis)\n",
    "      n = channels + self._filters\n",
    "      m = 2 * self._filters if self._filters > 1 else 2\n",
    "      W = tf.get_variable('kernel', self._kernel + [n, m])\n",
    "      y = tf.nn.convolution(inputs, W, self._padding, data_format=self._data_format)\n",
    "      if self._normalize:\n",
    "        r, u = tf.split(y, 2, axis=self._feature_axis)\n",
    "        r = tf.contrib.layers.layer_norm(r)\n",
    "        u = tf.contrib.layers.layer_norm(u)\n",
    "      else:\n",
    "        y += tf.get_variable('bias', [m], initializer=tf.ones_initializer())\n",
    "        r, u = tf.split(y, 2, axis=self._feature_axis)\n",
    "      r, u = tf.sigmoid(r), tf.sigmoid(u)\n",
    "\n",
    "    with tf.variable_scope('candidate'):\n",
    "      inputs = tf.concat([x, r * h], axis=self._feature_axis)\n",
    "      n = channels + self._filters\n",
    "      m = self._filters\n",
    "      W = tf.get_variable('kernel', self._kernel + [n, m])\n",
    "      y = tf.nn.convolution(inputs, W, self._padding, data_format=self._data_format)\n",
    "      if self._normalize:\n",
    "        y = tf.contrib.layers.layer_norm(y)\n",
    "      else:\n",
    "        y += tf.get_variable('bias', [m], initializer=tf.zeros_initializer())\n",
    "      h = u * h + (1 - u) * self._activation(y)\n",
    "\n",
    "    return h, h\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "def norm(x, norm_type, is_train, G=32, esp=1e-5, scope = 'gn'):\n",
    "    with tf.variable_scope('{}_norm{}'.format(norm_type, scope)):\n",
    "        if norm_type == 'none':\n",
    "            output = x\n",
    "        elif norm_type == 'batch':\n",
    "            output = tf.contrib.layers.batch_norm(\n",
    "                x, center=True, scale=True, decay=0.999,\n",
    "                is_training=is_train, updates_collections=None\n",
    "            )\n",
    "        elif norm_type == 'group':\n",
    "            # normalize\n",
    "            # tranpose: [bs, h, w, c] to [bs, c, h, w] following the paper\n",
    "            x = tf.transpose(x, [0, 3, 1, 2])\n",
    "            N, C, H, W = x.get_shape().as_list()\n",
    "            G = min(G, C)\n",
    "            x = tf.reshape(x, [-1, G, C // G, H, W])\n",
    "            mean, var = tf.nn.moments(x, [2, 3, 4], keep_dims=True)\n",
    "            x = (x - mean) / tf.sqrt(var + esp)\n",
    "            # per channel gamma and beta\n",
    "            gamma = tf.Variable(tf.constant(1.0, shape=[C]), dtype=tf.float32, name='gamma')\n",
    "            beta = tf.Variable(tf.constant(0.0, shape=[C]), dtype=tf.float32, name='beta')\n",
    "            gamma = tf.reshape(gamma, [1, C, 1, 1])\n",
    "            beta = tf.reshape(beta, [1, C, 1, 1])\n",
    "\n",
    "            output = tf.reshape(x, [-1, C, H, W]) * gamma + beta\n",
    "            # tranpose: [bs, c, h, w, c] to [bs, h, w, c] following the paper\n",
    "            output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    return output\n",
    "\n",
    "def Batch_Normalization(x, training, scope):\n",
    "    return batch_normalization(inputs=x, momentum = 0.9, training=training, renorm = True, reuse=None, name = scope)\n",
    "        #return tf.cond(training,\n",
    "         #              lambda : batch_normalization(inputs=x, momentum = 0.9, training=True, reuse=None, name = scope),\n",
    "        #               lambda : batch_normalization(inputs=x, momentum=0.9, training=False, reuse=True, name = scope))\n",
    "\n",
    "        \n",
    "#def Batch_Normalization(x, training, groups, scope):\n",
    "#    print(x)\n",
    "#    return norm(x = x, norm_type = 'group', is_train = training, G = groups, scope = scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 14\n",
    "shift_size = 9\n",
    "\n",
    "down_16 = 8\n",
    "down_8 = 16\n",
    "down_4 = 32\n",
    "up_8 = 24\n",
    "up_16 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-1b1a49f60fc7>:46: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "FIRST GRU (?, 24, 12, 12, 16)\n",
      "DOWNSAMPLE (?, 24, 6, 6, 16)\n",
      "SECOND GRU (?, 6, 6, 32)\n",
      "THIRD GRU (?, 3, 3, 64)\n",
      "WARNING:tensorflow:From <ipython-input-2-a2481c416ae9>:96: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-1b1a49f60fc7>:11: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "Down block conv (?, 3, 3, 32)\n",
      "Upblock 8 (?, 6, 6, 24)\n",
      "Up block 16 (?, 12, 12, 16)\n",
      "(?, 12, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "reg = keras.regularizers.l2(0.01)\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 24, image_size, image_size, 13))\n",
    "length = tf.placeholder(tf.int32, shape = (None, 1))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, image_size, image_size))#, 1))\n",
    "\n",
    "length2 = tf.reshape(length, (-1,))\n",
    "is_training = is_training = tf.placeholder_with_default(False, (), 'is_training')\n",
    "\n",
    "def Fully_connected(x, units, layer_name='fully_connected') :\n",
    "    with tf.name_scope(layer_name) :\n",
    "        return tf.layers.dense(inputs=x, use_bias=True, units=units)\n",
    "\n",
    "def Relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def Sigmoid(x):\n",
    "    return tf.nn.sigmoid(x)\n",
    "\n",
    "def Global_Average_Pooling(x):\n",
    "    return global_avg_pool(x, name='Global_avg_pooling')\n",
    "\n",
    "def Squeeze_excitation_layer(input_x, out_dim, ratio, layer_name):\n",
    "    with tf.name_scope(layer_name) :\n",
    "        squeeze = global_avg_pool(input_x)\n",
    "\n",
    "        excitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name+'_fully_connected1')\n",
    "        excitation = Relu(excitation)\n",
    "        excitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name+'_fully_connected2')\n",
    "        excitation = Sigmoid(excitation)\n",
    "\n",
    "        excitation = tf.reshape(excitation, [-1,1,1,out_dim])\n",
    "\n",
    "        scale = input_x * excitation\n",
    "\n",
    "        return scale\n",
    "\n",
    "with tf.variable_scope('10'):\n",
    "    # Downsampling Block 1 (14 x 14)\n",
    "    cell_10 = ConvGRUCell(shape = [image_size, image_size],\n",
    "                   filters = down_16,\n",
    "                   kernel = [3,3],\n",
    "                   padding = 'SAME')\n",
    "\n",
    "    def convGRU(x, cell, ln):\n",
    "        output, final = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell, cell, x, ln, dtype=tf.float32)\n",
    "        output = tf.concat(output, -1)\n",
    "        final = tf.concat(final, -1)\n",
    "        return [output, final]\n",
    "\n",
    "# Return the final state and the output states\n",
    "first_conv = convGRU(inp, cell_10, length2)\n",
    "print(\"FIRST GRU {}\".format(first_conv[0].shape))\n",
    "\n",
    "downsampled = TimeDistributed(MaxPool2D(pool_size = (2, 2)))(first_conv[0])\n",
    "print(\"DOWNSAMPLE {}\".format(downsampled.shape))\n",
    "\n",
    "# Downsampling block 2 (7 x 7)\n",
    "with tf.variable_scope('8'):\n",
    "    cell_7 = ConvGRUCell(shape = [image_size / 2, image_size / 2],\n",
    "                   filters = down_8,\n",
    "                   kernel = [3,3],\n",
    "                   padding = 'SAME')\n",
    "    state_7 = convGRU(downsampled, cell_7, length2)\n",
    "downsampled_4 = TimeDistributed(MaxPool2D(pool_size = (2, 2)))(state_7[0])\n",
    "print(\"SECOND GRU {}\".format(state_7[1].shape))\n",
    "\n",
    "with tf.variable_scope('4'):\n",
    "    cell_4 = ConvGRUCell(shape = [image_size / 4, image_size / 4],\n",
    "                   filters = down_4,\n",
    "                   kernel = [3,3],\n",
    "                   padding = 'SAME')\n",
    "    state_4 = convGRU(downsampled_4, cell_4, length2)\n",
    "print(\"THIRD GRU {}\".format(state_4[1].shape))\n",
    "\n",
    "# 4x4 - 4x4\n",
    "conv_block_7_u = Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', activity_regularizer=reg)(state_4[1])\n",
    "elu_7_u = ELU()(conv_block_7_u)\n",
    "x = Batch_Normalization(elu_7_u, training=is_training, scope = 'bn1')\n",
    "#x = batchnorm(elu_7_u, is_training, 'bn1')\n",
    "squeezed = Squeeze_excitation_layer(input_x = x, out_dim = 32, ratio = 4, layer_name = \"squeezed\")\n",
    "print(\"Down block conv {}\".format(elu_7_u.shape))\n",
    "\n",
    "# 4x4 - 8x8\n",
    "upsampling_8 = tf.keras.layers.Conv2DTranspose(filters = 24, kernel_size = (3, 3), strides=(2, 2), padding='same')(squeezed)\n",
    "concat_8 = Concatenate(axis = -1)([upsampling_8, state_7[1]])\n",
    "padded_8 = ReflectionPadding2D((1, 1))(concat_8)\n",
    "conv_8 = Conv2D(filters = 24,\n",
    "            kernel_size = (3, 3), \n",
    "            padding = 'valid',\n",
    "            activity_regularizer=reg,\n",
    "            )(padded_8)\n",
    "elu_8 = ELU()(conv_8)\n",
    "#bn_8 = batchnorm(elu_8, is_training, 'bn2')\n",
    "bn_8 = Batch_Normalization(elu_8, training=is_training, scope = 'bn8')\n",
    "squeeze_8 = Squeeze_excitation_layer(input_x = bn_8, out_dim = 24, ratio = 4, layer_name = \"squeezed_8\")\n",
    "print(\"Upblock 8 {}\".format(squeeze_8.shape))\n",
    "\n",
    "# 8x8 - 16 x 16\n",
    "upsampling_16 = tf.keras.layers.Conv2DTranspose(filters = 16, kernel_size = (3, 3), strides=(2, 2), padding='same')(squeeze_8)\n",
    "concat_16 = Concatenate(axis = -1)([upsampling_16, first_conv[1]])\n",
    "padded_16 = ReflectionPadding2D((1, 1))(concat_16)\n",
    "conv_16 = Conv2D(filters = 16,\n",
    "            kernel_size = (3, 3), \n",
    "            padding = 'valid',\n",
    "            activity_regularizer=reg,\n",
    "            )(padded_16)\n",
    "elu_16 = ELU()(conv_16)\n",
    "#bn_16 = batchnorm(elu_16, is_training, 'bn3')\n",
    "bn_16 = Batch_Normalization(elu_16, training=is_training, scope = 'bn16')\n",
    "squeezed_16 = Squeeze_excitation_layer(input_x = bn_16, out_dim = 16, ratio = 4, layer_name = \"squeezed_16\")\n",
    "print(\"Up block 16 {}\".format(squeezed_16.shape))\n",
    "\n",
    "#padded = ReflectionPadding2D((1, 1))(squeezed_16)\n",
    "#fm = Conv2D(filters = 12,\n",
    "#            kernel_size = (3, 3), \n",
    "#            padding = 'valid',\n",
    "#            activity_regularizer=reg,\n",
    "#            )(padded)\n",
    "#elu = ELU()(fm)\n",
    "#bn_final = Batch_Normalization(elu, training=is_training, scope = 'bnfinal')\n",
    "#squeezed_16 = Squeeze_excitation_layer(input_x = bn_final, out_dim = 12, ratio = 4, layer_name = \"squeezed_final\")\n",
    "#print(\"Up block conv 3 {}\".format(squeezed_16.shape))\n",
    "# Output layer\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1), \n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid'\n",
    "            )(squeezed_16)\n",
    "print(fm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3024\n",
      "16\n",
      "1512\n",
      "8\n",
      "9216\n",
      "32\n",
      "4608\n",
      "16\n",
      "36864\n",
      "64\n",
      "18432\n",
      "32\n",
      "18432\n",
      "32\n",
      "32\n",
      "32\n",
      "256\n",
      "8\n",
      "256\n",
      "32\n",
      "6912\n",
      "24\n",
      "12096\n",
      "24\n",
      "24\n",
      "24\n",
      "144\n",
      "6\n",
      "144\n",
      "24\n",
      "3456\n",
      "16\n",
      "4608\n",
      "16\n",
      "16\n",
      "16\n",
      "64\n",
      "4\n",
      "64\n",
      "16\n",
      "16\n",
      "1\n",
      "120619\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "9\n",
      "45\n",
      "81\n",
      "117\n",
      "153\n",
      "189\n",
      "225\n",
      "261\n",
      "297\n",
      "333\n",
      "369\n",
      "405\n",
      "441\n",
      "477\n",
      "513\n",
      "549\n",
      "585\n",
      "621\n",
      "657\n",
      "693\n",
      "729\n",
      "765\n",
      "801\n",
      "837\n",
      "873\n",
      "909\n",
      "945\n",
      "981\n",
      "1017\n",
      "1053\n",
      "1089\n",
      "1125\n",
      "1161\n",
      "1197\n",
      "1233\n",
      "1269\n",
      "1305\n",
      "1341\n",
      "1377\n",
      "1413\n",
      "1449\n",
      "1485\n",
      "1521\n",
      "1557\n",
      "1593\n",
      "1629\n",
      "1665\n",
      "1701\n",
      "1737\n",
      "1773\n",
      "1809\n",
      "1845\n",
      "1881\n",
      "1917\n",
      "1953\n",
      "1989\n",
      "2025\n",
      "2061\n",
      "2097\n",
      "2133\n",
      "2169\n",
      "2205\n",
      "2241\n",
      "2277\n",
      "2313\n",
      "2349\n",
      "2385\n",
      "2421\n",
      "2457\n",
      "2493\n",
      "2529\n",
      "2565\n",
      "2601\n",
      "2637\n",
      "2673\n",
      "2709\n",
      "2745\n",
      "2781\n",
      "2817\n",
      "2853\n",
      "2889\n",
      "2925\n",
      "2961\n",
      "2997\n",
      "3033\n",
      "3069\n",
      "3105\n",
      "3141\n",
      "3177\n",
      "3213\n",
      "3249\n",
      "3285\n",
      "3321\n",
      "3357\n",
      "3393\n",
      "3429\n",
      "3465\n",
      "3501\n",
      "3537\n",
      "3573\n",
      "3609\n",
      "3645\n",
      "3681\n",
      "3717\n",
      "3753\n",
      "3789\n",
      "3825\n",
      "3861\n",
      "3897\n",
      "3933\n",
      "3969\n",
      "4005\n",
      "4041\n",
      "4077\n",
      "4113\n",
      "4149\n",
      "4185\n",
      "4221\n",
      "4257\n",
      "4293\n",
      "4329\n",
      "4365\n",
      "4401\n",
      "4437\n",
      "4473\n",
      "4509\n",
      "4545\n",
      "4581\n",
      "4617\n",
      "4653\n",
      "4689\n",
      "4725\n",
      "4761\n",
      "4797\n",
      "4833\n",
      "4869\n",
      "4905\n",
      "4941\n",
      "4977\n",
      "5013\n",
      "5049\n",
      "5085\n",
      "22\n",
      "5121\n",
      "22\n",
      "5157\n",
      "5193\n",
      "5229\n",
      "5265\n",
      "5301\n",
      "5337\n",
      "5373\n",
      "5409\n",
      "5445\n",
      "5481\n",
      "5517\n",
      "5553\n",
      "5589\n",
      "5625\n",
      "5661\n",
      "5697\n",
      "5733\n",
      "5769\n",
      "5805\n",
      "5841\n",
      "5877\n",
      "5913\n",
      "5949\n",
      "5985\n",
      "6021\n",
      "6057\n",
      "6093\n",
      "6129\n",
      "6165\n",
      "6201\n",
      "6237\n",
      "6273\n",
      "6309\n",
      "6345\n",
      "6381\n",
      "6417\n",
      "6453\n",
      "6489\n",
      "6525\n",
      "6561\n",
      "6597\n",
      "6633\n",
      "6669\n",
      "6705\n",
      "6741\n",
      "6777\n",
      "6813\n",
      "6849\n",
      "6885\n",
      "6921\n",
      "6957\n",
      "6993\n",
      "7029\n",
      "7065\n",
      "7101\n",
      "7137\n",
      "7173\n",
      "7209\n",
      "7245\n",
      "7281\n",
      "7317\n",
      "7353\n",
      "7389\n",
      "7425\n",
      "7461\n",
      "7497\n",
      "7533\n",
      "7569\n",
      "7605\n",
      "7641\n",
      "7677\n",
      "7713\n",
      "7749\n",
      "7785\n",
      "7821\n",
      "7857\n",
      "7893\n",
      "7929\n",
      "7965\n",
      "8001\n",
      "8037\n",
      "8073\n",
      "8109\n",
      "8145\n",
      "8181\n",
      "8217\n",
      "8253\n",
      "8289\n",
      "8325\n",
      "8361\n",
      "8397\n",
      "8433\n",
      "8469\n",
      "8505\n",
      "8541\n",
      "8577\n",
      "8613\n",
      "8649\n",
      "8685\n",
      "8721\n",
      "8757\n",
      "8793\n",
      "8829\n",
      "8865\n",
      "8901\n",
      "8937\n",
      "8973\n",
      "9009\n",
      "9045\n",
      "9081\n",
      "9117\n",
      "9153\n",
      "9189\n",
      "9225\n",
      "9261\n",
      "9297\n",
      "9333\n",
      "9369\n",
      "9405\n",
      "9441\n",
      "9477\n",
      "9513\n",
      "9549\n",
      "9585\n",
      "9621\n",
      "9657\n",
      "9693\n",
      "9729\n",
      "9765\n",
      "9801\n",
      "9837\n",
      "9873\n",
      "9909\n",
      "9945\n",
      "9981\n",
      "10017\n",
      "10053\n",
      "10089\n",
      "10125\n",
      "10161\n",
      "10197\n",
      "10233\n",
      "10269\n",
      "10305\n",
      "10341\n",
      "10377\n",
      "10413\n",
      "10449\n",
      "10485\n",
      "10521\n",
      "10557\n",
      "10593\n",
      "10629\n",
      "10665\n",
      "10701\n",
      "10737\n",
      "10773\n",
      "10809\n",
      "10845\n",
      "10881\n",
      "10917\n",
      "10953\n",
      "10989\n",
      "11025\n",
      "11061\n",
      "11097\n",
      "11133\n",
      "11169\n",
      "11205\n",
      "11241\n",
      "11277\n",
      "11313\n",
      "11349\n",
      "11385\n",
      "11421\n",
      "11457\n",
      "11493\n",
      "11529\n",
      "11565\n",
      "11601\n",
      "11637\n",
      "11673\n",
      "11709\n",
      "11745\n",
      "11781\n",
      "11817\n",
      "11853\n",
      "11889\n",
      "11925\n",
      "11961\n",
      "11997\n",
      "12033\n",
      "12069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"../data/subplot.csv\")\n",
    "df1 = pd.read_csv(\"../data/subplot2.csv\")\n",
    "\n",
    "df = df.drop('IMAGERY_TITLE', axis = 1)\n",
    "df1 = df1.drop('IMAGERY_TITLE', axis = 1)\n",
    "df = pd.concat([df, df1], ignore_index = True)\n",
    "df = df.dropna(axis = 0)\n",
    "\n",
    "\n",
    "N_SAMPLES = int(df.shape[0]/196)\n",
    "print(N_SAMPLES)\n",
    "\n",
    "plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "\n",
    "def reconstruct_images(plot_id):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    rows = []\n",
    "    lats = reversed(sorted(subs['LAT'].unique()))\n",
    "    for i, val in enumerate(lats):\n",
    "        subs_lat = subs[subs['LAT'] == val]\n",
    "        subs_lat = subs_lat.sort_values('LON', axis = 0)\n",
    "        rows.append(list(subs_lat['TREE']))\n",
    "    return rows\n",
    "\n",
    "data = [reconstruct_images(x) for x in plot_ids]\n",
    "\n",
    "def remove_blank_steps(array):\n",
    "    to_update = {}\n",
    "    sets = []\n",
    "    for k in range(6):\n",
    "        for i in range(array.shape[0]):\n",
    "            for k in range(array.shape[-1]):\n",
    "                mean = (np.mean(array[i, :, :, k]))\n",
    "                if mean == 0:\n",
    "                    sets.append(i)\n",
    "                    if i < array.shape[0] - 1:\n",
    "                        array[i, :, :, k] = array[i + 1, :, :, k]\n",
    "                    else:\n",
    "                        array[i, :, :, k] = array[i - 1, :, :, k]\n",
    "                if mean == 1:\n",
    "                    sets.append(i)\n",
    "                    if i < array.shape[0] - 1:\n",
    "                        array[i, :, :, k] = array[i + 1, :, :, k]\n",
    "                    else:\n",
    "                        array[i, :, :, k] = array[i - 1, :, :, k]\n",
    "    for i in range(array.shape[0]):\n",
    "        for k in range(array.shape[-1]):\n",
    "            mean = (np.mean(array[i, :, :, k]))\n",
    "            if mean == 0:\n",
    "                if i < array.shape[0] - 2:\n",
    "                    array[i, :, :, k] = array[i + 2, :, :, k]\n",
    "                else:\n",
    "                    array[i, :, :, k] = array[i - 2, :, :, k]\n",
    "            if mean == 1:\n",
    "                if i < array.shape[0] - 2:\n",
    "                    array[i, :, :, k] = array[i + 2, :, :, k]\n",
    "                else:\n",
    "                    array[i, :, :, k] = array[i - 2, :, :, k]\n",
    "    return array\n",
    "\n",
    "import os\n",
    "\n",
    "def ndvi(x):\n",
    "    # (B8 - B4)/(B8 + B4)\n",
    "    ndvis = [(im[:, :, 6] - im[:, :, 2]) / (im[:, :, 6] + im[:, :, 2]) for im in x]\n",
    "    min_ndvi = min([np.min(x) for x in ndvis])\n",
    "    max_ndvi = max([np.max(x) for x in ndvis])\n",
    "    if min_ndvi < -1 or max_ndvi > 1:\n",
    "        print(\"ERROR\")\n",
    "    ndvis = [((x + 1) / 2) for x in ndvis]\n",
    "    min_ndvi = min([np.min(x) for x in ndvis])\n",
    "    max_ndvi = max([np.max(x) for x in ndvis])\n",
    "    x_padding = np.zeros((x.shape[0], image_size, image_size, 1))\n",
    "    x = np.concatenate((x, x_padding), axis = 3)\n",
    "    # Iterate over each time step and add NDVI in as the 11th channel\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i, :, :, 10] = ndvis[i]\n",
    "    return x\n",
    "\n",
    "def evi(x):\n",
    "    # 2.5 x (08 - 04) / (08 + 6 * 04 - 7.5 * 02 + 1)\n",
    "    evis = [2.5 * ((im[:, :, 6] - im[:, :, 2]) / (im[:, :, 6] + 6 * im[:,:, 2] - 7.5 * im[:, :, 0] + 1)) for im in x]\n",
    "    x_padding = np.zeros((x.shape[0], image_size, image_size, 1))\n",
    "    x = np.concatenate((x, x_padding), axis = 3)\n",
    "    # Iterate over each time step and add NDVI in as the 11th channel\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i, :, :, 11] = evis[i]\n",
    "    return x\n",
    "    \n",
    "def savi(x):\n",
    "    # (1.5)(08 - 04)/ (08 + 04 + 0.5)\n",
    "    savis = [(1.5 * im[:, :, 6] - im[:, :, 2]) / (im[:, :, 6] + im[:, :, 2] + 0.5) for im in x]\n",
    "    x_padding = np.zeros((x.shape[0], image_size, image_size, 1))\n",
    "    x = np.concatenate((x, x_padding), axis = 3)\n",
    "    # Iterate over each time step and add NDVI in as the 11th channel\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i, :, :, 12] = savis[i]\n",
    "    return x\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "binary_y = []\n",
    "data_location_x = []\n",
    "data_location_y = []\n",
    "lengths = []\n",
    "\n",
    "def append_shifts(x, y):\n",
    "    data_x.append(x[:, 0:12, 0:12, :])\n",
    "    data_x.append(x[:, 0:12, 1:13, :])\n",
    "    data_x.append(x[:, 0:12, 2:14, :])\n",
    "    data_x.append(x[:, 1:13, 0:12, :])\n",
    "    data_x.append(x[:, 1:13, 1:13, :])\n",
    "    data_x.append(x[:, 1:13, 2:14, :])\n",
    "    data_x.append(x[:, 2:14, 0:12, :])\n",
    "    data_x.append(x[:, 2:14, 1:13, :])\n",
    "    data_x.append(x[:, 2:14, 2:14, :])\n",
    "    data_y.append(y[0:12, 0:12])\n",
    "    data_y.append(y[0:12, 1:13])\n",
    "    data_y.append(y[0:12, 2:14])\n",
    "    data_y.append(y[1:13, 0:12])\n",
    "    data_y.append(y[1:13, 1:13])\n",
    "    data_y.append(y[1:13, 2:14])\n",
    "    data_y.append(y[2:14, 0:12])\n",
    "    data_y.append(y[2:14, 1:13])\n",
    "    data_y.append(y[2:14, 2:14])\n",
    "    for i in range(9):\n",
    "        lengths.append(x.shape[0])\n",
    "\n",
    "# Initiate empty lists to store the X and Y data in\n",
    "\n",
    "\n",
    "# Iterate over each plot\n",
    "pad = True\n",
    "flip = True\n",
    "for i in plot_ids:\n",
    "    # Load the sentinel imagery\n",
    "    x = np.load(\"../data/ids/\" + str(i) + \".npy\")\n",
    "    # Shape check\n",
    "    if x.shape[1] == 14:\n",
    "        x = ndvi(x)                # calc NDVI\n",
    "        x = evi(x)\n",
    "        x = savi(x)\n",
    "        x = remove_blank_steps(x)\n",
    "        y = reconstruct_images(i)\n",
    "        #x = x[:, 1:13, 1:13, :]\n",
    "        y = np.array(y)\n",
    "        #y = y[1:13, 1:13]\n",
    "        if sum([sum(x) for x in y]) >= 1:\n",
    "            binary_y.append(1)\n",
    "        else:\n",
    "            binary_y.append(0)\n",
    "        #x = np.median(x, axis = 0) # and calculate the median over the time steps\n",
    "        if pad:\n",
    "            if x.shape[0] < 24:\n",
    "                print(x.shape[0])\n",
    "                padding = np.zeros((24 - x.shape[0], 14, 14, 13))\n",
    "                x = np.concatenate((x, padding), axis = 0)\n",
    "        append_shifts(x, y)\n",
    "        print(len(data_x))\n",
    "        if flip:\n",
    "                # FLIP HORIZONTAL\n",
    "            x1 = np.flip(x, 1)\n",
    "            append_shifts(x1, np.flip(y, 0))\n",
    "    \n",
    "                # FLIP BOTH\n",
    "            x2 = np.flip(x, 2)\n",
    "            x2 = np.flip(x2, 1)\n",
    "            #data_x.append(x2)\n",
    "            #data_y.append(np.flip(y, [0, 1]))\n",
    "            append_shifts(x2, np.flip(y, [0, 1]))\n",
    "            #lengths.append(x.shape[0])\n",
    "                # FLIP VERTICAL\n",
    "            x3 = np.flip(x, 2)\n",
    "            append_shifts(x3, np.flip(y, 1))\n",
    "            #data_x.append(x3)\n",
    "            #data_y.append(np.flip(y, 1))\n",
    "            #lengths.append(x.shape[0])\n",
    "\n",
    "data_x = np.stack(data_x)\n",
    "data_y = np.stack(data_y)\n",
    "data_y = np.reshape(data_y, (N_SAMPLES*4*9, 12, 12, 1))\n",
    "binary_y = np.stack(binary_y)\n",
    "lengths = np.stack(lengths)\n",
    "lengths = np.reshape(lengths, (lengths.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_foc(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "\n",
    "        return -K.sum(0.5 * K.pow(1. - pt_1, 2) * K.log(pt_1)) \\\n",
    "               -K.sum((1 - 0.5) * K.pow(pt_0, 2) * K.log(1. - pt_0))  \n",
    "    \n",
    "def focal_loss(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    r\"\"\"Compute focal loss for predictions.\n",
    "        Multi-labels Focal loss formula:\n",
    "            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "    Args:\n",
    "     prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing the predicted logits for each class\n",
    "     target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing one-hot encoded classification targets\n",
    "     weights: A float tensor of shape [batch_size, num_anchors]\n",
    "     alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "     gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "    Returns:\n",
    "        loss: A (scalar) tensor representing the value of the loss function\n",
    "    \"\"\"\n",
    "    sigmoid_p = prediction_tensor\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "    \n",
    "    # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "    \n",
    "    # For negative prediction, only need consider back part loss, front part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return tf.reduce_sum(per_entry_cross_ent)\n",
    "\n",
    "def foc_lovasz(y_true, y_pred):\n",
    "    #jaccard_loss = jaccard_distance(y_true, y_pred)\n",
    "    lovasz = lovasz_hinge(y_pred, y_true)\n",
    "    #pred_reshape = tf.reshape(y_pred, (-1, 14, 14))\n",
    "    #true_reshape = tf.reshape(y_true, (-1, 14, 14))\n",
    "    focal_loss = bin_foc(y_true, y_pred)\n",
    "    summed = lovasz + np.log(focal_loss)\n",
    "    return summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thirty_meter(true, pred):\n",
    "    indices_x = [x for x in range(0, 11, 1)]\n",
    "    indices_y = [x for x in range(0, 11, 1)]\n",
    "    perms = [(y, x) for x, y in itertools.product(indices_y, indices_x)]\n",
    "    \n",
    "    #perms = ([list(zip(indices_x, p)) for p in itertools.permutations(indices_y)])\n",
    "    #perms = [item for sublist in perms for item in sublist]\n",
    "    #perms = list(set(perms))\n",
    "    indexes = [([a, a + 1], [b, b + 1]) for a,b in perms]\n",
    "    subs_true = []\n",
    "    subs_pred = []\n",
    "    for i in indexes:\n",
    "        true_i = true[i[0][0]:i[0][1], i[1][0]:i[1][1]]\n",
    "        pred_i = pred[i[0][0]:i[0][1], i[1][0]:i[1][1]]\n",
    "        subs_true.append(true_i)\n",
    "        subs_pred.append(pred_i)\n",
    "    pred = [np.sum(x) for x in subs_pred]\n",
    "    true = [np.sum(x) for x in subs_true]\n",
    "    true_positives = []\n",
    "    false_positives = []\n",
    "    false_negatives = []\n",
    "    for p, t in zip(pred, true):\n",
    "        if p > t:\n",
    "            tp = p - (p - t)\n",
    "            fp = p - tp\n",
    "            fn = 0\n",
    "        if t >= p:\n",
    "            tp = t\n",
    "            fp = 0\n",
    "            fn = t - p\n",
    "        true_positives.append(tp)\n",
    "        false_positives.append(fp)\n",
    "        false_negatives.append(fn)\n",
    "    prec = [x / (x + y) for x,y in zip(true_positives, false_positives) if (x+y) > 0]\n",
    "    prec = [x for x in prec if not np.isnan(x)]\n",
    "    rec = [x / (x + y) for x,y in zip(true_positives, false_negatives) if (x+y) > 0]\n",
    "    rec = [x for x in rec if not np.isnan(x)]\n",
    "    \n",
    "    #recall = [min(x / y, 1) for x, y in zip(pred, true) if y > 0]\n",
    "    #precision = [(y - x) / x for x, y in zip(pred, true)]\n",
    "    #print(precision)\n",
    "    return rec, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "# --------------------------- MULTICLASS LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None, order='BHWC'):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, H, W, C] or [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "      order: use BHWC or BCHW\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(prob_lab):\n",
    "            prob, lab = prob_lab\n",
    "            prob, lab = tf.expand_dims(prob, 0), tf.expand_dims(lab, 0)\n",
    "            prob, lab = flatten_probas(prob, lab, ignore, order)\n",
    "            return lovasz_softmax_flat(prob, lab, classes=classes)\n",
    "        losses = tf.map_fn(treat_image, (probas, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore, order), classes=classes)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, classes='present'):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "    \"\"\"\n",
    "    C = probas.shape[1]\n",
    "    losses = []\n",
    "    present = []\n",
    "    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n",
    "    for c in class_to_sum:\n",
    "        fg = tf.cast(tf.equal(labels, c), probas.dtype)  # foreground for class c\n",
    "        if classes == 'present':\n",
    "            present.append(tf.reduce_sum(fg) > 0)\n",
    "        if C == 1:\n",
    "            if len(classes) > 1:\n",
    "                raise ValueError('Sigmoid output possible only with 1 class')\n",
    "            class_pred = probas[:, 0]\n",
    "        else:\n",
    "            class_pred = probas[:, c]\n",
    "        errors = tf.abs(fg - class_pred)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort_{}\".format(c))\n",
    "        fg_sorted = tf.gather(fg, perm)\n",
    "        grad = lovasz_grad(fg_sorted)\n",
    "        losses.append(\n",
    "            tf.tensordot(errors_sorted, tf.stop_gradient(grad), 1, name=\"loss_class_{}\".format(c))\n",
    "                      )\n",
    "    if len(class_to_sum) == 1:  # short-circuit mean when only one class\n",
    "        return losses[0]\n",
    "    losses_tensor = tf.stack(losses)\n",
    "    if classes == 'present':\n",
    "        present = tf.stack(present)\n",
    "        losses_tensor = tf.boolean_mask(losses_tensor, present)\n",
    "    loss = tf.reduce_mean(losses_tensor)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None, order='BHWC'):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    if len(probas.shape) == 3:\n",
    "        probas, order = tf.expand_dims(probas, 3), 'BHWC'\n",
    "    if order == 'BCHW':\n",
    "        probas = tf.transpose(probas, (0, 2, 3, 1), name=\"BCHW_to_BHWC\")\n",
    "        order = 'BHWC'\n",
    "    if order != 'BHWC':\n",
    "        raise NotImplementedError('Order {} unknown'.format(order))\n",
    "    C = probas.shape[3]\n",
    "    probas = tf.reshape(probas, (-1, C))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vprobas = tf.boolean_mask(probas, valid, name='valid_probas')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vprobas, vlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 0.36791515350341797 Val: 0.3983909785747528 P 0.839312252311757 R 0.6443941666871603 F1 0.7290497803247058\n",
      "Epoch 2: Loss 0.35567453503608704 Val: 0.4085640013217926 P 0.8834405144694534 R 0.6463738533802228 F1 0.7465387455766638\n",
      "Epoch 3: Loss 0.33830463886260986 Val: 0.375378280878067 P 0.8296878188124872 R 0.6867545434424416 F1 0.7514850460403285\n",
      "Epoch 4: Loss 0.3229468762874603 Val: 0.423970490694046 P 0.8222721022405565 R 0.6383690332734919 F1 0.7187433439088123\n",
      "Epoch 5: Loss 0.3137832283973694 Val: 0.3939630687236786 P 0.7316910785619174 R 0.7005508693406782 F1 0.715782444336325\n",
      "Epoch 6: Loss 0.30127233266830444 Val: 0.4258996844291687 P 0.780884527490254 R 0.6847871529400191 F1 0.729685508009517\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-87ecf4c2d50d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m                                                         \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                                                         \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                                         \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                                                         })\n\u001b[1;32m     76\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "def weighted_cross_entropy(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "    y_pred = tf.log(y_pred / (1 - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(logits=y_pred, targets=y_true, pos_weight=2.)\n",
    "\n",
    "    # or reduce_sum and/or axis=-1\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def smooth_jaccard(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth\n",
    "\n",
    "def bce_jaccard(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, (-1, 12, 12, 1))\n",
    "    #y_true = tf.slice(y_true, [0, 1, 1, 0], [-1, 14, 14, -1])\n",
    "    #y_pred = tf.slice(y_pred, [0, 1, 1, 0], [-1, 14, 14, -1])\n",
    "    print(y_true.shape)\n",
    "    return binary_crossentropy(y_true, y_pred) + (0.5 * smooth_jaccard(y_true, y_pred))\n",
    "\n",
    "def bce_lovasz(y_true, y_pred):\n",
    "    return binary_crossentropy(tf.reshape(y_true, (-1, 14, 14, 1)), y_pred) + lovasz_softmax(y_pred, y_true, classes=[1], per_image=False)\n",
    "\n",
    "def foc_jaccard(y_true, y_pred):\n",
    "    y_true_r = tf.reshape(y_true, (-1, 16, 16, 1))\n",
    "    y_pred_r = tf.reshape(y_pred, (-1, 16, 16))\n",
    "    y_true_f = tf.reshape(y_true, (-1, 16*16, 1))\n",
    "    y_pred_f = tf.reshape(y_pred, (-1, 16*16, 1))\n",
    "    jac = smooth_jaccard(y_true_r, y_pred)\n",
    "    foc = focal_loss(y_pred_f, y_true_f, alpha=0.5, gamma=1, weights = weights)\n",
    "    return foc\n",
    "\n",
    "#optimizer = AdaBoundOptimizer(learning_rate=2e-6, final_lr=1e-4, beta1=0.9, beta2=0.999, amsbound=True)\n",
    "#loss2 = bce_jaccard(labels, fm)\n",
    "#\n",
    "#update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "#with tf.control_dependencies(update_ops):\n",
    "#    train_op = optimizer.minimize(loss2)\n",
    "\n",
    "#init_op = tf.global_variables_initializer()\n",
    "#sess.run(init_op)\n",
    "#saver = tf.train.Saver(max_to_keep = 2)\n",
    "\n",
    "# dev --> 225\n",
    "\n",
    "# Run training loop\n",
    "for i in range(100):\n",
    "    randomize = np.arange(1088*9)\n",
    "    np.random.shuffle(randomize)\n",
    "    test_randomize = np.arange(1088*9, 1344*9)\n",
    "    np.random.shuffle(test_randomize)\n",
    "\n",
    "    losses = []\n",
    "    val_loss = []\n",
    "\n",
    "    for k in range(68*4*9):\n",
    "        batch_ids = randomize[k*4:(k+1)*4]\n",
    "        op, tr = sess.run([train_op, loss2], feed_dict={inp: data_x[batch_ids, :, :, :],\n",
    "                                                        length: lengths[batch_ids],\n",
    "                                                        labels: data_y[batch_ids, :, :].reshape(4, 12, 12),\n",
    "                                                        is_training: True\n",
    "                                                        })\n",
    "        losses.append(tr)\n",
    "    for j in range(32*9):\n",
    "        batch_ids = test_randomize[j*8:(j+1)*8]\n",
    "        vl, y = sess.run([loss2, fm], feed_dict={inp: data_x[batch_ids, :, :, :],\n",
    "                                                 length: lengths[batch_ids],\n",
    "                                                 labels: data_y[batch_ids][:, :].reshape(8, 12, 12),\n",
    "                                                 is_training: False,\n",
    "                                                })\n",
    "        val_loss.append(vl)\n",
    "        \n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    for m in range(1088*9, 1344*9):\n",
    "        y = sess.run([fm], feed_dict={inp: data_x[m].reshape(1, 24, 12, 12, 13),\n",
    "                                  length: lengths[m].reshape(1, 1),\n",
    "                                  is_training: False,\n",
    "                                  })[0]\n",
    "        true = data_y[m].reshape((12, 12))\n",
    "        pred = y.reshape((12, 12))\n",
    "        #pred = np.sigmoid(pred)\n",
    "        pred[np.where(pred > 0.45)] = 1\n",
    "        pred[np.where(pred < 0.45)] = 0\n",
    "        rec, prec = thirty_meter(true, pred)\n",
    "        recalls.append(rec)\n",
    "        precisions.append(prec)\n",
    "    precisions = [item for sublist in precisions for item in sublist]\n",
    "    recalls = [item for sublist in recalls for item in sublist]\n",
    "    precision = np.mean(precisions)\n",
    "    recall = np.mean(recalls)\n",
    "    f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "    save_path = saver.save(sess, \"../models/dev/model\")\n",
    "    if np.mean(val_loss) < 0.27:\n",
    "        save_path = saver.save(sess, \"../models/dev_best/model\")\n",
    "    print(\"Epoch {}: Loss {} Val: {} P {} R {} F1 {}\".format(i + 1,\n",
    "                                                             np.mean(losses), np.mean(val_loss),\n",
    "                                                             precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x148bfe940>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = int((len(data_x))*0.8) + (21*9)+6# 105, 25, 215, 90, 140\n",
    "y = sess.run([fm], feed_dict={inp: data_x[idx].reshape(1, 24, 12, 12, 13),\n",
    "                              length: lengths[idx].reshape(1, 1),\n",
    "                              is_training: False,\n",
    "                              })\n",
    "\n",
    "sns.heatmap(data_y[idx][:, :, :].reshape(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x148cbc7f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = y[0][:, :, :].reshape(12, 12)\n",
    "#pred[np.where(pred > 0.3)] = 1\n",
    "sns.heatmap(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recalls = []\n",
    "precisions = []\n",
    "for i in range(1088*9, 1344*9):\n",
    "    y = sess.run([fm], feed_dict={inp: data_x[i].reshape(1, 24, 12, 12, 13),\n",
    "                              length: lengths[i].reshape(1, 1),\n",
    "                              is_training: False,\n",
    "                              })[0]\n",
    "    true = data_y[i].reshape((12, 12))\n",
    "    pred = y.reshape((12, 12))\n",
    "    pred[np.where(pred > 0.4)] = 1\n",
    "    pred[np.where(pred < 0.4)] = 0\n",
    "    rec, prec = thirty_meter(true, pred)\n",
    "    #rec, prec = half_hectare_accuracy(true, pred)\n",
    "    recalls.append(rec)\n",
    "    precisions.append(prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7131544647468214"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls = [item for sublist in recalls for item in sublist]\n",
    "np.mean(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7684733718864573"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions = [item for sublist in precisions for item in sublist]\n",
    "np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AdaBound for TensorFlow.\"\"\"\n",
    "\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import resource_variable_ops\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.ops import variable_scope\n",
    "from tensorflow.python.training import optimizer\n",
    "from tensorflow.python.ops.clip_ops import clip_by_value\n",
    "\n",
    "\"\"\"Implements AdaBound algorithm.\n",
    "    It has been proposed in `Adaptive Gradient Methods with Dynamic Bound of Learning Rate`_.\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): Adam learning rate (default: 1e-3)\n",
    "        betas (Tuple[float, float], optional): coefficients used for computing\n",
    "            running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        final_lr (float, optional): final (SGD) learning rate (default: 0.1)\n",
    "        gamma (float, optional): convergence speed of the bound functions (default: 1e-3)\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "        amsbound (boolean, optional): whether to use the AMSBound variant of this algorithm\n",
    "    .. Adaptive Gradient Methods with Dynamic Bound of Learning Rate:\n",
    "        https://openreview.net/forum?id=Bkg3g2R9FX\n",
    "    \"\"\"\n",
    "\n",
    "class AdaBoundOptimizer(optimizer.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, final_lr=0.1, beta1=0.9, beta2=0.999,\n",
    "                 gamma=1e-3, epsilon=1e-8, amsbound=False,\n",
    "                 use_locking=False, name=\"AdaBound\"):\n",
    "        super(AdaBoundOptimizer, self).__init__(use_locking, name)\n",
    "        self._lr = learning_rate\n",
    "        self._final_lr = final_lr\n",
    "        self._beta1 = beta1\n",
    "        self._beta2 = beta2\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "        self._gamma = gamma\n",
    "        self._amsbound = amsbound\n",
    "\n",
    "        self._lr_t = None\n",
    "        self._beta1_t = None\n",
    "        self._beta2_t = None\n",
    "        self._epsilon_t = None\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        first_var = min(var_list, key=lambda x: x.name)\n",
    "\n",
    "        graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "        create_new = self._get_non_slot_variable(\"beta1_power\", graph) is None\n",
    "        if not create_new and context.in_graph_mode():\n",
    "            create_new = (self._get_non_slot_variable(\"beta1_power\", graph).graph is not first_var.graph)\n",
    "\n",
    "        if create_new:\n",
    "            self._create_non_slot_variable(initial_value=self._beta1,\n",
    "                                           name=\"beta1_power\",\n",
    "                                           colocate_with=first_var)\n",
    "            self._create_non_slot_variable(initial_value=self._beta2,\n",
    "                                           name=\"beta2_power\",\n",
    "                                           colocate_with=first_var)\n",
    "            self._create_non_slot_variable(initial_value=self._gamma,\n",
    "                                           name=\"gamma_multi\",\n",
    "                                           colocate_with=first_var)\n",
    "        # Create slots for the first and second moments.\n",
    "        for v in var_list :\n",
    "            self._zeros_slot(v, \"m\", self._name)\n",
    "            self._zeros_slot(v, \"v\", self._name)\n",
    "            self._zeros_slot(v, \"vhat\", self._name)\n",
    "\n",
    "\n",
    "    def _prepare(self):\n",
    "        self._lr_t = ops.convert_to_tensor(self._lr)\n",
    "        self._base_lr_t = ops.convert_to_tensor(self._lr)\n",
    "        self._beta1_t = ops.convert_to_tensor(self._beta1)\n",
    "        self._beta2_t = ops.convert_to_tensor(self._beta2)\n",
    "        self._epsilon_t = ops.convert_to_tensor(self._epsilon)\n",
    "        self._gamma_t = ops.convert_to_tensor(self._gamma)\n",
    "\n",
    "    def _apply_dense(self, grad, var):\n",
    "        graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "        beta1_power = math_ops.cast(self._get_non_slot_variable(\"beta1_power\", graph=graph), var.dtype.base_dtype)\n",
    "        beta2_power = math_ops.cast(self._get_non_slot_variable(\"beta2_power\", graph=graph), var.dtype.base_dtype)\n",
    "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
    "        base_lr_t = math_ops.cast(self._base_lr_t, var.dtype.base_dtype)\n",
    "        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n",
    "        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n",
    "        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)\n",
    "        gamma_multi = math_ops.cast(self._get_non_slot_variable(\"gamma_multi\", graph=graph), var.dtype.base_dtype)\n",
    "\n",
    "        step_size = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n",
    "        final_lr = self._final_lr * lr_t / base_lr_t\n",
    "        lower_bound = final_lr * (1. - 1. / (gamma_multi + 1.))\n",
    "        upper_bound = final_lr * (1. + 1. / (gamma_multi))\n",
    "\n",
    "        # m_t = beta1 * m + (1 - beta1) * g_t\n",
    "        m = self.get_slot(var, \"m\")\n",
    "        m_scaled_g_values = grad * (1 - beta1_t)\n",
    "        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)\n",
    "\n",
    "        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
    "        v = self.get_slot(var, \"v\")\n",
    "        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n",
    "        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)\n",
    "\n",
    "        # amsgrad\n",
    "        vhat = self.get_slot(var, \"vhat\")\n",
    "        if self._amsbound :\n",
    "            vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n",
    "            v_sqrt = math_ops.sqrt(vhat_t)\n",
    "        else :\n",
    "            vhat_t = state_ops.assign(vhat, vhat)\n",
    "            v_sqrt = math_ops.sqrt(v_t)\n",
    "\n",
    "\n",
    "        # Compute the bounds\n",
    "        step_size_bound = step_size / (v_sqrt + epsilon_t)\n",
    "        bounded_lr = m_t * clip_by_value(step_size_bound, lower_bound, upper_bound)\n",
    "\n",
    "        var_update = state_ops.assign_sub(var, bounded_lr, use_locking=self._use_locking)\n",
    "        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "        beta1_power = math_ops.cast(self._get_non_slot_variable(\"beta1_power\", graph=graph), grad.dtype.base_dtype)\n",
    "        beta2_power = math_ops.cast(self._get_non_slot_variable(\"beta2_power\", graph=graph), grad.dtype.base_dtype)\n",
    "        lr_t = math_ops.cast(self._lr_t, grad.dtype.base_dtype)\n",
    "        base_lr_t = math_ops.cast(self._base_lr_t, var.dtype.base_dtype)\n",
    "        beta1_t = math_ops.cast(self._beta1_t, grad.dtype.base_dtype)\n",
    "        beta2_t = math_ops.cast(self._beta2_t, grad.dtype.base_dtype)\n",
    "        epsilon_t = math_ops.cast(self._epsilon_t, grad.dtype.base_dtype)\n",
    "        gamma_multi = math_ops.cast(self._get_non_slot_variable(\"gamma_multi\", graph=graph), var.dtype.base_dtype)\n",
    "\n",
    "        step_size = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n",
    "        final_lr = self._final_lr * lr_t / base_lr_t\n",
    "        lower_bound = final_lr * (1. - 1. / (gamma_multi + 1.))\n",
    "        upper_bound = final_lr * (1. + 1. / (gamma_multi))\n",
    "\n",
    "        # m_t = beta1 * m + (1 - beta1) * g_t\n",
    "        m = self.get_slot(var, \"m\")\n",
    "        m_scaled_g_values = grad * (1 - beta1_t)\n",
    "        m_t = state_ops.assign(m, beta1_t * m + m_scaled_g_values, use_locking=self._use_locking)\n",
    "\n",
    "        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
    "        v = self.get_slot(var, \"v\")\n",
    "        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n",
    "        v_t = state_ops.assign(v, beta2_t * v + v_scaled_g_values, use_locking=self._use_locking)\n",
    "\n",
    "        # amsgrad\n",
    "        vhat = self.get_slot(var, \"vhat\")\n",
    "        if self._amsbound:\n",
    "            vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n",
    "            v_sqrt = math_ops.sqrt(vhat_t)\n",
    "        else:\n",
    "            vhat_t = state_ops.assign(vhat, vhat)\n",
    "            v_sqrt = math_ops.sqrt(v_t)\n",
    "\n",
    "        # Compute the bounds\n",
    "        step_size_bound = step_size / (v_sqrt + epsilon_t)\n",
    "        bounded_lr = m_t * clip_by_value(step_size_bound, lower_bound, upper_bound)\n",
    "\n",
    "        var_update = state_ops.assign_sub(var, bounded_lr, use_locking=self._use_locking)\n",
    "\n",
    "        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n",
    "\n",
    "    def _apply_sparse_shared(self, grad, var, indices, scatter_add):\n",
    "        graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "        beta1_power = math_ops.cast(self._get_non_slot_variable(\"beta1_power\", graph=graph), var.dtype.base_dtype)\n",
    "        beta2_power = math_ops.cast(self._get_non_slot_variable(\"beta2_power\", graph=graph), var.dtype.base_dtype)\n",
    "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
    "        base_lr_t = math_ops.cast(self._base_lr_t, var.dtype.base_dtype)\n",
    "        beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n",
    "        beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n",
    "        epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)\n",
    "        gamma_t = math_ops.cast(self._gamma_t, var.dtype.base_dtype)\n",
    "\n",
    "        step_size = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n",
    "        final_lr = self._final_lr * lr_t / base_lr_t\n",
    "        lower_bound = final_lr * (1. - 1. / (gamma_t + 1.))\n",
    "        upper_bound = final_lr * (1. + 1. / (gamma_t))\n",
    "\n",
    "        # m_t = beta1 * m + (1 - beta1) * g_t\n",
    "        m = self.get_slot(var, \"m\")\n",
    "        m_scaled_g_values = grad * (1 - beta1_t)\n",
    "        m_t = state_ops.assign(m, m * beta1_t, use_locking=self._use_locking)\n",
    "        with ops.control_dependencies([m_t]):\n",
    "            m_t = scatter_add(m, indices, m_scaled_g_values)\n",
    "\n",
    "        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
    "        v = self.get_slot(var, \"v\")\n",
    "        v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n",
    "        v_t = state_ops.assign(v, v * beta2_t, use_locking=self._use_locking)\n",
    "        with ops.control_dependencies([v_t]):\n",
    "            v_t = scatter_add(v, indices, v_scaled_g_values)\n",
    "\n",
    "        # amsgrad\n",
    "        vhat = self.get_slot(var, \"vhat\")\n",
    "        if self._amsbound:\n",
    "            vhat_t = state_ops.assign(vhat, math_ops.maximum(v_t, vhat))\n",
    "            v_sqrt = math_ops.sqrt(vhat_t)\n",
    "        else:\n",
    "            vhat_t = state_ops.assign(vhat, vhat)\n",
    "            v_sqrt = math_ops.sqrt(v_t)\n",
    "\n",
    "        # Compute the bounds\n",
    "        step_size_bound = step_size / (v_sqrt + epsilon_t)\n",
    "        bounded_lr = m_t * clip_by_value(step_size_bound, lower_bound, upper_bound)\n",
    "\n",
    "        var_update = state_ops.assign_sub(var, bounded_lr, use_locking=self._use_locking)\n",
    "\n",
    "        return control_flow_ops.group(*[var_update, m_t, v_t, vhat_t])\n",
    "\n",
    "    def _apply_sparse(self, grad, var):\n",
    "        return self._apply_sparse_shared(\n",
    "            grad.values, var, grad.indices,\n",
    "            lambda x, i, v: state_ops.scatter_add(  # pylint: disable=g-long-lambda\n",
    "                x, i, v, use_locking=self._use_locking))\n",
    "\n",
    "    def _resource_scatter_add(self, x, i, v):\n",
    "        with ops.control_dependencies(\n",
    "                [resource_variable_ops.resource_scatter_add(x, i, v)]):\n",
    "            return x.value()\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var, indices):\n",
    "        return self._apply_sparse_shared(\n",
    "            grad, var, indices, self._resource_scatter_add)\n",
    "\n",
    "    def _finish(self, update_ops, name_scope):\n",
    "        # Update the power accumulators.\n",
    "        with ops.control_dependencies(update_ops):\n",
    "            graph = None if context.executing_eagerly() else ops.get_default_graph()\n",
    "            beta1_power = self._get_non_slot_variable(\"beta1_power\", graph=graph)\n",
    "            beta2_power = self._get_non_slot_variable(\"beta2_power\", graph=graph)\n",
    "            gamma_multi = self._get_non_slot_variable(\"gamma_multi\", graph=graph)\n",
    "            with ops.colocate_with(beta1_power):\n",
    "                update_beta1 = beta1_power.assign(\n",
    "                    beta1_power * self._beta1_t,\n",
    "                    use_locking=self._use_locking)\n",
    "                update_beta2 = beta2_power.assign(\n",
    "                    beta2_power * self._beta2_t,\n",
    "                    use_locking=self._use_locking)\n",
    "                update_gamma = gamma_multi.assign(\n",
    "                    gamma_multi + self._gamma_t,\n",
    "                    use_locking=self._use_locking)\n",
    "        return control_flow_ops.group(*update_ops + [update_beta1, update_beta2, update_gamma],\n",
    "                                      name=name_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
