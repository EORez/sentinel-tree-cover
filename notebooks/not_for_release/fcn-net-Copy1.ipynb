{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master model development\n",
    "\n",
    "## John Brandt\n",
    "\n",
    "### Last updated: November 1 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Package loading\n",
    "*  Hyperparameter definitions\n",
    "*  Additional layer definitions\n",
    "*  Model definition\n",
    "*  Data loading\n",
    "*  Data preprocessing\n",
    "*  K means clustering\n",
    "*  Augment training data\n",
    "*  Loss definition\n",
    "*  Equibatch creation\n",
    "*  Model training\n",
    "*  Model validation and sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# The model is very sensitive to zoneout prob, do not go above 0.05\n",
    "# AdaBound seems to perform worse, stick to Adam with step down loss\n",
    "# 32 x 24 x 32 model overfits after 100 epochs\n",
    "# Investigate more hypercolumn parametrizations to increase available data at output \n",
    "#    while maintaining low dimensionality of filters\n",
    "# 5e-4 LR worked, investigating 8e-4 for 60% faster training time\n",
    "# ONLY CHANGE ONE THING AT A TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#TODO Remove imports that aren't needed to save RAM\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.keras.layers import Conv2D, Lambda, Dense, Multiply, Add, Bidirectional, ConvLSTM2D\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim import conv2d\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import itertools\n",
    "from tflearn.layers.conv import global_avg_pool\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.layers import batch_normalization\n",
    "from tensorflow.python.util import deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/zoneout.py\n",
    "%run ../src/convgru.py\n",
    "%run ../src/lovasz.py\n",
    "%run ../src/utils.py\n",
    "%run ../src/adabound.py\n",
    "%run ../src/slope.py\n",
    "%run ../src/dropblock.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539 135\n"
     ]
    }
   ],
   "source": [
    "ZONE_OUT_PROB = 0.25\n",
    "L2_REG = 0.0\n",
    "INITIAL_LR = 2e-4\n",
    "FINAL_LR = 1e-3\n",
    "BN_MOMENTUM = 0.9\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_RATIO = 0.8\n",
    "TEST_RATIO = 0.2\n",
    "MAX_DROPBLOCK = 0.85\n",
    "\n",
    "gru_flt = 10\n",
    "fpa_flt = 20\n",
    "out_conv_flt = 24\n",
    "\n",
    "\n",
    "AUGMENTATION_RATIO = 4\n",
    "IMAGE_SIZE = 16\n",
    "existing = [int(x[:-4]) for x in os.listdir('../data/final/') if \".DS\" not in x]\n",
    "N_SAMPLES = len(existing)\n",
    "\n",
    "LABEL_SIZE = 14\n",
    "\n",
    "    \n",
    "TRAIN_SAMPLES = int((N_SAMPLES * AUGMENTATION_RATIO) * TRAIN_RATIO)\n",
    "TEST_SAMPLES = int((N_SAMPLES * AUGMENTATION_RATIO) - TRAIN_SAMPLES)\n",
    "print(TRAIN_SAMPLES // AUGMENTATION_RATIO, N_SAMPLES - (TRAIN_SAMPLES // AUGMENTATION_RATIO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_elu(inp, is_training, kernel_size, scope, filter_count = 16, pad = True, padding = 'valid'):\n",
    "    if kernel_size == 3:\n",
    "        if pad:\n",
    "            padded = ReflectionPadding2D((1, 1,))(inp)\n",
    "        else:\n",
    "            padded = inp\n",
    "        padding = padding\n",
    "    else:\n",
    "        padded = inp\n",
    "        padding = padding\n",
    "    conv = Conv2D(filters = filter_count, kernel_size = (kernel_size, kernel_size),\n",
    "                      padding = padding, kernel_initializer = 'he_normal')(padded)\n",
    "    elu = ELU()(conv)\n",
    "    bn = Batch_Normalization(elu, training=is_training, scope = scope + \"bn\")\n",
    "    return bn\n",
    "\n",
    "def td_conv_bn_elu(inp, is_training, kernel_size, scope, filter_count = 16, pad = True, padding = 'valid'):\n",
    "    #padded = TimeDistributed(ReflectionPadding2D((1, 1,)))(inp)\n",
    "    padded = tf.pad(inp, [[0,0], [0,0], [1,1], [1,1], [0,0] ], 'REFLECT')\n",
    "    conv = TimeDistributed(Conv2D(filters = filter_count, kernel_size = (kernel_size, kernel_size),\n",
    "                      padding = padding, kernel_initializer = 'he_normal'))(padded)\n",
    "    elu = TimeDistributed(ELU())(conv)\n",
    "    #bn = TimeDistributed(Batch_Normalization(elu, training=is_training, scope = scope + \"bn\")\n",
    "    return elu\n",
    "\n",
    "def resnet_block(inp, is_training, scope, flt):\n",
    "    drop1 = DropBlock2D(keep_prob = keep_rate, block_size = 3)\n",
    "    drop2 = DropBlock2D(keep_prob = keep_rate, block_size = 3)\n",
    "    padded = ReflectionPadding2D((1, 1,))(inp)\n",
    "    conv1 = Conv2D(filters = flt, kernel_size = (3, 3),\n",
    "                      padding = 'valid', kernel_initializer = 'he_normal')(padded)\n",
    "    elu1 = ELU()(conv1)\n",
    "    bn1 = Batch_Normalization(elu1, training=is_training, scope = scope + \"bn1\")\n",
    "    d1 = drop1(bn1, is_training)\n",
    "    \n",
    "    pad2 = ReflectionPadding2D((1, 1))(d1)\n",
    "    conv2 = Conv2D(filters = flt, kernel_size = (3, 3),\n",
    "                      padding = 'valid', kernel_initializer = 'he_normal')(pad2)\n",
    "    elu2 = ELU()(conv2)\n",
    "    bn2 = Batch_Normalization(elu2, training=is_training, scope = scope + \"bn2\")\n",
    "    d2 = drop2(bn2, is_training)\n",
    "    skip = tf.add(inp, d2)\n",
    "    reweighted = csse_block(skip, scope + \"csse\")\n",
    "    return reweighted\n",
    "    \n",
    "    \n",
    "def fpa(inp, is_training, filter_count):\n",
    "    one = conv_bn_elu(inp, is_training, 1, 'forward1', filter_count, False, 'valid')\n",
    "    five = conv_bn_elu(inp, is_training, 5, 'down1', filter_count, False, 'valid')\n",
    "    five_f = conv_bn_elu(five, is_training, 5, 'down1_f', filter_count, False, 'valid')\n",
    "    three = conv_bn_elu(five, is_training, 3, 'down2', filter_count, False, 'valid')\n",
    "    three_f = conv_bn_elu(three, is_training, 3, 'down2_f', filter_count, False, 'valid')\n",
    "    \n",
    "    three_up = get_deconv2d(three_f, filter_count, filter_count, \"fpa1\", is_training)\n",
    "    five_up = get_deconv2d(five_f, filter_count, filter_count, \"fpa2\", is_training)\n",
    "    \n",
    "    print(\"One: {}\".format(one.shape))\n",
    "    print(\"Five: {}\".format(five.shape))\n",
    "    print(\"Five_F: {}\".format(five_f.shape))\n",
    "    print(\"Three: {}\".format(three.shape))\n",
    "    print(\"Three_f: {}\".format(three_f.shape))\n",
    "    print(\"Three_up: {}\".format(three_up.shape))\n",
    "    print(\"Five_up: {}\".format(five_up.shape))\n",
    "    \n",
    "    # top block\n",
    "    pooled = tf.keras.layers.GlobalAveragePooling2D()(inp)\n",
    "    one_top = conv_bn_elu(tf.reshape(pooled, (-1, 1, 1, pooled.shape[-1])),\n",
    "                          is_training, 1, 'top1', filter_count)\n",
    "    four_top = tf.keras.layers.UpSampling2D((16, 16))(one_top)\n",
    "    \n",
    "    \n",
    "    concat_1 = tf.multiply(one, tf.add(three_up, five_up))\n",
    "    concat_2 = tf.add(concat_1, four_top)\n",
    "    print(\"Feature pyramid attention shape {}\".format(concat_2.shape))\n",
    "    return concat_2\n",
    "\n",
    "    \n",
    "def create_deconv_init(filter_size, num_channels):\n",
    "    bilinear_kernel = np.zeros([filter_size, filter_size], dtype=np.float32)\n",
    "    scale_factor = (filter_size + 1) // 2\n",
    "    if filter_size % 2 == 1:\n",
    "        center = scale_factor - 1\n",
    "    else:\n",
    "        center = scale_factor - 0.5\n",
    "    for x in range(filter_size):\n",
    "        for y in range(filter_size):\n",
    "            bilinear_kernel[x,y] = (1 - abs(x - center) / scale_factor) * \\\n",
    "                                   (1 - abs(y - center) / scale_factor)\n",
    "    weights = np.zeros((filter_size, filter_size, num_channels, num_channels))\n",
    "    for i in range(num_channels):\n",
    "        weights[:, :, i, i] = bilinear_kernel\n",
    "\n",
    "    #assign numpy array to constant_initalizer and pass to get_variable\n",
    "    bilinear_init = tf.constant_initializer(value=weights, dtype=tf.float32)\n",
    "    return bilinear_init\n",
    "\n",
    "\n",
    "def get_deconv2d(inp, filter_count, num_channels, scope, is_training):\n",
    "    bilinear_init = create_deconv_init(4, filter_count)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters = filter_count, kernel_size = (4, 4),\n",
    "                                        strides=(2, 2), padding='same', \n",
    "                                        kernel_initializer = bilinear_init)(inp)\n",
    "    x = ELU()(x)\n",
    "    x = Batch_Normalization(x, training=is_training, scope = scope + \"bn\")\n",
    "    return x\n",
    "\n",
    "\n",
    "def Batch_Normalization(x, training, scope):\n",
    "    return batch_normalization(inputs=x, \n",
    "                               momentum = BN_MOMENTUM, \n",
    "                               training=training,\n",
    "                               renorm = True,\n",
    "                               reuse=None,\n",
    "                               name = scope)\n",
    "\n",
    "\n",
    "def attention(inputs, attention_size, time_major=False, return_alphas=False):\n",
    "    inputs_orig = inputs\n",
    "    inputs = tf.reduce_mean(inputs, axis = [2, 3])\n",
    "    #print(\"ATT means: {}\".format(inputs.shape))\n",
    "    if isinstance(inputs, tuple):\n",
    "        # In case of Bi-RNN, concatenate the forward and the backward RNN outputs.\n",
    "        inputs = tf.concat(inputs, 2)\n",
    "\n",
    "    if time_major:\n",
    "        # (T,B,D) => (B,T,D)\n",
    "        inputs = tf.array_ops.transpose(inputs, [1, 0, 2])\n",
    "\n",
    "    hidden_size = inputs.shape[2].value  # D value - hidden size of the RNN layer\n",
    "\n",
    "    # Trainable parameters\n",
    "    w_omega = tf.Variable(tf.random_normal([hidden_size, attention_size], stddev=0.1))\n",
    "    b_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
    "    u_omega = tf.Variable(tf.random_normal([attention_size], stddev=0.1))\n",
    "\n",
    "    with tf.name_scope('v'):\n",
    "        # Applying fully connected layer with non-linear activation to each of the B*T timestamps;\n",
    "        #  the shape of `v` is (B,T,D)*(D,A)=(B,T,A), where A=attention_size\n",
    "        v = tf.tanh(tf.tensordot(inputs, w_omega, axes=1) + b_omega)\n",
    "\n",
    "    # For each of the timestamps its vector of size A from `v` is reduced with `u` vector\n",
    "    vu = tf.tensordot(v, u_omega, axes=1, name='vu')  # (B,T) shape\n",
    "    alphas = tf.nn.softmax(vu, name='alphas')         # (B,T) shape\n",
    "    print(\"Alphas: {}\".format(alphas.shape))\n",
    "    # Output of (Bi-)RNN is reduced with attention vector; the result has (B,D) shape\n",
    "    output = tf.reduce_sum(inputs_orig * tf.reshape(alphas, (-1, 24, 1, 1, 1)), axis = 1)\n",
    "    #output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), 1)\n",
    "    print(output.shape)\n",
    "    if not return_alphas:\n",
    "        return output\n",
    "    else:\n",
    "        return output, alphas\n",
    "\n",
    "def cse_block(prevlayer, prefix):\n",
    "    mean = Lambda(lambda xin: K.mean(xin, axis=[1, 2]))(prevlayer)\n",
    "    lin1 = Dense(K.int_shape(prevlayer)[3] // 2, name=prefix + 'cse_lin1', activation='relu')(mean)\n",
    "    lin2 = Dense(K.int_shape(prevlayer)[3], name=prefix + 'cse_lin2', activation='sigmoid')(lin1)\n",
    "    x = Multiply()([prevlayer, lin2])\n",
    "    return x\n",
    "\n",
    "\n",
    "def sse_block(prevlayer, prefix):\n",
    "    conv = Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "                  activation='sigmoid', strides=(1, 1),\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
    "    return conv\n",
    "\n",
    "\n",
    "def csse_block(x, prefix):\n",
    "    '''\n",
    "    Implementation of Concurrent Spatial and Channel ‘Squeeze & Excitation’ in Fully Convolutional Networks\n",
    "    https://arxiv.org/abs/1803.02579\n",
    "    '''\n",
    "    cse = cse_block(x, prefix)\n",
    "    sse = sse_block(x, prefix)\n",
    "    x = Add(name=prefix + \"_csse_mul\")([cse, sse])\n",
    "\n",
    "    return x\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "    \n",
    "    \n",
    "def gru_block(inp, length, size, flt, scope, train, normalize = True):\n",
    "    with tf.variable_scope(scope):\n",
    "        print(\"GRU input shape {}, zoneout: {}\".format(inp.shape, ZONE_OUT_PROB))\n",
    "        cell_fw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], normalize = normalize)\n",
    "        cell_bw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], normalize = normalize)\n",
    "        cell_fw = ZoneoutWrapper(\n",
    "           cell_fw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        cell_bw = ZoneoutWrapper(\n",
    "            cell_bw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        output, final_state = convGRU(inp, cell_fw, cell_bw, length)\n",
    "        final_state = tf.concat(final_state, axis = -1)\n",
    "        means = tf.reduce_mean(inp, axis = 1)\n",
    "        out = tf.concat([final_state, means], axis = -1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU input shape (?, 24, 16, 16, 15), zoneout: 0.25\n",
      "One: (?, 16, 16, 20)\n",
      "Five: (?, 12, 12, 20)\n",
      "Five_F: (?, 8, 8, 20)\n",
      "Three: (?, 10, 10, 20)\n",
      "Three_f: (?, 8, 8, 20)\n",
      "Three_up: (?, 16, 16, 20)\n",
      "Five_up: (?, 16, 16, 20)\n",
      "Feature pyramid attention shape (?, 16, 16, 20)\n",
      "Initializing last sigmoid bias with -2.94 constant\n"
     ]
    }
   ],
   "source": [
    "reg = keras.regularizers.l2(L2_REG)\n",
    "inp = tf.placeholder(tf.float32, shape=(None, 24, IMAGE_SIZE, IMAGE_SIZE, 15))\n",
    "length = tf.placeholder(tf.int32, shape = (None, 1))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 14, 14))#, 1))\n",
    "keep_rate = tf.placeholder_with_default(1.0, ())\n",
    "length2 = tf.reshape(length, (-1,))\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training')\n",
    "    \n",
    "    \n",
    "# GRU -> Conv -> Conv\n",
    "\n",
    "gru_output = gru_block(inp = inp, length = length2, size = [16, 16],\n",
    "                      flt = gru_flt, scope = 'down_16', train = is_training)\n",
    "\n",
    "gru_conv1 = conv_bn_elu(gru_output, is_training, 3, \"gru_conv1\", gru_flt*2, pad = True)\n",
    "gru_csse1 = csse_block(gru_conv1, \"csse_conv1\")\n",
    "\n",
    "# Skip -> FPA\n",
    "#gru_skip = tf.concat([gru_output, gru_csse1], axis = -1)\n",
    "drop2 = DropBlock2D(keep_prob = keep_rate, block_size = 3)\n",
    "drop = drop2(gru_output, is_training)\n",
    "\n",
    "fpa = fpa(drop, is_training, fpa_flt)\n",
    "fpa_skip = tf.concat([fpa, gru_csse1], axis = -1)\n",
    "drop3 = DropBlock2D(keep_prob = keep_rate, block_size = 3)\n",
    "out_drop1 = drop3(fpa_skip, is_training)\n",
    "#out_drop = drop3(out_conv1, is_training)\n",
    "\n",
    "# Conv -> Hyperpyramid -> Conv\n",
    "out_conv2 = conv_bn_elu(out_drop1, is_training, 3, \"out_conv2\", out_conv_flt, pad = False)\n",
    "#out = csse_block(out_conv2, \"csse_out2\")\n",
    "\n",
    "\n",
    "print(\"Initializing last sigmoid bias with -2.94 constant\")\n",
    "init = tf.constant_initializer([-np.log(0.95/0.05)]) # For focal loss\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1), \n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid',\n",
    "            bias_initializer = init,\n",
    "           )(out_conv2) # For focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 78548 parameters\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(\"This model has {} parameters\".format(total_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/subplot.csv\")\n",
    "df1 = pd.read_csv(\"../data/subplot2.csv\")\n",
    "df2 = pd.read_csv(\"../data/subplot3.csv\")\n",
    "df3 = pd.read_csv(\"../data/subplot4.csv\")\n",
    "\n",
    "df = df.drop('IMAGERY_TITLE', axis = 1).dropna(axis = 0)\n",
    "df1 = df1.drop('IMAGERY_TITLE', axis = 1).dropna(axis = 0)\n",
    "df2 = df2.drop('IMAGERY_TITLE', axis = 1).dropna(axis = 0)\n",
    "df3 = df3.drop('IMAGERY_TITLE', axis = 1).dropna(axis = 0)\n",
    "\n",
    "lens = [len(x) for x in [df, df1, df2, df3]]\n",
    "\n",
    "df = pd.concat([df, df1, df2, df3], ignore_index = True)\n",
    "df = df.dropna(axis = 0)\n",
    "\n",
    "existing = [int(x[:-4]) for x in os.listdir('../data/correct_dem/') if \".DS\" not in x]\n",
    "N_SAMPLES = len(existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef0691fc65f4f2ea4fef7b878f57639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=682), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished data loading\n"
     ]
    }
   ],
   "source": [
    "df = df[df['PLOT_ID'].isin(existing)]\n",
    "N_SAMPLES = int(df.shape[0]/196)\n",
    "N_YEARS = 1\n",
    "\n",
    "plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "\n",
    "\n",
    "def reconstruct_images(plot_id):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    rows = []\n",
    "    lats = reversed(sorted(subs['LAT'].unique()))\n",
    "    for i, val in enumerate(lats):\n",
    "        subs_lat = subs[subs['LAT'] == val]\n",
    "        subs_lat = subs_lat.sort_values('LON', axis = 0)\n",
    "        rows.append(list(subs_lat['TREE']))\n",
    "    return rows\n",
    "\n",
    "data = [reconstruct_images(x) for x in plot_ids]\n",
    "\n",
    "\n",
    "# Initiate empty lists to store the X and Y data in\n",
    "data_x, data_y, lengths = [], [], []\n",
    "\n",
    "# Iterate over each plot\n",
    "for i in tnrange(len(plot_ids)):\n",
    "    # Load the sentinel imagery\n",
    "    for year in [\"correct_dem\"]:  \n",
    "        x = np.load(\"../data/\" + year + \"/\" + str(plot_ids[i]) + \".npy\")\n",
    "        x = ndvi(x, image_size = 16)\n",
    "        x = evi(x, image_size = 16)\n",
    "        x = savi(x, image_size = 16)\n",
    "        x = bi(x)\n",
    "        x = remove_blank_steps(x)\n",
    "        y = reconstruct_images(plot_ids[i])\n",
    "        x[:, :, :, 10] /= 90\n",
    "        lengths.append(x.shape[0])\n",
    "        if x.shape[0] < 24:\n",
    "            padding = np.zeros((24 - x.shape[0], IMAGE_SIZE, IMAGE_SIZE, 14))\n",
    "            x = np.concatenate((x, padding), axis = 0)\n",
    "        data_x.append(x)\n",
    "        data_y.append(y)\n",
    "print(\"Finished data loading\")\n",
    "\n",
    "data_x = np.stack(data_x)\n",
    "data_y = np.stack(data_y)\n",
    "lengths = np.stack(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8164800855848524"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data_x[:, :, :, :, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outliers are: [7, 45, 141, 195, 292, 324, 327, 336, 363, 382, 385, 440, 497, 549, 601, 610, 652, 661, 7, 195, 225, 318, 487, 497, 634, 661], totalling 26\n",
      "\n",
      "\n",
      "[-6.321969935282787, -4.535834700871396, -27.47112805642772, -5.6786949197057535, -1.8062032684100147, -1.993483055138996, -4.530147022565086, -154.96879970980808, -9.975800327549234, -28.58520075669514, -2.238301983142812, -11.793600000161678, -738.3066513950349, -7.680050306753378, -5.0765703897432335, -4.257098714871306, -4.458718742819538, -1191.1332383574356] [5.0, 5.0, 5.0, 5.0, 5.0, 4291.504339112331, 5.0, 144.11851966358546]\n",
      "The data has been scaled to [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "below_1 = [i for i, val in enumerate(data_x) if np.min(val) < -1.5]\n",
    "above_1 = [i for i, val in enumerate(data_x) if np.max(val) > 1.5]\n",
    "min_vals = [np.min(val) for i, val in enumerate(data_x) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(data_x) if np.max(val) > 1.5]\n",
    "outliers = below_1 + above_1\n",
    "print(\"The outliers are: {}, totalling {}\".format(outliers, len(outliers)))\n",
    "print(\"\\n\")\n",
    "print(min_vals, max_vals)\n",
    "data_x = data_x[[x for x in range(0, len(data_x)) if x not in outliers]]\n",
    "data_y = data_y[[x for x in range(0, len(data_y)) if x not in outliers]]\n",
    "lengths = lengths[[x for x in range(0, len(lengths)) if x not in outliers]]\n",
    "\n",
    "min_all = []\n",
    "max_all = []\n",
    "for x in range(0, data_x.shape[-1]):\n",
    "    mins, maxs = (np.min(data_x[:, :, :, :, x]), np.max(data_x[:, :, :, :, x]))\n",
    "    min_all.append(mins)\n",
    "    max_all.append(maxs)\n",
    "    \n",
    "    data_x[:, :, :, :, x] = (data_x[:, :, :, :, x] - mins) / (maxs - mins)\n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(data_x), np.max(data_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The region sample distribution is [196, 131, 149, 184]\n",
      "660\n"
     ]
    }
   ],
   "source": [
    "plot_ids2 = [val for x, val in enumerate(plot_ids) if x not in list(set([x for x in outliers]))]\n",
    "N_SAMPLES = len(data_x)\n",
    "\n",
    "region_lengths = []\n",
    "for x in [df1, df2, df3]:\n",
    "    subs = [i for i in set(x['PLOT_ID']) if i in plot_ids2]\n",
    "    region_lengths.append(len(subs))\n",
    "    \n",
    "region_lengths = [N_SAMPLES - sum(region_lengths)] + region_lengths\n",
    "\n",
    "print(\"The region sample distribution is {}\".format(region_lengths))\n",
    "print(sum(region_lengths))\n",
    "train_ordering = []\n",
    "test_ordering = []\n",
    "ordering = []\n",
    "total_samples = 0\n",
    "for r in TRAIN_RATIO, TEST_RATIO:\n",
    "    for i, val in enumerate(region_lengths):\n",
    "        start = int(np.sum(region_lengths[:i]))\n",
    "        end = start + val\n",
    "        if r == 0.8:\n",
    "            start = start\n",
    "            end = end-((end-start)*(1-r))\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            total_samples += (end - start)\n",
    "            train_ordering += [x for x in range(start, end)]\n",
    "        if r == 0.2:\n",
    "            start = start + ((end-start)*(1-r))\n",
    "            end = end\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            total_samples += (end-start)\n",
    "            test_ordering += [x for x in range(start, end)]\n",
    "\n",
    "ordering = train_ordering + test_ordering\n",
    "\n",
    "data_x = data_x[ordering]\n",
    "data_y = data_y[ordering]\n",
    "lengths = lengths[ordering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=6, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=50, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "NONZERO_CLUSTERS = 10\n",
    "ZERO_CLUSTERS = 6\n",
    "\n",
    "kmeans = KMeans(n_clusters=NONZERO_CLUSTERS, random_state = 50)\n",
    "kmeans_zero = KMeans(n_clusters = ZERO_CLUSTERS, random_state = 50)\n",
    "unaugmented = [x for x in range(0, len(data_y))]\n",
    "zeros = [x for x in unaugmented if np.sum(data_y[x]) == 0]\n",
    "nonzero = [x for x in unaugmented if x not in zeros]\n",
    "kmeans.fit(data_y[nonzero, :, :].reshape((len(nonzero), 14*14)))\n",
    "kmeans_zero.fit(np.mean(data_x[zeros, :, :], axis = 1).reshape((len(zeros), 16*16*15)))             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplot(matrices):\n",
    "    '''Plot multiple heatmaps with subplots'''\n",
    "    fig, axs = plt.subplots(ncols=4)\n",
    "    fig.set_size_inches(20, 4)\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        sns.heatmap(data = matrix, ax = axs[i], vmin = 0, vmax = 0.9)\n",
    "        axs[i].set_xlabel(\"\")\n",
    "        axs[i].set_ylabel(\"\")\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_xticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143, 236, 348, 486]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random \n",
    "samples_x = [val for x, val in enumerate(nonzero) if kmeans.labels_[x] == 1]\n",
    "print(samples_x)\n",
    "randoms = random.sample(samples_x, 4)\n",
    "randoms = [data_y[x] for x in randoms]\n",
    "randoms = [x.reshape((14, 14)) for x in randoms]\n",
    "multiplot(randoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 9.0, 14.0, 19.0, 27.0, 32.0, 41.0, 56.0, 93.0]\n"
     ]
    }
   ],
   "source": [
    "percs = np.sum(data_y.reshape((-1, 14*14)), axis = 1)\n",
    "idx = [x for x in range(0, len(data_y))]\n",
    "print([i for x, i in enumerate(sorted(percs)) if x % (len(data_y)//15) == 0 ])\n",
    "\n",
    "ids = {\n",
    "    0: [x for x, z in zip(idx, percs) if 0 < z <= 5],\n",
    "    1: [x for x, z in zip(idx, percs) if 5 < z <= 9],\n",
    "    2: [x for x, z in zip(idx, percs) if 9 < z <= 14],\n",
    "    3: [x for x, z in zip(idx, percs) if 14 < z <= 19],\n",
    "    4: [x for x, z in zip(idx, percs) if 19 < z <= 27],\n",
    "    5: [x for x, z in zip(idx, percs) if 27 < z <= 33],\n",
    "    6: [x for x, z in zip(idx, percs) if 33 < z <= 41],\n",
    "    7: [x for x, z in zip(idx, percs) if 41 < z <= 56],\n",
    "    8: [x for x, z in zip(idx, percs) if 56  < z <= 93],\n",
    "    9: [x for x, z in zip(idx, percs) if 93 < z <= 120],\n",
    "    10: [x for x, z in zip(idx, percs) if 120 < z]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(data_y, ids, labels, labels2, unaugmented = unaugmented):\n",
    "    # Loop over the nonzero clusters\n",
    "    #for i in range(0, NONZERO_CLUSTERS):\n",
    "    #    tmp = [val for x, val in enumerate(nonzero) if labels[x] == i]\n",
    "    #    ids[i] = tmp\n",
    "    # Loop over the zero clusters\n",
    "    for i in range(0, ZERO_CLUSTERS):\n",
    "        tmp = [val for x, val in enumerate(zeros) if labels2[x] == i]\n",
    "        ids[i + 11] = tmp\n",
    "    #ids[10] = zeros\n",
    "    return ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 660 samples have been balanced between the sampling sites\n"
     ]
    }
   ],
   "source": [
    "ids = balance_data(data_y, ids, kmeans.labels_, kmeans_zero.labels_ )\n",
    "items = [v for k, v in ids.items()]\n",
    "items = [item for sublist in items for item in sublist]\n",
    "print(\"The {} samples have been balanced between the sampling sites\".format(len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 12 57\n",
      "36 10 46\n",
      "33 9 42\n",
      "36 10 46\n",
      "36 9 45\n",
      "33 9 42\n",
      "36 9 45\n",
      "32 8 40\n",
      "35 9 44\n",
      "12 3 15\n",
      "21 6 27\n",
      "6 2 8\n",
      "24 7 31\n",
      "39 10 49\n",
      "28 7 35\n",
      "37 10 47\n",
      "32 9 41\n"
     ]
    }
   ],
   "source": [
    "train_ids = []\n",
    "test_ids = []\n",
    "for i in ids:\n",
    "    ln = len(ids[i])\n",
    "    train_len = int(np.floor([ln * TRAIN_RATIO]))\n",
    "    test_len = ln - train_len\n",
    "    print(train_len, test_len, ln)\n",
    "    trains = ids[i][:train_len]\n",
    "    tests = ids[i][train_len:]\n",
    "    train_ids += trains\n",
    "    test_ids += tests\n",
    "    \n",
    "train_labels = []\n",
    "for i in train_ids:\n",
    "    train_labels.append([k for k, v in ids.items() if i in v][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test characteristics:\n",
      "Train mean Y 25.456813819577736\n",
      "Test mean Y 25.85611510791367\n",
      "Train STD Y 37.17885593737099\n",
      "Test STD Y 40.8012485968982\n",
      "Train number with zero trees 33.2\n",
      "Test number with zero trees 36.0\n",
      "Train mean NDVI\n",
      "Test mean NDVI\n",
      "There are 521 train and 139 test samples\n",
      "There is 0 overlap between train and test\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and test characteristics:\")\n",
    "print(\"Train mean Y {}\".format(np.mean([np.sum(x) for x in data_y[train_ids]])))\n",
    "print(\"Test mean Y {}\".format(np.mean([np.sum(x) for x in data_y[test_ids]])))\n",
    "print(\"Train STD Y {}\".format(np.std([np.sum(x) for x in data_y[train_ids]])))\n",
    "print(\"Test STD Y {}\".format(np.std([np.sum(x) for x in data_y[test_ids]])))\n",
    "print(\"Train number with zero trees {}\".format(0.2*len([x for x in data_y[train_ids] if np.sum(x) == 0])))\n",
    "print(\"Test number with zero trees {}\".format(0.8*len([x for x in data_y[test_ids] if np.sum(x) == 0])))\n",
    "print(\"Train mean NDVI\")\n",
    "print(\"Test mean NDVI\")\n",
    "print(\"There are {} train and {} test samples\".format(len(train_ids), len(test_ids)))\n",
    "print(\"There is {} overlap between train and test\".format(len([x for x in train_ids if x in test_ids])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_augmented = []\n",
    "data_y_augmented = []\n",
    "lengths_augmented = []\n",
    "labels_augmented = []\n",
    "for i, val in enumerate(train_ids):\n",
    "    data_x_augmented.append(data_x[val])\n",
    "    data_y_augmented.append(data_y[val])\n",
    "    lengths_augmented.append(data_x[val].shape[0])\n",
    "    labels_augmented.append(train_labels[i])\n",
    "    \n",
    "    x1 = np.flip(data_x[val], 1)\n",
    "    y1 = np.flip(data_y[val], 0)\n",
    "    lengths_augmented.append(x1.shape[0])\n",
    "    labels_augmented.append(train_labels[i])\n",
    "    data_x_augmented.append(x1)\n",
    "    data_y_augmented.append(y1)\n",
    "    \n",
    "    x1 = np.flip(data_x[val], [2, 1])\n",
    "    y1 = np.flip(data_y[val], [1, 0])\n",
    "    lengths_augmented.append(x1.shape[0])\n",
    "    labels_augmented.append(train_labels[i])\n",
    "    data_x_augmented.append(x1)\n",
    "    data_y_augmented.append(y1)\n",
    "    \n",
    "    x1 = np.flip(data_x[val], 2)\n",
    "    y1 = np.flip(data_y[val], 1)\n",
    "    lengths_augmented.append(x1.shape[0])\n",
    "    labels_augmented.append(train_labels[i])\n",
    "    data_x_augmented.append(x1)\n",
    "    data_y_augmented.append(y1)\n",
    "\n",
    "train_x = np.stack(data_x_augmented)\n",
    "train_y = np.stack(data_y_augmented)\n",
    "train_y = np.reshape(train_y, (train_y.shape[0], 14, 14, 1))\n",
    "train_l = np.stack(lengths_augmented)\n",
    "train_l = np.reshape(train_l, (train_y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = data_x[test_ids]\n",
    "test_y = data_y[test_ids]\n",
    "test_lengths = lengths[test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM TRAIN SAMPLES - SHOULD BE AUGMENTED\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"RANDOM TRAIN SAMPLES - SHOULD BE AUGMENTED\")\n",
    "multiplot([x.reshape(14, 14) for x in train_y[25:29]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM TEST SAMPLES - SHOULD BE NOT AUGMENTED\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"RANDOM TEST SAMPLES - SHOULD BE NOT AUGMENTED\")\n",
    "multiplot([x.reshape(14, 14) for x in test_y[25:29]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "import math\n",
    "\n",
    "def smooth_jaccard(y_true, y_pred, smooth=1):\n",
    "    y_true = tf.reshape(y_true, (-1, 14*14))\n",
    "    y_pred = tf.reshape(y_pred, (-1, 14*14))\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth\n",
    "\n",
    "def focal_loss_fixed(y_true, y_pred, gamma = 2., alpha = 0.5):\n",
    "    y_true = tf.reshape(y_true, (-1, 14*14, 1))\n",
    "    y_pred = tf.reshape(y_pred, (-1, 14*14, 1))\n",
    "    y_pred = K.clip(y_pred, 1e-8, 1-1e-8)\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    epsilon = K.epsilon()\n",
    "        # clip to prevent NaN's and Inf's\n",
    "    pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "    pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "    loss = -K.mean(alpha * 1 * K.log(K.epsilon()+pt_1)) - K.mean((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return 2 * tf.reduce_mean(loss)\n",
    "\n",
    "def bce_jaccard(y_true, y_pred):\n",
    "    jac = smooth_jaccard(y_true, y_pred)\n",
    "    bce = binary_crossentropy(y_true, y_pred)\n",
    "    return bce + 0.15*tf.reshape(jac, (-1, 1, 1, 1))\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight, smooth = 0.01):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    #y_true = K.clip(y_true, smooth, 1. - smooth)\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        y_true,\n",
    "        logit_y_pred,\n",
    "        weight,\n",
    "    )\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def lovasz_foc(y_true, y_pred):\n",
    "    foc_losses = []\n",
    "    #bce = weighted_bce_loss(y_true, y_pred, weight = 1.3)\n",
    "    foc = focal_loss_fixed(y_true, y_pred, gamma = 1.5, alpha = 0.4)\n",
    "    lv_image = lovasz_softmax(y_pred, tf.reshape(y_true, (-1, 14, 14)), classes=[1], per_image=True)\n",
    "    return foc + 0.05*lv_image\n",
    "\n",
    "def lovasz(y_true, y_pred):\n",
    "    lv = lovasz_softmax(y_pred, tf.reshape(y_true, (-1, 14, 14)), classes=[1], per_image=True)\n",
    "    return lv\n",
    "\n",
    "def calculate_metrics():\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0\n",
    "    p = 0\n",
    "    r = 0\n",
    "    error = 0\n",
    "    for j in range(7, 12):\n",
    "        tps = []\n",
    "        fps = []\n",
    "        fns = []\n",
    "        perc_error = []\n",
    "        trues = []\n",
    "        preds = []\n",
    "        val_loss = []\n",
    "        for m in test_ids:\n",
    "            y, vl = sess.run([fm, test_loss], feed_dict={inp: test_x[m].reshape(1, 24, 16, 16, 15),\n",
    "                                      length: test_lengths[m].reshape(1, 1),\n",
    "                                      is_training: False,\n",
    "                                      labels: test_y[m, :, :].reshape(1, 14, 14),\n",
    "                                      })\n",
    "            true = test_y[m].reshape((14, 14))\n",
    "            pred = y.reshape((14, 14))\n",
    "            pred[np.where(pred > j*0.05)] = 1\n",
    "            pred[np.where(pred < j*0.05)] = 0\n",
    "            true_s = np.sum(true)\n",
    "            pred_s = np.sum(pred)\n",
    "            #true_p = true_s - (true_s - pred_s)\n",
    "            perc_error.append(abs(pred_s - true_s) / 196)\n",
    "            tp, fp, fn = thirty_meter(true, pred)\n",
    "            tps.append(tp)\n",
    "            fps.append(fp)\n",
    "            fns.append(fn)\n",
    "            trues.append(true_s)\n",
    "            preds.append(pred_s)\n",
    "            val_loss.append(np.mean(vl))\n",
    "        oa_error = abs(np.sum(preds) - np.sum(trues)) / np.sum(trues)\n",
    "        precision = np.sum(tps) / (np.sum(tps) + np.sum(fps))\n",
    "        recall = np.sum(tps) / (np.sum(tps) + np.sum(fns))\n",
    "        f1 = 2*((precision* recall) / (precision + recall))\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            p = precision\n",
    "            r = recall\n",
    "            error = oa_error\n",
    "            best_thresh = j*0.05\n",
    "    print(\"Val loss: {} Thresh: {} F1: {} Recall: {} Precision: {} Error: {}\".format(np.around(np.mean(val_loss), 3), np.around(best_thresh, 2),\n",
    "                                                                                     np.around(best_f1, 3), np.around(p, 3), np.around(r, 3), \n",
    "                                                                                     np.around(error, 3)))\n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2084\n"
     ]
    }
   ],
   "source": [
    "train_ids = [x for x in range(0, len(train_y))]\n",
    "print(len(train_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equibatch creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def equibatch(train_ids, lovasz = False):\n",
    "    first_len = 5\n",
    "    second_len = 9\n",
    "    third_len = 14\n",
    "    np.random.shuffle(train_ids)\n",
    "    ix = train_ids\n",
    "    percs = [np.sum(x) for x in train_y[ix]]\n",
    "    zero_ids = [x for x, z in zip(ix, percs) if z == 0]\n",
    "    one_ids = [x for x, z in zip(ix, percs) if 0 < z <= first_len]\n",
    "    two_ids = [x for x, z in zip(ix, percs) if first_len < z <= second_len]\n",
    "    three_ids = [x for x, z in zip(ix, percs) if second_len < z <= third_len]\n",
    "    four_ids = [x for x, z in zip(ix, percs) if third_len < z <= 19]\n",
    "    five_ids = [x for x, z in zip(ix, percs) if 19 < z < 27]\n",
    "    six_ids = [x for x, z in zip(ix, percs) if 27 < z <= 33]\n",
    "    seven_ids = [x for x, z in zip(ix, percs) if 33 < z <= 41]\n",
    "    eight_ids = [x for x, z in zip(ix, percs) if 41 < z <= 56]\n",
    "    nine_ids =  [x for x, z in zip(ix, percs) if 56 < z <= 80]\n",
    "    ten_ids =  [x for x, z in zip(ix, percs) if 80 < z <= 120]\n",
    "    eleven_ids = [x for x, z in zip(ix, percs) if 120 < z]\n",
    "    #ten_ids = [x for x, z in zip(ix, percs) if 125 < z]\n",
    "    \n",
    "    \n",
    "\n",
    "    all_ids = [x for x in [zero_ids, one_ids, two_ids, three_ids, four_ids, five_ids, six_ids,\n",
    "              seven_ids, eight_ids, nine_ids, ten_ids, eleven_ids]]\n",
    "    \n",
    "    new_batches = []\n",
    "    maxes = [len(zero_ids), len(one_ids), len(two_ids), len(three_ids), len(four_ids),\n",
    "             len(five_ids), len(six_ids), len(seven_ids), len(eight_ids), len(nine_ids), len(ten_ids), len(eleven_ids)]#, len(ten_ids)]\n",
    "    cur_ids = [0] * 12\n",
    "    iter_len = len(train_ids)// 16\n",
    "    for i in range(0, iter_len):\n",
    "        random_ids = np.random.randint(0, 12, 3)\n",
    "        for i, val in enumerate(cur_ids):\n",
    "            if val > maxes[i] - 5:\n",
    "                cur_ids[i] = 0\n",
    "        if cur_ids[0] >= (maxes[0] - 2):\n",
    "            cur_ids[0] = 0\n",
    "        to_append = [zero_ids[cur_ids[0]], zero_ids[cur_ids[0] + 1], one_ids[cur_ids[1]], two_ids[cur_ids[2]],\n",
    "                    three_ids[cur_ids[3]], four_ids[cur_ids[4]], five_ids[cur_ids[5]],\n",
    "                    six_ids[cur_ids[6]], seven_ids[cur_ids[7]], eight_ids[cur_ids[8]],\n",
    "                               nine_ids[cur_ids[9]], ten_ids[cur_ids[10]], eleven_ids[cur_ids[11]],\n",
    "                    all_ids[random_ids[0]][cur_ids[random_ids[0]]+1],\n",
    "                     all_ids[random_ids[1]][cur_ids[random_ids[1]]+1],\n",
    "                     all_ids[random_ids[2]][cur_ids[random_ids[2]]]+1]\n",
    "        np.random.shuffle(to_append)\n",
    "        new_batches.append(to_append)\n",
    "        cur_ids = [x + 1 for x in cur_ids]\n",
    "        cur_ids[0] += 1\n",
    "        for x in random_ids:\n",
    "            cur_ids[x] += 1\n",
    "        \n",
    "    new_batches = [item for sublist in new_batches for item in sublist]\n",
    "    #overlap = [x for x in new_batches if x in test_ids]\n",
    "    #print(\"There is {} overlap. Error if > 0\".format(len(overlap)))\n",
    "    return new_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = equibatch(train_ids, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[:4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[4:8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiplot([x.reshape((14, 14)) for x in train_y[batch[8:12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.61105769230769"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.sum(x) for x in train_y[batch]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_saver = tf.train.import_meta_graph('../models/f1_auc/model.meta')\n",
    "#new_saver.restore(sess, tf.train.latest_checkpoint('../models/f1_auc/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model with: \n",
      " 0.25 zone out \n",
      " 0.0 l2 \n",
      " 0.0002 initial LR \n",
      " 0.001 final LR \n",
      " 78548 parameters\n",
      "Restarting training from scratch on 2084 train and 139 test samples, total 660\n",
      "()\n",
      "()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2daf2c8cb6b14d86a24d66d38efb35c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Loss 0.4519999921321869\n",
      "Val loss: 0.39399999380111694 Thresh: 0.35 F1: 0.451 Recall: 0.647 Precision: 0.346 Error: 0.464\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40b2f851a884106b049678b1b797b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Loss 0.4059999883174896\n",
      "Val loss: 0.4449999928474426 Thresh: 0.55 F1: 0.44 Recall: 0.409 Precision: 0.475 Error: 0.161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53155110ad844f2cb739a2d59cca9353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Loss 0.40799999237060547\n",
      "Val loss: 0.38499999046325684 Thresh: 0.35 F1: 0.465 Recall: 0.513 Precision: 0.425 Error: 0.171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fc76f61b224746acc86ad8c964bad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Loss 0.35600000619888306\n",
      "Val loss: 0.3529999852180481 Thresh: 0.35 F1: 0.496 Recall: 0.497 Precision: 0.496 Error: 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97af3d8e53d3489c88a711f8431ae296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-742d40dd3c5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m                                          \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                                          \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                          \u001b[0mkeep_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.004\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                                          })\n\u001b[1;32m     62\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FRESH_START = True\n",
    "FINE_TUNE = False\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "print(\"Starting model with: \\n {} zone out \\n {} l2 \\n {} initial LR \\n {} final LR \\n {} parameters\"\n",
    "     .format(ZONE_OUT_PROB, L2_REG, INITIAL_LR, FINAL_LR, total_parameters))\n",
    "best_val = 0.620\n",
    "if not FRESH_START:\n",
    "    print(\"Resuming training with a best validation score of {}\".format(best_val))\n",
    "if FRESH_START:\n",
    "    print(\"Restarting training from scratch on {} train and {} test samples, total {}\".format(len(train_ids), len(test_ids), N_SAMPLES))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(2e-4, epsilon = 1e-4)\n",
    "    optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, clip_norm=0.05)\n",
    "\n",
    "    ft_optimizer = tf.train.AdamOptimizer(1e-4, epsilon = 1e-4)\n",
    "    ft_optimizer = tf.contrib.estimator.clip_gradients_by_norm(ft_optimizer, clip_norm=0.1)\n",
    "    \n",
    "    train_loss = lovasz_foc(tf.reshape(labels, (-1, 14, 14, 1)), fm)\n",
    "    #train_loss = focal_loss_fixed(labels, fm, gamma = 1.1, alpha = 0.5)\n",
    "    test_loss = weighted_bce_loss(tf.reshape(labels, (-1, 14, 14, 1)), fm, weight = 1.25)\n",
    "    ft_loss = lovasz(tf.reshape(labels, (-1, 14, 14, 1)), fm)\n",
    "    l2_loss = tf.losses.get_regularization_loss()\n",
    "    train_loss += l2_loss\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(train_loss)   \n",
    "        #wu_op = wu_optimizer.minimize(wu_loss)\n",
    "        ft_op = ft_optimizer.minimize(ft_loss)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    saver = tf.train.Saver(max_to_keep = 2)\n",
    "\n",
    "# Run training 1oop\n",
    "for i in range(1, 250):\n",
    "    randomize = equibatch(train_ids, lovasz = False)\n",
    "    randomize = [np.min([x, len(train_y) - 1]) for x in randomize]\n",
    "        #print(\"Loss: BCE + 0.30 Lovasz\")\n",
    "    op = train_op\n",
    "    loss = train_loss\n",
    "    #op = ft_op\n",
    "    #loss = ft_loss\n",
    "    BATCH_SIZE = 16\n",
    "    test_ids = [x for x in range(0, len(test_x))]\n",
    "    losses = []\n",
    "    bce_losses = []\n",
    "    \n",
    "    for k in tnrange(int(len(train_ids) // BATCH_SIZE)):\n",
    "        batch_ids = randomize[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "        batch_y = train_y[batch_ids, :, :].reshape(len(batch_ids), 14, 14)\n",
    "        opt, tr = sess.run([op, loss],\n",
    "                              feed_dict={inp: train_x[batch_ids, :, :, :],\n",
    "                                         length: train_l[batch_ids].reshape((-1, 1)),\n",
    "                                         labels: batch_y,\n",
    "                                         is_training: True,\n",
    "                                         keep_rate: np.max((1 - (i*0.004), 0.90))\n",
    "                                         })\n",
    "        losses.append(tr)\n",
    "    \n",
    "    print(\"Epoch {}: Loss {}\".format(i, np.around(np.mean(losses[:-1]), 3)))\n",
    "    f1 = calculate_metrics()\n",
    "    if f1 > best_val:\n",
    "        best_val = f1\n",
    "        print(\"Saving model with {}\".format(f1))\n",
    "        save_path = saver.save(sess, \"../models/f1_auc/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation and sanity checks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Plot multiple heatmaps with subplots'''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(20, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show()\n",
    "start = 30\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2446043165467626\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "    \n",
    "test_losses = []\n",
    "print(start/len(test_ids))\n",
    "test_ids = sorted(test_ids)\n",
    "matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3],\n",
    "              test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "#matrix_ids = random.sample(test_ids, 4)z\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    print(i)\n",
    "    y = sess.run([fm], feed_dict={inp: test_x[idx].reshape(1, 24, IMAGE_SIZE, IMAGE_SIZE, 15),\n",
    "                                  length: test_lengths[idx].reshape(1, 1),\n",
    "                                  is_training: False,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    preds.append(y)\n",
    "    true = test_y[idx].reshape(LABEL_SIZE, LABEL_SIZE)\n",
    "    trues.append(true)\n",
    "    \n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4]# + trues[5:] + preds[5:]\n",
    "multiplot(to_plot, nrows = 2, ncols = 4)\n",
    "#plot_ids[ordering[976]//4] \n",
    "\n",
    "start = start + 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "    \n",
    "test_losses = []\n",
    "print(start/len(test_ids))\n",
    "test_ids = sorted(test_ids)\n",
    "#matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3],\n",
    "#              test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "matrix_ids = random.sample(train_ids, 4)\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    print(i)\n",
    "    y = sess.run([fm], feed_dict={inp: train_x[idx].reshape(1, 24, IMAGE_SIZE, IMAGE_SIZE, 15),\n",
    "                                  length: train_l[idx].reshape(1, 1),\n",
    "                                  is_training: False,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    preds.append(y)\n",
    "    true = train_y[idx].reshape(LABEL_SIZE, LABEL_SIZE)\n",
    "    trues.append(true)\n",
    "    \n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4]# + trues[5:] + preds[5:]\n",
    "multiplot(to_plot, nrows = 2, ncols = 4)\n",
    "#plot_ids[ordering[976]//4] \n",
    "start = start + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ids2 = [val for x, val in enumerate(plot_ids) if x not in list(set([x // 4 for x in outliers]))]\n",
    "plot_ids2[ordering[460]//4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate ROC for best threshold selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.27799999713897705 Thresh: 0.35 F1: 0.597 Recall: 0.66 Precision: 0.546 Error: 0.173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5974105102817975"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO @jombrandt top 10 worst training, test samples by IOU \n",
    "\n",
    "These should be written to a tmp/ .txt file and indexed by validate-data.ipynb to ensure that original classifications were correct, and to identify regions that need more training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-toolkit",
   "language": "python",
   "name": "policy-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
