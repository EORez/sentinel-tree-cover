{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants, DataSource, CustomUrlParam\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage.transform import resize\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import splu\n",
    "\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "        key = (yaml.safe_load(stream))\n",
    "        API_KEY = key['key'] \n",
    "        \n",
    "%run ../src/slope.py\n",
    "%run ../src/utils-bilinear.py\n",
    "%run ../src/dsen2/utils/DSen2Net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ('2018-12-15', '2020-01-15')\n",
    "EPSG = CRS.WGS84\n",
    "IMSIZE = 48\n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions (to be moved to a utils file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic Model Created.\n"
     ]
    }
   ],
   "source": [
    "def calculate_proximal_steps_index(date, satisfactory):\n",
    "    arg_before = None\n",
    "    arg_after = None\n",
    "    if date > 0:\n",
    "        idx_before = satisfactory - date\n",
    "        arg_before = idx_before[np.where(idx_before < 0, idx_before, -np.inf).argmax()]\n",
    "    if date < np.max(satisfactory):\n",
    "        idx_after = satisfactory - date\n",
    "        arg_after = idx_after[np.where(idx_after > 0, idx_after, np.inf).argmin()]\n",
    "    if not arg_after and not arg_before:\n",
    "        arg_after = date\n",
    "        arg_before = date\n",
    "    if not arg_after:\n",
    "        arg_after = arg_before\n",
    "    if not arg_before:\n",
    "        arg_before = arg_after\n",
    "    return arg_before, arg_after\n",
    "\n",
    "def speyediff(N, d, format = 'csc'):\n",
    "    shape = (N-d, N)\n",
    "    diagonals = np.zeros(2*d + 1)\n",
    "    diagonals[d] = 1.\n",
    "    for i in range(d):\n",
    "        diff = diagonals[:-1] - diagonals[1:]\n",
    "        diagonals = diff\n",
    "    offsets = np.arange(d+1)\n",
    "    spmat = sparse.diags(diagonals, offsets, shape, format = format)\n",
    "    return spmat\n",
    "\n",
    "def smooth(y, lmbd, d = 2):\n",
    "    m = len(y)\n",
    "    E = sparse.eye(m, format = 'csc')\n",
    "    D = speyediff(m, d, format = 'csc')\n",
    "    coefmat = E + lmbd * D.conj().T.dot(D)\n",
    "    z = splu(coefmat).solve(y)\n",
    "    return z\n",
    "\n",
    "MDL_PATH = \"../src/dsen2/models/\"\n",
    "\n",
    "input_shape = ((4, None, None), (6, None, None))\n",
    "model = s2model(input_shape, num_layers=6, feature_size=128)\n",
    "predict_file = MDL_PATH+'s2_032_lr_1e-04.hdf5'\n",
    "print('Symbolic Model Created.')\n",
    "\n",
    "model.load_weights(predict_file)\n",
    "\n",
    "def DSen2(d10, d20):\n",
    "    test = [d10, d20]\n",
    "    input_shape = ((4, None, None), (6, None, None))\n",
    "    prediction = _predict(test, input_shape, deep=False)\n",
    "    #prediction *= 5\n",
    "    return prediction\n",
    "\n",
    "def _predict(test, input_shape, model = model, deep=False, run_60=False):\n",
    "    \n",
    "    print(\"Predicting using file: {}\".format(predict_file))\n",
    "    prediction = model.predict(test, verbose=1)\n",
    "    return prediction\n",
    "\n",
    "c_arr = np.array([[1, 1, 1, 1, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 2, 3, 2, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 1, 1, 1, 1,],])\n",
    "                  \n",
    "c_arr = c_arr / 3\n",
    "o_arr = 1 - c_arr\n",
    "c_arr = np.tile(c_arr[:, :, np.newaxis], (1, 1, 11))\n",
    "o_arr = np.tile(o_arr[:, :, np.newaxis], (1, 1, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCoords(xy, src='', targ=''):\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])\n",
    "\n",
    "def calc_bbox(plot_id, df):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    # TOP, LEFT, BOTTOM, RIGHT\n",
    "    # (min x, min y), (max x, max y)\n",
    "    return [(min(subs['LON']), min(subs['LAT'])),\n",
    "            (max(subs['LON']), max(subs['LAT']))]\n",
    "\n",
    "def bounding_box(points, expansion = 160):\n",
    "    # LONG, LAT FOR SOME REASON\n",
    "    bl = list(points[0])\n",
    "    tr = list(points[1])\n",
    "    \n",
    "    if 78 <= tr[0] <= 84:\n",
    "        epsg = 32644 if tr[1] > 0 else 32744\n",
    "    if 72 <= tr[0] <= 78:\n",
    "        epsg = 32643 if tr[1] > 0 else 32743\n",
    "    if 66 <= tr[0] <= 72:\n",
    "        epsg = 32642 if tr[1] > 0 else 32742\n",
    "    if 60 <= tr[0] <= 66:\n",
    "        epsg = 32641 if tr[1] > 0 else 32741\n",
    "    if 54 <= tr[0] <= 60:\n",
    "        epsg = 32640 if tr[1] > 0 else 32740\n",
    "    if 48 <= tr[0] <= 54:\n",
    "        epsg = 32639 if tr[1] > 0 else 32739\n",
    "    if 42 <= tr[0] <= 48:\n",
    "        epsg = 32638 if tr[1] > 0 else 32738\n",
    "    if 36 <= tr[0] <= 42:\n",
    "        epsg = 32637 if tr[1] > 0 else 32737\n",
    "    if 30 <= tr[0] <= 36:\n",
    "        epsg = 32636 if tr[1] > 0 else 32736\n",
    "    if 24 <= tr[0] <= 30:\n",
    "        epsg = 32635 if tr[1] > 0 else 32735\n",
    "    if 18 <= tr[0] <= 24:\n",
    "        epsg = 32634 if tr[1] > 0 else 32734\n",
    "    if 12 <= tr[0] <= 18:\n",
    "        epsg = 32633 if tr[1] > 0 else 32733\n",
    "    if 6 <= tr[0] <= 12:\n",
    "        epsg = 32632 if tr[1] > 0 else 32732\n",
    "    if 0 <= tr[0] <= 6:\n",
    "        epsg = 32631 if tr[1] > 0 else 32731\n",
    "    if -6 <= tr[0] <= 0:\n",
    "        epsg = 32630 if tr[1] > 0 else 32730\n",
    "    if -12 <= tr[0] <= -6:\n",
    "        epsg = 32629 if tr[1] > 0 else 32729\n",
    "    if -18 <= tr[0] <= -12:\n",
    "        epsg = 32628 if tr[1] > 0 else 32728\n",
    "    if -24 <= tr[0] <= -18:\n",
    "        epsg = 32627 if tr[1] > 0 else 32727\n",
    "    if -30 <= tr[0] <= -24:\n",
    "        epsg = 32626 if tr[1] > 0 else 32726\n",
    "    if -36 <= tr[0] <= -30:\n",
    "        epsg = 32625 if tr[1] > 0 else 32725\n",
    "    if -42 <= tr[0] <= -36:\n",
    "        epsg = 32624 if tr[1] > 0 else 32724\n",
    "    if -48 <= tr[0] <= -42:\n",
    "        epsg = 32623 if tr[1] > 0 else 32723\n",
    "    if -54 <= tr[0] <= -48:\n",
    "        epsg = 32622 if tr[1] > 0 else 32722\n",
    "    if -60 <= tr[0] <= -54:\n",
    "        epsg = 32621 if tr[1] > 0 else 32721\n",
    "    if -66 <= tr[0] <= -60:\n",
    "        epsg = 32620 if tr[1] > 0 else 32720\n",
    "    if -72 <= tr[0] <= -66:\n",
    "        epsg = 32619 if tr[1] > 0 else 32719\n",
    "    if -78 <= tr[0] <= -72:\n",
    "        epsg = 32618 if tr[1] > 0 else 32718\n",
    "    if -84 <= tr[0] <= -78:\n",
    "        epsg = 32617 if tr[1] > 0 else 32717\n",
    "    if -90 <= tr[0] <= -84:\n",
    "        epsg = 32616 if tr[1] > 0 else 32716\n",
    "    if -96 <= tr[0] <= -90:\n",
    "        epsg = 32615 if tr[1] > 0 else 32715\n",
    "    if -102 <= tr[0] <= -96:\n",
    "        epsg = 32614 if tr[1] > 0 else 32714\n",
    "    if -108 <= tr[0] <= -102:\n",
    "        epsg = 32613 if tr[1] > 0 else 32713\n",
    "\n",
    "    bl = convertCoords(bl, 4326, epsg)\n",
    "    tr = convertCoords(tr, 4326, epsg)\n",
    "    init = [b - a for a,b in zip(bl, tr)]\n",
    "    distance1 = tr[0] - bl[0]\n",
    "    distance2 = tr[1] - bl[1]\n",
    "    expansion1 = (expansion - distance1)/2\n",
    "    expansion2 = (expansion - distance2)/2\n",
    "    bl = [bl[0] - expansion1, bl[1] - expansion2]\n",
    "    tr = [tr[0] + expansion1, tr[1] + expansion2]\n",
    "\n",
    "    after = [b - a for a,b in zip(bl, tr)]   \n",
    "    print(after)\n",
    "    if max(init) > 130:\n",
    "        print(\"ERROR: Initial field greater than 130m\")\n",
    "    if min(init) < 120:\n",
    "        print(\"ERROR: Initial field less than 130m\")\n",
    "        \n",
    "    if min(after) < (expansion - 4.5):\n",
    "        print(\"ERROR\")\n",
    "    if max(after) > (expansion + 5):\n",
    "        print(\"ERROR\")\n",
    "    diffs = [b - a for b, a in zip(after, init)]\n",
    "\n",
    "    bl = convertCoords(bl, epsg, 4326)\n",
    "    tr = convertCoords(tr, epsg, 4326)\n",
    "    return bl, tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_clouds(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        cloud_request = WmsRequest(\n",
    "            layer='CLOUD_DETECTION',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=IMSIZE,\n",
    "            height=IMSIZE,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.75,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        cloud_img = cloud_request.get_data()\n",
    "        cloud_probs = cloud_detector.get_cloud_probability_maps(np.array(cloud_img))\n",
    "        means = np.mean(cloud_probs, (1, 2))\n",
    "        clean_steps = [i for i, val in enumerate(means) if val < 0.20]\n",
    "        return clean_steps, means, cloud_probs\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(val, df, epsg = EPSG, ):\n",
    "    location = calc_bbox(val, df = df)\n",
    "    bbox = bounding_box(location, expansion = (IMSIZE+2)*10)\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=IMSIZE+2,\n",
    "                         height=IMSIZE+2,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, IMSIZE+2, IMSIZE+2)),\n",
    "                  np.full((IMSIZE+2, IMSIZE+2), 10), np.full((IMSIZE+2, IMSIZE+2), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((IMSIZE+2, IMSIZE+2, 1))\n",
    "    dem_image = dem_image[1:IMSIZE+1, 1:IMSIZE+1, :]\n",
    "    return dem_image\n",
    "\n",
    "def check_zenith(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        zenith = WmsRequest(\n",
    "            layer='ZENITH',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=IMSIZE,\n",
    "            height=IMSIZE,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.75,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        zenith = zenith.get_data()\n",
    "        return zenith\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "        \n",
    "def download_layer(bbox, epsg = EPSG, time = time):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A20',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        img_20 = np.stack(img_bands)\n",
    "        img_20 = resize(img_20, (img_20.shape[0], IMSIZE, IMSIZE, img_20.shape[-1]), order = 0)\n",
    "        \n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A10',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'BICUBIC',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        img_bands = image_request.get_data()\n",
    "        img_10 = np.stack(img_bands)\n",
    "        print(\"Original size: {}\".format(img_10.shape))\n",
    "        img_10 = resize(img_10, (img_10.shape[0], IMSIZE, IMSIZE, img_10.shape[-1]), order = 0)\n",
    "        shadows = img_10[:, :, :, -1]\n",
    "        img_10 = img_10[:, :, :, :-1]\n",
    "        \n",
    "        shadows[np.where(shadows != 3)] = 0\n",
    "        shadows[np.where(shadows == 3)] = 1\n",
    "        shadows_sums = np.sum(shadows, axis = 0)\n",
    "        before = np.sum(shadows)\n",
    "        #shadows[np.where(shadows_sums > shadows.shape[0]/2)] = 0.\n",
    "        print(\"Difference: {}\".format(np.sum(shadows) - before))\n",
    "        print(\"Shadows: {}\".format(shadows.shape))\n",
    "        shadow_sum = np.sum(shadows, axis = (1, 2))\n",
    "        shadow_steps = np.argwhere(shadow_sum > (IMSIZE*IMSIZE) / 5)\n",
    "        \n",
    "        img = np.concatenate([img_10, img_20], axis = -1)\n",
    "        return img, image_request, shadows, shadow_steps\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "        \n",
    "def download_sentinel_1(bbox, epsg = EPSG, time = time, layer = \"SENT\", year = 2019):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer=layer,\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=1.0,\n",
    "                resx='5m', resy='5m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        s1 = np.stack(img_bands)\n",
    "        s1 = resize(s1, (s1.shape[0], IMSIZE*2, IMSIZE*2, s1.shape[-1]), order = 0)\n",
    "        s1 = np.reshape(s1, (s1.shape[0], s1.shape[1]//2, 2, s1.shape[2] // 2, 2, s1.shape[-1]))\n",
    "        s1 = np.mean(s1, (2, 4))\n",
    "        s1 = s1[:, 8:24, 8:24, :]\n",
    "        \n",
    "        image_dates = []\n",
    "        for date in image_request.get_dates():\n",
    "            if date.year == year - 1:\n",
    "                image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year:\n",
    "                image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "            if date.year == year + 1:\n",
    "                image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "        image_dates = np.array(image_dates)\n",
    "        to_remove = np.argwhere(np.max(s1, (1, 2, 3)) == 1.).flatten()\n",
    "        s1 = np.delete(s1, to_remove, 0)\n",
    "        #print(np.max(s1, (1, 2, 3)))\n",
    "        image_dates = np.delete(image_dates, to_remove)\n",
    "        return s1, image_dates\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud and shadow removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cloud_and_shadows(tiles, probs, shadows, image_dates, wsize = 5):\n",
    "    c_probs = np.copy(probs)\n",
    "    c_probs = c_probs - np.min(c_probs, axis = 0)\n",
    "    c_probs[np.where(c_probs > 0.33)] = 1.\n",
    "    c_probs[np.where(c_probs < 0.33)] = 0.\n",
    "    c_probs = np.reshape(c_probs, [c_probs.shape[0], int(IMSIZE/8), 8, int(IMSIZE/8), 8])\n",
    "    c_probs = np.sum(c_probs, (2, 4))\n",
    "    c_probs = resize(c_probs, (c_probs.shape[0], IMSIZE, IMSIZE), 0)\n",
    "    c_probs[np.where(c_probs < 12)] = 0.\n",
    "    c_probs[np.where(c_probs >= 12)] = 1.\n",
    "    c_probs += shadows\n",
    "    c_probs[np.where(c_probs >= 1.)] = 1.\n",
    "    n_interp = 0\n",
    "    for cval in range(0, IMSIZE - 4, 1):\n",
    "        for rval in range(0, IMSIZE - 4, 1):\n",
    "            subs = c_probs[:, cval:cval + wsize, rval:rval+wsize]\n",
    "            satisfactory = [x for x in range(c_probs.shape[0]) if np.sum(subs[x, :, :]) < 10]\n",
    "            satisfactory = np.array(satisfactory)\n",
    "            for date in range(0, tiles.shape[0]):\n",
    "                if np.sum(subs[date, :, :]) > 10:\n",
    "                    n_interp += 1\n",
    "                    before, after = calculate_proximal_steps_index(date, satisfactory)\n",
    "                    before = date + before\n",
    "                    after = date + after\n",
    "                    bef = tiles[before, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    aft = tiles[after, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    before = image_dates[before]\n",
    "                    after = image_dates[after]\n",
    "                    before_diff = abs(image_dates[date] - before)\n",
    "                    after_diff = abs(image_dates[date] - after)\n",
    "                    bef_wt = 1 - before_diff / (before_diff + after_diff)\n",
    "                    aft_wt = 1 - bef_wt\n",
    "                    candidate = bef_wt*bef + aft_wt*aft\n",
    "                    candidate = candidate*c_arr + tiles[date, cval:cval+wsize, rval:rval+wsize, : ]*o_arr\n",
    "                    tiles[date, cval:cval+wsize, rval:rval+wsize, : ] = candidate  \n",
    "    print(\"Interpolated {} px\".format(n_interp))\n",
    "    return tiles\n",
    "\n",
    "def remove_missed_clouds(img):\n",
    "    iqr = np.percentile(img[:, :, :, 3].flatten(), 75) - np.percentile(img[:, :, :, 3].flatten(), 25)\n",
    "    thresh_t = np.percentile(img[:, :, :, 3].flatten(), 75) + iqr*2\n",
    "    thresh_b = np.percentile(img[:, :, :, 3].flatten(), 25) - iqr*2\n",
    "    diffs_fw = np.diff(img, 1, axis = 0)\n",
    "    diffs_fw = np.mean(diffs_fw, axis = (1, 2, 3))\n",
    "    diffs_fw = np.array([0] + list(diffs_fw))\n",
    "    diffs_bw = np.diff(np.flip(img, 0), 1, axis = 0)\n",
    "    diffs_bw = np.flip(np.mean(diffs_bw, axis = (1, 2, 3)))\n",
    "    diffs_bw = np.array(list(diffs_bw) + [0])\n",
    "    diffs = abs(diffs_fw - diffs_bw) * 100 # 3, -3 -> 6, -3, 3 -> 6, -3, -3\n",
    "    #diffs = [int(x) for x in diffs]\n",
    "    outlier_percs = []\n",
    "    for step in range(img.shape[0]):\n",
    "        bottom = len(np.argwhere(img[step, :, :, 3].flatten() > thresh_t))\n",
    "        top = len(np.argwhere(img[step, :, :, 3].flatten() < thresh_b))\n",
    "        p = 100* ((bottom + top) / (IMSIZE*IMSIZE))\n",
    "        outlier_percs.append(p)\n",
    "    to_remove = np.argwhere(np.array(outlier_percs) > 15)\n",
    "    print([int(x) for x in outlier_percs])\n",
    "    return to_remove\n",
    "\n",
    "def threshold_shadows(arr):\n",
    "    arr = np.copy(arr)\n",
    "    iqr = np.percentile(arr.flatten(), 75) - np.percentile(arr.flatten(), 25)\n",
    "    low = np.percentile(arr.flatten(), 25)\n",
    "    #high = np.percentile(arr.flatten(), 75)\n",
    "    thresh_low = low - 1.5*iqr\n",
    "    #thresh_high = high + 2*iqr\n",
    "    #arr[np.where(arr > thresh_high)] = 1.\n",
    "    arr[np.where(arr < thresh_low)] = 1.\n",
    "    arr[np.where(arr < 1)] = 0.\n",
    "    arr = np.reshape(arr, (arr.shape[0], 6, 8, 6, 8))\n",
    "    arr = np.sum(arr, axis = (2, 4))\n",
    "    arr = resize(arr, (arr.shape[0], 48, 48), 0)\n",
    "    fake_shadows = np.zeros((arr.shape[0], arr.shape[1], arr.shape[2]))\n",
    "    for step in range(arr.shape[0]):\n",
    "        if step > 0:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        before = arr[step - 1, x, y]\n",
    "                        if abs(before - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "                            \n",
    "    for step in range(arr.shape[0]):\n",
    "        if step < arr.shape[0] - 1:\n",
    "            for x in range(arr.shape[1]):\n",
    "                for y in range(arr.shape[2]):\n",
    "                    if arr[step, x, y] > 0:\n",
    "                        after = arr[step + 1, x, y]\n",
    "                        if abs(after - arr[step, x, y]) <= 20:\n",
    "                            fake_shadows[step, x, y] = 1\n",
    "    arr[np.where(arr > 5)] = 1.\n",
    "    arr[np.where(arr < 5)] = 0.\n",
    "    before = np.sum(arr)\n",
    "    arr[np.where(fake_shadows == 1)] = 0.\n",
    "    after = np.sum(arr)\n",
    "    \n",
    "    print(\"Removed {} fake shadows, leaving {}\".format(before - after, after))\n",
    "    print(\"The total percent shadow cover is: {}%\".format(100*(after/(arr.shape[0]*arr.shape[1]*arr.shape[2]))))\n",
    "    for step in range(arr.shape[0]):\n",
    "        for x in range(1, arr.shape[1] -1):\n",
    "            for y in range(1, arr.shape[2] - 1):\n",
    "                if np.sum(arr[step, x-1:x+2, y-1:y+2]) == 1:\n",
    "                    if arr[step, x, y] != 0:\n",
    "                        print(\"Removing: {} {} {} {}\".format(step, x, y, np.sum(arr[step, x-1:x+2, y-1:y+2])))\n",
    "                        arr[step, x, y] = 0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_best_images(img_bands, image_dates):\n",
    "    # This function interpolates data to 5 day windows linearly\n",
    "\n",
    "    biweekly_dates = [day for day in range(0, 360, 5)] # ideal imagery dates are every 15 days\n",
    "    \n",
    "    # Clouds have been removed at this step, so all steps are satisfactory\n",
    "    satisfactory_ids = [x for x in range(0, img_bands.shape[0])]\n",
    "    satisfactory_dates = [value for idx, value in enumerate(image_dates) if idx in satisfactory_ids]\n",
    "    \n",
    "    \n",
    "    selected_images = {}\n",
    "    for i in biweekly_dates:\n",
    "        distances = [abs(date - i) for date in satisfactory_dates]\n",
    "        closest = np.min(distances)\n",
    "        closest_id = np.argmin(distances)\n",
    "        # If there is imagery within 5 days, select it\n",
    "        if closest < 8:\n",
    "            date = satisfactory_dates[closest_id]\n",
    "            image_idx = int(np.argwhere(np.array(image_dates) == date)[0])\n",
    "            selected_images[i] = {'image_date': [date], 'image_ratio': [1], 'image_idx': [image_idx]}\n",
    "        # If there is not imagery within 7 days, look for the closest above and below imagery\n",
    "        else:\n",
    "            distances = np.array([(date - i) for date in satisfactory_dates])\n",
    "            # Number of days above and below the selected date of the nearest clean imagery\n",
    "            above = distances[np.where(distances < 0, distances, -np.inf).argmax()]\n",
    "            below = distances[np.where(distances > 0, distances, np.inf).argmin()]\n",
    "            if abs(above) > 240: # If date is the last date, occassionally argmax would set above to - number\n",
    "                above = below\n",
    "            if abs(below) > 240:\n",
    "                below = above\n",
    "            if above != below:\n",
    "                below_ratio = above / (above - below)\n",
    "                above_ratio = 1 - below_ratio\n",
    "            else:\n",
    "                above_ratio = below_ratio = 0.5\n",
    "                \n",
    "            # Extract the image date and imagery index for the above and below values\n",
    "            above_date = i + above\n",
    "            above_image_idx = int(np.argwhere(np.array(image_dates) == above_date)[0])\n",
    "            \n",
    "            below_date = i + below\n",
    "            below_image_idx = int(np.argwhere(np.array(image_dates) == below_date)[0])\n",
    "            \n",
    "            selected_images[i] = {'image_date': [above_date, below_date], 'image_ratio': [above_ratio, below_ratio],\n",
    "                                 'image_idx': [above_image_idx, below_image_idx]}\n",
    "                               \n",
    "    max_distance = 0\n",
    "    \n",
    "    for i in selected_images.keys():\n",
    "        #print(i, selected_images[i])\n",
    "        if len(selected_images[i]['image_date']) == 2:\n",
    "            dist = selected_images[i]['image_date'][1] - selected_images[i]['image_date'][0]\n",
    "            if dist > max_distance:\n",
    "                max_distance = dist\n",
    "    \n",
    "    print(\"Maximum time distance: {}\".format(max_distance))\n",
    "        \n",
    "    # Compute the weighted average of the selected imagery for each time step\n",
    "    keep_steps = []\n",
    "    use_median = False\n",
    "    for i in selected_images.keys():\n",
    "        step1_additional = None\n",
    "        step2_additional = None\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "        if len(info['image_idx']) == 2:\n",
    "            step1 = img_bands[info['image_idx'][0]] # * info['image_ratio'][0]\n",
    "            step2 = img_bands[info['image_idx'][1]]\n",
    "            #if info['image_idx'][0] == 0:\n",
    "            #    step1_additional = img_bands[-1]\n",
    "            #    print(\"Using last step\")\n",
    "            #if info['image_idx'][1] == (img_bands.shape[0] - 1):\n",
    "            #    step2_additional = img_bands[0]\n",
    "            ##    print(\"Using first step\")\n",
    "            #if step1_additional is None and step2_additional is None:\n",
    "            step = step1 * 0.5 + step2 * 0.5\n",
    "            #if step1_additional is not None:\n",
    "            #    print(\"Echo\")\n",
    "            #    step = (step1 + step2 + step1_additional) * (1/3)\n",
    "            #if step2_additional is not None:\n",
    "             #   print(\"Echo\")\n",
    "            #    step = (step1 + step2 + step2_additional) * (1/3)\n",
    "        keep_steps.append(step)\n",
    "    '''\n",
    "    for i in selected_images.keys():\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "            use_median = False\n",
    "        if len(info['image_idx']) == 2:\n",
    "            difference = np.max([abs(info['image_date'][0] - int(i)),\n",
    "                                 abs(info['image_date'][1] - int(i))]) \n",
    "            step1 = img_bands[info['image_idx'][0]] # * info['image_ratio'][0]\n",
    "            step2_idx = info['image_idx'][0] - 1\n",
    "            if step2_idx < 0:\n",
    "                step2_idx = (img_bands.shape[0] - 1)\n",
    "            step2 = img_bands[step2_idx]\n",
    "            step3 = img_bands[info['image_idx'][1]]\n",
    "            step4_idx = info['image_idx'][1] + 1\n",
    "            if step4_idx > (img_bands.shape[0] - 1):\n",
    "                step4_idx = 0\n",
    "            step4 = img_bands[step4_idx]\n",
    "            #step2 = img_bands[info['image_idx'][1]] * 0.5 # info['image_ratio'][1]\n",
    "            if difference > 100 or use_median == True:\n",
    "                print(\"Median, {}\".format(difference))\n",
    "                use_median = True\n",
    "                stacked = np.stack([step1, step2, step3, step4])\n",
    "                step = np.median(stacked, axis = 0)\n",
    "            else:\n",
    "                use_median = False\n",
    "                step = step1 * 0.5 + step3 * 0.5\n",
    "        '''\n",
    "        #keep_steps.append(step)\n",
    "        \n",
    "    keep_steps = np.stack(keep_steps)\n",
    "    return keep_steps, max_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  31  59  90 120 151 181 212 243 273 304 334]\n"
     ]
    }
   ],
   "source": [
    "days_per_month = [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30]\n",
    "starting_days = np.cumsum(days_per_month)\n",
    "print(starting_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "super_resolve = True\n",
    "year = 2019\n",
    "\n",
    "DATA_LOCATION = '../data/ghana-test.csv'\n",
    "OUTPUT_FOLDER = '../data/test-smooth-200/'\n",
    "\n",
    "\n",
    "def download_plots(data_location = DATA_LOCATION, output_folder = OUTPUT_FOLDER):\n",
    "    print(data_location)\n",
    "    df = pd.read_csv(data_location, encoding = \"ISO-8859-1\")\n",
    "    print(df.columns)\n",
    "    df = df.drop('IMAGERY_TITLE', axis = 1)\n",
    "    df = df.dropna(axis = 0)\n",
    "    plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "    existing = [int(x[:-4]) for x in os.listdir(output_folder) if \".DS\" not in x]\n",
    "    to_download = [x for x in plot_ids if x not in existing]\n",
    "    print(\"STARTING DOWNLOAD OF {} plots from {} to {}\".format(len(to_download), data_location, output_folder))\n",
    "    errors = []\n",
    "    for i, val in enumerate(to_download):\n",
    "        print(i, val)\n",
    "        print(\"Downloading {}/{}, {}\".format(i+1, len(to_download), val))\n",
    "        location = calc_bbox(val, df = df)\n",
    "        location = bounding_box(location, expansion = IMSIZE*10)\n",
    "        try:\n",
    "            # Identify cloud steps, download DEM, and download L2A series\n",
    "            s1, s1_dates = download_sentinel_1(location, layer = 'SENT')\n",
    "            print(\"ASCENDING: {}\".format(s1.shape))\n",
    "            if s1.shape[0] == 0:\n",
    "                s1, s1_dates = download_sentinel_1(location, layer = \"SENT_DESC\")\n",
    "                print(\"DESCENDING: {}\".format(s1.shape))\n",
    "            if s1_dates.shape[0] > 0:\n",
    "                s1, max_distance_s1 = calculate_and_save_best_images(s1, s1_dates)\n",
    "\n",
    "\n",
    "                # Retain only iamgery every 15 days\n",
    "                biweekly_dates = np.array([day for day in range(0, 360, 5)])\n",
    "                to_remove = np.argwhere(biweekly_dates % 15 != 0)\n",
    "                s1 = np.delete(s1, to_remove, 0)\n",
    "\n",
    "                if max_distance_s1 <= 240:\n",
    "                    np.save(output_folder + str(val), s1)\n",
    "                    print(\"\\n\")\n",
    "                else:\n",
    "                    print(\"Skipping {} because there is a {} distance\".format(val, max_distance))\n",
    "                    print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.fatal(e, exc_info=True)\n",
    "            errors.append(img)\n",
    "            #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/project-val/ghana-val.csv\n",
      "Index(['PLOT_ID', 'SAMPLE_ID', 'LON', 'LAT', 'FLAGGED', 'ANALYSES', 'USER_ID',\n",
      "       'COLLECTION_TIME', 'ANALYSIS_DURATION', 'IMAGERY_TITLE', 'TREE'],\n",
      "      dtype='object')\n",
      "STARTING DOWNLOAD OF 175 plots from ../data/project-val/ghana-val.csv to ../data/project-val/sentinel-1/\n",
      "0 136399866\n",
      "Downloading 1/175, 136399866\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "1 136399867\n",
      "Downloading 2/175, 136399867\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "2 136399868\n",
      "Downloading 3/175, 136399868\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "3 136399869\n",
      "Downloading 4/175, 136399869\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "4 136399870\n",
      "Downloading 5/175, 136399870\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "5 136399871\n",
      "Downloading 6/175, 136399871\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "6 136399872\n",
      "Downloading 7/175, 136399872\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "7 136399873\n",
      "Downloading 8/175, 136399873\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "8 136399874\n",
      "Downloading 9/175, 136399874\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "9 136399875\n",
      "Downloading 10/175, 136399875\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "10 136399876\n",
      "Downloading 11/175, 136399876\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "11 136399877\n",
      "Downloading 12/175, 136399877\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "12 136399878\n",
      "Downloading 13/175, 136399878\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "13 136399879\n",
      "Downloading 14/175, 136399879\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "14 136399880\n",
      "Downloading 15/175, 136399880\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "15 136399881\n",
      "Downloading 16/175, 136399881\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "16 136399882\n",
      "Downloading 17/175, 136399882\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "17 136399883\n",
      "Downloading 18/175, 136399883\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "18 136399884\n",
      "Downloading 19/175, 136399884\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "19 136399885\n",
      "Downloading 20/175, 136399885\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "20 136399886\n",
      "Downloading 21/175, 136399886\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "21 136399887\n",
      "Downloading 22/175, 136399887\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "22 136399888\n",
      "Downloading 23/175, 136399888\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "23 136399889\n",
      "Downloading 24/175, 136399889\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "24 136399890\n",
      "Downloading 25/175, 136399890\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "25 136399891\n",
      "Downloading 26/175, 136399891\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "26 136399892\n",
      "Downloading 27/175, 136399892\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "27 136399893\n",
      "Downloading 28/175, 136399893\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "28 136399894\n",
      "Downloading 29/175, 136399894\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "29 136399895\n",
      "Downloading 30/175, 136399895\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "30 136399896\n",
      "Downloading 31/175, 136399896\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "31 136399897\n",
      "Downloading 32/175, 136399897\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "32 136399898\n",
      "Downloading 33/175, 136399898\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "33 136399899\n",
      "Downloading 34/175, 136399899\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "34 136399900\n",
      "Downloading 35/175, 136399900\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "35 136399901\n",
      "Downloading 36/175, 136399901\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "36 136399902\n",
      "Downloading 37/175, 136399902\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "37 136399903\n",
      "Downloading 38/175, 136399903\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "38 136399904\n",
      "Downloading 39/175, 136399904\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "39 136399905\n",
      "Downloading 40/175, 136399905\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "40 136399906\n",
      "Downloading 41/175, 136399906\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "41 136399907\n",
      "Downloading 42/175, 136399907\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "42 136399908\n",
      "Downloading 43/175, 136399908\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "43 136399909\n",
      "Downloading 44/175, 136399909\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "44 136399910\n",
      "Downloading 45/175, 136399910\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "45 136399911\n",
      "Downloading 46/175, 136399911\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "46 136399912\n",
      "Downloading 47/175, 136399912\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "47 136399913\n",
      "Downloading 48/175, 136399913\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "48 136399914\n",
      "Downloading 49/175, 136399914\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "49 136399915\n",
      "Downloading 50/175, 136399915\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "50 136399916\n",
      "Downloading 51/175, 136399916\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "51 136399917\n",
      "Downloading 52/175, 136399917\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "52 136399918\n",
      "Downloading 53/175, 136399918\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "53 136399919\n",
      "Downloading 54/175, 136399919\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "54 136399920\n",
      "Downloading 55/175, 136399920\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "55 136399921\n",
      "Downloading 56/175, 136399921\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "56 136399922\n",
      "Downloading 57/175, 136399922\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "57 136399923\n",
      "Downloading 58/175, 136399923\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "58 136399924\n",
      "Downloading 59/175, 136399924\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "59 136399925\n",
      "Downloading 60/175, 136399925\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "60 136399926\n",
      "Downloading 61/175, 136399926\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "61 136399927\n",
      "Downloading 62/175, 136399927\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "62 136399928\n",
      "Downloading 63/175, 136399928\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "63 136399929\n",
      "Downloading 64/175, 136399929\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "64 136399930\n",
      "Downloading 65/175, 136399930\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "65 136399931\n",
      "Downloading 66/175, 136399931\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "66 136399932\n",
      "Downloading 67/175, 136399932\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "67 136399933\n",
      "Downloading 68/175, 136399933\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "68 136399934\n",
      "Downloading 69/175, 136399934\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "69 136399935\n",
      "Downloading 70/175, 136399935\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "70 136399936\n",
      "Downloading 71/175, 136399936\n",
      "[480.0, 480.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "71 136399937\n",
      "Downloading 72/175, 136399937\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "72 136399938\n",
      "Downloading 73/175, 136399938\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "73 136399939\n",
      "Downloading 74/175, 136399939\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "74 136399940\n",
      "Downloading 75/175, 136399940\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "75 136399941\n",
      "Downloading 76/175, 136399941\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "76 136399942\n",
      "Downloading 77/175, 136399942\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "77 136399943\n",
      "Downloading 78/175, 136399943\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "78 136399944\n",
      "Downloading 79/175, 136399944\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "79 136399945\n",
      "Downloading 80/175, 136399945\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "80 136399946\n",
      "Downloading 81/175, 136399946\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "81 136399947\n",
      "Downloading 82/175, 136399947\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "82 136399948\n",
      "Downloading 83/175, 136399948\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "83 136399949\n",
      "Downloading 84/175, 136399949\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "84 136399950\n",
      "Downloading 85/175, 136399950\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "85 136399951\n",
      "Downloading 86/175, 136399951\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "86 136399952\n",
      "Downloading 87/175, 136399952\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "87 136399953\n",
      "Downloading 88/175, 136399953\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "88 136399954\n",
      "Downloading 89/175, 136399954\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "89 136399955\n",
      "Downloading 90/175, 136399955\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "90 136399956\n",
      "Downloading 91/175, 136399956\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "91 136399957\n",
      "Downloading 92/175, 136399957\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "92 136399958\n",
      "Downloading 93/175, 136399958\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "93 136399959\n",
      "Downloading 94/175, 136399959\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "94 136399960\n",
      "Downloading 95/175, 136399960\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "95 136399961\n",
      "Downloading 96/175, 136399961\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "96 136399962\n",
      "Downloading 97/175, 136399962\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "97 136399963\n",
      "Downloading 98/175, 136399963\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "98 136399964\n",
      "Downloading 99/175, 136399964\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "99 136399965\n",
      "Downloading 100/175, 136399965\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "100 136399966\n",
      "Downloading 101/175, 136399966\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "101 136399967\n",
      "Downloading 102/175, 136399967\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "102 136399968\n",
      "Downloading 103/175, 136399968\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "103 136399969\n",
      "Downloading 104/175, 136399969\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "104 136399970\n",
      "Downloading 105/175, 136399970\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "105 136399971\n",
      "Downloading 106/175, 136399971\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "106 136399972\n",
      "Downloading 107/175, 136399972\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "107 136399973\n",
      "Downloading 108/175, 136399973\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "108 136399974\n",
      "Downloading 109/175, 136399974\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "109 136399975\n",
      "Downloading 110/175, 136399975\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "110 136399976\n",
      "Downloading 111/175, 136399976\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "111 136399977\n",
      "Downloading 112/175, 136399977\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "112 136399978\n",
      "Downloading 113/175, 136399978\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "113 136399979\n",
      "Downloading 114/175, 136399979\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "114 136399980\n",
      "Downloading 115/175, 136399980\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "115 136399981\n",
      "Downloading 116/175, 136399981\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "116 136399982\n",
      "Downloading 117/175, 136399982\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "117 136399983\n",
      "Downloading 118/175, 136399983\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "118 136399984\n",
      "Downloading 119/175, 136399984\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "119 136399985\n",
      "Downloading 120/175, 136399985\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "120 136399986\n",
      "Downloading 121/175, 136399986\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "121 136399987\n",
      "Downloading 122/175, 136399987\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "122 136399988\n",
      "Downloading 123/175, 136399988\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "123 136399989\n",
      "Downloading 124/175, 136399989\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "124 136399990\n",
      "Downloading 125/175, 136399990\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "125 136399991\n",
      "Downloading 126/175, 136399991\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "126 136399992\n",
      "Downloading 127/175, 136399992\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "127 136399993\n",
      "Downloading 128/175, 136399993\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "128 136399994\n",
      "Downloading 129/175, 136399994\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "129 136399995\n",
      "Downloading 130/175, 136399995\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "130 136399996\n",
      "Downloading 131/175, 136399996\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "131 136399997\n",
      "Downloading 132/175, 136399997\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "132 136399998\n",
      "Downloading 133/175, 136399998\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "133 136399999\n",
      "Downloading 134/175, 136399999\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "134 136400000\n",
      "Downloading 135/175, 136400000\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "135 136400001\n",
      "Downloading 136/175, 136400001\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "136 136400002\n",
      "Downloading 137/175, 136400002\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "137 136400003\n",
      "Downloading 138/175, 136400003\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "138 136400004\n",
      "Downloading 139/175, 136400004\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "139 136400005\n",
      "Downloading 140/175, 136400005\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "140 136400006\n",
      "Downloading 141/175, 136400006\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "141 136400007\n",
      "Downloading 142/175, 136400007\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "142 136400008\n",
      "Downloading 143/175, 136400008\n",
      "[480.0, 480.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "143 136400009\n",
      "Downloading 144/175, 136400009\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "144 136400010\n",
      "Downloading 145/175, 136400010\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "145 136400011\n",
      "Downloading 146/175, 136400011\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "146 136400012\n",
      "Downloading 147/175, 136400012\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "147 136400013\n",
      "Downloading 148/175, 136400013\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "148 136400014\n",
      "Downloading 149/175, 136400014\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "149 136400015\n",
      "Downloading 150/175, 136400015\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "150 136400016\n",
      "Downloading 151/175, 136400016\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "151 136400017\n",
      "Downloading 152/175, 136400017\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "152 136400019\n",
      "Downloading 153/175, 136400019\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "153 136400020\n",
      "Downloading 154/175, 136400020\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "154 136400021\n",
      "Downloading 155/175, 136400021\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "155 136400022\n",
      "Downloading 156/175, 136400022\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "156 136400023\n",
      "Downloading 157/175, 136400023\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "157 136400024\n",
      "Downloading 158/175, 136400024\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "158 136400025\n",
      "Downloading 159/175, 136400025\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "159 136400026\n",
      "Downloading 160/175, 136400026\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "160 136400027\n",
      "Downloading 161/175, 136400027\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "161 136400028\n",
      "Downloading 162/175, 136400028\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "162 136400029\n",
      "Downloading 163/175, 136400029\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "163 136400030\n",
      "Downloading 164/175, 136400030\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "164 136400031\n",
      "Downloading 165/175, 136400031\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "165 136400032\n",
      "Downloading 166/175, 136400032\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "166 136400033\n",
      "Downloading 167/175, 136400033\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "167 136400034\n",
      "Downloading 168/175, 136400034\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "168 136400035\n",
      "Downloading 169/175, 136400035\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "169 136400036\n",
      "Downloading 170/175, 136400036\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "170 136400037\n",
      "Downloading 171/175, 136400037\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "171 136400038\n",
      "Downloading 172/175, 136400038\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "172 136400039\n",
      "Downloading 173/175, 136400039\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "173 136400040\n",
      "Downloading 174/175, 136400040\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n",
      "174 136400041\n",
      "Downloading 175/175, 136400041\n",
      "[480.0, 480.0]\n",
      "ASCENDING: (26, 16, 16, 2)\n",
      "Maximum time distance: 30\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(\"../data/project-val\"):\n",
    "    if \"ghana\" in i and i[-4:] == \".csv\":\n",
    "        #if any(x in i for x in [\"africa-west\", \"cameroon\", \"koure\", \"niger\"]):\n",
    "        download_plots(\"../data/project-val/\" + i, \"../data/project-val/sentinel-1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
