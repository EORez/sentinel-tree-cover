{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and process sentinel 2 data\n",
    "\n",
    "## John Brandt\n",
    "## April 1, 2020\n",
    "\n",
    "## Package imports, API import, source scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import scipy.sparse as sparse\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "from collections import Counter\n",
    "from osgeo import ogr, osr\n",
    "from random import shuffle\n",
    "from scipy.sparse.linalg import splu\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType\n",
    "from sentinelhub import CRS, BBox, constants, DataSource, CustomUrlParam\n",
    "from skimage.transform import resize\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "        key = (yaml.safe_load(stream))\n",
    "        API_KEY = key['key'] \n",
    "        \n",
    "%matplotlib inline\n",
    "%run ../src/utils/slope.py\n",
    "%run ../src/utils/utils.py\n",
    "%run ../src/utils/download_utils.py\n",
    "%run ../src/utils/whittaker_smoother.py\n",
    "%run ../src/dsen2/utils/DSen2Net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "SUPER_RESOLVE = True\n",
    "YEAR = 2019\n",
    "TIME = ('{}-12-15'.format(str(YEAR - 1)), '{}-01-15'.format(str(YEAR + 1)))\n",
    "EPSG = CRS.WGS84\n",
    "IMSIZE = 48\n",
    "CLOUD_DETECTOR = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)\n",
    "DATA_LOCATION = '../data/ghana-test.csv'\n",
    "OUTPUT_FOLDER = '../data/test-smooth-200/'\n",
    "\n",
    "# For DSen2 superresolve\n",
    "MDL_PATH = \"../src/dsen2/models/\"\n",
    "INPUT_SHAPE = ((4, None, None), (6, None, None))\n",
    "MODEL = s2model(INPUT_SHAPE, num_layers=6, feature_size=128)\n",
    "PREDICT_FILE = MDL_PATH+'s2_032_lr_1e-04.hdf5'\n",
    "MODEL.load_weights(PREDICT_FILE)\n",
    "\n",
    "# Constants\n",
    "starting_days = np.cumsum([0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30])\n",
    "c_arr = np.array([[1, 1, 1, 1, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 2, 3, 2, 1,],\n",
    "                  [1, 2, 2, 2, 1,],\n",
    "                  [1, 1, 1, 1, 1,],])\n",
    "                  \n",
    "c_arr = c_arr / 3\n",
    "o_arr = 1 - c_arr\n",
    "c_arr = np.tile(c_arr[:, :, np.newaxis], (1, 1, 11))\n",
    "o_arr = np.tile(o_arr[:, :, np.newaxis], (1, 1, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proximal_steps_index(date, satisfactory):\n",
    "    \"\"\"Returns proximal steps that are cloud and shadow free\n",
    "\n",
    "         Parameters:\n",
    "          date (int): current time step\n",
    "          satisfactory (list): time steps with no clouds or shadows\n",
    "\n",
    "         Returns:\n",
    "          arg_before (str): index of the prior clean image\n",
    "          arg_after (int): index of the next clean image\n",
    "    \"\"\"\n",
    "    arg_before, arg_after = None, None\n",
    "    if date > 0:\n",
    "        idx_before = satisfactory - date\n",
    "        arg_before = idx_before[np.where(idx_before < 0, idx_before, -np.inf).argmax()]\n",
    "    if date < np.max(satisfactory):\n",
    "        idx_after = satisfactory - date\n",
    "        arg_after = idx_after[np.where(idx_after > 0, idx_after, np.inf).argmin()]\n",
    "    if not arg_after and not arg_before:\n",
    "        arg_after = date\n",
    "        arg_before = date\n",
    "    if not arg_after:\n",
    "        arg_after = arg_before\n",
    "    if not arg_before:\n",
    "        arg_before = arg_after\n",
    "    return arg_before, arg_after\n",
    "\n",
    "\n",
    "def DSen2(d10, d20):\n",
    "    \"\"\"Super resolves 20 meter bans using the DSen2 convolutional\n",
    "       neural network, as specified in Lanaras et al. 2018\n",
    "       https://github.com/lanha/DSen2\n",
    "\n",
    "        Parameters:\n",
    "         d10 (arr): (4, X, Y) shape array with 10 meter resolution\n",
    "         d20 (arr): (6, X, Y) shape array with 20 meter resolution\n",
    "\n",
    "        Returns:\n",
    "         prediction (arr): (6, X, Y) shape array with 10 meter superresolved\n",
    "                          output of DSen2 on d20 array\n",
    "    \"\"\"\n",
    "    test = [d10, d20]\n",
    "    input_shape = ((4, None, None), (6, None, None))\n",
    "    prediction = _predict(test, input_shape, deep=False)\n",
    "    return prediction\n",
    "\n",
    "def _predict(test, input_shape, model = MODEL, deep=False, run_60=False):\n",
    "    \n",
    "    prediction = model.predict(test, verbose=1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bbox(plot_id, df):\n",
    "    \"\"\" Calculates the corners of a bounding box from an input\n",
    "        pandas dataframe as output by Collect Earth Online\n",
    "\n",
    "        Parameters:\n",
    "         plot_id (int): plot_id of associated plot\n",
    "         df (pandas.DataFrame): dataframe of associated CEO survey\n",
    "    \n",
    "        Returns:\n",
    "         bounding_box (list): [(min(x), min(y)),\n",
    "                              (max(x), max_y))]\n",
    "    \"\"\"\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    # TOP, LEFT, BOTTOM, RIGHT\n",
    "    # (min x, min y), (max x, max y)\n",
    "    return [(min(subs['LON']), min(subs['LAT'])),\n",
    "            (max(subs['LON']), max(subs['LAT']))]\n",
    "\n",
    "def bounding_box(points, expansion = 160):\n",
    "    \"\"\" Calculates the corners of a bounding box with an\n",
    "        input expansion in meters from a given bounding_box\n",
    "        \n",
    "        Subcalls:\n",
    "         calculate_epsg, convertCoords\n",
    "\n",
    "        Parameters:\n",
    "         points (list): output of calc_bbox\n",
    "         expansion (float): number of meters to expand or shrink the\n",
    "                            points edges to be\n",
    "    \n",
    "        Returns:\n",
    "         bl (tuple): x, y of bottom left corner with edges of expansion meters\n",
    "         tr (tuple): x, y of top right corner with edges of expansion meters\n",
    "    \"\"\"\n",
    "    bl = list(points[0])\n",
    "    tr = list(points[1])\n",
    "    inproj = Proj('epsg:4326')\n",
    "    outproj_code = calculate_epsg(bl)\n",
    "    outproj = Proj('epsg:' + str(outproj_code))\n",
    "    \n",
    "    bl_utm =  transform(inproj, outproj, bl[1], bl[0])\n",
    "    tr_utm =  transform(inproj, outproj, tr[1], tr[0])\n",
    "    #print(\"Before the expansion\")\n",
    "    #print((bl_utm, tr_utm))\n",
    "    \n",
    "    distance1 = tr_utm[0] - bl_utm[0]\n",
    "    distance2 = tr_utm[1] - bl_utm[1]\n",
    "    expansion1 = (expansion - distance1)/2\n",
    "    expansion2 = (expansion - distance2)/2\n",
    "        \n",
    "    bl_utm = [bl_utm[0] - expansion1, bl_utm[1] - expansion2]\n",
    "    tr_utm = [tr_utm[0] + expansion1, tr_utm[1] + expansion2]\n",
    "\n",
    "    assert (tr_utm[0] - bl_utm[0]) == expansion\n",
    "    assert (tr_utm[1] - bl_utm[1]) == expansion\n",
    "\n",
    "    \n",
    "    zone = str(outproj_code)[3:]\n",
    "    zone = zone[1:] if zone[0] == \"0\" else zone\n",
    "    direction = 'N' if tr[1] >= 0 else 'S'\n",
    "    utm_epsg = \"UTM_\" + zone + direction\n",
    "    return (bl_utm, tr_utm), CRS[utm_epsg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcm_shadow_mask(arr, c_probs):\n",
    "    \"\"\" Calculates the multitemporal shadow mask for Sentinel-2 using\n",
    "        the methods from Candra et al. 2020 on L1C images and matching\n",
    "        outputs to the s2cloudless cloud probabilities\n",
    "\n",
    "        Parameters:\n",
    "         arr (arr): (Time, X, Y, Band) array of L1C data scaled from [0, 1]\n",
    "         c_probs (arr): (Time, X, Y) array of S2cloudless cloud probabilities\n",
    "    \n",
    "        Returns:\n",
    "         shadows_new (arr): cloud mask after Candra et al. 2020 and cloud matching \n",
    "         shadows_original (arr): cloud mask after Candra et al. 2020\n",
    "    \"\"\"\n",
    "    \n",
    "    def _rank_array(arr):\n",
    "        order = arr.argsort()\n",
    "        ranks = order.argsort()\n",
    "        return ranks\n",
    "    \n",
    "    mean_c_probs = np.mean(c_probs, axis = (1, 2))\n",
    "    cloudy_steps = np.argwhere(mean_c_probs > 0.25)\n",
    "    images_clean = np.delete(arr, cloudy_steps, 0)\n",
    "    cloud_ranks = _rank_array(mean_c_probs)\n",
    "    diffs = abs(np.sum(arr - np.mean(images_clean, axis = 0), axis = (1, 2, 3)))\n",
    "    diff_ranks = _rank_array(diffs)\n",
    "    overall_rank = diff_ranks + cloud_ranks\n",
    "    reference_idx = np.argmin(overall_rank)\n",
    "    ri = arr[reference_idx]\n",
    "    print(\"The shadow reference index is: {}\".format(reference_idx))\n",
    "    \n",
    "    shadows = np.zeros((arr.shape[0], 96, 96))    \n",
    "    # Candra et al. 2020\n",
    "    \n",
    "    for time in range(arr.shape[0]):\n",
    "        for x in range(arr.shape[1]):\n",
    "            for y in range(arr.shape[2]):\n",
    "                ti_slice = arr[time, x, y]\n",
    "                ri_slice = ri[x, y]\n",
    "                deltab2 = ti_slice[0] - ri_slice[0]\n",
    "                #deltab3 = ti_slice[2] - ri_slice[2]\n",
    "                #deltab4 = ti_slice[3] - ri_slice[3]\n",
    "                deltab8a = ti_slice[1] - ri_slice[1]\n",
    "                deltab11 = ti_slice[2] - ri_slice[2]\n",
    "\n",
    "                if deltab2 <0.1: #(1000/65535):\n",
    "                    #if deltab3 < (800/65535)\n",
    "                        #if deltab4 < (800/65535)\n",
    "                    if deltab8a < -0.04: # (-400/65535):\n",
    "                        if deltab11 < -0.04: ##(-400/65535):\n",
    "                            if ti_slice[0] < 0.095: #(950/65535):\n",
    "                                shadows[time, x, y] = 1.\n",
    "                                        \n",
    "    shadows_original = np.copy(shadows)\n",
    "    # Remove shadows if cannot coreference a cloud\n",
    "    print(shadows.shape)\n",
    "    shadow_large = np.reshape(shadows, (shadows.shape[0], 96//8, 8, 96//8, 8))\n",
    "    shadow_large = np.sum(shadow_large, axis = (2, 4))\n",
    "    \n",
    "    cloud_large = np.copy(c_probs)\n",
    "    cloud_large[np.where(c_probs > 0.33)] = 1.\n",
    "    cloud_large[np.where(c_probs < 0.33)] = 0.\n",
    "    cloud_large = np.reshape(cloud_large, (shadows.shape[0], 96//8, 8, 96//8, 8))\n",
    "    cloud_large = np.sum(cloud_large, axis = (2, 4))\n",
    "    for time in range(shadow_large.shape[0]):\n",
    "        for x in range(shadow_large.shape[1]):\n",
    "            x_low = np.max([x - 8, 0])\n",
    "            x_high = np.min([x + 8, shadow_large.shape[1] - 1])\n",
    "            for y in range(shadow_large.shape[2]):\n",
    "                y_low = np.max([y - 8, 0])\n",
    "                y_high = np.min([y + 8, shadow_large.shape[1] - 1])\n",
    "                if shadow_large[time, x, y] < 8:\n",
    "                    shadow_large[time, x, y] = 0.\n",
    "                if shadow_large[time, x, y] >= 8:\n",
    "                    shadow_large[time, x, y] = 1.\n",
    "                c_prob_window = cloud_large[time, x_low:x_high, y_low:y_high]\n",
    "                if np.max(c_prob_window) < 24:\n",
    "                    shadow_large[time, x, y] = 0.\n",
    "                    \n",
    "    \n",
    "    shadow_large = resize(shadow_large, (shadow_large.shape[0], 96, 96), order = 0)\n",
    "    shadows *= shadow_large\n",
    "    \n",
    "    # Go through and aggregate the shadow map to an 80m grid, and extend it one grid size around\n",
    "    # any positive ID\n",
    "    \n",
    "    \n",
    "    shadows = np.reshape(shadows, (shadows.shape[0], 96//8, 8, 96//8, 8))\n",
    "    shadows = np.sum(shadows, axis = (2, 4))\n",
    "    shadows[np.where(shadows < 16)] = 0.\n",
    "    shadows[np.where(shadows >= 16)] = 1.\n",
    "    shadows = resize(shadows, (shadows.shape[0], 96, 96), order = 0)\n",
    "    shadows = np.reshape(shadows, (shadows.shape[0], 96//4, 4, 96//4, 4))\n",
    "    shadows = np.max(shadows, (2, 4))\n",
    "    \n",
    "    shadows_new = np.zeros_like(shadows)\n",
    "    for time in range(shadows.shape[0]):\n",
    "        for x in range(shadows.shape[1]):\n",
    "            for y in range(shadows.shape[2]):\n",
    "                if shadows[time, x, y] == 1:\n",
    "                    min_x = np.max([x - 1, 0])\n",
    "                    max_x = np.min([x + 2, shadows.shape[1] - 1])\n",
    "                    min_y = np.max([y - 1, 0])\n",
    "                    max_y = np.min([y + 2, shadows.shape[1] - 1])\n",
    "                    for x_idx in range(min_x, max_x):\n",
    "                        for y_idx in range(min_y, max_y):\n",
    "                            shadows_new[time, x_idx, y_idx] = 1.\n",
    "    shadows_new = resize(shadows_new, (shadows.shape[0], 96, 96), order = 0)\n",
    "    print(\"The shadow probability is: {}\".format(100*np.sum(shadows_new)/(96*96*shadows_new.shape[0])))\n",
    "    return np.array(shadows_new)\n",
    "\n",
    "\n",
    "def identify_clouds(bbox, epsg, time = TIME):\n",
    "\n",
    "    for try_ in range(0, 5):\n",
    "        try:\n",
    "            box = BBox(bbox, crs = epsg)\n",
    "            cloud_request = WmsRequest(\n",
    "                layer='CLOUD_NEW',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                width=96,\n",
    "                height=96,\n",
    "                image_format =  MimeType.TIFF_d8,\n",
    "                maxcc=0.75,\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=48))\n",
    "            \n",
    "            shadow_request = WmsRequest(\n",
    "                layer='SHADOW',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                width=96,\n",
    "                height=96,\n",
    "                image_format =  MimeType.TIFF_d16,\n",
    "                maxcc=0.75,\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=48))\n",
    "\n",
    "            cloud_img = cloud_request.get_data()\n",
    "            cloud_img = np.array(cloud_img)\n",
    "\n",
    "            if np.max(cloud_img > 10):\n",
    "                cloud_img = cloud_img / 255\n",
    "            assert np.max(cloud_img) <= 1.\n",
    "            print(\"Cloud_probs shape: {}\".format(cloud_img.shape))\n",
    "            \n",
    "            shadow_img = shadow_request.get_data()\n",
    "            shadow_img = np.array(shadow_img)\n",
    "            print(\"Shadows_shape: {}\".format(shadow_img.shape))\n",
    "\n",
    "            if np.max(shadow_img > 10):\n",
    "                shadow_img = shadow_img / 65535\n",
    "            print(np.max(shadow_img))\n",
    "            \n",
    "            shadows = mcm_shadow_mask(np.array(shadow_img), cloud_img)\n",
    "            shadows = shadows[:, 24:-24, 24:-24]\n",
    "            return cloud_img[:, 24:-24, 24:-24], shadows\n",
    "        except Exception as e:\n",
    "            logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(plot_id, df, epsg, image_format = MimeType.TIFF_d32f):\n",
    "    #! TODO: ensure that centroid vs. bbox is correctly distinguished\n",
    "    \"\"\" Downloads MapZen digital elevation model and return slope\n",
    "\n",
    "        Parameters:\n",
    "         plot_id (tuple): plot id from collect earth online (CEO)\n",
    "         df (pandas.DataFrame): data associated with plot_id from CEO\n",
    "         epsg (int): UTM EPSG associated with plot_id\n",
    "    \n",
    "        Returns:\n",
    "         slope (arr): (X, Y, 1) array of per-pixel slope from [0, 1]\n",
    "    \"\"\"\n",
    "    location = calc_bbox(plot_id, df = df)\n",
    "    bbox, epsg = bounding_box(location, expansion = (IMSIZE+2)*10)\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=IMSIZE+2,\n",
    "                         height=IMSIZE+2,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format= image_format,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    slope = calcSlope(dem_image.reshape((1, IMSIZE+2, IMSIZE+2)),\n",
    "                      np.full((IMSIZE+2, IMSIZE+2), 10),\n",
    "                      np.full((IMSIZE+2, IMSIZE+2), 10), \n",
    "                      zScale = 1, minSlope = 0.02)\n",
    "    slope = slope.reshape((IMSIZE+2, IMSIZE+2, 1))\n",
    "    slope = slope[1:IMSIZE+1, 1:IMSIZE+1, :]\n",
    "    return slope\n",
    "\n",
    "        \n",
    "def download_layer(bbox, epsg, time = TIME, image_format = MimeType.TIFF_d16):\n",
    "    \"\"\" Downloads the L2A sentinel layer with 10 and 20 meter bands\n",
    "        \n",
    "        Parameters:\n",
    "         bbox (list): output of calc_bbox\n",
    "         epsg (float): EPSG associated with bbox \n",
    "         time (tuple): YY-MM-DD - YY-MM-DD bounds for downloading \n",
    "    \n",
    "        Returns:\n",
    "         img (arr):\n",
    "         img_request (obj): \n",
    "    \"\"\"\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A20',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = image_format,\n",
    "                maxcc=0.75,\n",
    "                resx='20m', resy='20m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'NEAREST',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'NEAREST'},\n",
    "                time_difference=datetime.timedelta(hours=48),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        img_20 = np.stack(img_bands)\n",
    "\n",
    "        if np.max(img_20) >= 10:\n",
    "            img_20 = img_20 / 65535\n",
    "        assert np.max(img_20) <= 2.\n",
    "\n",
    "        s2_20_usage = (img_20.shape[1]*img_20.shape[2])/(512*512) * (6/3) * img_20.shape[0]\n",
    "        print(\"Original 20 meter bands size: {}, using {} PU\".format(img_20.shape, s2_20_usage))\n",
    "        img_20 = resize(img_20, (img_20.shape[0], IMSIZE, IMSIZE, img_20.shape[-1]), order = 0)\n",
    "        \n",
    "        image_request = WcsRequest(\n",
    "                layer='L2A10',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                image_format = image_format,\n",
    "                maxcc=0.75,\n",
    "                resx='10m', resy='10m',\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.DOWNSAMPLING: 'BICUBIC',\n",
    "                                    constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=48),\n",
    "        )\n",
    "        \n",
    "        img_bands = image_request.get_data()\n",
    "        img_10 = np.stack(img_bands)\n",
    "        print(\"The original L2A image size is: {}\".format(img_10.shape))\n",
    "        img_10 = resize(img_10, (img_10.shape[0], IMSIZE, IMSIZE, img_10.shape[-1]), order = 0)\n",
    "        img = np.concatenate([img_10, img_20], axis = -1)\n",
    "\n",
    "        if np.max(img_10) >= 10:\n",
    "            img_10 = img_10 / 65535\n",
    "        assert np.max(img_10) <= 2.\n",
    "        return img, image_request\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud and shadow removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cloud_and_shadows(tiles, probs, shadows, image_dates, wsize = 5):\n",
    "    \"\"\" Interpolates clouds and shadows for each time step with \n",
    "        linear combination of proximal clean time steps for each\n",
    "        region of specified window size\n",
    "        \n",
    "        Parameters:\n",
    "         tiles (arr):\n",
    "         probs (arr): \n",
    "         shadows (arr):\n",
    "         image_dates (list):\n",
    "         wsize (int): \n",
    "    \n",
    "        Returns:\n",
    "         tiles (arr): \n",
    "    \"\"\"\n",
    "    c_probs = np.copy(probs)\n",
    "    c_probs = c_probs - np.min(c_probs, axis = 0)\n",
    "    c_probs[np.where(c_probs > 0.33)] = 1.\n",
    "    c_probs[np.where(c_probs < 0.33)] = 0.\n",
    "    c_probs = np.reshape(c_probs, [c_probs.shape[0], int(IMSIZE/8), 8, int(IMSIZE/8), 8])\n",
    "    c_probs = np.sum(c_probs, (2, 4))\n",
    "    c_probs = resize(c_probs, (c_probs.shape[0], IMSIZE, IMSIZE), 0)\n",
    "    c_probs[np.where(c_probs < 12)] = 0.\n",
    "    c_probs[np.where(c_probs >= 12)] = 1.\n",
    "    c_probs += shadows\n",
    "    c_probs[np.where(c_probs >= 1.)] = 1.\n",
    "    n_interp = 0\n",
    "    for cval in range(0, IMSIZE - 5, 1):\n",
    "        for rval in range(0, IMSIZE - 5, 1):\n",
    "            subs = c_probs[:, cval:cval + wsize, rval:rval+wsize]\n",
    "            satisfactory = [x for x in range(c_probs.shape[0]) if np.sum(subs[x, :, :]) < 10]\n",
    "            satisfactory = np.array(satisfactory)\n",
    "            for date in range(0, tiles.shape[0]):\n",
    "                if np.sum(subs[date, :, :]) > 10:\n",
    "                    n_interp += 1\n",
    "                    before, after = calculate_proximal_steps_index(date, satisfactory)\n",
    "                    before = date + before\n",
    "                    after = date + after\n",
    "                    if after >= tiles.shape[0]:\n",
    "                        after = before\n",
    "                    if before < 0:\n",
    "                        before = after\n",
    "                    bef = tiles[before, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    aft = tiles[after, cval:cval+wsize, rval:rval+wsize, : ]\n",
    "                    before = image_dates[before]\n",
    "                    after = image_dates[after]\n",
    "                    before_diff = abs(image_dates[date] - before)\n",
    "                    after_diff = abs(image_dates[date] - after)\n",
    "                    bef_wt = 1 - before_diff / (before_diff + after_diff)\n",
    "                    aft_wt = 1 - bef_wt\n",
    "                    candidate = bef_wt*bef + aft_wt*aft\n",
    "                    candidate = candidate*c_arr + tiles[date, cval:cval+wsize, rval:rval+wsize, : ]*o_arr\n",
    "                    tiles[date, cval:cval+wsize, rval:rval+wsize, : ] = candidate  \n",
    "    print(\"Interpolated {} px\".format(n_interp))\n",
    "    return tiles\n",
    "\n",
    "def remove_missed_clouds(img):\n",
    "    \"\"\" Removes steps that are likely to be missed cloud or shadows\n",
    "        based on two interquartile ranges for the near infrared band\n",
    "        \n",
    "        Parameters:\n",
    "         img (arr):\n",
    "\n",
    "        Returns:\n",
    "         to_remove (list): \n",
    "    \"\"\"\n",
    "    iqr = np.percentile(img[:, :, :, 3].flatten(), 75) - np.percentile(img[:, :, :, 3].flatten(), 25)\n",
    "    thresh_t = np.percentile(img[:, :, :, 3].flatten(), 75) + iqr*2\n",
    "    thresh_b = np.percentile(img[:, :, :, 3].flatten(), 25) - iqr*2\n",
    "    diffs_fw = np.diff(img, 1, axis = 0)\n",
    "    diffs_fw = np.mean(diffs_fw, axis = (1, 2, 3))\n",
    "    diffs_fw = np.array([0] + list(diffs_fw))\n",
    "    diffs_bw = np.diff(np.flip(img, 0), 1, axis = 0)\n",
    "    diffs_bw = np.flip(np.mean(diffs_bw, axis = (1, 2, 3)))\n",
    "    diffs_bw = np.array(list(diffs_bw) + [0])\n",
    "    diffs = abs(diffs_fw - diffs_bw) * 100 # 3, -3 -> 6, -3, 3 -> 6, -3, -3\n",
    "    #diffs = [int(x) for x in diffs]\n",
    "    outlier_percs = []\n",
    "    for step in range(img.shape[0]):\n",
    "        bottom = len(np.argwhere(img[step, :, :, 3].flatten() > thresh_t))\n",
    "        top = len(np.argwhere(img[step, :, :, 3].flatten() < thresh_b))\n",
    "        p = 100* ((bottom + top) / (IMSIZE*IMSIZE))\n",
    "        outlier_percs.append(p)\n",
    "    to_remove = np.argwhere(np.array(outlier_percs) > 15)\n",
    "    return to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def download_plots(data_location = DATA_LOCATION, output_folder = OUTPUT_FOLDER, image_format = MimeType.TIFF_d16):\n",
    "    \"\"\" Downloads slope and sentinel-2 data for all plots associated\n",
    "        with an input CSV from a collect earth online survey\n",
    "        \n",
    "        Parameters:\n",
    "         data_location (os.path)\n",
    "         output_folder (os.path)\n",
    "        \n",
    "        Subcalls:\n",
    "         calc_bbox, bounding_box\n",
    "         identify_clouds, download_layer, check_zenith, download_dem\n",
    "         remove_clouds_and_shadows, remove_missed_clouds\n",
    "         DSen2\n",
    "         calculate_and_save_best_images\n",
    "         \n",
    "        Creates:\n",
    "         output_folder/{plot_id}.npy\n",
    "    \n",
    "        Returns:\n",
    "         None\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_location)\n",
    "    for column in ['IMAGERY_TITLE', 'STACKINGPROFILEDG', 'PL_PLOTID', 'IMAGERYYEARDG']:\n",
    "        if column in df.columns:\n",
    "            df = df.drop(column, axis = 1)\n",
    "    df = df.dropna(axis = 0)\n",
    "    plot_ids = sorted(df['PLOT_ID'].unique())\n",
    "    existing = [int(x[:-4]) for x in os.listdir(output_folder) if \".DS\" not in x]\n",
    "    to_download = [x for x in plot_ids if x not in existing]\n",
    "    print(\"STARTING DOWNLOAD OF {} plots from {} to {}\".format(len(to_download), data_location, output_folder))\n",
    "    errors = []\n",
    "    for i, val in enumerate(to_download):\n",
    "        print(\"Downloading {}/{}, {}\".format(i+1, len(to_download), val))\n",
    "        initial_bbx = calc_bbox(val, df = df)\n",
    "        sentinel2_bbx, epsg = bounding_box(initial_bbx, expansion = IMSIZE*10)\n",
    "        cloud_bbx, _ = bounding_box(initial_bbx, expansion = 96*10)\n",
    "        try:\n",
    "            # Identify cloud steps, download DEM, and download L2A series\n",
    "            probs, shadows = identify_clouds(cloud_bbx, epsg = epsg)\n",
    "            shadow_sums = np.sum(shadows, axis = (1, 2))\n",
    "            shadow_steps = np.argwhere(shadow_sums > (48*48/3))\n",
    "            dem = download_dem(val, epsg = epsg, df = df)\n",
    "            img, image_request = download_layer(sentinel2_bbx, epsg = epsg, image_format = image_format)\n",
    "\n",
    "            #np.save(\"../data/raw/train-raw/\" + str(val) + \".npy\", img)\n",
    "            #np.save(\"../data/raw/train-dates/\" + str(val) + \".npy\", image_request.get_dates())\n",
    "\n",
    "            # Calculate imagery dates\n",
    "            image_dates = []\n",
    "            for date in image_request.get_dates():\n",
    "                if date.year == YEAR - 1:\n",
    "                    image_dates.append(-365 + starting_days[(date.month-1)] + date.day)\n",
    "                if date.year == YEAR:\n",
    "                    image_dates.append(starting_days[(date.month-1)] + date.day)\n",
    "                if date.year == YEAR + 1:\n",
    "                    image_dates.append(365 + starting_days[(date.month-1)]+date.day)\n",
    "            image_dates = np.array(image_dates)\n",
    "\n",
    "            # Remove imagery where >4% is clouds, and where there is null data\n",
    "            args = np.array([len(np.argwhere(probs[x].flatten() > 0.3)) for x in range(probs.shape[0])])\n",
    "            dirty_steps = np.argwhere(args > (IMSIZE)*(IMSIZE) / 5)\n",
    "            missing_images = [np.argwhere(img[x, :, : :].flatten() == 0.0) for x in range(img.shape[0])]\n",
    "            missing_images = np.array([len(x) for x in missing_images])\n",
    "            missing_images_p = [np.argwhere(img[x, :, : :].flatten() >= 1) for x in range(img.shape[0])]\n",
    "            missing_images_p = np.array([len(x) for x in missing_images_p])\n",
    "            missing_images += missing_images_p\n",
    "            missing_images = list(np.argwhere(missing_images >= 25))\n",
    "            to_remove = np.unique(np.array(list(dirty_steps) + list(missing_images) + list(shadow_steps)))\n",
    "\n",
    "            # Remove null steps\n",
    "            print(\"There are {}/{} dirty steps: {}\"\n",
    "                  \" cloud, {} missing, {} shadow\".format(len(to_remove),\n",
    "                                                         len(img), len(dirty_steps),\n",
    "                                                         len(missing_images),\n",
    "                                                         #len(zenith_outliers),\n",
    "                                                         len(shadow_steps)))\n",
    "\n",
    "            img = np.delete(img, to_remove, 0)\n",
    "            probs = np.delete(probs, to_remove, 0)\n",
    "            image_dates = np.delete(image_dates, to_remove)\n",
    "            shadows = np.delete(shadows, to_remove, 0)\n",
    "\n",
    "            to_remove = remove_missed_clouds(img)\n",
    "            img = np.delete(img, to_remove, 0)\n",
    "            probs = np.delete(probs, to_remove, 0)\n",
    "            image_dates = np.delete(image_dates, to_remove)\n",
    "            shadows = np.delete(shadows, to_remove, 0)\n",
    "            print(\"Removing {} steps based on ratio\".format(len(to_remove)))\n",
    "\n",
    "\n",
    "            # Concatenate DEM\n",
    "            dem = np.tile(dem.reshape((1, IMSIZE, IMSIZE, 1)), (img.shape[0], 1, 1, 1))\n",
    "            tiles = np.concatenate([img, dem], axis = -1)\n",
    "            tiles[:, :, :, -1] /= 90\n",
    "\n",
    "            x = remove_cloud_and_shadows(tiles, probs, shadows, image_dates)\n",
    "            if SUPER_RESOLVE:\n",
    "                x = x[:, 8:40, 8:40, :]\n",
    "                print(\"Shape before super: {}\".format(x.shape))\n",
    "\n",
    "                d10 = x[:, :, :, 0:4]\n",
    "                d20 = x[:, :, :, 4:10]\n",
    "\n",
    "                d10 = np.swapaxes(d10, 1, -1)\n",
    "                d10 = np.swapaxes(d10, 2, 3)\n",
    "                d20 = np.swapaxes(d20, 1, -1)\n",
    "                d20 = np.swapaxes(d20, 2, 3)\n",
    "                superresolved = DSen2(d10, d20)\n",
    "                superresolved = np.swapaxes(superresolved, 1, -1)\n",
    "                superresolved = np.swapaxes(superresolved, 1, 2)\n",
    "                print(superresolved.shape)\n",
    "                print(x.shape)\n",
    "\n",
    "                # returns band IDXs 3, 4, 5, 7, 8, 9\n",
    "                x[:, :, :, 4:10] = superresolved\n",
    "                x = x[:, 8:24, 8:24, :]\n",
    "                print(\"Shape after super: {}\".format(x.shape))\n",
    "            else:\n",
    "                bottom = int(IMSIZE/2 - 8)\n",
    "                top = int(IMSIZE/2 + 8)\n",
    "                x = x[:, bottom:top, bottom:top, :]\n",
    "\n",
    "            # Calculate indices\n",
    "            tiles = evi(x, True)\n",
    "            tiles = bi(tiles, True)\n",
    "            tiles = msavi2(tiles, True)\n",
    "            x = si(tiles, True)\n",
    "\n",
    "            print(\"Shape after vegetation indexes: {}\".format(x.shape))\n",
    "            \n",
    "            missing_pixels = 0\n",
    "            for band in range(0, 15):\n",
    "                for time in range(0, x.shape[0]):\n",
    "                    x_i = x[time, :, :, band]\n",
    "                    missing_pixels += len(np.argwhere(np.isnan(x_i)))\n",
    "                    x_i[np.argwhere(np.isnan(x_i))] = np.mean(x_i)\n",
    "                    x[time, :, :, band] = x_i\n",
    "            print(\"There are {} missing pixels\".format(missing_pixels))\n",
    "\n",
    "            # Interpolate linearly to 5 day frequency\n",
    "            tiles, max_distance = calculate_and_save_best_images(x, image_dates)\n",
    "\n",
    "            # Smooth linear interpolation\n",
    "            coefmat = intialize_smoother()\n",
    "            tiles = interpolate_array(tiles, dim = tiles.shape[1])\n",
    "            \n",
    "            if max_distance <= 240:\n",
    "                np.save(output_folder + str(val), tiles)\n",
    "                #np.save(\"../data/raw/train-clouds/\" + str(val) + \".npy\", probs)\n",
    "                #np.save(\"../data/raw/train-shadows/\" + str(val) + \".npy\", shadows)\n",
    "                print(\"Saved array of {} shape to {}\".format(tiles.shape, val))\n",
    "                print(\"\\n\")\n",
    "            else:\n",
    "                print(\"Skipping {} because there is a {} distance\".format(val, max_distance))\n",
    "                print(\"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.fatal(e, exc_info=True)\n",
    "            #errors.append(img)\n",
    "            #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING DOWNLOAD OF 67 plots from ../data/test-csv/africaoceana-test.csv to ../data/test-s2/\n",
      "Downloading 1/67, 136752947\n",
      "22.19793468382462 -6.447527627293992\n",
      "22.19793468382462 -6.447527627293992\n",
      "Cloud_probs shape: (64, 96, 96)\n",
      "Shadows_shape: (64, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 18\n",
      "(64, 96, 96)\n",
      "The shadow probability is: 1.6221788194444444\n",
      "22.19793468382462 -6.447527627293992\n",
      "Original 20 meter bands size: (64, 24, 24, 6), using 0.28125 PU\n",
      "The original L2A image size is: (64, 48, 48, 4)\n",
      "There are 30/64 dirty steps: 29 cloud, 2 missing, 2 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 770 px\n",
      "Shape before super: (34, 32, 32, 11)\n",
      "34/34 [==============================] - 1s 29ms/step\n",
      "(34, 32, 32, 6)\n",
      "(34, 32, 32, 11)\n",
      "Shape after super: (34, 16, 16, 11)\n",
      "Shape after vegetation indexes: (34, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 67\n",
      "Saved array of (24, 16, 16, 15) shape to 136752947\n",
      "\n",
      "\n",
      "Downloading 2/67, 136752948\n",
      "5.851330090047343 20.33011351949701\n",
      "5.851330090047343 20.33011351949701\n",
      "Cloud_probs shape: (63, 96, 96)\n",
      "Shadows_shape: (63, 96, 96, 3)\n",
      "0.8399023422598612\n",
      "The shadow reference index is: 3\n",
      "(63, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "5.851330090047343 20.33011351949701\n",
      "Original 20 meter bands size: (63, 24, 24, 6), using 0.27685546875 PU\n",
      "The original L2A image size is: (63, 48, 48, 4)\n",
      "There are 5/63 dirty steps: 5 cloud, 0 missing, 0 shadow\n",
      "Removing 6 steps based on ratio\n",
      "Interpolated 0 px\n",
      "Shape before super: (52, 32, 32, 11)\n",
      "52/52 [==============================] - 1s 29ms/step\n",
      "(52, 32, 32, 6)\n",
      "(52, 32, 32, 11)\n",
      "Shape after super: (52, 16, 16, 11)\n",
      "Shape after vegetation indexes: (52, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 20\n",
      "Saved array of (24, 16, 16, 15) shape to 136752948\n",
      "\n",
      "\n",
      "Downloading 3/67, 136752949\n",
      "-0.8466471411691057 29.335573260586735\n",
      "-0.8466471411691057 29.335573260586735\n",
      "Cloud_probs shape: (77, 96, 96)\n",
      "Shadows_shape: (77, 96, 96, 3)\n",
      "0.9830014496070801\n",
      "The shadow reference index is: 9\n",
      "(77, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "-0.8466471411691057 29.335573260586735\n",
      "Original 20 meter bands size: (77, 24, 24, 6), using 0.33837890625 PU\n",
      "The original L2A image size is: (77, 48, 48, 4)\n",
      "There are 26/77 dirty steps: 26 cloud, 2 missing, 0 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 916 px\n",
      "Shape before super: (51, 32, 32, 11)\n",
      "51/51 [==============================] - 1s 29ms/step\n",
      "(51, 32, 32, 6)\n",
      "(51, 32, 32, 11)\n",
      "Shape after super: (51, 16, 16, 11)\n",
      "Shape after vegetation indexes: (51, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 40\n",
      "Saved array of (24, 16, 16, 15) shape to 136752949\n",
      "\n",
      "\n",
      "Downloading 4/67, 136752950\n",
      "18.12002438890602 -20.407711269309075\n",
      "18.12002438890602 -20.407711269309075\n",
      "Cloud_probs shape: (67, 96, 96)\n",
      "Shadows_shape: (67, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 10\n",
      "(67, 96, 96)\n",
      "The shadow probability is: 0.6115257048092869\n",
      "18.12002438890602 -20.407711269309075\n",
      "Original 20 meter bands size: (67, 24, 24, 6), using 0.29443359375 PU\n",
      "The original L2A image size is: (67, 48, 48, 4)\n",
      "There are 8/67 dirty steps: 8 cloud, 2 missing, 1 shadow\n",
      "Removing 3 steps based on ratio\n",
      "Interpolated 462 px\n",
      "Shape before super: (56, 32, 32, 11)\n",
      "56/56 [==============================] - 2s 28ms/step\n",
      "(56, 32, 32, 6)\n",
      "(56, 32, 32, 11)\n",
      "Shape after super: (56, 16, 16, 11)\n",
      "Shape after vegetation indexes: (56, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 0\n",
      "Saved array of (24, 16, 16, 15) shape to 136752950\n",
      "\n",
      "\n",
      "Downloading 5/67, 136752951\n",
      "-3.6275811177119768 21.129985737575108\n",
      "-3.6275811177119768 21.129985737575108\n",
      "Cloud_probs shape: (71, 96, 96)\n",
      "Shadows_shape: (71, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 19\n",
      "(71, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "-3.6275811177119768 21.129985737575108\n",
      "Original 20 meter bands size: (71, 24, 24, 6), using 0.31201171875 PU\n",
      "The original L2A image size is: (71, 48, 48, 4)\n",
      "There are 6/71 dirty steps: 6 cloud, 1 missing, 0 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 0 px\n",
      "Shape before super: (65, 32, 32, 11)\n",
      "65/65 [==============================] - 2s 30ms/step\n",
      "(65, 32, 32, 6)\n",
      "(65, 32, 32, 11)\n",
      "Shape after super: (65, 16, 16, 11)\n",
      "Shape after vegetation indexes: (65, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 20\n",
      "Saved array of (24, 16, 16, 15) shape to 136752951\n",
      "\n",
      "\n",
      "Downloading 6/67, 136752952\n",
      "26.43571630613652 -0.7705706544970534\n",
      "26.43571630613652 -0.7705706544970534\n",
      "Cloud_probs shape: (45, 96, 96)\n",
      "Shadows_shape: (45, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 12\n",
      "(45, 96, 96)\n",
      "The shadow probability is: 2.4498456790123457\n",
      "26.43571630613652 -0.7705706544970534\n",
      "Original 20 meter bands size: (45, 24, 24, 6), using 0.19775390625 PU\n",
      "The original L2A image size is: (45, 48, 48, 4)\n",
      "There are 34/45 dirty steps: 31 cloud, 1 missing, 3 shadow\n",
      "Removing 1 steps based on ratio\n",
      "Interpolated 380 px\n",
      "Shape before super: (10, 32, 32, 11)\n",
      "10/10 [==============================] - 0s 30ms/step\n",
      "(10, 32, 32, 6)\n",
      "(10, 32, 32, 11)\n",
      "Shape after super: (10, 16, 16, 11)\n",
      "Shape after vegetation indexes: (10, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 95\n",
      "Saved array of (24, 16, 16, 15) shape to 136752952\n",
      "\n",
      "\n",
      "Downloading 7/67, 136752953\n",
      "32.371964166384515 -13.755611200514336\n",
      "32.371964166384515 -13.755611200514336\n",
      "Cloud_probs shape: (59, 96, 96)\n",
      "Shadows_shape: (59, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 22\n",
      "(59, 96, 96)\n",
      "The shadow probability is: 2.6777306967984935\n",
      "32.371964166384515 -13.755611200514336\n",
      "Original 20 meter bands size: (59, 24, 24, 6), using 0.25927734375 PU\n",
      "The original L2A image size is: (59, 48, 48, 4)\n",
      "There are 17/59 dirty steps: 15 cloud, 2 missing, 3 shadow\n",
      "Removing 1 steps based on ratio\n",
      "Interpolated 630 px\n",
      "Shape before super: (41, 32, 32, 11)\n",
      "41/41 [==============================] - 1s 30ms/step\n",
      "(41, 32, 32, 6)\n",
      "(41, 32, 32, 11)\n",
      "Shape after super: (41, 16, 16, 11)\n",
      "Shape after vegetation indexes: (41, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 55\n",
      "Saved array of (24, 16, 16, 15) shape to 136752953\n",
      "\n",
      "\n",
      "Downloading 8/67, 136752954\n",
      "13.485773900035722 -1.6591198644713157\n",
      "13.485773900035722 -1.6591198644713157\n",
      "Cloud_probs shape: (36, 96, 96)\n",
      "Shadows_shape: (36, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 4\n",
      "(36, 96, 96)\n",
      "The shadow probability is: 0.7185570987654321\n",
      "13.485773900035722 -1.6591198644713157\n",
      "Original 20 meter bands size: (36, 24, 24, 6), using 0.158203125 PU\n",
      "The original L2A image size is: (36, 48, 48, 4)\n",
      "There are 31/36 dirty steps: 31 cloud, 4 missing, 0 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 272 px\n",
      "Shape before super: (5, 32, 32, 11)\n",
      "5/5 [==============================] - 0s 29ms/step\n",
      "(5, 32, 32, 6)\n",
      "(5, 32, 32, 11)\n",
      "Shape after super: (5, 16, 16, 11)\n",
      "Shape after vegetation indexes: (5, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 270\n",
      "Skipping 136752954 because there is a 270 distance\n",
      "\n",
      "\n",
      "Downloading 9/67, 136752955\n",
      "48.71248389705753 9.702655570630448\n",
      "48.71248389705753 9.702655570630448\n",
      "Cloud_probs shape: (72, 96, 96)\n",
      "Shadows_shape: (72, 96, 96, 3)\n",
      "0.9044937819485771\n",
      "The shadow reference index is: 52\n",
      "(72, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "48.71248389705753 9.702655570630448\n",
      "Original 20 meter bands size: (72, 24, 24, 6), using 0.31640625 PU\n",
      "The original L2A image size is: (72, 48, 48, 4)\n",
      "There are 17/72 dirty steps: 17 cloud, 0 missing, 0 shadow\n",
      "Removing 1 steps based on ratio\n",
      "Interpolated 766 px\n",
      "Shape before super: (54, 32, 32, 11)\n",
      "54/54 [==============================] - 2s 29ms/step\n",
      "(54, 32, 32, 6)\n",
      "(54, 32, 32, 11)\n",
      "Shape after super: (54, 16, 16, 11)\n",
      "Shape after vegetation indexes: (54, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 45\n",
      "Saved array of (24, 16, 16, 15) shape to 136752955\n",
      "\n",
      "\n",
      "Downloading 10/67, 136752956\n",
      "7.538665062194721 16.754972760586668\n",
      "7.538665062194721 16.754972760586668\n",
      "Cloud_probs shape: (72, 96, 96)\n",
      "Shadows_shape: (72, 96, 96, 3)\n",
      "0.7069047074082552\n",
      "The shadow reference index is: 51\n",
      "(72, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "7.538665062194721 16.754972760586668\n",
      "Original 20 meter bands size: (72, 24, 24, 6), using 0.31640625 PU\n",
      "The original L2A image size is: (72, 48, 48, 4)\n",
      "There are 11/72 dirty steps: 11 cloud, 0 missing, 0 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 0 px\n",
      "Shape before super: (61, 32, 32, 11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 2s 27ms/step\n",
      "(61, 32, 32, 6)\n",
      "(61, 32, 32, 11)\n",
      "Shape after super: (61, 16, 16, 11)\n",
      "Shape after vegetation indexes: (61, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 20\n",
      "Saved array of (24, 16, 16, 15) shape to 136752956\n",
      "\n",
      "\n",
      "Downloading 11/67, 136752957\n",
      "9.993457780322002 26.32164219755552\n",
      "9.993457780322002 26.32164219755552\n",
      "Cloud_probs shape: (72, 96, 96)\n",
      "Shadows_shape: (72, 96, 96, 3)\n",
      "0.9165941863126573\n",
      "The shadow reference index is: 6\n",
      "(72, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "9.993457780322002 26.32164219755552\n",
      "Original 20 meter bands size: (72, 24, 24, 6), using 0.31640625 PU\n",
      "The original L2A image size is: (72, 48, 48, 4)\n",
      "There are 6/72 dirty steps: 6 cloud, 0 missing, 0 shadow\n",
      "Removing 2 steps based on ratio\n",
      "Interpolated 2801 px\n",
      "Shape before super: (64, 32, 32, 11)\n",
      "64/64 [==============================] - 2s 28ms/step\n",
      "(64, 32, 32, 6)\n",
      "(64, 32, 32, 11)\n",
      "Shape after super: (64, 16, 16, 11)\n",
      "Shape after vegetation indexes: (64, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 20\n",
      "Saved array of (24, 16, 16, 15) shape to 136752957\n",
      "\n",
      "\n",
      "Downloading 12/67, 136752958\n",
      "48.50986690273462 8.653384732640955\n",
      "48.50986690273462 8.653384732640955\n",
      "Cloud_probs shape: (73, 96, 96)\n",
      "Shadows_shape: (73, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 61\n",
      "(73, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "48.50986690273462 8.653384732640955\n",
      "Original 20 meter bands size: (73, 24, 24, 6), using 0.32080078125 PU\n",
      "The original L2A image size is: (73, 48, 48, 4)\n",
      "There are 40/73 dirty steps: 40 cloud, 3 missing, 0 shadow\n",
      "Removing 3 steps based on ratio\n",
      "Interpolated 375 px\n",
      "Shape before super: (30, 32, 32, 11)\n",
      "30/30 [==============================] - 1s 29ms/step\n",
      "(30, 32, 32, 6)\n",
      "(30, 32, 32, 11)\n",
      "Shape after super: (30, 16, 16, 11)\n",
      "Shape after vegetation indexes: (30, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 75\n",
      "Saved array of (24, 16, 16, 15) shape to 136752958\n",
      "\n",
      "\n",
      "Downloading 13/67, 136752959\n",
      "35.89208956121772 9.109687872920714\n",
      "35.89208956121772 9.109687872920714\n",
      "Cloud_probs shape: (67, 96, 96)\n",
      "Shadows_shape: (67, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 14\n",
      "(67, 96, 96)\n",
      "The shadow probability is: 1.0027985074626866\n",
      "35.89208956121772 9.109687872920714\n",
      "Original 20 meter bands size: (67, 24, 24, 6), using 0.29443359375 PU\n",
      "The original L2A image size is: (67, 48, 48, 4)\n",
      "There are 26/67 dirty steps: 25 cloud, 4 missing, 0 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 0 px\n",
      "Shape before super: (41, 32, 32, 11)\n",
      "41/41 [==============================] - 1s 28ms/step\n",
      "(41, 32, 32, 6)\n",
      "(41, 32, 32, 11)\n",
      "Shape after super: (41, 16, 16, 11)\n",
      "Shape after vegetation indexes: (41, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 65\n",
      "Saved array of (24, 16, 16, 15) shape to 136752959\n",
      "\n",
      "\n",
      "Downloading 14/67, 136752962\n",
      "18.772514313587717 16.613235942365478\n",
      "18.772514313587717 16.613235942365478\n",
      "Cloud_probs shape: (73, 96, 96)\n",
      "Shadows_shape: (73, 96, 96, 3)\n",
      "0.9570000762951095\n",
      "The shadow reference index is: 0\n",
      "(73, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "18.772514313587717 16.613235942365478\n",
      "Original 20 meter bands size: (73, 24, 24, 6), using 0.32080078125 PU\n",
      "The original L2A image size is: (73, 48, 48, 4)\n",
      "There are 14/73 dirty steps: 14 cloud, 1 missing, 0 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 557 px\n",
      "Shape before super: (59, 32, 32, 11)\n",
      "59/59 [==============================] - 2s 31ms/step\n",
      "(59, 32, 32, 6)\n",
      "(59, 32, 32, 11)\n",
      "Shape after super: (59, 16, 16, 11)\n",
      "Shape after vegetation indexes: (59, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 20\n",
      "Saved array of (24, 16, 16, 15) shape to 136752962\n",
      "\n",
      "\n",
      "Downloading 15/67, 136752965\n",
      "-12.453973404481475 20.273530698638424\n",
      "-12.453973404481475 20.273530698638424\n",
      "Cloud_probs shape: (73, 96, 96)\n",
      "Shadows_shape: (73, 96, 96, 3)\n",
      "0.7579003585870145\n",
      "The shadow reference index is: 61\n",
      "(73, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "-12.453973404481475 20.273530698638424\n",
      "Original 20 meter bands size: (73, 24, 24, 6), using 0.32080078125 PU\n",
      "The original L2A image size is: (73, 48, 48, 4)\n",
      "There are 4/73 dirty steps: 4 cloud, 0 missing, 0 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 119 px\n",
      "Shape before super: (69, 32, 32, 11)\n",
      "69/69 [==============================] - 2s 31ms/step\n",
      "(69, 32, 32, 6)\n",
      "(69, 32, 32, 11)\n",
      "Shape after super: (69, 16, 16, 11)\n",
      "Shape after vegetation indexes: (69, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 0\n",
      "Saved array of (24, 16, 16, 15) shape to 136752965\n",
      "\n",
      "\n",
      "Downloading 16/67, 136752966\n",
      "20.106819477632122 -0.03879270968173798\n",
      "20.106819477632122 -0.03879270968173798\n",
      "Cloud_probs shape: (59, 96, 96)\n",
      "Shadows_shape: (59, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 22\n",
      "(59, 96, 96)\n",
      "The shadow probability is: 1.0534369114877589\n",
      "20.106819477632122 -0.03879270968173798\n",
      "Original 20 meter bands size: (59, 24, 24, 6), using 0.25927734375 PU\n",
      "The original L2A image size is: (59, 48, 48, 4)\n",
      "There are 33/59 dirty steps: 32 cloud, 5 missing, 1 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 1034 px\n",
      "Shape before super: (26, 32, 32, 11)\n",
      "26/26 [==============================] - 1s 43ms/step\n",
      "(26, 32, 32, 6)\n",
      "(26, 32, 32, 11)\n",
      "Shape after super: (26, 16, 16, 11)\n",
      "Shape after vegetation indexes: (26, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 40\n",
      "Saved array of (24, 16, 16, 15) shape to 136752966\n",
      "\n",
      "\n",
      "Downloading 17/67, 136752967\n",
      "27.88085958021692 21.18379640272329\n",
      "27.88085958021692 21.18379640272329\n",
      "Cloud_probs shape: (70, 96, 96)\n",
      "Shadows_shape: (70, 96, 96, 3)\n",
      "0.8632944228274968\n",
      "The shadow reference index is: 12\n",
      "(70, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "27.88085958021692 21.18379640272329\n",
      "Original 20 meter bands size: (70, 24, 24, 6), using 0.3076171875 PU\n",
      "The original L2A image size is: (70, 48, 48, 4)\n",
      "There are 5/70 dirty steps: 5 cloud, 1 missing, 0 shadow\n",
      "Removing 1 steps based on ratio\n",
      "Interpolated 0 px\n",
      "Shape before super: (64, 32, 32, 11)\n",
      "64/64 [==============================] - 2s 28ms/step\n",
      "(64, 32, 32, 6)\n",
      "(64, 32, 32, 11)\n",
      "Shape after super: (64, 16, 16, 11)\n",
      "Shape after vegetation indexes: (64, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 0\n",
      "Saved array of (24, 16, 16, 15) shape to 136752967\n",
      "\n",
      "\n",
      "Downloading 18/67, 136752969\n",
      "33.823929644572026 4.4617226871143405\n",
      "33.823929644572026 4.4617226871143405\n",
      "Cloud_probs shape: (70, 96, 96)\n",
      "Shadows_shape: (70, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 42\n",
      "(70, 96, 96)\n",
      "The shadow probability is: 3.5441468253968256\n",
      "33.823929644572026 4.4617226871143405\n",
      "Original 20 meter bands size: (70, 24, 24, 6), using 0.3076171875 PU\n",
      "The original L2A image size is: (70, 48, 48, 4)\n",
      "There are 32/70 dirty steps: 30 cloud, 3 missing, 2 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 1684 px\n",
      "Shape before super: (38, 32, 32, 11)\n",
      "38/38 [==============================] - 1s 28ms/step\n",
      "(38, 32, 32, 6)\n",
      "(38, 32, 32, 11)\n",
      "Shape after super: (38, 16, 16, 11)\n",
      "Shape after vegetation indexes: (38, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 40\n",
      "Saved array of (24, 16, 16, 15) shape to 136752969\n",
      "\n",
      "\n",
      "Downloading 19/67, 136752970\n",
      "-7.765437410223938 33.05181595035315\n",
      "-7.765437410223938 33.05181595035315\n",
      "Cloud_probs shape: (72, 96, 96)\n",
      "Shadows_shape: (72, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 20\n",
      "(72, 96, 96)\n",
      "The shadow probability is: 1.4154128086419753\n",
      "-7.765437410223938 33.05181595035315\n",
      "Original 20 meter bands size: (72, 24, 24, 6), using 0.31640625 PU\n",
      "The original L2A image size is: (72, 48, 48, 4)\n",
      "There are 9/72 dirty steps: 8 cloud, 2 missing, 1 shadow\n",
      "Removing 1 steps based on ratio\n",
      "Interpolated 193 px\n",
      "Shape before super: (62, 32, 32, 11)\n",
      "62/62 [==============================] - 2s 30ms/step\n",
      "(62, 32, 32, 6)\n",
      "(62, 32, 32, 11)\n",
      "Shape after super: (62, 16, 16, 11)\n",
      "Shape after vegetation indexes: (62, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 0\n",
      "Saved array of (24, 16, 16, 15) shape to 136752970\n",
      "\n",
      "\n",
      "Downloading 20/67, 136752971\n",
      "21.088530356695227 -3.914041336759544\n",
      "21.088530356695227 -3.914041336759544\n",
      "Cloud_probs shape: (46, 96, 96)\n",
      "Shadows_shape: (46, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 12\n",
      "(46, 96, 96)\n",
      "The shadow probability is: 1.2454710144927537\n",
      "21.088530356695227 -3.914041336759544\n",
      "Original 20 meter bands size: (46, 24, 24, 6), using 0.2021484375 PU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original L2A image size is: (46, 48, 48, 4)\n",
      "There are 26/46 dirty steps: 26 cloud, 7 missing, 0 shadow\n",
      "Removing 0 steps based on ratio\n",
      "Interpolated 2100 px\n",
      "Shape before super: (20, 32, 32, 11)\n",
      "20/20 [==============================] - 1s 27ms/step\n",
      "(20, 32, 32, 6)\n",
      "(20, 32, 32, 11)\n",
      "Shape after super: (20, 16, 16, 11)\n",
      "Shape after vegetation indexes: (20, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 55\n",
      "Saved array of (24, 16, 16, 15) shape to 136752971\n",
      "\n",
      "\n",
      "Downloading 21/67, 136752972\n",
      "29.30082801425613 -16.727141774212296\n",
      "29.30082801425613 -16.727141774212296\n",
      "Cloud_probs shape: (67, 96, 96)\n",
      "Shadows_shape: (67, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 40\n",
      "(67, 96, 96)\n",
      "The shadow probability is: 1.062396351575456\n",
      "29.30082801425613 -16.727141774212296\n",
      "Original 20 meter bands size: (67, 24, 24, 6), using 0.29443359375 PU\n",
      "The original L2A image size is: (67, 48, 48, 4)\n",
      "There are 9/67 dirty steps: 8 cloud, 0 missing, 1 shadow\n",
      "Removing 1 steps based on ratio\n",
      "Interpolated 652 px\n",
      "Shape before super: (57, 32, 32, 11)\n",
      "57/57 [==============================] - 2s 28ms/step\n",
      "(57, 32, 32, 6)\n",
      "(57, 32, 32, 11)\n",
      "Shape after super: (57, 16, 16, 11)\n",
      "Shape after vegetation indexes: (57, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 40\n",
      "Saved array of (24, 16, 16, 15) shape to 136752972\n",
      "\n",
      "\n",
      "Downloading 22/67, 136752973\n",
      "12.82165784634332 26.860198195916645\n",
      "12.82165784634332 26.860198195916645\n",
      "Cloud_probs shape: (75, 96, 96)\n",
      "Shadows_shape: (75, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 7\n",
      "(75, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "12.82165784634332 26.860198195916645\n",
      "Original 20 meter bands size: (75, 24, 24, 6), using 0.32958984375 PU\n",
      "The original L2A image size is: (75, 48, 48, 4)\n",
      "There are 3/75 dirty steps: 3 cloud, 1 missing, 0 shadow\n",
      "Removing 2 steps based on ratio\n",
      "Interpolated 375 px\n",
      "Shape before super: (70, 32, 32, 11)\n",
      "70/70 [==============================] - 2s 28ms/step\n",
      "(70, 32, 32, 6)\n",
      "(70, 32, 32, 11)\n",
      "Shape after super: (70, 16, 16, 11)\n",
      "Shape after vegetation indexes: (70, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 0\n",
      "Saved array of (24, 16, 16, 15) shape to 136752973\n",
      "\n",
      "\n",
      "Downloading 23/67, 136752974\n",
      "13.073895523387923 -19.251057724592282\n",
      "13.073895523387923 -19.251057724592282\n",
      "Cloud_probs shape: (71, 96, 96)\n",
      "Shadows_shape: (71, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 53\n",
      "(71, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "13.073895523387923 -19.251057724592282\n",
      "Original 20 meter bands size: (71, 24, 24, 6), using 0.31201171875 PU\n",
      "The original L2A image size is: (71, 48, 48, 4)\n",
      "There are 7/71 dirty steps: 7 cloud, 2 missing, 0 shadow\n",
      "Removing 2 steps based on ratio\n",
      "Interpolated 380 px\n",
      "Shape before super: (62, 32, 32, 11)\n",
      "62/62 [==============================] - 2s 28ms/step\n",
      "(62, 32, 32, 6)\n",
      "(62, 32, 32, 11)\n",
      "Shape after super: (62, 16, 16, 11)\n",
      "Shape after vegetation indexes: (62, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 0\n",
      "Saved array of (24, 16, 16, 15) shape to 136752974\n",
      "\n",
      "\n",
      "Downloading 24/67, 136752975\n",
      "-1.8928650774316376 27.660678294534573\n",
      "-1.8928650774316376 27.660678294534573\n",
      "Cloud_probs shape: (77, 96, 96)\n",
      "Shadows_shape: (77, 96, 96, 3)\n",
      "0.8890058747234302\n",
      "The shadow reference index is: 20\n",
      "(77, 96, 96)\n",
      "The shadow probability is: 0.0\n",
      "-1.8928650774316376 27.660678294534573\n",
      "Original 20 meter bands size: (77, 24, 24, 6), using 0.33837890625 PU\n",
      "The original L2A image size is: (77, 48, 48, 4)\n",
      "There are 13/77 dirty steps: 13 cloud, 0 missing, 0 shadow\n",
      "Removing 3 steps based on ratio\n",
      "Interpolated 1695 px\n",
      "Shape before super: (61, 32, 32, 11)\n",
      "61/61 [==============================] - 2s 27ms/step\n",
      "(61, 32, 32, 6)\n",
      "(61, 32, 32, 11)\n",
      "Shape after super: (61, 16, 16, 11)\n",
      "Shape after vegetation indexes: (61, 16, 16, 15)\n",
      "There are 0 missing pixels\n",
      "Maximum time distance: 30\n",
      "Saved array of (24, 16, 16, 15) shape to 136752975\n",
      "\n",
      "\n",
      "Downloading 25/67, 136752976\n",
      "22.84186361835352 -7.914100617866899\n",
      "22.84186361835352 -7.914100617866899\n",
      "Cloud_probs shape: (57, 96, 96)\n",
      "Shadows_shape: (57, 96, 96, 3)\n",
      "1.0\n",
      "The shadow reference index is: 24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-f74c29462fc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#if \".csv\" in i:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#if any(x in i for x in [\"africa-west\", \"cameroon\", \"koure\", \"niger\"]):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/test-csv/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../data/test-s2/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMimeType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTIFF_d16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-338ee0f0d5b4>\u001b[0m in \u001b[0;36mdownload_plots\u001b[0;34m(data_location, output_folder, image_format)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Identify cloud steps, download DEM, and download L2A series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentify_clouds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_bbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mshadow_sums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshadows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mshadow_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshadow_sums\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-7713f22aab1a>\u001b[0m in \u001b[0;36midentify_clouds\u001b[0;34m(bbox, epsg, time)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshadow_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mshadows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcm_shadow_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshadow_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloud_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mshadows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshadows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcloud_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-7713f22aab1a>\u001b[0m in \u001b[0;36mmcm_shadow_mask\u001b[0;34m(arr, c_probs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;31m#deltab4 = ti_slice[3] - ri_slice[3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mdeltab8a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mti_slice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mri_slice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mdeltab11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mti_slice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mri_slice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdeltab2\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#(1000/65535):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in os.listdir(\"../data/test-csv/\"):\n",
    "    if \".csv\" in i:\n",
    "    #if \".csv\" in i:\n",
    "        #if any(x in i for x in [\"africa-west\", \"cameroon\", \"koure\", \"niger\"]):\n",
    "        tile = download_plots(\"../data/test-csv/\" + i, \"../data/test-s2/\", image_format = MimeType.TIFF_d16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
