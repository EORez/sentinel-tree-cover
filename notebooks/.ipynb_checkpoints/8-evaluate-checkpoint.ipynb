{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "from osgeo import ogr, osr\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from scipy.ndimage import median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/dec-9-model/model\n"
     ]
    }
   ],
   "source": [
    "new_saver = tf.train.import_meta_graph('../models/dec-9-model/model.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint('../models/dec-9-model/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has been scaled to [-1.0000001192092896, 1.0]\n"
     ]
    }
   ],
   "source": [
    "data_x = np.load(\"../data/processed/data_x_l2a_processed.npy\")\n",
    "data_y = np.load(\"../data/processed/data_y_l2a_processed.npy\")\n",
    "lengths = np.load(\"../data/processed/length_l2a_processed.npy\")\n",
    "\n",
    "min_all = []\n",
    "max_all = []\n",
    "for band in range(0, data_x.shape[-1]):\n",
    "\n",
    "    mins, maxs = (np.min(data_x[:, :, :, :, band]), np.max(data_x[:, :, :, :, band]))\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (data_x[:, :, :, :, band] - midrange) / (rng / 2)\n",
    "    data_x[:, :, :, :, band] = standardized\n",
    "    \n",
    "    min_all.append(mins)\n",
    "    max_all.append(maxs)\n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(data_x), np.max(data_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.00868639,\n",
       " -0.00719124,\n",
       " -0.006613449,\n",
       " 0.00050473574,\n",
       " -0.0004941218,\n",
       " -0.00020531435,\n",
       " 0.00055620476,\n",
       " -0.00021091112,\n",
       " -7.808548e-05,\n",
       " -6.7808665e-05,\n",
       " 0.0,\n",
       " -0.97086316,\n",
       " -0.8299099,\n",
       " -0.32858843,\n",
       " 0.51505876]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outliers are: [], totalling 0\n",
      "\n",
      "\n",
      "[] []\n",
      "4 Offender max/min: 14 12\n",
      "76 Offender max/min: 14 12\n",
      "83 Offender max/min: 14 12\n",
      "161 Offender max/min: 14 12\n",
      "296 Offender max/min: 11 12\n",
      "620 Offender max/min: 11 12\n",
      "0.0031038225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc206682ff5e45bbb580f0e2d2c7b8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=739), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The data has been scaled to [-1.0000001192092896, 1.0]\n",
      "(739, 24, 16, 16, 15)\n"
     ]
    }
   ],
   "source": [
    "test_x = np.load(\"../data/processed/data_x_l2a_processed.npy\")\n",
    "test_y = np.load(\"../data/processed/data_y_l2a_processed.npy\")\n",
    "test_lengths = np.load(\"../data/processed/length_l2a_processed.npy\")\n",
    "\n",
    "#test_x = np.delete(test_x, 11, -1)\n",
    "#test_x = np.delete(test_x, 13, -1)\n",
    "\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x) if np.min(val) < -1.5]\n",
    "above_1 = [i for i, val in enumerate(test_x) if np.max(val) > 1.5]\n",
    "min_vals = [np.min(val) for i, val in enumerate(test_x) if np.min(val) < -1.5]\n",
    "max_vals = [np.max(val) for i, val in enumerate(test_x) if np.max(val) > 1.5]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "print(\"The outliers are: {}, totalling {}\".format(outliers, len(outliers)))\n",
    "print(\"\\n\")\n",
    "print(min_vals, max_vals)\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    mins = np.min(test_x[i, :, :, :, :])\n",
    "    maxs = np.max(test_x[i, :, :, :, :])\n",
    "    if mins < -1 or maxs > 1:\n",
    "        offender_max = np.argmax(np.max(test_x[i, :, :, :, :], (0, 1, 2)), -1)\n",
    "        offender_min = np.argmin(np.min(test_x[i, :, :, :, :], (0, 1, 2)), -1)\n",
    "        \n",
    "        print(\"{} Offender max/min: {} {}\".format(i, offender_max, offender_min))\n",
    "test_x = test_x[[x for x in range(0, len(test_x)) if x not in outliers]]\n",
    "test_y = test_y[[x for x in range(0, len(test_y)) if x not in outliers]]\n",
    "test_lengths = test_lengths[[x for x in range(0, len(test_lengths)) if x not in outliers]]\n",
    "print(np.min(test_x[19]))\n",
    "\n",
    "for sample in tnrange(0, len(test_x)):\n",
    "    filtered = median_filter(test_x[sample, 0, :, :, 10], size = 5)\n",
    "    test_x[sample, :, :, :, 10] = np.stack([filtered] * 24)\n",
    "\n",
    "#test_x = np.delete(test_x, 10, -1)\n",
    "    \n",
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[:, :, :, :, band] = np.clip(test_x[:, :, :, :, band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[:, :, :, :, band] - midrange) / (rng / 2)\n",
    "    test_x[:, :, :, :, band] = standardized\n",
    "    \n",
    "print(\"The data has been scaled to [{}, {}]\".format(np.min(test_x), np.max(test_x)))\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    try:\n",
    "        fm = tf.get_default_graph().get_tensor_by_name(\"conv2d_{}/Sigmoid:0\".format(i))\n",
    "    except Exception:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logits = tf.get_default_graph().get_tensor_by_name(\"conv2d_11/Sigmoid:0\")\n",
    "inp = tf.get_default_graph().get_tensor_by_name(\"Placeholder:0\")\n",
    "length = tf.get_default_graph().get_tensor_by_name(\"Placeholder_1:0\")\n",
    "labels = tf.get_default_graph().get_tensor_by_name(\"Placeholder_2:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../src/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metrics():\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0\n",
    "    p = 0\n",
    "    r = 0\n",
    "    error = 0\n",
    "    ys = []\n",
    "    vls = []\n",
    "    t_alls = []\n",
    "    test_ids = [x for x in range(len(test_x))]\n",
    "    test_ids = [x for x in test_ids if x not in [158, 105]]\n",
    "    for test_sample in test_ids:\n",
    "        y = sess.run([fm], feed_dict={inp: test_x[test_sample].reshape(1, 24, 16, 16, 15),\n",
    "                                          length: test_lengths[test_sample].reshape(1, 1),\n",
    "                                          labels: test_y[test_sample, :, :].reshape(1, 14, 14),\n",
    "                                          })\n",
    "        ys.append(y[0].reshape((14, 14)))\n",
    "        t = test_y[test_sample].reshape((14, 14))\n",
    "        t_alls.append(t)\n",
    "    #to_remove = np.argwhere(vls > np.percentile(vls, 95))\n",
    "    #print(len(to_remove))\n",
    "    #ys = list(np.delete(np.array(ys), to_remove, 0))\n",
    "    #t_alls = list(np.delete(np.array(t_alls), to_remove, 0))\n",
    "    for thresh in range(6, 13):\n",
    "        tps = []\n",
    "        fps = []\n",
    "        fns = []\n",
    "        perc_error = []\n",
    "        trues = []\n",
    "        preds = []\n",
    "        #val_loss = []\n",
    "        for sample in range(len(ys)):\n",
    "            pred = np.copy(ys[sample])\n",
    "            true = t_alls[sample]\n",
    "            #vl = vls[sample]\n",
    "            pred[np.where(pred > thresh*0.05)] = 1\n",
    "            pred[np.where(pred < thresh*0.05)] = 0\n",
    "            true_s = np.sum(true)\n",
    "            pred_s = np.sum(pred)\n",
    "\n",
    "            perc_error.append(abs(pred_s - true_s) / 196)\n",
    "            tp, fp, fn = thirty_meter(true, pred)\n",
    "            tps.append(tp)\n",
    "            fps.append(fp)\n",
    "            fns.append(fn)\n",
    "            trues.append(true_s)\n",
    "            preds.append(pred_s)\n",
    "            #val_loss.append(np.mean(vl))\n",
    "        oa_error = abs(np.sum(preds) - np.sum(trues)) / np.sum(trues)\n",
    "        precision = np.sum(tps) / (np.sum(tps) + np.sum(fps))\n",
    "        recall = np.sum(tps) / (np.sum(tps) + np.sum(fns))\n",
    "        f1 = 2*((precision* recall) / (precision + recall))\n",
    "        print(thresh*0.05, oa_error, f1, recall)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            p = precision\n",
    "            r = recall\n",
    "            error = oa_error\n",
    "            best_thresh = thresh*0.05\n",
    "            to_return = fns\n",
    "    print(\"Val loss: {} Thresh: {} F1: {} Recall: {} Precision: {} Error: {}\".format(3, np.around(best_thresh, 2),\n",
    "                                                                                     np.around(best_f1, 3), np.around(r, 3), np.around(p, 3), \n",
    "                                                                                     np.around(error, 3)))\n",
    "    return best_f1, to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicubic\n",
      "0.30000000000000004 0.4021325209444021 0.7420207144366943 0.8912160446813913\n",
      "0.35000000000000003 0.2923330794617923 0.7565202945899552 0.8670982482863671\n",
      "0.4 0.20525514089870525 0.7645196569389282 0.842980451891343\n",
      "0.45 0.12795125666412796 0.7667621092817943 0.8158161970043158\n",
      "0.5 0.06105610561056106 0.7704625238652459 0.7939832444782939\n",
      "0.55 0.0030464584920030465 0.7700228832951945 0.7688499619192688\n",
      "0.6000000000000001 0.06575272911906575 0.7658485365533535 0.7406702208682406\n",
      "Val loss: 3 Thresh: 0.5 F1: 0.77 Recall: 0.794 Precision: 0.748 Error: 0.061\n"
     ]
    }
   ],
   "source": [
    "print(\"bicubic\")\n",
    "best_f1, fns = calculate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated size\n",
      "0.30000000000000004 0.4515801497651986 0.7270656450610893 0.8912298515039979\n",
      "0.35000000000000003 0.3417946439903541 0.74055606742182 0.8671151161314887\n",
      "0.4 0.25434699835004443 0.7478887512667494 0.8430003807589795\n",
      "0.45 0.1762914075390278 0.7497521432320522 0.8158395735499429\n",
      "0.5 0.1085163091762914 0.753145127309938 0.7940093920548293\n",
      "0.55 0.043533443330371874 0.752499844730141 0.7688792994034775\n",
      "0.6000000000000001 0.021068663535981722 0.7485890200102617 0.7407031349155985\n",
      "Val loss: 3 Thresh: 0.5 F1: 0.753 Recall: 0.794 Precision: 0.716 Error: 0.109\n"
     ]
    }
   ],
   "source": [
    "print(\"validated size\")\n",
    "best_f1, fns = calculate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Plot multiple heatmaps with subplots'''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(20, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show\n",
    "start = 736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9959404600811907\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-407-00a57255f63a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmatrix_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m               \u001b[0;31m#test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#matrix_ids = random.sample(test_ids, 4)z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "print(start/len(test_ids))\n",
    "test_ids = sorted(test_ids)\n",
    "matrix_ids = [test_ids[start], test_ids[start + 1], test_ids[start + 2], test_ids[start + 3]]\n",
    "              #test_ids[start + 4], test_ids[start + 5], test_ids[start + 6], test_ids[start + 7]]\n",
    "#matrix_ids = random.sample(test_ids, 4)z\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    print(i)\n",
    "    y = sess.run([fm], feed_dict={inp: test_x[idx].reshape(1, 24, 16, 16, 15),\n",
    "                                  length: test_lengths[idx].reshape(1, 1),\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    y[np.where(y > 0.5)] = 1.0\n",
    "    preds.append(y)\n",
    "    true = test_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "    \"\"\n",
    "\"\"\n",
    "to_plot = trues[0:4] + preds[0:4]# + trues[5:] + preds[5:]\n",
    "multiplot(to_plot, nrows = 2, ncols = 4)\n",
    "#plot_ids[/ordering[976]//4] \n",
    "start = start + 4 # 50, 87, 107 is a concern\n",
    "\n",
    "# 513  - 135345883 image issues? CONFIRMED\n",
    "# remove 608 - 135346016 (ambiguous labelling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
