{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.brandt/anaconda3/envs/remote_sensing/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from osgeo import ogr, osr\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox, constants\n",
    "from s2cloudless import S2PixelCloudDetector, CloudMaskRequest\n",
    "import logging\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "\n",
    "DATA_LOCATION = '../data/test1.csv'\n",
    "OUTPUT_FOLDER = '../data/test/'\n",
    "EPSG = CRS.WGS84\n",
    "IMAGE_SIZE = 16\n",
    "FRESH_START = True\n",
    "OFFSET = 0\n",
    "\n",
    "\n",
    "with open(\"../config.yaml\", 'r') as stream:\n",
    "        key = (yaml.safe_load(stream))\n",
    "        API_KEY = key['key']\n",
    "        \n",
    "existing = [int(x[:-4]) for x in os.listdir(OUTPUT_FOLDER) if \".DS\" not in x]\n",
    "len(existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/slope.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup function to reproject coordinates\n",
    "def convertCoords(xy, src='', targ=''):\n",
    "\n",
    "    srcproj = osr.SpatialReference()\n",
    "    srcproj.ImportFromEPSG(src)\n",
    "    targproj = osr.SpatialReference()\n",
    "    if isinstance(targ, str):\n",
    "        targproj.ImportFromProj4(targ)\n",
    "    else:\n",
    "        targproj.ImportFromEPSG(targ)\n",
    "    transform = osr.CoordinateTransformation(srcproj, targproj)\n",
    "\n",
    "    pt = ogr.Geometry(ogr.wkbPoint)\n",
    "    pt.AddPoint(xy[0], xy[1])\n",
    "    pt.Transform(transform)\n",
    "    return([pt.GetX(), pt.GetY()])\n",
    "\n",
    "def bounding_box(points, expansion = 160):\n",
    "    # LONG, LAT FOR SOME REASON\n",
    "    bl = list(points[0])\n",
    "    tr = list(points[1])\n",
    "    \n",
    "    if 48 <= bl[0] <= 54:\n",
    "        epsg = 32639 if bl[1] > 0 else 32739\n",
    "    if 42 <= bl[0] <= 48:\n",
    "        epsg = 32638 if bl[1] > 0 else 32738\n",
    "    if 36 <= bl[0] <= 42:\n",
    "        epsg = 32637 if bl[1] > 0 else 32737\n",
    "    if 30 <= bl[0] <= 36:\n",
    "        epsg = 32636 if bl[1] > 0 else 32736\n",
    "    if 24 <= bl[0] <= 30:\n",
    "        epsg = 32635 if bl[1] > 0 else 32735\n",
    "    if 18 <= bl[0] <= 24:\n",
    "        epsg = 32634 if bl[1] > 0 else 32734\n",
    "\n",
    "    bl = convertCoords(bl, 4326, epsg)\n",
    "    tr = convertCoords(tr, 4326, epsg)\n",
    "    init = [b - a for a,b in zip(bl, tr)]\n",
    "    distance1 = tr[0] - bl[0]\n",
    "    distance2 = tr[1] - bl[1]\n",
    "    print(distance1, distance2)\n",
    "    EXPANSION = (expansion - np.mean([distance1, distance2]))/2 # should this be 155 or 160?\n",
    "    \n",
    "    bl = [a - EXPANSION for a in bl]\n",
    "    tr = [a + EXPANSION for a in tr]\n",
    "    \n",
    "    after = [b - a for a,b in zip(bl, tr)]\n",
    "    print(after)\n",
    "    \n",
    "    if max(init) > 130:\n",
    "        print(\"ERROR: Initial field greater than 130m\")\n",
    "    if min(init) < 120:\n",
    "        print(\"ERROR: Initial field less than 130m\")\n",
    "        \n",
    "    if min(after) < (expansion - 4.5):\n",
    "        print(\"ERROR\")\n",
    "    if max(after) > (expansion + 5):\n",
    "        print(\"ERROR\")\n",
    "    diffs = [b - a for b, a in zip(after, init)]\n",
    "    #if min(diffs) and max(diffs) != EXPANSION*2:\n",
    "    #    print(\"ERROR: Field change more or less than 10m\")\n",
    "    bl = convertCoords(bl, epsg, 4326)\n",
    "    tr = convertCoords(tr, epsg, 4326)\n",
    "    return bl, tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "location = calc_bbox(val)\n",
    "location = bounding_box(location)\n",
    "box = BBox(location, crs = EPSG)\n",
    "\n",
    "image_request = WcsRequest(\n",
    "                layer='ALL_BANDS_NDVI',\n",
    "                bbox=box,\n",
    "                time = ('2018-01-01', '2018-12-31'),\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=1,\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "img_bands = image_request.get_data()\n",
    "img_bands[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bbox(plot_id):\n",
    "    subs = df[df['PLOT_ID'] == plot_id]\n",
    "    # TOP, LEFT, BOTTOM, RIGHT\n",
    "    # (min x, min y), (max x, max y)\n",
    "    return [(min(subs['LON']), min(subs['LAT'])),\n",
    "            (max(subs['LON']), max(subs['LAT']))]\n",
    "\n",
    "\n",
    "df = pd.read_csv(DATA_LOCATION)\n",
    "df = df.drop('IMAGERY_TITLE', axis = 1)\n",
    "df = df.dropna(axis = 0)\n",
    "plot_ids = sorted(df['PLOT_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.59663699171506 129.04405692382716\n",
      "[159.77629003394395, 160.22370996605605]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([35.5559782847398, 6.495840355743953],\n",
       " [35.55742923785911, 6.4972810163447425])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounding_box(calc_bbox(plot_ids[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'first': [0, 1, 2], 'last': [3, 4, 5]}, 2: {'first': [6, 7], 'last': [8]}, 3: {'first': [9], 'last': [11]}, 4: {'first': [12], 'last': []}, 5: {'first': [14, 15], 'last': []}, 6: {'first': [], 'last': []}, 7: {'first': [], 'last': []}, 8: {'first': [17], 'last': [18]}, 9: {'first': [19], 'last': [20, 21]}, 10: {'first': [22], 'last': []}, 11: {'first': [25, 26], 'last': [27]}, 12: {'first': [28], 'last': [30, 31, 32]}}\n",
      "{1: {'first': [0, 1, 2], 'last': [3, 4, 5]}, 2: {'first': [6, 7], 'last': [8]}, 3: {'first': [9], 'last': [11]}, 4: {'first': [12], 'last': [12, 14, 15]}, 5: {'first': [14, 15], 'last': [14, 15]}, 6: {'first': [14, 15], 'last': [14, 15]}, 7: {'first': [17], 'last': [17]}, 8: {'first': [17], 'last': [18]}, 9: {'first': [19], 'last': [20, 21]}, 10: {'first': [22], 'last': [22, 25, 26]}, 11: {'first': [25, 26], 'last': [27]}, 12: {'first': [28], 'last': [30, 31, 32]}}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "cloud_detector = S2PixelCloudDetector(threshold=0.4, average_over=4, dilation_size=2)\n",
    "\n",
    "def identify_clouds(bbox, epsg = EPSG, time = ('2018-01-01', '2018-12-31')):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        cloud_request = WmsRequest(\n",
    "            layer='CLOUD_DETECTION',\n",
    "            bbox=box,\n",
    "            time=time,\n",
    "            width=16,\n",
    "            height=16,\n",
    "            image_format = MimeType.TIFF_d32f,\n",
    "            maxcc=0.33,\n",
    "            instance_id=API_KEY,\n",
    "            custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "            time_difference=datetime.timedelta(hours=24),\n",
    "        )\n",
    "        \n",
    "        cloud_img = cloud_request.get_data()\n",
    "        cloud_probs = cloud_detector.get_cloud_probability_maps(np.array(cloud_img))\n",
    "        means = np.mean(cloud_probs, (1, 2))\n",
    "        cloud_steps = [i for i, val in enumerate(means) if val > 0.25]\n",
    "        return cloud_steps, means, cloud_probs\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)\n",
    "    \n",
    "    \n",
    "def download_dem(val, epsg = EPSG):\n",
    "    location = calc_bbox(val)\n",
    "    bbox = bounding_box(location, expansion = 180)\n",
    "    box = BBox(bbox, crs = epsg)\n",
    "    dem_request = WmsRequest(data_source=DataSource.DEM,\n",
    "                         layer='DEM',\n",
    "                         bbox=box,\n",
    "                         width=18,\n",
    "                         height=18,\n",
    "                         instance_id=API_KEY,\n",
    "                         image_format=MimeType.TIFF_d32f,\n",
    "                         custom_url_params={CustomUrlParam.SHOWLOGO: False})\n",
    "    dem_image = dem_request.get_data()[0]\n",
    "    dem_image = calcSlope(dem_image.reshape((1, 18, 18)),\n",
    "                  np.full((18, 18), 10), np.full((18, 18), 10), zScale = 1, minSlope = 0.02)\n",
    "    dem_image = dem_image.reshape((18, 18, 1))\n",
    "    dem_image = dem_image[1:17, 1:17, :]\n",
    "    print(dem_image.shape)\n",
    "    return dem_image #/ np.max(dem_image)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "def download_tiles(bbox, epsg = EPSG, time = ('2018-01-01', '2018-12-31')):\n",
    "    try:\n",
    "        box = BBox(bbox, crs = epsg)\n",
    "        image_request = WmsRequest(\n",
    "                layer='ALL_BANDS_NDVI',\n",
    "                bbox=box,\n",
    "                time=time,\n",
    "                width=16,\n",
    "                height=16,\n",
    "                image_format = MimeType.TIFF_d32f,\n",
    "                maxcc=0.33,\n",
    "                instance_id=API_KEY,\n",
    "                custom_url_params = {constants.CustomUrlParam.UPSAMPLING: 'BICUBIC'},\n",
    "                time_difference=datetime.timedelta(hours=24),\n",
    "            )\n",
    "        img_bands = image_request.get_data()\n",
    "        return img_bands, image_request\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.fatal(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'image_date': [32, 32], 'image_ratio': [0.5, 0.5], 'image_idx': [0, 0]}\n",
      "15 {'image_date': [32, 32], 'image_ratio': [0.5, 0.5], 'image_idx': [0, 0]}\n",
      "30 {'image_date': [32], 'image_ratio': [1], 'image_idx': [0]}\n",
      "45 {'image_date': [47], 'image_ratio': [1], 'image_idx': [3]}\n",
      "60 {'image_date': [61], 'image_ratio': [1], 'image_idx': [6]}\n",
      "75 {'image_date': [76], 'image_ratio': [1], 'image_idx': [8]}\n",
      "90 {'image_date': [76, 98], 'image_ratio': [0.36363636363636365, 0.6363636363636364], 'image_idx': [8, 9]}\n",
      "105 {'image_date': [108], 'image_ratio': [1], 'image_idx': [11]}\n",
      "120 {'image_date': [122], 'image_ratio': [1], 'image_idx': [12]}\n",
      "135 {'image_date': [122, 157], 'image_ratio': [0.6285714285714286, 0.37142857142857144], 'image_idx': [12, 14]}\n",
      "150 {'image_date': [157], 'image_ratio': [1], 'image_idx': [14]}\n",
      "165 {'image_date': [162], 'image_ratio': [1], 'image_idx': [15]}\n",
      "180 {'image_date': [162, 250], 'image_ratio': [0.7954545454545454, 0.20454545454545456], 'image_idx': [15, 17]}\n",
      "195 {'image_date': [162, 250], 'image_ratio': [0.625, 0.375], 'image_idx': [15, 17]}\n",
      "210 {'image_date': [162, 250], 'image_ratio': [0.4545454545454546, 0.5454545454545454], 'image_idx': [15, 17]}\n",
      "225 {'image_date': [162, 250], 'image_ratio': [0.28409090909090906, 0.7159090909090909], 'image_idx': [15, 17]}\n",
      "240 {'image_date': [162, 250], 'image_ratio': [0.11363636363636365, 0.8863636363636364], 'image_idx': [15, 17]}\n",
      "255 {'image_date': [255], 'image_ratio': [1], 'image_idx': [18]}\n",
      "270 {'image_date': [255, 279], 'image_ratio': [0.375, 0.625], 'image_idx': [18, 19]}\n",
      "285 {'image_date': [279], 'image_ratio': [1], 'image_idx': [19]}\n",
      "300 {'image_date': [299], 'image_ratio': [1], 'image_idx': [21]}\n",
      "315 {'image_date': [304, 333], 'image_ratio': [0.6206896551724138, 0.3793103448275862], 'image_idx': [22, 25]}\n",
      "330 {'image_date': [333], 'image_ratio': [1], 'image_idx': [25]}\n",
      "345 {'image_date': [343], 'image_ratio': [1], 'image_idx': [26]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_and_save_best_images(cloud_steps, img_bands, image_request, means):\n",
    "    # Identify the date of the imagery\n",
    "    image_dates = []\n",
    "    for date in image_request.get_dates():\n",
    "        image_dates.append(date.month*30 + date.day)\n",
    "\n",
    "    biweekly_dates = [day for day in range(0, 360, 15)] # ideal imagery dates are every 15 days\n",
    "    \n",
    "    # Identify the dates where there is < 20% cloud cover\n",
    "    satisfactory_ids = list(np.argwhere(np.array(means) < 0.2).reshape(-1, )) \n",
    "    satisfactory_dates = [value for idx, value in enumerate(image_dates) if idx in satisfactory_ids]\n",
    "    \n",
    "    \n",
    "    selected_images = {}\n",
    "    for i in biweekly_dates:\n",
    "        distances = [abs(date - i) for date in satisfactory_dates]\n",
    "        closest = np.min(distances)\n",
    "        closest_id = np.argmin(distances)\n",
    "        # If there is imagery within 8 days, select it\n",
    "        if closest < 8:\n",
    "            date = satisfactory_dates[closest_id]\n",
    "            image_idx = int(np.argwhere(np.array(image_dates) == date)[0])\n",
    "            selected_images[i] = {'image_date': [date], 'image_ratio': [1], 'image_idx': [image_idx]}\n",
    "        # If there is not imagery within 8 days, look for the closest above and below imagery\n",
    "        else:\n",
    "            distances = np.array([(date - i) for date in satisfactory_dates])\n",
    "            # Number of days above and below the selected date of the nearest clean imagery\n",
    "            above = distances[np.where(distances < 0, distances, -np.inf).argmax()]\n",
    "            below = distances[np.where(distances > 0, distances, np.inf).argmin()]\n",
    "            if above != below:\n",
    "                below_ratio = above / (above - below)\n",
    "                above_ratio = 1 - below_ratio\n",
    "            else:\n",
    "                above_ratio = below_ratio = 0.5\n",
    "                \n",
    "            # Extract the image date and imagery index for the above and below values\n",
    "            above_date = i + above\n",
    "            above_image_idx = int(np.argwhere(np.array(image_dates) == above_date)[0])\n",
    "            \n",
    "            below_date = i + below\n",
    "            below_image_idx = int(np.argwhere(np.array(image_dates) == below_date)[0])\n",
    "            \n",
    "            selected_images[i] = {'image_date': [above_date, below_date], 'image_ratio': [above_ratio, below_ratio],\n",
    "                                 'image_idx': [above_image_idx, below_image_idx]}\n",
    "                            \n",
    "    for i in selected_images.keys():\n",
    "        print(i, selected_images[i])\n",
    "        \n",
    "    keep_steps = []\n",
    "    for i in selected_images.keys():\n",
    "        info = selected_images[i]\n",
    "        if len(info['image_idx']) == 1:\n",
    "            step = img_bands[info['image_idx'][0]]\n",
    "        if len(info['image_idx']) == 2:\n",
    "            step1 = img_bands[info['image_idx'][0]] * info['image_ratio'][0]\n",
    "            step2 = img_bands[info['image_idx'][1]] * info['image_ratio'][1]\n",
    "            step = step1 + step2\n",
    "        keep_steps.append(step)\n",
    "        \n",
    "    keep_steps = np.stack(keep_steps)\n",
    "    return keep_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proximal_steps(arr, date):\n",
    "    satisfactory = np.argwhere(np.array(arr) < 0.2)\n",
    "    if date > 0:\n",
    "        idx_before = satisfactory - date\n",
    "        arg_before = idx_before[np.where(idx_before < 0, idx_before, -np.inf).argmax()]\n",
    "    if date < 23:\n",
    "        idx_after = satisfactory - date\n",
    "        arg_after = idx_after[np.where(idx_after > 0, idx_after, np.inf).argmin()]\n",
    "    if not arg_after:\n",
    "        arg_after = arg_before\n",
    "    if not arg_before:\n",
    "        arg_before = arg_after\n",
    "    print(arg_before, date, arg_after)\n",
    "    return arg_before, arg_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_best(tiles, cloud_probs, request, offset_x, offset_y):\n",
    "    c_probs = cloud_probs[:, offset_x:offset_x+16, offset_y:offset_y+16]\n",
    "    images = np.stack(tiles)[:, offset_x:offset_x+16, offset_y:offset_y+16]\n",
    "    means = np.mean(c_probs, (1, 2))\n",
    "    cloud_steps = [i for i, val in enumerate(means) if val > 0.20]\n",
    "    best = calculate_and_save_best_images(cloud_steps, images, request, means)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import DataSource\n",
    "from sentinelhub import CustomUrlParam\n",
    "\n",
    "to_download = [x for x in plot_ids if x not in existing]\n",
    "#to_download = [plot_ids[0]]\n",
    "errors = []\n",
    "print(\"STARTING DOWNLOAD OF {} plots from {} to {}\".format(len(to_download), DATA_LOCATION, OUTPUT_FOLDER))\n",
    "for i, val in enumerate(plot_ids):\n",
    "    if val not in existing:\n",
    "        print(\"Downloading {}\".format(val))\n",
    "        location = calc_bbox(val)\n",
    "        location = bounding_box(location, expansion = 160)\n",
    "        try:\n",
    "            # Initiate hash tables\n",
    "            cloud, means, probs = identify_clouds(location)\n",
    "            dem = download_dem(val)\n",
    "            img, image_request = download_tiles(location)\n",
    "            #tiles = calc_best(img, probs, image_request,  7, 7)\n",
    "            #dem = dem[10:26, 10:26]\n",
    "            #print(tiles.shape)\n",
    "            tiles = calculate_and_save_best_images(cloud, img, image_request, means) # 22, 16, 16, 10\n",
    "            dem = np.tile(dem.reshape((1, 16, 16, 1)), (tiles.shape[0], 1, 1, 1))\n",
    "            tiles = np.concatenate([tiles, dem], axis = -1)\n",
    "            print(tiles.shape)\n",
    "            np.save(OUTPUT_FOLDER + str(val), tiles)\n",
    "\n",
    "        except Exception as e:\n",
    "        #    print(e)\n",
    "            logging.fatal(e, exc_info=True)\n",
    "            errors.append(img)\n",
    "            #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing",
   "language": "python",
   "name": "remote_sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
